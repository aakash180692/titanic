{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/python35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/python/python35/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/opt/python/python35/lib/python3.5/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Always have this line in python files so that Python 3's print function is\n",
    "# found even in python 2.x\n",
    "# It makes it easier to run the same python file in python 2.x and python 3.x\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "from sklearn import *\n",
    "from multiprocessing import *\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/axp/rim/imml/dev/sshar654/MLS_run1/800_vars/new/data_800_week_3_dev.csv\n",
      "/axp/rim/imml/dev/sshar654/MLS_run1/800_vars/new/data_800_week_3_val.csv\n",
      "/axp/rim/imml/dev/sshar654/MLS_run1/800_vars/new/data_800_week_4_val.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/axp/rim/imml/dev/sshar654/MLS_run1/800_vars/new/'\n",
    "\n",
    "cd_file = folder_path+\"catboost_cd_file.csv\"\n",
    "train_file = folder_path + \"data_800_week_3_dev.csv\"\n",
    "val_file = folder_path + \"data_800_week_3_val.csv\"\n",
    "test_file = folder_path + \"data_800_week_4_val.csv\"\n",
    "\n",
    "print(train_file)\n",
    "print(val_file)\n",
    "print(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_file = folder_path+\"catboost_cd_file.csv\"\n",
    "\n",
    "col_df = pd.read_csv(cd_file,header=None)\n",
    "\n",
    "col_list = col_df[2].tolist()\n",
    "\n",
    "cat_list = col_df[col_df[1] == \"Categ\"][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 13, 34, 47]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_pickle_path = '/axp/hivequerylogs/agupt489/catboost/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(catboost_pickle_path + 'train_w3.pkl')\n",
    "val = pd.read_pickle(catboost_pickle_path + 'val_w3.pkl')\n",
    "test = pd.read_pickle(catboost_pickle_path + 'val_w4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4709546, 803)\n",
      "(2018378, 803)\n",
      "(615979, 803)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100features = ['ecp_training_clicked_total_last_30_day',\n",
    " 'goal_category',\n",
    " 'ecp_training_opened_total_last_30_day',\n",
    " 'customer_need_category',\n",
    " 'ecp_training_clicked_total_last_15_day',\n",
    " 'ecp_training_opened_total_last_15_day',\n",
    " 'gsn_training_click_last_30_day',\n",
    " 'ecp_training_clicked_other_last_30_day',\n",
    " 'cto_last_7_day',\n",
    " 'ecp_training_clicked_ba_last_30_day',\n",
    " 'apac_monthly_hist1_apac_account_tenure',\n",
    " 'email_type',\n",
    " 'business_unit',\n",
    " 'ecp_training_clicked_ba_last_15_day',\n",
    " 'msg_clicked_last_180_day',\n",
    " 'ecp_training_clicked_total_last_7_day',\n",
    " 'cto_last_1_day',\n",
    " 'apac_monthly_hist1_apac_acctmon_fico_score',\n",
    " 'doe_transaction8_sum_shopping_imp_60',\n",
    " 'myca_mobile_web_logon_activity6_ratio_sum_oth_60',\n",
    " 'cto_last_3_day',\n",
    " 'ecp_training_opened_total_last_7_day',\n",
    " 'auto_clk_strm_vars_final_ratio_mr_view_180',\n",
    " 'msg_opened_last_3_day',\n",
    " 'ecp_training_clicked_br_os_last_30_day',\n",
    " 'auto_clk_strm_vars_final_ratio_mer_view_180',\n",
    " 'gsn_training_sent_last_30_day',\n",
    " 'ram1_ram_points_earned',\n",
    " 'ecp_training_opened_br_os_last_30_day',\n",
    " 'msg_clicked_last_7_day',\n",
    " 'apac_monthly_hist1_apac_se_credit_amt',\n",
    " 'msg_clicked_last_15_day',\n",
    " 'kw_dynamic',\n",
    " 'doe_transaction8_doe_sum_imp_60',\n",
    " 'sow1_avg_moext_py_lst3m_am',\n",
    " 'ecp_training_opened_br_os_last_7_day',\n",
    " 'msg_optout_last_15_day',\n",
    " 'phone_call7_sum_ivr_call_dur_90',\n",
    " 'msg_opened_last_1_day',\n",
    " 'auto_clk_strm_vars_final_ratio_others_view_180',\n",
    " 'ecp_training_opened_ba_last_30_day',\n",
    " 'auto_oet_trnst_var_final_tot_offer_clk_180',\n",
    " 'ecp_training_opened_other_last_30_day',\n",
    " 'msg_optout_last_180_day',\n",
    " 'msg_opened_last_180_day',\n",
    " 'apac_monthly_hist1_apac_total_debit_prin_amt',\n",
    " 'apac_monthly_hist1_apac_total_debit_amt',\n",
    " 'auto_clk_strm_vars_final_ratio_loy_view_180',\n",
    " 'msg_sent_last_180_day',\n",
    " 'myca_mobile_web_logon_activity6_sum_oth_60',\n",
    " 'cto_last_15_day',\n",
    " 'apac_monthly_hist1_apac_total_bal_amt',\n",
    " 'cto_last_90_day',\n",
    " 'cust_opened_last_180_day',\n",
    " 'msg_opened',\n",
    " 'auto_clk_strm_vars_final_loy_view_180',\n",
    " 'ram1_ram_eff_disc_revn_am',\n",
    " 'apac_monthly_hist1_apac_total_remit_amt',\n",
    " 'doe_transaction8_doe_ctr_30',\n",
    " 'msg_sent_last_30_day',\n",
    " 'doe_transaction8_doe_sum_click_30',\n",
    " 'doe_transaction8_doe_ctr_60',\n",
    " 'ecp_training_clicked_br_os_last_7_day',\n",
    " 'auto_clk_strm_vars_final_mr_view_180',\n",
    " 'auto_clk_strm_vars_final_ratio_loy_time_180',\n",
    " 'ecp_training_opened_other_last_7_day',\n",
    " 'ecp_training_opened_cc_last_30_day',\n",
    " 'auto_oet_trnst_var_final_loyalty_ctr_180',\n",
    " 'auto_clk_strm_vars_final_mr_time_180',\n",
    " 'spend_training_health_debit_amt_last_180_day',\n",
    " 'cto_last_30_day',\n",
    " 'cto_last_180_day',\n",
    " 'auto_mr_redemp_vars_final_mr_tot_90',\n",
    " 'auto_oet_trnst_var_final_benefit_awareness_imp_180',\n",
    " 'apac_monthly_hist1_apac_total_disc_rev_amt',\n",
    " 'auto_oet_trnst_var_final_acquisition_others_imp_180',\n",
    " 'auto_oet_trnst_var_final_loyalty_imp_180',\n",
    " 'auto_clk_strm_vars_final_loy_time_180',\n",
    " 'ram1_ram_lend_res_am',\n",
    " 'auto_clk_strm_vars_final_ratio_acq_view_180',\n",
    " 'spend_training_retail_credit_cnt_last_180_day',\n",
    " 'ecp_training_sent_br_os_last_30_day',\n",
    " 'ctr_last_180_day',\n",
    " 'ecp_training_opened_br_os_last_15_day',\n",
    " 'auto_clk_strm_vars_final_estatement_view_180',\n",
    " 'spend_training_travel_debit_cnt_last_180_day',\n",
    " 'spend_training_health_debit_cnt_last_180_day',\n",
    " 'myca_mobile_web_logon_activity6_tot_logins_30',\n",
    " 'ram1_ram_discount_rev_post_secm',\n",
    " 'auto_clk_strm_vars_final_ratio_travel_view_180',\n",
    " 'spend_training_other_credit_cnt_last_180_day',\n",
    " 'doe_transaction8_doe_sum_click_60',\n",
    " 'auto_clk_strm_vars_final_acq_view_180',\n",
    " 'auto_clk_strm_vars_final_prepaid_view_180',\n",
    " 'ram1_ram_ram_expn_am',\n",
    " 'ram1_ram_lend_fund_cost_am',\n",
    " 'auto_clk_strm_vars_final_ratio_mer_view_90',\n",
    " 'msg_clicked_last_3_day',\n",
    " 'ecp_training_opened_br_ba_last_30_day',\n",
    " 'auto_oet_trnst_var_final_loyalty_imp_90']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goal_category', 'customer_need_category', 'email_type', 'business_unit']\n",
      "[1, 3, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['key_col','act_dt','response'], axis=1)\n",
    "y_train = train['response']\n",
    "X_val = val.drop(['key_col','act_dt','response'], axis=1)\n",
    "y_val = val['response']\n",
    "\n",
    "del train\n",
    "del val\n",
    "\n",
    "X_test = test.drop(['key_col','act_dt','response'], axis=1)\n",
    "y_test = test['response']\n",
    "\n",
    "del test\n",
    "\n",
    "X_train100 = X_train[top100features]\n",
    "X_test100 = X_test[top100features]\n",
    "X_val100 = X_val[top100features]\n",
    "\n",
    "d_t100 = X_train100.dtypes\n",
    "\n",
    "#d_t[d_t == object].axes\n",
    "list_cat100 = [x for x in d_t100[d_t100 == object].axes[0]]\n",
    "\n",
    "print(list_cat100)\n",
    "\n",
    "cat_indices100 = [X_train100.columns.tolist().index(col) for col in list_cat100]\n",
    "print(cat_indices100)\n",
    "\n",
    "del X_train\n",
    "del X_val\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 TREES\n"
     ]
    }
   ],
   "source": [
    "n_tree = 100\n",
    "print(str(n_tree) + \" TREES\")\n",
    "\n",
    "#catboost_run(cat_indices=cat_indices,n_tr=500,rsm=0.8,lrn_rt=0.05,dep=10,l2_reg=3,num_split=128,cat_split=16,bag_temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_run(X_train,y_train,X_val,y_val,X_test,y_test,cat_indices,n_tr,rsm,lrn_rt,dep,l2_reg,num_split,cat_split,bag_temp):\n",
    "    \n",
    "    print(\"model train start\")\n",
    "    \n",
    "    t1 = datetime.datetime.now()\n",
    "    print(t1)\n",
    "    \n",
    "    model = CatBoostClassifier(iterations=n_tr,\n",
    "                               rsm=rsm,\n",
    "                               learning_rate=lrn_rt, \n",
    "                               depth=dep,\n",
    "                               l2_leaf_reg=l2_reg,\n",
    "                               border_count=num_split,\n",
    "                               ctr_border_count=cat_split,\n",
    "                               bagging_temperature = bag_temp,\n",
    "                               random_seed=2)\n",
    "    \n",
    "    model.fit(X_train, y_train,cat_indices, use_best_model=True, eval_set=(X_val, y_val), verbose=True)\n",
    "    #model.fit(X_train, y_train,cat_indices)\n",
    "    print('read5')\n",
    "        \n",
    "    model_name = 'model_w3_'+str(n_tr)+'T_rsm_'+str(rsm)+'_learn_rate_'+str(lrn_rt)+'_depth_'+str(dep)+'_l2_reg_'+str(l2_reg)+'_num_split_'+str(num_split)+'_cat_split_'+str(cat_split)+'_bag_temp_'+str(bag_temp)\n",
    "    print(model_name)\n",
    "\n",
    "    model.save_model('/axp/hivequerylogs/agupt489/catboost/models/' + model_name)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(t2)\n",
    "    print(\"train time given below\")\n",
    "    print(t2-t1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y, pred):\n",
    "    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    g = 2 * metrics.auc(fpr, tpr) -1\n",
    "    return g\n",
    "\n",
    "def gini_catboost(pred, y):\n",
    "    return gini(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "rsm_pv = [0.5,0.6,0.7,0.75,0.8,0.85,0.9,1]\n",
    "print(len(rsm_pv))\n",
    "lrn_rt_pv = [0.01,0.02,0.03,0.05,0.075,0.1,0.125,0.15]\n",
    "print(len(lrn_rt_pv))\n",
    "dep_pv = [4,5,6,7,8,9,10]\n",
    "print(len(dep_pv))\n",
    "l2_reg_pv = [1,3,5,10,50,100]\n",
    "print(len(l2_reg_pv))\n",
    "num_split_pv = [5,10,16,32,64,128,255]\n",
    "print(len(num_split_pv))\n",
    "cat_split_pv = [5,10,16,32,64,128,255]\n",
    "print(len(cat_split_pv))\n",
    "bag_temp_pv = [0,0.1,0.5,1,2,5,10,100]\n",
    "print(len(bag_temp_pv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm_def = 1\n",
    "lrn_rt_def = 0.03\n",
    "dep_def = 6\n",
    "l2_reg_def = 3\n",
    "num_split_def = 128\n",
    "cat_split_def = 16\n",
    "bag_temp_def = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_col_list = ['n_tree',\n",
    "                   'rsm',\n",
    "                   'learning_rate',\n",
    "                   'depth',\n",
    "                   'l2_regularization',\n",
    "                   'numerical_split',\n",
    "                   'categorical_split',\n",
    "                   'bagging_temperature',\n",
    "                   'ISIT_GINI',\n",
    "                   'OSIT_GINI',\n",
    "                   'OSOT_GINI']\n",
    "\n",
    "results_df = pd.DataFrame(data=None,columns=result_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [n_tree, rsm, learning_rate, depth, l2_regularization, numerical_split, categorical_split, bagging_temperature, ISIT_GINI, OSIT_GINI, OSOT_GINI]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 regularizatio = 3\n",
      "2018-04-18 02:51:31.925156\n",
      "model train start\n",
      "2018-04-18 02:51:31.925951\n",
      "0: learn: 0.6581866\ttest: 0.6581573\tbestTest: 0.6581573 (0)\ttotal: 8.17s\tremaining: 13m 29s\n",
      "1: learn: 0.6256835\ttest: 0.6256275\tbestTest: 0.6256275 (1)\ttotal: 21.7s\tremaining: 17m 45s\n",
      "2: learn: 0.5950976\ttest: 0.5950213\tbestTest: 0.5950213 (2)\ttotal: 33.3s\tremaining: 17m 57s\n",
      "3: learn: 0.5671602\ttest: 0.5670661\tbestTest: 0.5670661 (3)\ttotal: 45.2s\tremaining: 18m 3s\n",
      "4: learn: 0.5415567\ttest: 0.5414338\tbestTest: 0.5414338 (4)\ttotal: 57.9s\tremaining: 18m 19s\n",
      "5: learn: 0.5173878\ttest: 0.5172488\tbestTest: 0.5172488 (5)\ttotal: 1m 8s\tremaining: 17m 59s\n",
      "6: learn: 0.4958949\ttest: 0.4957409\tbestTest: 0.4957409 (6)\ttotal: 1m 20s\tremaining: 17m 53s\n",
      "7: learn: 0.4754494\ttest: 0.4752687\tbestTest: 0.4752687 (7)\ttotal: 1m 31s\tremaining: 17m 27s\n",
      "8: learn: 0.4569905\ttest: 0.4567955\tbestTest: 0.4567955 (8)\ttotal: 1m 42s\tremaining: 17m 14s\n",
      "9: learn: 0.4403821\ttest: 0.4401601\tbestTest: 0.4401601 (9)\ttotal: 1m 53s\tremaining: 17m 2s\n",
      "10: learn: 0.4249301\ttest: 0.4246959\tbestTest: 0.4246959 (10)\ttotal: 2m 5s\tremaining: 16m 52s\n",
      "11: learn: 0.4112644\ttest: 0.4110146\tbestTest: 0.4110146 (11)\ttotal: 2m 11s\tremaining: 16m\n",
      "12: learn: 0.3976725\ttest: 0.3974036\tbestTest: 0.3974036 (12)\ttotal: 2m 22s\tremaining: 15m 56s\n",
      "13: learn: 0.384876\ttest: 0.3845835\tbestTest: 0.3845835 (13)\ttotal: 2m 32s\tremaining: 15m 39s\n",
      "14: learn: 0.3739876\ttest: 0.3736738\tbestTest: 0.3736738 (14)\ttotal: 2m 43s\tremaining: 15m 24s\n",
      "15: learn: 0.363417\ttest: 0.3630775\tbestTest: 0.3630775 (15)\ttotal: 2m 53s\tremaining: 15m 9s\n",
      "16: learn: 0.3535879\ttest: 0.3532286\tbestTest: 0.3532286 (16)\ttotal: 3m 2s\tremaining: 14m 52s\n",
      "17: learn: 0.3446133\ttest: 0.3442304\tbestTest: 0.3442304 (17)\ttotal: 3m 12s\tremaining: 14m 37s\n",
      "18: learn: 0.3367779\ttest: 0.336377\tbestTest: 0.336377 (18)\ttotal: 3m 23s\tremaining: 14m 29s\n",
      "19: learn: 0.3293672\ttest: 0.3289531\tbestTest: 0.3289531 (19)\ttotal: 3m 35s\tremaining: 14m 21s\n",
      "20: learn: 0.3220507\ttest: 0.3216187\tbestTest: 0.3216187 (20)\ttotal: 3m 45s\tremaining: 14m 8s\n",
      "21: learn: 0.3159512\ttest: 0.3155109\tbestTest: 0.3155109 (21)\ttotal: 3m 55s\tremaining: 13m 56s\n",
      "22: learn: 0.3103001\ttest: 0.3098481\tbestTest: 0.3098481 (22)\ttotal: 4m 6s\tremaining: 13m 44s\n",
      "23: learn: 0.3046916\ttest: 0.3042354\tbestTest: 0.3042354 (23)\ttotal: 4m 17s\tremaining: 13m 34s\n",
      "24: learn: 0.2993332\ttest: 0.2988653\tbestTest: 0.2988653 (24)\ttotal: 4m 28s\tremaining: 13m 24s\n",
      "25: learn: 0.2946375\ttest: 0.2941566\tbestTest: 0.2941566 (25)\ttotal: 4m 38s\tremaining: 13m 13s\n",
      "26: learn: 0.290001\ttest: 0.2895012\tbestTest: 0.2895012 (26)\ttotal: 4m 50s\tremaining: 13m 4s\n",
      "27: learn: 0.2856958\ttest: 0.2851807\tbestTest: 0.2851807 (27)\ttotal: 4m 59s\tremaining: 12m 51s\n",
      "28: learn: 0.2818412\ttest: 0.2813153\tbestTest: 0.2813153 (28)\ttotal: 5m 9s\tremaining: 12m 38s\n",
      "29: learn: 0.2784306\ttest: 0.2778959\tbestTest: 0.2778959 (29)\ttotal: 5m 20s\tremaining: 12m 28s\n",
      "30: learn: 0.2750889\ttest: 0.2745409\tbestTest: 0.2745409 (30)\ttotal: 5m 30s\tremaining: 12m 16s\n",
      "31: learn: 0.2719029\ttest: 0.2713436\tbestTest: 0.2713436 (31)\ttotal: 5m 41s\tremaining: 12m 5s\n",
      "32: learn: 0.2689887\ttest: 0.2684204\tbestTest: 0.2684204 (32)\ttotal: 5m 51s\tremaining: 11m 52s\n",
      "33: learn: 0.266438\ttest: 0.2658549\tbestTest: 0.2658549 (33)\ttotal: 6m\tremaining: 11m 39s\n",
      "34: learn: 0.2639633\ttest: 0.2633715\tbestTest: 0.2633715 (34)\ttotal: 6m 10s\tremaining: 11m 28s\n",
      "35: learn: 0.2616224\ttest: 0.2610196\tbestTest: 0.2610196 (35)\ttotal: 6m 22s\tremaining: 11m 19s\n",
      "36: learn: 0.2594971\ttest: 0.258884\tbestTest: 0.258884 (36)\ttotal: 6m 32s\tremaining: 11m 8s\n",
      "37: learn: 0.2574739\ttest: 0.2568514\tbestTest: 0.2568514 (37)\ttotal: 6m 42s\tremaining: 10m 56s\n",
      "38: learn: 0.2555676\ttest: 0.2549357\tbestTest: 0.2549357 (38)\ttotal: 6m 52s\tremaining: 10m 45s\n",
      "39: learn: 0.253698\ttest: 0.2530595\tbestTest: 0.2530595 (39)\ttotal: 7m 3s\tremaining: 10m 34s\n",
      "40: learn: 0.2520361\ttest: 0.2513944\tbestTest: 0.2513944 (40)\ttotal: 7m 13s\tremaining: 10m 24s\n",
      "41: learn: 0.2505819\ttest: 0.2499159\tbestTest: 0.2499159 (41)\ttotal: 7m 26s\tremaining: 10m 15s\n",
      "42: learn: 0.2491997\ttest: 0.2485236\tbestTest: 0.2485236 (42)\ttotal: 7m 36s\tremaining: 10m 4s\n",
      "43: learn: 0.2478933\ttest: 0.2472073\tbestTest: 0.2472073 (43)\ttotal: 7m 47s\tremaining: 9m 54s\n",
      "44: learn: 0.2465489\ttest: 0.2458534\tbestTest: 0.2458534 (44)\ttotal: 7m 56s\tremaining: 9m 42s\n",
      "45: learn: 0.2453125\ttest: 0.2446098\tbestTest: 0.2446098 (45)\ttotal: 8m 7s\tremaining: 9m 32s\n",
      "46: learn: 0.2441576\ttest: 0.2434469\tbestTest: 0.2434469 (46)\ttotal: 8m 17s\tremaining: 9m 21s\n",
      "47: learn: 0.2431815\ttest: 0.2424608\tbestTest: 0.2424608 (47)\ttotal: 8m 28s\tremaining: 9m 10s\n",
      "48: learn: 0.2422709\ttest: 0.2415422\tbestTest: 0.2415422 (48)\ttotal: 8m 39s\tremaining: 9m\n",
      "49: learn: 0.2413936\ttest: 0.2406577\tbestTest: 0.2406577 (49)\ttotal: 8m 49s\tremaining: 8m 49s\n",
      "50: learn: 0.2329166\ttest: 0.2321179\tbestTest: 0.2321179 (63)\ttotal: 11m 19s\tremaining: 6m 22s\n",
      "64: learn: 0.2325349\ttest: 0.2317318\tbestTest: 0.2317318 (64)\ttotal: 11m 31s\tremaining: 6m 12s\n",
      "65: learn: 0.232186\ttest: 0.2313794\tbestTest: 0.2313794 (65)\ttotal: 11m 42s\tremaining: 6m 1s\n",
      "66: learn: 0.2318369\ttest: 0.2310274\tbestTest: 0.2310274 (66)\ttotal: 11m 53s\tremaining: 5m 51s\n",
      "67: learn: 0.2314761\ttest: 0.2306621\tbestTest: 0.2306621 (67)\ttotal: 12m 5s\tremaining: 5m 41s\n",
      "68: learn: 0.2311896\ttest: 0.2303726\tbestTest: 0.2303726 (68)\ttotal: 12m 16s\tremaining: 5m 31s\n",
      "69: learn: 0.2308737\ttest: 0.2300541\tbestTest: 0.2300541 (69)\ttotal: 12m 29s\tremaining: 5m 21s\n",
      "70: learn: 0.2305987\ttest: 0.2297772\tbestTest: 0.2297772 (70)\ttotal: 12m 42s\tremaining: 5m 11s\n",
      "71: learn: 0.2303324\ttest: 0.2295079\tbestTest: 0.2295079 (71)\ttotal: 12m 53s\tremaining: 5m\n",
      "72: learn: 0.2300738\ttest: 0.229247\tbestTest: 0.229247 (72)\ttotal: 13m 4s\tremaining: 4m 50s\n",
      "73: learn: 0.2298527\ttest: 0.2290249\tbestTest: 0.2290249 (73)\ttotal: 13m 16s\tremaining: 4m 39s\n",
      "74: learn: 0.2296187\ttest: 0.228789\tbestTest: 0.228789 (74)\ttotal: 13m 27s\tremaining: 4m 29s\n",
      "75: learn: 0.2293945\ttest: 0.2285614\tbestTest: 0.2285614 (75)\ttotal: 13m 39s\tremaining: 4m 18s\n",
      "76: learn: 0.2292082\ttest: 0.2283736\tbestTest: 0.2283736 (76)\ttotal: 13m 51s\tremaining: 4m 8s\n",
      "77: learn: 0.2289995\ttest: 0.228163\tbestTest: 0.228163 (77)\ttotal: 14m 3s\tremaining: 3m 57s\n",
      "78: learn: 0.228806\ttest: 0.2279667\tbestTest: 0.2279667 (78)\ttotal: 14m 14s\tremaining: 3m 47s\n",
      "79: learn: 0.2286308\ttest: 0.2277886\tbestTest: 0.2277886 (79)\ttotal: 14m 26s\tremaining: 3m 36s\n",
      "80: learn: 0.2284505\ttest: 0.227606\tbestTest: 0.227606 (80)\ttotal: 14m 37s\tremaining: 3m 25s\n",
      "81: learn: 0.2282775\ttest: 0.2274296\tbestTest: 0.2274296 (81)\ttotal: 14m 49s\tremaining: 3m 15s\n",
      "82: learn: 0.2281264\ttest: 0.2272761\tbestTest: 0.2272761 (82)\ttotal: 15m\tremaining: 3m 4s\n",
      "83: learn: 0.2279852\ttest: 0.2271319\tbestTest: 0.2271319 (83)\ttotal: 15m 10s\tremaining: 2m 53s\n",
      "84: learn: 0.2278351\ttest: 0.2269788\tbestTest: 0.2269788 (84)\ttotal: 15m 22s\tremaining: 2m 42s\n",
      "85: learn: 0.2276969\ttest: 0.2268387\tbestTest: 0.2268387 (85)\ttotal: 15m 33s\tremaining: 2m 32s\n",
      "86: learn: 0.2275809\ttest: 0.2267215\tbestTest: 0.2267215 (86)\ttotal: 15m 46s\tremaining: 2m 21s\n",
      "87: learn: 0.2274593\ttest: 0.2265987\tbestTest: 0.2265987 (87)\ttotal: 15m 57s\tremaining: 2m 10s\n",
      "88: learn: 0.2273348\ttest: 0.2264713\tbestTest: 0.2264713 (88)\ttotal: 16m 8s\tremaining: 1m 59s\n",
      "89: learn: 0.2272198\ttest: 0.2263548\tbestTest: 0.2263548 (89)\ttotal: 16m 19s\tremaining: 1m 48s\n",
      "90: learn: 0.2271203\ttest: 0.2262534\tbestTest: 0.2262534 (90)\ttotal: 16m 32s\tremaining: 1m 38s\n",
      "91: learn: 0.227017\ttest: 0.2261477\tbestTest: 0.2261477 (91)\ttotal: 16m 42s\tremaining: 1m 27s\n",
      "92: learn: 0.2269044\ttest: 0.2260345\tbestTest: 0.2260345 (92)\ttotal: 16m 55s\tremaining: 1m 16s\n",
      "93: learn: 0.2268044\ttest: 0.2259342\tbestTest: 0.2259342 (93)\ttotal: 17m 5s\tremaining: 1m 5s\n",
      "94: learn: 0.2267207\ttest: 0.2258502\tbestTest: 0.2258502 (94)\ttotal: 17m 16s\tremaining: 54.6s\n",
      "95: learn: 0.226623\ttest: 0.2257518\tbestTest: 0.2257518 (95)\ttotal: 17m 27s\tremaining: 43.6s\n",
      "96: learn: 0.226545\ttest: 0.2256733\tbestTest: 0.2256733 (96)\ttotal: 17m 39s\tremaining: 32.8s\n",
      "97: learn: 0.2264834\ttest: 0.2256097\tbestTest: 0.2256097 (97)\ttotal: 17m 52s\tremaining: 21.9s\n",
      "98: learn: 0.2263934\ttest: 0.2255184\tbestTest: 0.2255184 (98)\ttotal: 18m 3s\tremaining: 10.9s\n",
      "99: learn: 0.2263169\ttest: 0.2254396\tbestTest: 0.2254396 (99)\ttotal: 18m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254396103\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_16_bag_temp_1\n",
      "2018-04-18 03:18:34.543652\n",
      "train time given below\n",
      "0:27:02.617701\n",
      "2018-04-18 03:18:34.546322\n",
      "2018-04-18 03:18:34.556832\n",
      "GINI ISIT = 0.455322130277\n",
      "2018-04-18 03:22:17.302425\n",
      "GINI OSIT = 0.456847407704\n",
      "2018-04-18 03:23:48.844406\n",
      "GINI OSOT = 0.411085756609\n",
      "2018-04-18 03:24:16.520679\n",
      "2018-04-18 03:24:16.525246\n"
     ]
    }
   ],
   "source": [
    "# optimize l2 regularization\n",
    "\n",
    "for l2_reg in l2_reg_pv[1:2]:\n",
    "    \n",
    "    print('L2 regularizatio = ' + str(l2_reg))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_def,\n",
    "                           lrn_rt = lrn_rt_def,\n",
    "                           dep = dep_def,\n",
    "                           l2_reg = l2_reg,\n",
    "                           num_split = num_split_def,\n",
    "                           cat_split = cat_split_def,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_def\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt_def\n",
    "    result_df_temp.loc[0,'depth'] = dep_def\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_def\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_def\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100   1          0.03     6                 1             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 5             128   \n",
       "0    100   1          0.03     6                10             128   \n",
       "0    100   1          0.03     6                50             128   \n",
       "0    100   1          0.03     6               100             128   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results_temp.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num split = 5\n",
      "2018-03-13 21:16:54.349955\n",
      "model train start\n",
      "2018-03-13 21:16:54.350368\n",
      "0: learn: 0.6575253\ttest: 0.6575087\tbestTest: 0.6575087 (0)\ttotal: 5.68s\tremaining: 9m 22s\n",
      "1: learn: 0.6244167\ttest: 0.6243741\tbestTest: 0.6243741 (1)\ttotal: 11.3s\tremaining: 9m 14s\n",
      "2: learn: 0.5943396\ttest: 0.59427\tbestTest: 0.59427 (2)\ttotal: 17.6s\tremaining: 9m 27s\n",
      "3: learn: 0.5662552\ttest: 0.5662212\tbestTest: 0.5662212 (3)\ttotal: 23.8s\tremaining: 9m 31s\n",
      "4: learn: 0.5409016\ttest: 0.5408353\tbestTest: 0.5408353 (4)\ttotal: 29.3s\tremaining: 9m 16s\n",
      "5: learn: 0.517924\ttest: 0.5178385\tbestTest: 0.5178385 (5)\ttotal: 33.7s\tremaining: 8m 47s\n",
      "6: learn: 0.4955424\ttest: 0.4954247\tbestTest: 0.4954247 (6)\ttotal: 39s\tremaining: 8m 38s\n",
      "7: learn: 0.4756636\ttest: 0.4755218\tbestTest: 0.4755218 (7)\ttotal: 45.3s\tremaining: 8m 41s\n",
      "8: learn: 0.457093\ttest: 0.4569372\tbestTest: 0.4569372 (8)\ttotal: 51.4s\tremaining: 8m 39s\n",
      "9: learn: 0.4405325\ttest: 0.440393\tbestTest: 0.440393 (9)\ttotal: 57.7s\tremaining: 8m 38s\n",
      "10: learn: 0.4246869\ttest: 0.4245296\tbestTest: 0.4245296 (10)\ttotal: 1m 3s\tremaining: 8m 37s\n",
      "11: learn: 0.4100065\ttest: 0.409832\tbestTest: 0.409832 (11)\ttotal: 1m 9s\tremaining: 8m 28s\n",
      "12: learn: 0.3972579\ttest: 0.3970578\tbestTest: 0.3970578 (12)\ttotal: 1m 15s\tremaining: 8m 25s\n",
      "13: learn: 0.3847759\ttest: 0.3845498\tbestTest: 0.3845498 (13)\ttotal: 1m 21s\tremaining: 8m 17s\n",
      "14: learn: 0.3733001\ttest: 0.3730528\tbestTest: 0.3730528 (14)\ttotal: 1m 26s\tremaining: 8m 9s\n",
      "15: learn: 0.3627038\ttest: 0.3624399\tbestTest: 0.3624399 (15)\ttotal: 1m 32s\tremaining: 8m 3s\n",
      "16: learn: 0.3530745\ttest: 0.3527919\tbestTest: 0.3527919 (16)\ttotal: 1m 37s\tremaining: 7m 55s\n",
      "17: learn: 0.3440798\ttest: 0.343775\tbestTest: 0.343775 (17)\ttotal: 1m 43s\tremaining: 7m 49s\n",
      "18: learn: 0.3359624\ttest: 0.3356223\tbestTest: 0.3356223 (18)\ttotal: 1m 49s\tremaining: 7m 44s\n",
      "19: learn: 0.328509\ttest: 0.3281559\tbestTest: 0.3281559 (19)\ttotal: 1m 54s\tremaining: 7m 37s\n",
      "20: learn: 0.3211734\ttest: 0.320796\tbestTest: 0.320796 (20)\ttotal: 1m 59s\tremaining: 7m 30s\n",
      "21: learn: 0.3145906\ttest: 0.3141845\tbestTest: 0.3141845 (21)\ttotal: 2m 5s\tremaining: 7m 24s\n",
      "22: learn: 0.3088636\ttest: 0.3084406\tbestTest: 0.3084406 (22)\ttotal: 2m 10s\tremaining: 7m 18s\n",
      "23: learn: 0.3033615\ttest: 0.3029269\tbestTest: 0.3029269 (23)\ttotal: 2m 16s\tremaining: 7m 12s\n",
      "24: learn: 0.2981082\ttest: 0.2976587\tbestTest: 0.2976587 (24)\ttotal: 2m 22s\tremaining: 7m 7s\n",
      "25: learn: 0.2933407\ttest: 0.2928739\tbestTest: 0.2928739 (25)\ttotal: 2m 27s\tremaining: 7m\n",
      "26: learn: 0.2890363\ttest: 0.2885559\tbestTest: 0.2885559 (26)\ttotal: 2m 33s\tremaining: 6m 55s\n",
      "27: learn: 0.2851225\ttest: 0.2846258\tbestTest: 0.2846258 (27)\ttotal: 2m 38s\tremaining: 6m 48s\n",
      "28: learn: 0.2811133\ttest: 0.2805996\tbestTest: 0.2805996 (28)\ttotal: 2m 44s\tremaining: 6m 42s\n",
      "29: learn: 0.2776057\ttest: 0.2770824\tbestTest: 0.2770824 (29)\ttotal: 2m 50s\tremaining: 6m 37s\n",
      "30: learn: 0.2745479\ttest: 0.2740139\tbestTest: 0.2740139 (30)\ttotal: 2m 56s\tremaining: 6m 32s\n",
      "31: learn: 0.2716057\ttest: 0.2710594\tbestTest: 0.2710594 (31)\ttotal: 3m 2s\tremaining: 6m 26s\n",
      "32: learn: 0.2686395\ttest: 0.2680807\tbestTest: 0.2680807 (32)\ttotal: 3m 7s\tremaining: 6m 20s\n",
      "33: learn: 0.2660547\ttest: 0.2654875\tbestTest: 0.2654875 (33)\ttotal: 3m 13s\tremaining: 6m 15s\n",
      "34: learn: 0.2636285\ttest: 0.2630504\tbestTest: 0.2630504 (34)\ttotal: 3m 18s\tremaining: 6m 9s\n",
      "35: learn: 0.2612466\ttest: 0.2606527\tbestTest: 0.2606527 (35)\ttotal: 3m 23s\tremaining: 6m 2s\n",
      "36: learn: 0.2592523\ttest: 0.2586495\tbestTest: 0.2586495 (36)\ttotal: 3m 29s\tremaining: 5m 56s\n",
      "37: learn: 0.2571852\ttest: 0.2565715\tbestTest: 0.2565715 (37)\ttotal: 3m 34s\tremaining: 5m 50s\n",
      "38: learn: 0.2552306\ttest: 0.2546049\tbestTest: 0.2546049 (38)\ttotal: 3m 40s\tremaining: 5m 44s\n",
      "39: learn: 0.2534394\ttest: 0.252804\tbestTest: 0.252804 (39)\ttotal: 3m 46s\tremaining: 5m 39s\n",
      "40: learn: 0.2516919\ttest: 0.2510479\tbestTest: 0.2510479 (40)\ttotal: 3m 51s\tremaining: 5m 33s\n",
      "41: learn: 0.2501355\ttest: 0.2494831\tbestTest: 0.2494831 (41)\ttotal: 3m 57s\tremaining: 5m 27s\n",
      "42: learn: 0.2486527\ttest: 0.2479901\tbestTest: 0.2479901 (42)\ttotal: 4m 2s\tremaining: 5m 22s\n",
      "43: learn: 0.2473237\ttest: 0.2466541\tbestTest: 0.2466541 (43)\ttotal: 4m 8s\tremaining: 5m 16s\n",
      "44: learn: 0.2460582\ttest: 0.2453847\tbestTest: 0.2453847 (44)\ttotal: 4m 13s\tremaining: 5m 9s\n",
      "45: learn: 0.2449867\ttest: 0.2443047\tbestTest: 0.2443047 (45)\ttotal: 4m 18s\tremaining: 5m 3s\n",
      "46: learn: 0.2439125\ttest: 0.2432273\tbestTest: 0.2432273 (46)\ttotal: 4m 24s\tremaining: 4m 58s\n",
      "47: learn: 0.2429061\ttest: 0.2422161\tbestTest: 0.2422161 (47)\ttotal: 4m 30s\tremaining: 4m 53s\n",
      "48: learn: 0.2419015\ttest: 0.2412035\tbestTest: 0.2412035 (48)\ttotal: 4m 35s\tremaining: 4m 47s\n",
      "49: learn: 0.2409352\ttest: 0.2402291\tbestTest: 0.2402291 (49)\ttotal: 4m 41s\tremaining: 4m 41s\n",
      "50: learn: 0.2401166\ttest: 0.2394043\tbestTest: 0.2394043 (50)\ttotal: 4m 46s\tremaining: 4m 35s\n",
      "51: learn: 0.2393366\ttest: 0.238617\tbestTest: 0.238617 (51)\ttotal: 4m 52s\tremaining: 4m 29s\n",
      "52: learn: 0.2385693\ttest: 0.2378433\tbestTest: 0.2378433 (52)\ttotal: 4m 58s\tremaining: 4m 24s\n",
      "53: learn: 0.2378449\ttest: 0.2371131\tbestTest: 0.2371131 (53)\ttotal: 5m 3s\tremaining: 4m 18s\n",
      "54: learn: 0.2372229\ttest: 0.2364866\tbestTest: 0.2364866 (54)\ttotal: 5m 9s\tremaining: 4m 13s\n",
      "55: learn: 0.2365928\ttest: 0.2358512\tbestTest: 0.2358512 (55)\ttotal: 5m 14s\tremaining: 4m 7s\n",
      "56: learn: 0.236077\ttest: 0.2353299\tbestTest: 0.2353299 (56)\ttotal: 5m 20s\tremaining: 4m 1s\n",
      "57: learn: 0.2354635\ttest: 0.2347142\tbestTest: 0.2347142 (57)\ttotal: 5m 25s\tremaining: 3m 55s\n",
      "58: learn: 0.2348842\ttest: 0.2341305\tbestTest: 0.2341305 (58)\ttotal: 5m 31s\tremaining: 3m 50s\n",
      "59: learn: 0.2343852\ttest: 0.2336259\tbestTest: 0.2336259 (59)\ttotal: 5m 37s\tremaining: 3m 44s\n",
      "60: learn: 0.2339647\ttest: 0.2332013\tbestTest: 0.2332013 (60)\ttotal: 5m 42s\tremaining: 3m 38s\n",
      "61: learn: 0.2335457\ttest: 0.2327792\tbestTest: 0.2327792 (61)\ttotal: 5m 47s\tremaining: 3m 32s\n",
      "62: learn: 0.2331313\ttest: 0.2323619\tbestTest: 0.2323619 (62)\ttotal: 5m 53s\tremaining: 3m 27s\n",
      "63: learn: 0.2327477\ttest: 0.2319743\tbestTest: 0.2319743 (63)\ttotal: 5m 59s\tremaining: 3m 22s\n",
      "64: learn: 0.2323718\ttest: 0.2315942\tbestTest: 0.2315942 (64)\ttotal: 6m 5s\tremaining: 3m 16s\n",
      "65: learn: 0.2320064\ttest: 0.2312263\tbestTest: 0.2312263 (65)\ttotal: 6m 11s\tremaining: 3m 11s\n",
      "66: learn: 0.2316435\ttest: 0.2308583\tbestTest: 0.2308583 (66)\ttotal: 6m 16s\tremaining: 3m 5s\n",
      "67: learn: 0.231341\ttest: 0.2305521\tbestTest: 0.2305521 (67)\ttotal: 6m 21s\tremaining: 2m 59s\n",
      "68: learn: 0.2310999\ttest: 0.2303069\tbestTest: 0.2303069 (68)\ttotal: 6m 27s\tremaining: 2m 54s\n",
      "69: learn: 0.2308407\ttest: 0.2300439\tbestTest: 0.2300439 (69)\ttotal: 6m 33s\tremaining: 2m 48s\n",
      "70: learn: 0.2305684\ttest: 0.2297674\tbestTest: 0.2297674 (70)\ttotal: 6m 39s\tremaining: 2m 43s\n",
      "71: learn: 0.230304\ttest: 0.2294998\tbestTest: 0.2294998 (71)\ttotal: 6m 44s\tremaining: 2m 37s\n",
      "72: learn: 0.2300651\ttest: 0.2292576\tbestTest: 0.2292576 (72)\ttotal: 6m 49s\tremaining: 2m 31s\n",
      "73: learn: 0.2298449\ttest: 0.2290355\tbestTest: 0.2290355 (73)\ttotal: 6m 55s\tremaining: 2m 25s\n",
      "74: learn: 0.2296436\ttest: 0.2288309\tbestTest: 0.2288309 (74)\ttotal: 7m\tremaining: 2m 20s\n",
      "75: learn: 0.2294019\ttest: 0.2285862\tbestTest: 0.2285862 (75)\ttotal: 7m 5s\tremaining: 2m 14s\n",
      "76: learn: 0.2292053\ttest: 0.2283867\tbestTest: 0.2283867 (76)\ttotal: 7m 11s\tremaining: 2m 8s\n",
      "77: learn: 0.229022\ttest: 0.2281992\tbestTest: 0.2281992 (77)\ttotal: 7m 16s\tremaining: 2m 3s\n",
      "78: learn: 0.2288906\ttest: 0.2280659\tbestTest: 0.2280659 (78)\ttotal: 7m 23s\tremaining: 1m 57s\n",
      "79: learn: 0.228696\ttest: 0.2278676\tbestTest: 0.2278676 (79)\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "80: learn: 0.2285\ttest: 0.2276702\tbestTest: 0.2276702 (80)\ttotal: 7m 34s\tremaining: 1m 46s\n",
      "81: learn: 0.2283279\ttest: 0.2274951\tbestTest: 0.2274951 (81)\ttotal: 7m 39s\tremaining: 1m 40s\n",
      "82: learn: 0.2281586\ttest: 0.227325\tbestTest: 0.227325 (82)\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "83: learn: 0.2280302\ttest: 0.2271947\tbestTest: 0.2271947 (83)\ttotal: 7m 51s\tremaining: 1m 29s\n",
      "84: learn: 0.2278749\ttest: 0.2270372\tbestTest: 0.2270372 (84)\ttotal: 7m 56s\tremaining: 1m 24s\n",
      "85: learn: 0.2277684\ttest: 0.2269281\tbestTest: 0.2269281 (85)\ttotal: 8m 2s\tremaining: 1m 18s\n",
      "86: learn: 0.2276264\ttest: 0.2267852\tbestTest: 0.2267852 (86)\ttotal: 8m 7s\tremaining: 1m 12s\n",
      "87: learn: 0.2275201\ttest: 0.2266786\tbestTest: 0.2266786 (87)\ttotal: 8m 13s\tremaining: 1m 7s\n",
      "88: learn: 0.2274197\ttest: 0.2265774\tbestTest: 0.2265774 (88)\ttotal: 8m 19s\tremaining: 1m 1s\n",
      "89: learn: 0.2272969\ttest: 0.2264522\tbestTest: 0.2264522 (89)\ttotal: 8m 24s\tremaining: 56.1s\n",
      "90: learn: 0.2271961\ttest: 0.2263505\tbestTest: 0.2263505 (90)\ttotal: 8m 30s\tremaining: 50.4s\n",
      "91: learn: 0.2270941\ttest: 0.2262479\tbestTest: 0.2262479 (91)\ttotal: 8m 35s\tremaining: 44.8s\n",
      "92: learn: 0.2269942\ttest: 0.2261474\tbestTest: 0.2261474 (92)\ttotal: 8m 40s\tremaining: 39.2s\n",
      "93: learn: 0.2268984\ttest: 0.2260504\tbestTest: 0.2260504 (93)\ttotal: 8m 46s\tremaining: 33.6s\n",
      "94: learn: 0.2267845\ttest: 0.2259361\tbestTest: 0.2259361 (94)\ttotal: 8m 51s\tremaining: 28s\n",
      "95: learn: 0.2266966\ttest: 0.2258474\tbestTest: 0.2258474 (95)\ttotal: 8m 56s\tremaining: 22.4s\n",
      "96: learn: 0.2266138\ttest: 0.2257639\tbestTest: 0.2257639 (96)\ttotal: 9m 2s\tremaining: 16.8s\n",
      "97: learn: 0.2265558\ttest: 0.2257055\tbestTest: 0.2257055 (97)\ttotal: 9m 8s\tremaining: 11.2s\n",
      "98: learn: 0.2264711\ttest: 0.2256203\tbestTest: 0.2256203 (98)\ttotal: 9m 13s\tremaining: 5.59s\n",
      "99: learn: 0.2263855\ttest: 0.2255336\tbestTest: 0.2255336 (99)\ttotal: 9m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2255336143\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_5_cat_split_16_bag_temp_1\n",
      "2018-03-13 21:29:29.689369\n",
      "train time given below\n",
      "0:12:35.339001\n",
      "2018-03-13 21:29:29.818652\n",
      "2018-03-13 21:29:29.822365\n",
      "GINI ISIT = 0.45566422187\n",
      "2018-03-13 21:30:59.998787\n",
      "GINI OSIT = 0.456603216226\n",
      "2018-03-13 21:31:37.482830\n",
      "GINI OSOT = 0.410217906797\n",
      "2018-03-13 21:31:49.060157\n",
      "2018-03-13 21:31:49.062227\n",
      "num split = 10\n",
      "2018-03-13 21:31:49.063639\n",
      "model train start\n",
      "2018-03-13 21:31:49.063878\n",
      "0: learn: 0.6575478\ttest: 0.6575253\tbestTest: 0.6575253 (0)\ttotal: 5.26s\tremaining: 8m 41s\n",
      "1: learn: 0.6243339\ttest: 0.6242794\tbestTest: 0.6242794 (1)\ttotal: 10.9s\tremaining: 8m 52s\n",
      "2: learn: 0.5943355\ttest: 0.5942543\tbestTest: 0.5942543 (2)\ttotal: 16.8s\tremaining: 9m 1s\n",
      "3: learn: 0.5661831\ttest: 0.5661429\tbestTest: 0.5661429 (3)\ttotal: 22.7s\tremaining: 9m 5s\n",
      "4: learn: 0.5407197\ttest: 0.5406487\tbestTest: 0.5406487 (4)\ttotal: 28.3s\tremaining: 8m 57s\n",
      "5: learn: 0.5177574\ttest: 0.5176678\tbestTest: 0.5176678 (5)\ttotal: 32.9s\tremaining: 8m 35s\n",
      "6: learn: 0.4953888\ttest: 0.4952672\tbestTest: 0.4952672 (6)\ttotal: 38.3s\tremaining: 8m 29s\n",
      "7: learn: 0.4752751\ttest: 0.4751269\tbestTest: 0.4751269 (7)\ttotal: 43.4s\tremaining: 8m 19s\n",
      "8: learn: 0.4568096\ttest: 0.4566387\tbestTest: 0.4566387 (8)\ttotal: 49.4s\tremaining: 8m 19s\n",
      "9: learn: 0.4399933\ttest: 0.4398097\tbestTest: 0.4398097 (9)\ttotal: 55.5s\tremaining: 8m 19s\n",
      "10: learn: 0.4241744\ttest: 0.4239722\tbestTest: 0.4239722 (10)\ttotal: 1m 1s\tremaining: 8m 16s\n",
      "11: learn: 0.4099782\ttest: 0.4097549\tbestTest: 0.4097549 (11)\ttotal: 1m 6s\tremaining: 8m 9s\n",
      "12: learn: 0.3970836\ttest: 0.39684\tbestTest: 0.39684 (12)\ttotal: 1m 12s\tremaining: 8m 3s\n",
      "13: learn: 0.3846523\ttest: 0.3843894\tbestTest: 0.3843894 (13)\ttotal: 1m 17s\tremaining: 7m 58s\n",
      "14: learn: 0.3733437\ttest: 0.3730629\tbestTest: 0.3730629 (14)\ttotal: 1m 23s\tremaining: 7m 51s\n",
      "15: learn: 0.3629833\ttest: 0.3626853\tbestTest: 0.3626853 (15)\ttotal: 1m 29s\tremaining: 7m 49s\n",
      "16: learn: 0.353551\ttest: 0.3532376\tbestTest: 0.3532376 (16)\ttotal: 1m 34s\tremaining: 7m 43s\n",
      "17: learn: 0.344278\ttest: 0.3439397\tbestTest: 0.3439397 (17)\ttotal: 1m 40s\tremaining: 7m 37s\n",
      "18: learn: 0.3360288\ttest: 0.3356775\tbestTest: 0.3356775 (18)\ttotal: 1m 46s\tremaining: 7m 33s\n",
      "19: learn: 0.3285336\ttest: 0.3281656\tbestTest: 0.3281656 (19)\ttotal: 1m 51s\tremaining: 7m 27s\n",
      "20: learn: 0.3216373\ttest: 0.3212521\tbestTest: 0.3212521 (20)\ttotal: 1m 57s\tremaining: 7m 20s\n",
      "21: learn: 0.3155112\ttest: 0.3151032\tbestTest: 0.3151032 (21)\ttotal: 2m 3s\tremaining: 7m 16s\n",
      "22: learn: 0.309503\ttest: 0.3090816\tbestTest: 0.3090816 (22)\ttotal: 2m 8s\tremaining: 7m 11s\n",
      "23: learn: 0.3038687\ttest: 0.3034343\tbestTest: 0.3034343 (23)\ttotal: 2m 14s\tremaining: 7m 6s\n",
      "24: learn: 0.2984839\ttest: 0.2980362\tbestTest: 0.2980362 (24)\ttotal: 2m 19s\tremaining: 6m 59s\n",
      "25: learn: 0.2939637\ttest: 0.2935047\tbestTest: 0.2935047 (25)\ttotal: 2m 25s\tremaining: 6m 54s\n",
      "26: learn: 0.2893758\ttest: 0.2889069\tbestTest: 0.2889069 (26)\ttotal: 2m 30s\tremaining: 6m 48s\n",
      "27: learn: 0.2852566\ttest: 0.2847705\tbestTest: 0.2847705 (27)\ttotal: 2m 36s\tremaining: 6m 41s\n",
      "28: learn: 0.2811928\ttest: 0.2806901\tbestTest: 0.2806901 (28)\ttotal: 2m 41s\tremaining: 6m 35s\n",
      "29: learn: 0.277652\ttest: 0.2771329\tbestTest: 0.2771329 (29)\ttotal: 2m 46s\tremaining: 6m 28s\n",
      "30: learn: 0.2745976\ttest: 0.2740705\tbestTest: 0.2740705 (30)\ttotal: 2m 51s\tremaining: 6m 22s\n",
      "31: learn: 0.2714949\ttest: 0.2709559\tbestTest: 0.2709559 (31)\ttotal: 2m 56s\tremaining: 6m 15s\n",
      "32: learn: 0.2687826\ttest: 0.2682324\tbestTest: 0.2682324 (32)\ttotal: 3m 2s\tremaining: 6m 10s\n",
      "33: learn: 0.2659359\ttest: 0.2653712\tbestTest: 0.2653712 (33)\ttotal: 3m 8s\tremaining: 6m 5s\n",
      "34: learn: 0.2634737\ttest: 0.2628953\tbestTest: 0.2628953 (34)\ttotal: 3m 13s\tremaining: 5m 58s\n",
      "35: learn: 0.2610349\ttest: 0.260444\tbestTest: 0.260444 (35)\ttotal: 3m 18s\tremaining: 5m 52s\n",
      "36: learn: 0.259071\ttest: 0.2584739\tbestTest: 0.2584739 (36)\ttotal: 3m 24s\tremaining: 5m 47s\n",
      "37: learn: 0.257087\ttest: 0.256481\tbestTest: 0.256481 (37)\ttotal: 3m 29s\tremaining: 5m 41s\n",
      "38: learn: 0.255111\ttest: 0.2544951\tbestTest: 0.2544951 (38)\ttotal: 3m 34s\tremaining: 5m 36s\n",
      "39: learn: 0.2534308\ttest: 0.2528042\tbestTest: 0.2528042 (39)\ttotal: 3m 40s\tremaining: 5m 30s\n",
      "40: learn: 0.2517754\ttest: 0.2511367\tbestTest: 0.2511367 (40)\ttotal: 3m 45s\tremaining: 5m 24s\n",
      "41: learn: 0.2502848\ttest: 0.249637\tbestTest: 0.249637 (41)\ttotal: 3m 51s\tremaining: 5m 19s\n",
      "42: learn: 0.2488929\ttest: 0.248235\tbestTest: 0.248235 (42)\ttotal: 3m 56s\tremaining: 5m 14s\n",
      "43: learn: 0.2474902\ttest: 0.2468272\tbestTest: 0.2468272 (43)\ttotal: 4m 2s\tremaining: 5m 8s\n",
      "44: learn: 0.2461795\ttest: 0.2455081\tbestTest: 0.2455081 (44)\ttotal: 4m 8s\tremaining: 5m 3s\n",
      "45: learn: 0.2450437\ttest: 0.2443659\tbestTest: 0.2443659 (45)\ttotal: 4m 14s\tremaining: 4m 58s\n",
      "46: learn: 0.2439371\ttest: 0.2432528\tbestTest: 0.2432528 (46)\ttotal: 4m 19s\tremaining: 4m 52s\n",
      "47: learn: 0.2428548\ttest: 0.2421661\tbestTest: 0.2421661 (47)\ttotal: 4m 25s\tremaining: 4m 47s\n",
      "48: learn: 0.2418589\ttest: 0.2411634\tbestTest: 0.2411634 (48)\ttotal: 4m 30s\tremaining: 4m 41s\n",
      "49: learn: 0.2409214\ttest: 0.2402194\tbestTest: 0.2402194 (49)\ttotal: 4m 36s\tremaining: 4m 36s\n",
      "50: learn: 0.2401375\ttest: 0.239427\tbestTest: 0.239427 (50)\ttotal: 4m 42s\tremaining: 4m 30s\n",
      "51: learn: 0.2394036\ttest: 0.2386886\tbestTest: 0.2386886 (51)\ttotal: 4m 47s\tremaining: 4m 25s\n",
      "52: learn: 0.2387411\ttest: 0.2380195\tbestTest: 0.2380195 (52)\ttotal: 4m 53s\tremaining: 4m 20s\n",
      "53: learn: 0.2380637\ttest: 0.2373343\tbestTest: 0.2373343 (53)\ttotal: 4m 59s\tremaining: 4m 15s\n",
      "54: learn: 0.2374169\ttest: 0.2366823\tbestTest: 0.2366823 (54)\ttotal: 5m 5s\tremaining: 4m 9s\n",
      "55: learn: 0.2367577\ttest: 0.2360169\tbestTest: 0.2360169 (55)\ttotal: 5m 10s\tremaining: 4m 3s\n",
      "56: learn: 0.2362231\ttest: 0.2354766\tbestTest: 0.2354766 (56)\ttotal: 5m 16s\tremaining: 3m 58s\n",
      "57: learn: 0.2356812\ttest: 0.2349294\tbestTest: 0.2349294 (57)\ttotal: 5m 21s\tremaining: 3m 52s\n",
      "58: learn: 0.2351325\ttest: 0.2343759\tbestTest: 0.2343759 (58)\ttotal: 5m 27s\tremaining: 3m 47s\n",
      "59: learn: 0.2346294\ttest: 0.2338673\tbestTest: 0.2338673 (59)\ttotal: 5m 33s\tremaining: 3m 42s\n",
      "60: learn: 0.2341099\ttest: 0.2333404\tbestTest: 0.2333404 (60)\ttotal: 5m 38s\tremaining: 3m 36s\n",
      "61: learn: 0.2336515\ttest: 0.2328762\tbestTest: 0.2328762 (61)\ttotal: 5m 44s\tremaining: 3m 31s\n",
      "62: learn: 0.2332396\ttest: 0.2324604\tbestTest: 0.2324604 (62)\ttotal: 5m 49s\tremaining: 3m 25s\n",
      "63: learn: 0.2328968\ttest: 0.2321138\tbestTest: 0.2321138 (63)\ttotal: 5m 55s\tremaining: 3m 20s\n",
      "64: learn: 0.2324794\ttest: 0.2316926\tbestTest: 0.2316926 (64)\ttotal: 6m\tremaining: 3m 14s\n",
      "65: learn: 0.232131\ttest: 0.2313403\tbestTest: 0.2313403 (65)\ttotal: 6m 6s\tremaining: 3m 8s\n",
      "66: learn: 0.2317785\ttest: 0.2309825\tbestTest: 0.2309825 (66)\ttotal: 6m 10s\tremaining: 3m 2s\n",
      "67: learn: 0.2314559\ttest: 0.2306563\tbestTest: 0.2306563 (67)\ttotal: 6m 16s\tremaining: 2m 56s\n",
      "68: learn: 0.2311716\ttest: 0.2303673\tbestTest: 0.2303673 (68)\ttotal: 6m 21s\tremaining: 2m 51s\n",
      "69: learn: 0.2308985\ttest: 0.2300924\tbestTest: 0.2300924 (69)\ttotal: 6m 26s\tremaining: 2m 45s\n",
      "70: learn: 0.2306002\ttest: 0.2297926\tbestTest: 0.2297926 (70)\ttotal: 6m 32s\tremaining: 2m 40s\n",
      "71: learn: 0.2303421\ttest: 0.2295316\tbestTest: 0.2295316 (71)\ttotal: 6m 37s\tremaining: 2m 34s\n",
      "72: learn: 0.2300919\ttest: 0.2292772\tbestTest: 0.2292772 (72)\ttotal: 6m 43s\tremaining: 2m 29s\n",
      "73: learn: 0.2298734\ttest: 0.2290555\tbestTest: 0.2290555 (73)\ttotal: 6m 48s\tremaining: 2m 23s\n",
      "74: learn: 0.2296436\ttest: 0.2288227\tbestTest: 0.2288227 (74)\ttotal: 6m 54s\tremaining: 2m 18s\n",
      "75: learn: 0.229444\ttest: 0.2286192\tbestTest: 0.2286192 (75)\ttotal: 6m 59s\tremaining: 2m 12s\n",
      "76: learn: 0.229218\ttest: 0.2283896\tbestTest: 0.2283896 (76)\ttotal: 7m 4s\tremaining: 2m 6s\n",
      "77: learn: 0.2290204\ttest: 0.2281889\tbestTest: 0.2281889 (77)\ttotal: 7m 9s\tremaining: 2m 1s\n",
      "78: learn: 0.2288486\ttest: 0.2280152\tbestTest: 0.2280152 (78)\ttotal: 7m 15s\tremaining: 1m 55s\n",
      "79: learn: 0.2286732\ttest: 0.2278401\tbestTest: 0.2278401 (79)\ttotal: 7m 21s\tremaining: 1m 50s\n",
      "80: learn: 0.22854\ttest: 0.2277039\tbestTest: 0.2277039 (80)\ttotal: 7m 27s\tremaining: 1m 44s\n",
      "81: learn: 0.2283988\ttest: 0.2275611\tbestTest: 0.2275611 (81)\ttotal: 7m 33s\tremaining: 1m 39s\n",
      "82: learn: 0.2282393\ttest: 0.2273999\tbestTest: 0.2273999 (82)\ttotal: 7m 38s\tremaining: 1m 33s\n",
      "83: learn: 0.2280833\ttest: 0.2272404\tbestTest: 0.2272404 (83)\ttotal: 7m 43s\tremaining: 1m 28s\n",
      "84: learn: 0.2279349\ttest: 0.2270889\tbestTest: 0.2270889 (84)\ttotal: 7m 48s\tremaining: 1m 22s\n",
      "85: learn: 0.2278136\ttest: 0.2269646\tbestTest: 0.2269646 (85)\ttotal: 7m 54s\tremaining: 1m 17s\n",
      "86: learn: 0.2276774\ttest: 0.2268264\tbestTest: 0.2268264 (86)\ttotal: 8m\tremaining: 1m 11s\n",
      "87: learn: 0.2275455\ttest: 0.2266933\tbestTest: 0.2266933 (87)\ttotal: 8m 5s\tremaining: 1m 6s\n",
      "88: learn: 0.2273962\ttest: 0.2265442\tbestTest: 0.2265442 (88)\ttotal: 8m 10s\tremaining: 1m\n",
      "89: learn: 0.2272606\ttest: 0.226408\tbestTest: 0.226408 (89)\ttotal: 8m 16s\tremaining: 55.2s\n",
      "90: learn: 0.2271271\ttest: 0.2262758\tbestTest: 0.2262758 (90)\ttotal: 8m 21s\tremaining: 49.6s\n",
      "91: learn: 0.2270307\ttest: 0.2261784\tbestTest: 0.2261784 (91)\ttotal: 8m 27s\tremaining: 44.1s\n",
      "92: learn: 0.2269337\ttest: 0.2260799\tbestTest: 0.2260799 (92)\ttotal: 8m 32s\tremaining: 38.6s\n",
      "93: learn: 0.2268342\ttest: 0.2259789\tbestTest: 0.2259789 (93)\ttotal: 8m 38s\tremaining: 33.1s\n",
      "94: learn: 0.2267296\ttest: 0.2258715\tbestTest: 0.2258715 (94)\ttotal: 8m 44s\tremaining: 27.6s\n",
      "95: learn: 0.2266453\ttest: 0.2257866\tbestTest: 0.2257866 (95)\ttotal: 8m 50s\tremaining: 22.1s\n",
      "96: learn: 0.2265609\ttest: 0.2257005\tbestTest: 0.2257005 (96)\ttotal: 8m 55s\tremaining: 16.6s\n",
      "97: learn: 0.2264743\ttest: 0.2256127\tbestTest: 0.2256127 (97)\ttotal: 9m 1s\tremaining: 11s\n",
      "98: learn: 0.226367\ttest: 0.2255052\tbestTest: 0.2255052 (98)\ttotal: 9m 6s\tremaining: 5.52s\n",
      "99: learn: 0.2262877\ttest: 0.2254245\tbestTest: 0.2254245 (99)\ttotal: 9m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254245242\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_10_cat_split_16_bag_temp_1\n",
      "2018-03-13 21:44:13.456744\n",
      "train time given below\n",
      "0:12:24.392866\n",
      "2018-03-13 21:44:13.477859\n",
      "2018-03-13 21:44:13.481568\n",
      "GINI ISIT = 0.455662696587\n",
      "2018-03-13 21:45:48.257001\n",
      "GINI OSIT = 0.456817443954\n",
      "2018-03-13 21:46:26.586005\n",
      "GINI OSOT = 0.41105567975\n",
      "2018-03-13 21:46:38.655726\n",
      "2018-03-13 21:46:38.657793\n",
      "num split = 16\n",
      "2018-03-13 21:46:38.659275\n",
      "model train start\n",
      "2018-03-13 21:46:38.659513\n",
      "0: learn: 0.6579359\ttest: 0.6579092\tbestTest: 0.6579092 (0)\ttotal: 5.65s\tremaining: 9m 19s\n",
      "1: learn: 0.624899\ttest: 0.624848\tbestTest: 0.624848 (1)\ttotal: 12.1s\tremaining: 9m 51s\n",
      "2: learn: 0.5950034\ttest: 0.5949273\tbestTest: 0.5949273 (2)\ttotal: 17.6s\tremaining: 9m 30s\n",
      "3: learn: 0.5670981\ttest: 0.5670047\tbestTest: 0.5670047 (3)\ttotal: 23.8s\tremaining: 9m 30s\n",
      "4: learn: 0.5420128\ttest: 0.5419054\tbestTest: 0.5419054 (4)\ttotal: 28.9s\tremaining: 9m 8s\n",
      "5: learn: 0.5178153\ttest: 0.5176891\tbestTest: 0.5176891 (5)\ttotal: 34.4s\tremaining: 8m 58s\n",
      "6: learn: 0.4960914\ttest: 0.495943\tbestTest: 0.495943 (6)\ttotal: 40.2s\tremaining: 8m 54s\n",
      "7: learn: 0.4755843\ttest: 0.4754047\tbestTest: 0.4754047 (7)\ttotal: 45.6s\tremaining: 8m 44s\n",
      "8: learn: 0.4576218\ttest: 0.4574191\tbestTest: 0.4574191 (8)\ttotal: 51.2s\tremaining: 8m 37s\n",
      "9: learn: 0.4407079\ttest: 0.440484\tbestTest: 0.440484 (9)\ttotal: 57.4s\tremaining: 8m 36s\n",
      "10: learn: 0.4249302\ttest: 0.4246871\tbestTest: 0.4246871 (10)\ttotal: 1m 2s\tremaining: 8m 26s\n",
      "11: learn: 0.4106045\ttest: 0.4103454\tbestTest: 0.4103454 (11)\ttotal: 1m 7s\tremaining: 8m 18s\n",
      "12: learn: 0.3974\ttest: 0.3971215\tbestTest: 0.3971215 (12)\ttotal: 1m 13s\tremaining: 8m 14s\n",
      "13: learn: 0.3848198\ttest: 0.3845182\tbestTest: 0.3845182 (13)\ttotal: 1m 19s\tremaining: 8m 7s\n",
      "14: learn: 0.3732353\ttest: 0.3729541\tbestTest: 0.3729541 (14)\ttotal: 1m 24s\tremaining: 8m\n",
      "15: learn: 0.3627998\ttest: 0.3624976\tbestTest: 0.3624976 (15)\ttotal: 1m 30s\tremaining: 7m 53s\n",
      "16: learn: 0.3536091\ttest: 0.3532901\tbestTest: 0.3532901 (16)\ttotal: 1m 35s\tremaining: 7m 48s\n",
      "17: learn: 0.3450204\ttest: 0.3446879\tbestTest: 0.3446879 (17)\ttotal: 1m 41s\tremaining: 7m 44s\n",
      "18: learn: 0.3368413\ttest: 0.3364927\tbestTest: 0.3364927 (18)\ttotal: 1m 47s\tremaining: 7m 36s\n",
      "19: learn: 0.3299815\ttest: 0.3296151\tbestTest: 0.3296151 (19)\ttotal: 1m 48s\tremaining: 7m 14s\n",
      "20: learn: 0.3229986\ttest: 0.3226159\tbestTest: 0.3226159 (20)\ttotal: 1m 54s\tremaining: 7m 10s\n",
      "21: learn: 0.3163858\ttest: 0.3159979\tbestTest: 0.3159979 (21)\ttotal: 2m\tremaining: 7m 5s\n",
      "22: learn: 0.3101483\ttest: 0.3097391\tbestTest: 0.3097391 (22)\ttotal: 2m 5s\tremaining: 6m 59s\n",
      "23: learn: 0.3044584\ttest: 0.3040412\tbestTest: 0.3040412 (23)\ttotal: 2m 10s\tremaining: 6m 53s\n",
      "24: learn: 0.299203\ttest: 0.2987651\tbestTest: 0.2987651 (24)\ttotal: 2m 15s\tremaining: 6m 46s\n",
      "25: learn: 0.2945475\ttest: 0.2940914\tbestTest: 0.2940914 (25)\ttotal: 2m 21s\tremaining: 6m 41s\n",
      "26: learn: 0.2899007\ttest: 0.2894277\tbestTest: 0.2894277 (26)\ttotal: 2m 26s\tremaining: 6m 35s\n",
      "27: learn: 0.2858475\ttest: 0.2853619\tbestTest: 0.2853619 (27)\ttotal: 2m 31s\tremaining: 6m 29s\n",
      "28: learn: 0.2820945\ttest: 0.2815949\tbestTest: 0.2815949 (28)\ttotal: 2m 37s\tremaining: 6m 25s\n",
      "29: learn: 0.2785602\ttest: 0.2780493\tbestTest: 0.2780493 (29)\ttotal: 2m 43s\tremaining: 6m 20s\n",
      "30: learn: 0.2751875\ttest: 0.2746614\tbestTest: 0.2746614 (30)\ttotal: 2m 48s\tremaining: 6m 15s\n",
      "31: learn: 0.2720585\ttest: 0.2715165\tbestTest: 0.2715165 (31)\ttotal: 2m 53s\tremaining: 6m 9s\n",
      "32: learn: 0.269241\ttest: 0.2686836\tbestTest: 0.2686836 (32)\ttotal: 2m 58s\tremaining: 6m 3s\n",
      "33: learn: 0.2664896\ttest: 0.2659234\tbestTest: 0.2659234 (33)\ttotal: 3m 4s\tremaining: 5m 58s\n",
      "34: learn: 0.2639268\ttest: 0.2633465\tbestTest: 0.2633465 (34)\ttotal: 3m 9s\tremaining: 5m 52s\n",
      "35: learn: 0.2617196\ttest: 0.2611286\tbestTest: 0.2611286 (35)\ttotal: 3m 15s\tremaining: 5m 47s\n",
      "36: learn: 0.2596207\ttest: 0.2590196\tbestTest: 0.2590196 (36)\ttotal: 3m 20s\tremaining: 5m 41s\n",
      "37: learn: 0.2576167\ttest: 0.2570048\tbestTest: 0.2570048 (37)\ttotal: 3m 26s\tremaining: 5m 36s\n",
      "38: learn: 0.2558583\ttest: 0.2552354\tbestTest: 0.2552354 (38)\ttotal: 3m 32s\tremaining: 5m 31s\n",
      "39: learn: 0.2540025\ttest: 0.2533718\tbestTest: 0.2533718 (39)\ttotal: 3m 38s\tremaining: 5m 27s\n",
      "40: learn: 0.2522446\ttest: 0.2516049\tbestTest: 0.2516049 (40)\ttotal: 3m 43s\tremaining: 5m 21s\n",
      "41: learn: 0.2507126\ttest: 0.2500657\tbestTest: 0.2500657 (41)\ttotal: 3m 49s\tremaining: 5m 16s\n",
      "42: learn: 0.2492274\ttest: 0.2485744\tbestTest: 0.2485744 (42)\ttotal: 3m 55s\tremaining: 5m 11s\n",
      "43: learn: 0.2478402\ttest: 0.2471786\tbestTest: 0.2471786 (43)\ttotal: 4m\tremaining: 5m 5s\n",
      "44: learn: 0.2465939\ttest: 0.2459262\tbestTest: 0.2459262 (44)\ttotal: 4m 6s\tremaining: 5m 1s\n",
      "45: learn: 0.2453199\ttest: 0.2446424\tbestTest: 0.2446424 (45)\ttotal: 4m 11s\tremaining: 4m 55s\n",
      "46: learn: 0.2442374\ttest: 0.2435539\tbestTest: 0.2435539 (46)\ttotal: 4m 17s\tremaining: 4m 50s\n",
      "47: learn: 0.2431476\ttest: 0.2424553\tbestTest: 0.2424553 (47)\ttotal: 4m 22s\tremaining: 4m 44s\n",
      "48: learn: 0.2422106\ttest: 0.241513\tbestTest: 0.241513 (48)\ttotal: 4m 27s\tremaining: 4m 38s\n",
      "49: learn: 0.2412777\ttest: 0.2405711\tbestTest: 0.2405711 (49)\ttotal: 4m 32s\tremaining: 4m 32s\n",
      "50: learn: 0.2404054\ttest: 0.2396922\tbestTest: 0.2396922 (50)\ttotal: 4m 37s\tremaining: 4m 26s\n",
      "51: learn: 0.2396035\ttest: 0.2388807\tbestTest: 0.2388807 (51)\ttotal: 4m 42s\tremaining: 4m 20s\n",
      "52: learn: 0.2388421\ttest: 0.238102\tbestTest: 0.238102 (52)\ttotal: 4m 48s\tremaining: 4m 15s\n",
      "53: learn: 0.2381679\ttest: 0.237426\tbestTest: 0.237426 (53)\ttotal: 4m 53s\tremaining: 4m 10s\n",
      "54: learn: 0.2375314\ttest: 0.2367855\tbestTest: 0.2367855 (54)\ttotal: 4m 59s\tremaining: 4m 4s\n",
      "55: learn: 0.2369017\ttest: 0.2361515\tbestTest: 0.2361515 (55)\ttotal: 5m 4s\tremaining: 3m 59s\n",
      "56: learn: 0.2362995\ttest: 0.2355464\tbestTest: 0.2355464 (56)\ttotal: 5m 9s\tremaining: 3m 53s\n",
      "57: learn: 0.2357192\ttest: 0.2349628\tbestTest: 0.2349628 (57)\ttotal: 5m 15s\tremaining: 3m 48s\n",
      "58: learn: 0.2351568\ttest: 0.234393\tbestTest: 0.234393 (58)\ttotal: 5m 20s\tremaining: 3m 42s\n",
      "59: learn: 0.2346892\ttest: 0.2339218\tbestTest: 0.2339218 (59)\ttotal: 5m 26s\tremaining: 3m 37s\n",
      "60: learn: 0.2342109\ttest: 0.2334398\tbestTest: 0.2334398 (60)\ttotal: 5m 31s\tremaining: 3m 31s\n",
      "61: learn: 0.2337846\ttest: 0.2330079\tbestTest: 0.2330079 (61)\ttotal: 5m 37s\tremaining: 3m 26s\n",
      "62: learn: 0.2333499\ttest: 0.2325669\tbestTest: 0.2325669 (62)\ttotal: 5m 43s\tremaining: 3m 21s\n",
      "63: learn: 0.2329711\ttest: 0.2321826\tbestTest: 0.2321826 (63)\ttotal: 5m 49s\tremaining: 3m 16s\n",
      "64: learn: 0.2325808\ttest: 0.2317879\tbestTest: 0.2317879 (64)\ttotal: 5m 54s\tremaining: 3m 10s\n",
      "65: learn: 0.2322154\ttest: 0.231417\tbestTest: 0.231417 (65)\ttotal: 5m 59s\tremaining: 3m 4s\n",
      "66: learn: 0.231851\ttest: 0.2310475\tbestTest: 0.2310475 (66)\ttotal: 6m 4s\tremaining: 2m 59s\n",
      "67: learn: 0.231571\ttest: 0.2307639\tbestTest: 0.2307639 (67)\ttotal: 6m 9s\tremaining: 2m 54s\n",
      "68: learn: 0.2312536\ttest: 0.230443\tbestTest: 0.230443 (68)\ttotal: 6m 15s\tremaining: 2m 48s\n",
      "69: learn: 0.2309617\ttest: 0.230146\tbestTest: 0.230146 (69)\ttotal: 6m 20s\tremaining: 2m 42s\n",
      "70: learn: 0.2306804\ttest: 0.2298643\tbestTest: 0.2298643 (70)\ttotal: 6m 26s\tremaining: 2m 37s\n",
      "71: learn: 0.2304155\ttest: 0.2295959\tbestTest: 0.2295959 (71)\ttotal: 6m 31s\tremaining: 2m 32s\n",
      "72: learn: 0.2301868\ttest: 0.2293642\tbestTest: 0.2293642 (72)\ttotal: 6m 36s\tremaining: 2m 26s\n",
      "73: learn: 0.2299484\ttest: 0.2291239\tbestTest: 0.2291239 (73)\ttotal: 6m 41s\tremaining: 2m 21s\n",
      "74: learn: 0.2297041\ttest: 0.2288767\tbestTest: 0.2288767 (74)\ttotal: 6m 47s\tremaining: 2m 15s\n",
      "75: learn: 0.2295014\ttest: 0.2286674\tbestTest: 0.2286674 (75)\ttotal: 6m 53s\tremaining: 2m 10s\n",
      "76: learn: 0.2292903\ttest: 0.2284539\tbestTest: 0.2284539 (76)\ttotal: 6m 58s\tremaining: 2m 5s\n",
      "77: learn: 0.2291047\ttest: 0.2282658\tbestTest: 0.2282658 (77)\ttotal: 7m 4s\tremaining: 1m 59s\n",
      "78: learn: 0.2289199\ttest: 0.22808\tbestTest: 0.22808 (78)\ttotal: 7m 10s\tremaining: 1m 54s\n",
      "79: learn: 0.2287286\ttest: 0.2278871\tbestTest: 0.2278871 (79)\ttotal: 7m 15s\tremaining: 1m 48s\n",
      "80: learn: 0.2285607\ttest: 0.2277171\tbestTest: 0.2277171 (80)\ttotal: 7m 20s\tremaining: 1m 43s\n",
      "81: learn: 0.2284021\ttest: 0.2275566\tbestTest: 0.2275566 (81)\ttotal: 7m 25s\tremaining: 1m 37s\n",
      "82: learn: 0.2282403\ttest: 0.2273916\tbestTest: 0.2273916 (82)\ttotal: 7m 31s\tremaining: 1m 32s\n",
      "83: learn: 0.2281045\ttest: 0.2272548\tbestTest: 0.2272548 (83)\ttotal: 7m 37s\tremaining: 1m 27s\n",
      "84: learn: 0.2279637\ttest: 0.2271128\tbestTest: 0.2271128 (84)\ttotal: 7m 42s\tremaining: 1m 21s\n",
      "85: learn: 0.2278316\ttest: 0.2269778\tbestTest: 0.2269778 (85)\ttotal: 7m 47s\tremaining: 1m 16s\n",
      "86: learn: 0.2276897\ttest: 0.2268349\tbestTest: 0.2268349 (86)\ttotal: 7m 53s\tremaining: 1m 10s\n",
      "87: learn: 0.2275461\ttest: 0.2266905\tbestTest: 0.2266905 (87)\ttotal: 7m 58s\tremaining: 1m 5s\n",
      "88: learn: 0.2274098\ttest: 0.2265529\tbestTest: 0.2265529 (88)\ttotal: 8m 4s\tremaining: 59.9s\n",
      "89: learn: 0.2272851\ttest: 0.2264272\tbestTest: 0.2264272 (89)\ttotal: 8m 9s\tremaining: 54.4s\n",
      "90: learn: 0.227148\ttest: 0.2262905\tbestTest: 0.2262905 (90)\ttotal: 8m 15s\tremaining: 49s\n",
      "91: learn: 0.2270497\ttest: 0.22619\tbestTest: 0.22619 (91)\ttotal: 8m 20s\tremaining: 43.5s\n",
      "92: learn: 0.2269441\ttest: 0.2260816\tbestTest: 0.2260816 (92)\ttotal: 8m 26s\tremaining: 38.1s\n",
      "93: learn: 0.2268528\ttest: 0.2259877\tbestTest: 0.2259877 (93)\ttotal: 8m 32s\tremaining: 32.7s\n",
      "94: learn: 0.2267555\ttest: 0.2258904\tbestTest: 0.2258904 (94)\ttotal: 8m 37s\tremaining: 27.2s\n",
      "95: learn: 0.2266565\ttest: 0.2257885\tbestTest: 0.2257885 (95)\ttotal: 8m 43s\tremaining: 21.8s\n",
      "96: learn: 0.226566\ttest: 0.2256963\tbestTest: 0.2256963 (96)\ttotal: 8m 48s\tremaining: 16.3s\n",
      "97: learn: 0.2264897\ttest: 0.2256193\tbestTest: 0.2256193 (97)\ttotal: 8m 54s\tremaining: 10.9s\n",
      "98: learn: 0.2264173\ttest: 0.2255461\tbestTest: 0.2255461 (98)\ttotal: 8m 59s\tremaining: 5.45s\n",
      "99: learn: 0.2263146\ttest: 0.2254435\tbestTest: 0.2254435 (99)\ttotal: 9m 4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254435069\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-13 21:59:09.150354\n",
      "train time given below\n",
      "0:12:30.490841\n",
      "2018-03-13 21:59:09.162720\n",
      "2018-03-13 21:59:09.166320\n",
      "GINI ISIT = 0.456057466662\n",
      "2018-03-13 22:00:43.227387\n",
      "GINI OSIT = 0.457324649713\n",
      "2018-03-13 22:01:21.292984\n",
      "GINI OSOT = 0.411554144757\n",
      "2018-03-13 22:01:33.321217\n",
      "2018-03-13 22:01:33.323317\n",
      "num split = 32\n",
      "2018-03-13 22:01:33.324808\n",
      "model train start\n",
      "2018-03-13 22:01:33.325222\n",
      "0: learn: 0.6575731\ttest: 0.6575547\tbestTest: 0.6575547 (0)\ttotal: 5.19s\tremaining: 8m 33s\n",
      "1: learn: 0.6244882\ttest: 0.6244417\tbestTest: 0.6244417 (1)\ttotal: 10.7s\tremaining: 8m 46s\n",
      "2: learn: 0.5944354\ttest: 0.594369\tbestTest: 0.594369 (2)\ttotal: 16.4s\tremaining: 8m 51s\n",
      "3: learn: 0.5668168\ttest: 0.5667343\tbestTest: 0.5667343 (3)\ttotal: 22.4s\tremaining: 8m 57s\n",
      "4: learn: 0.5411609\ttest: 0.5410449\tbestTest: 0.5410449 (4)\ttotal: 28.8s\tremaining: 9m 6s\n",
      "5: learn: 0.5175295\ttest: 0.5173922\tbestTest: 0.5173922 (5)\ttotal: 35s\tremaining: 9m 7s\n",
      "6: learn: 0.4965309\ttest: 0.4963714\tbestTest: 0.4963714 (6)\ttotal: 41.3s\tremaining: 9m 8s\n",
      "7: learn: 0.4766886\ttest: 0.4765168\tbestTest: 0.4765168 (7)\ttotal: 47.2s\tremaining: 9m 2s\n",
      "8: learn: 0.4577145\ttest: 0.4575173\tbestTest: 0.4575173 (8)\ttotal: 52.3s\tremaining: 8m 48s\n",
      "9: learn: 0.4409096\ttest: 0.4406901\tbestTest: 0.4406901 (9)\ttotal: 58.4s\tremaining: 8m 46s\n",
      "10: learn: 0.4251572\ttest: 0.4249153\tbestTest: 0.4249153 (10)\ttotal: 1m 3s\tremaining: 8m 37s\n",
      "11: learn: 0.4103401\ttest: 0.4100792\tbestTest: 0.4100792 (11)\ttotal: 1m 9s\tremaining: 8m 29s\n",
      "12: learn: 0.3969394\ttest: 0.3966662\tbestTest: 0.3966662 (12)\ttotal: 1m 15s\tremaining: 8m 22s\n",
      "13: learn: 0.3845624\ttest: 0.3842722\tbestTest: 0.3842722 (13)\ttotal: 1m 20s\tremaining: 8m 12s\n",
      "14: learn: 0.3730959\ttest: 0.3727952\tbestTest: 0.3727952 (14)\ttotal: 1m 25s\tremaining: 8m 5s\n",
      "15: learn: 0.3624703\ttest: 0.3621479\tbestTest: 0.3621479 (15)\ttotal: 1m 31s\tremaining: 7m 57s\n",
      "16: learn: 0.3529021\ttest: 0.3525656\tbestTest: 0.3525656 (16)\ttotal: 1m 36s\tremaining: 7m 49s\n",
      "17: learn: 0.3445664\ttest: 0.3442148\tbestTest: 0.3442148 (17)\ttotal: 1m 42s\tremaining: 7m 47s\n",
      "18: learn: 0.3367148\ttest: 0.3363523\tbestTest: 0.3363523 (18)\ttotal: 1m 47s\tremaining: 7m 37s\n",
      "19: learn: 0.3294223\ttest: 0.3290448\tbestTest: 0.3290448 (19)\ttotal: 1m 52s\tremaining: 7m 29s\n",
      "20: learn: 0.3224727\ttest: 0.3220807\tbestTest: 0.3220807 (20)\ttotal: 1m 57s\tremaining: 7m 23s\n",
      "21: learn: 0.3156225\ttest: 0.3152095\tbestTest: 0.3152095 (21)\ttotal: 2m 2s\tremaining: 7m 16s\n",
      "22: learn: 0.3097348\ttest: 0.3093073\tbestTest: 0.3093073 (22)\ttotal: 2m 8s\tremaining: 7m 9s\n",
      "23: learn: 0.3042422\ttest: 0.3038024\tbestTest: 0.3038024 (23)\ttotal: 2m 13s\tremaining: 7m 3s\n",
      "24: learn: 0.2990857\ttest: 0.2986263\tbestTest: 0.2986263 (24)\ttotal: 2m 19s\tremaining: 6m 59s\n",
      "25: learn: 0.2941676\ttest: 0.2936915\tbestTest: 0.2936915 (25)\ttotal: 2m 24s\tremaining: 6m 51s\n",
      "26: learn: 0.2897414\ttest: 0.2892497\tbestTest: 0.2892497 (26)\ttotal: 2m 29s\tremaining: 6m 45s\n",
      "27: learn: 0.285592\ttest: 0.2850829\tbestTest: 0.2850829 (27)\ttotal: 2m 35s\tremaining: 6m 40s\n",
      "28: learn: 0.2819986\ttest: 0.2814763\tbestTest: 0.2814763 (28)\ttotal: 2m 41s\tremaining: 6m 35s\n",
      "29: learn: 0.2783249\ttest: 0.2777903\tbestTest: 0.2777903 (29)\ttotal: 2m 46s\tremaining: 6m 29s\n",
      "30: learn: 0.2749784\ttest: 0.274431\tbestTest: 0.274431 (30)\ttotal: 2m 52s\tremaining: 6m 23s\n",
      "31: learn: 0.2719098\ttest: 0.2713525\tbestTest: 0.2713525 (31)\ttotal: 2m 57s\tremaining: 6m 17s\n",
      "32: learn: 0.2689713\ttest: 0.2683997\tbestTest: 0.2683997 (32)\ttotal: 3m 2s\tremaining: 6m 11s\n",
      "33: learn: 0.2664296\ttest: 0.265848\tbestTest: 0.265848 (33)\ttotal: 3m 8s\tremaining: 6m 6s\n",
      "34: learn: 0.264061\ttest: 0.2634748\tbestTest: 0.2634748 (34)\ttotal: 3m 14s\tremaining: 6m 1s\n",
      "35: learn: 0.2617729\ttest: 0.2611783\tbestTest: 0.2611783 (35)\ttotal: 3m 20s\tremaining: 5m 57s\n",
      "36: learn: 0.259525\ttest: 0.2589182\tbestTest: 0.2589182 (36)\ttotal: 3m 25s\tremaining: 5m 50s\n",
      "37: learn: 0.257501\ttest: 0.2568861\tbestTest: 0.2568861 (37)\ttotal: 3m 30s\tremaining: 5m 44s\n",
      "38: learn: 0.2555273\ttest: 0.2549008\tbestTest: 0.2549008 (38)\ttotal: 3m 36s\tremaining: 5m 38s\n",
      "39: learn: 0.2537826\ttest: 0.2531509\tbestTest: 0.2531509 (39)\ttotal: 3m 41s\tremaining: 5m 32s\n",
      "40: learn: 0.2521689\ttest: 0.2515264\tbestTest: 0.2515264 (40)\ttotal: 3m 47s\tremaining: 5m 27s\n",
      "41: learn: 0.2506074\ttest: 0.2499557\tbestTest: 0.2499557 (41)\ttotal: 3m 52s\tremaining: 5m 21s\n",
      "42: learn: 0.2491283\ttest: 0.2484676\tbestTest: 0.2484676 (42)\ttotal: 3m 58s\tremaining: 5m 15s\n",
      "43: learn: 0.2478361\ttest: 0.2471673\tbestTest: 0.2471673 (43)\ttotal: 4m 3s\tremaining: 5m 9s\n",
      "44: learn: 0.246656\ttest: 0.2459798\tbestTest: 0.2459798 (44)\ttotal: 4m 9s\tremaining: 5m 5s\n",
      "45: learn: 0.2453851\ttest: 0.2447044\tbestTest: 0.2447044 (45)\ttotal: 4m 14s\tremaining: 4m 59s\n",
      "46: learn: 0.2442229\ttest: 0.2435353\tbestTest: 0.2435353 (46)\ttotal: 4m 20s\tremaining: 4m 53s\n",
      "47: learn: 0.2432358\ttest: 0.2425411\tbestTest: 0.2425411 (47)\ttotal: 4m 25s\tremaining: 4m 47s\n",
      "48: learn: 0.2422318\ttest: 0.2415304\tbestTest: 0.2415304 (48)\ttotal: 4m 30s\tremaining: 4m 41s\n",
      "49: learn: 0.2413997\ttest: 0.2406899\tbestTest: 0.2406899 (49)\ttotal: 4m 36s\tremaining: 4m 36s\n",
      "50: learn: 0.2405484\ttest: 0.2398303\tbestTest: 0.2398303 (50)\ttotal: 4m 41s\tremaining: 4m 30s\n",
      "51: learn: 0.2397669\ttest: 0.2390431\tbestTest: 0.2390431 (51)\ttotal: 4m 47s\tremaining: 4m 24s\n",
      "52: learn: 0.2389239\ttest: 0.2381931\tbestTest: 0.2381931 (52)\ttotal: 4m 52s\tremaining: 4m 19s\n",
      "53: learn: 0.2381808\ttest: 0.2374405\tbestTest: 0.2374405 (53)\ttotal: 4m 58s\tremaining: 4m 14s\n",
      "54: learn: 0.2375153\ttest: 0.2367671\tbestTest: 0.2367671 (54)\ttotal: 5m 3s\tremaining: 4m 8s\n",
      "55: learn: 0.236874\ttest: 0.2361193\tbestTest: 0.2361193 (55)\ttotal: 5m 8s\tremaining: 4m 2s\n",
      "56: learn: 0.2362799\ttest: 0.2355189\tbestTest: 0.2355189 (56)\ttotal: 5m 13s\tremaining: 3m 56s\n",
      "57: learn: 0.2356825\ttest: 0.2349146\tbestTest: 0.2349146 (57)\ttotal: 5m 18s\tremaining: 3m 50s\n",
      "58: learn: 0.2351229\ttest: 0.2343483\tbestTest: 0.2343483 (58)\ttotal: 5m 23s\tremaining: 3m 44s\n",
      "59: learn: 0.2345874\ttest: 0.2338073\tbestTest: 0.2338073 (59)\ttotal: 5m 29s\tremaining: 3m 39s\n",
      "60: learn: 0.2341022\ttest: 0.233317\tbestTest: 0.233317 (60)\ttotal: 5m 34s\tremaining: 3m 33s\n",
      "61: learn: 0.2336304\ttest: 0.232844\tbestTest: 0.232844 (61)\ttotal: 5m 40s\tremaining: 3m 28s\n",
      "62: learn: 0.2332387\ttest: 0.2324492\tbestTest: 0.2324492 (62)\ttotal: 5m 46s\tremaining: 3m 23s\n",
      "63: learn: 0.2328594\ttest: 0.2320669\tbestTest: 0.2320669 (63)\ttotal: 5m 52s\tremaining: 3m 18s\n",
      "64: learn: 0.232468\ttest: 0.2316722\tbestTest: 0.2316722 (64)\ttotal: 5m 57s\tremaining: 3m 12s\n",
      "65: learn: 0.2321561\ttest: 0.2313571\tbestTest: 0.2313571 (65)\ttotal: 6m 2s\tremaining: 3m 6s\n",
      "66: learn: 0.2318078\ttest: 0.2310073\tbestTest: 0.2310073 (66)\ttotal: 6m 8s\tremaining: 3m 1s\n",
      "67: learn: 0.2314866\ttest: 0.2306831\tbestTest: 0.2306831 (67)\ttotal: 6m 13s\tremaining: 2m 55s\n",
      "68: learn: 0.2311616\ttest: 0.2303551\tbestTest: 0.2303551 (68)\ttotal: 6m 18s\tremaining: 2m 50s\n",
      "69: learn: 0.2308955\ttest: 0.2300842\tbestTest: 0.2300842 (69)\ttotal: 6m 24s\tremaining: 2m 44s\n",
      "70: learn: 0.2305828\ttest: 0.2297679\tbestTest: 0.2297679 (70)\ttotal: 6m 28s\tremaining: 2m 38s\n",
      "71: learn: 0.2303107\ttest: 0.2294928\tbestTest: 0.2294928 (71)\ttotal: 6m 33s\tremaining: 2m 33s\n",
      "72: learn: 0.2300578\ttest: 0.2292367\tbestTest: 0.2292367 (72)\ttotal: 6m 38s\tremaining: 2m 27s\n",
      "73: learn: 0.2298124\ttest: 0.228991\tbestTest: 0.228991 (73)\ttotal: 6m 44s\tremaining: 2m 22s\n",
      "74: learn: 0.2295581\ttest: 0.2287347\tbestTest: 0.2287347 (74)\ttotal: 6m 49s\tremaining: 2m 16s\n",
      "75: learn: 0.2293437\ttest: 0.2285167\tbestTest: 0.2285167 (75)\ttotal: 6m 54s\tremaining: 2m 10s\n",
      "76: learn: 0.2291357\ttest: 0.2283049\tbestTest: 0.2283049 (76)\ttotal: 7m\tremaining: 2m 5s\n",
      "77: learn: 0.2289357\ttest: 0.2281036\tbestTest: 0.2281036 (77)\ttotal: 7m 4s\tremaining: 1m 59s\n",
      "78: learn: 0.2287564\ttest: 0.2279224\tbestTest: 0.2279224 (78)\ttotal: 7m 10s\tremaining: 1m 54s\n",
      "79: learn: 0.2286017\ttest: 0.2277652\tbestTest: 0.2277652 (79)\ttotal: 7m 15s\tremaining: 1m 48s\n",
      "80: learn: 0.2284501\ttest: 0.2276121\tbestTest: 0.2276121 (80)\ttotal: 7m 21s\tremaining: 1m 43s\n",
      "81: learn: 0.2282862\ttest: 0.2274465\tbestTest: 0.2274465 (81)\ttotal: 7m 26s\tremaining: 1m 38s\n",
      "82: learn: 0.2281587\ttest: 0.2273186\tbestTest: 0.2273186 (82)\ttotal: 7m 31s\tremaining: 1m 32s\n",
      "83: learn: 0.2280156\ttest: 0.2271748\tbestTest: 0.2271748 (83)\ttotal: 7m 36s\tremaining: 1m 26s\n",
      "84: learn: 0.2278736\ttest: 0.2270321\tbestTest: 0.2270321 (84)\ttotal: 7m 41s\tremaining: 1m 21s\n",
      "85: learn: 0.2277294\ttest: 0.2268866\tbestTest: 0.2268866 (85)\ttotal: 7m 46s\tremaining: 1m 15s\n",
      "86: learn: 0.2276059\ttest: 0.226761\tbestTest: 0.226761 (86)\ttotal: 7m 52s\tremaining: 1m 10s\n",
      "87: learn: 0.2274709\ttest: 0.2266239\tbestTest: 0.2266239 (87)\ttotal: 7m 57s\tremaining: 1m 5s\n",
      "88: learn: 0.2273492\ttest: 0.2265016\tbestTest: 0.2265016 (88)\ttotal: 8m 2s\tremaining: 59.6s\n",
      "89: learn: 0.2272387\ttest: 0.2263891\tbestTest: 0.2263891 (89)\ttotal: 8m 7s\tremaining: 54.2s\n",
      "90: learn: 0.2271282\ttest: 0.2262762\tbestTest: 0.2262762 (90)\ttotal: 8m 13s\tremaining: 48.8s\n",
      "91: learn: 0.2270446\ttest: 0.2261899\tbestTest: 0.2261899 (91)\ttotal: 8m 19s\tremaining: 43.4s\n",
      "92: learn: 0.226946\ttest: 0.2260905\tbestTest: 0.2260905 (92)\ttotal: 8m 25s\tremaining: 38s\n",
      "93: learn: 0.2268404\ttest: 0.2259842\tbestTest: 0.2259842 (93)\ttotal: 8m 30s\tremaining: 32.6s\n",
      "94: learn: 0.2267461\ttest: 0.2258899\tbestTest: 0.2258899 (94)\ttotal: 8m 35s\tremaining: 27.1s\n",
      "95: learn: 0.2266573\ttest: 0.2258001\tbestTest: 0.2258001 (95)\ttotal: 8m 40s\tremaining: 21.7s\n",
      "96: learn: 0.2265578\ttest: 0.2256999\tbestTest: 0.2256999 (96)\ttotal: 8m 45s\tremaining: 16.3s\n",
      "97: learn: 0.2264701\ttest: 0.225611\tbestTest: 0.225611 (97)\ttotal: 8m 50s\tremaining: 10.8s\n",
      "98: learn: 0.226381\ttest: 0.2255191\tbestTest: 0.2255191 (98)\ttotal: 8m 55s\tremaining: 5.41s\n",
      "99: learn: 0.226306\ttest: 0.2254422\tbestTest: 0.2254422 (99)\ttotal: 9m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254422029\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_32_cat_split_16_bag_temp_1\n",
      "2018-03-13 22:14:06.248748\n",
      "train time given below\n",
      "0:12:32.923526\n",
      "2018-03-13 22:14:06.263716\n",
      "2018-03-13 22:14:06.267085\n",
      "GINI ISIT = 0.455677653619\n",
      "2018-03-13 22:15:39.541774\n",
      "GINI OSIT = 0.456833548432\n",
      "2018-03-13 22:16:18.088605\n",
      "GINI OSOT = 0.41085029475\n",
      "2018-03-13 22:16:30.046744\n",
      "2018-03-13 22:16:30.048641\n",
      "num split = 64\n",
      "2018-03-13 22:16:30.050021\n",
      "model train start\n",
      "2018-03-13 22:16:30.050241\n",
      "0: learn: 0.657567\ttest: 0.6575488\tbestTest: 0.6575488 (0)\ttotal: 5.2s\tremaining: 8m 34s\n",
      "1: learn: 0.6245031\ttest: 0.6244553\tbestTest: 0.6244553 (1)\ttotal: 10.5s\tremaining: 8m 32s\n",
      "2: learn: 0.5943693\ttest: 0.594302\tbestTest: 0.594302 (2)\ttotal: 16.1s\tremaining: 8m 39s\n",
      "3: learn: 0.566572\ttest: 0.5664839\tbestTest: 0.5664839 (3)\ttotal: 21.9s\tremaining: 8m 46s\n",
      "4: learn: 0.5409201\ttest: 0.5408091\tbestTest: 0.5408091 (4)\ttotal: 27.4s\tremaining: 8m 40s\n",
      "5: learn: 0.5169836\ttest: 0.5168638\tbestTest: 0.5168638 (5)\ttotal: 33.3s\tremaining: 8m 42s\n",
      "6: learn: 0.495208\ttest: 0.4950505\tbestTest: 0.4950505 (6)\ttotal: 39.2s\tremaining: 8m 40s\n",
      "7: learn: 0.4755306\ttest: 0.475356\tbestTest: 0.475356 (7)\ttotal: 44.3s\tremaining: 8m 28s\n",
      "8: learn: 0.4577553\ttest: 0.4575669\tbestTest: 0.4575669 (8)\ttotal: 50.2s\tremaining: 8m 27s\n",
      "9: learn: 0.4402045\ttest: 0.4399881\tbestTest: 0.4399881 (9)\ttotal: 55.9s\tremaining: 8m 23s\n",
      "10: learn: 0.4248865\ttest: 0.4246504\tbestTest: 0.4246504 (10)\ttotal: 1m 2s\tremaining: 8m 22s\n",
      "11: learn: 0.4100131\ttest: 0.4097523\tbestTest: 0.4097523 (11)\ttotal: 1m 8s\tremaining: 8m 20s\n",
      "12: learn: 0.3971205\ttest: 0.3968399\tbestTest: 0.3968399 (12)\ttotal: 1m 13s\tremaining: 8m 14s\n",
      "13: learn: 0.3846651\ttest: 0.3843679\tbestTest: 0.3843679 (13)\ttotal: 1m 19s\tremaining: 8m 8s\n",
      "14: learn: 0.3734798\ttest: 0.3731674\tbestTest: 0.3731674 (14)\ttotal: 1m 24s\tremaining: 8m\n",
      "15: learn: 0.3631029\ttest: 0.362767\tbestTest: 0.362767 (15)\ttotal: 1m 30s\tremaining: 7m 52s\n",
      "16: learn: 0.3539905\ttest: 0.3536352\tbestTest: 0.3536352 (16)\ttotal: 1m 35s\tremaining: 7m 45s\n",
      "17: learn: 0.3449614\ttest: 0.3445911\tbestTest: 0.3445911 (17)\ttotal: 1m 40s\tremaining: 7m 36s\n",
      "18: learn: 0.3365908\ttest: 0.3362073\tbestTest: 0.3362073 (18)\ttotal: 1m 45s\tremaining: 7m 28s\n",
      "19: learn: 0.3297288\ttest: 0.329329\tbestTest: 0.329329 (19)\ttotal: 1m 47s\tremaining: 7m 10s\n",
      "20: learn: 0.3224019\ttest: 0.3219842\tbestTest: 0.3219842 (20)\ttotal: 1m 52s\tremaining: 7m 3s\n",
      "21: learn: 0.3159208\ttest: 0.3154908\tbestTest: 0.3154908 (21)\ttotal: 1m 57s\tremaining: 6m 56s\n",
      "22: learn: 0.309751\ttest: 0.3093066\tbestTest: 0.3093066 (22)\ttotal: 2m 2s\tremaining: 6m 49s\n",
      "23: learn: 0.3044318\ttest: 0.3039769\tbestTest: 0.3039769 (23)\ttotal: 2m 8s\tremaining: 6m 46s\n",
      "24: learn: 0.2994784\ttest: 0.2990157\tbestTest: 0.2990157 (24)\ttotal: 2m 14s\tremaining: 6m 42s\n",
      "25: learn: 0.2945662\ttest: 0.2940882\tbestTest: 0.2940882 (25)\ttotal: 2m 19s\tremaining: 6m 35s\n",
      "26: learn: 0.2901739\ttest: 0.2896883\tbestTest: 0.2896883 (26)\ttotal: 2m 24s\tremaining: 6m 30s\n",
      "27: learn: 0.2858521\ttest: 0.2853548\tbestTest: 0.2853548 (27)\ttotal: 2m 29s\tremaining: 6m 24s\n",
      "28: learn: 0.28195\ttest: 0.2814441\tbestTest: 0.2814441 (28)\ttotal: 2m 35s\tremaining: 6m 19s\n",
      "29: learn: 0.2783593\ttest: 0.2778429\tbestTest: 0.2778429 (29)\ttotal: 2m 40s\tremaining: 6m 14s\n",
      "30: learn: 0.2751085\ttest: 0.2745789\tbestTest: 0.2745789 (30)\ttotal: 2m 45s\tremaining: 6m 8s\n",
      "31: learn: 0.2719594\ttest: 0.2714154\tbestTest: 0.2714154 (31)\ttotal: 2m 50s\tremaining: 6m 2s\n",
      "32: learn: 0.2690188\ttest: 0.2684605\tbestTest: 0.2684605 (32)\ttotal: 2m 55s\tremaining: 5m 56s\n",
      "33: learn: 0.2664772\ttest: 0.2659107\tbestTest: 0.2659107 (33)\ttotal: 3m 1s\tremaining: 5m 52s\n",
      "34: learn: 0.2639214\ttest: 0.2633413\tbestTest: 0.2633413 (34)\ttotal: 3m 6s\tremaining: 5m 47s\n",
      "35: learn: 0.2615034\ttest: 0.2609263\tbestTest: 0.2609263 (35)\ttotal: 3m 12s\tremaining: 5m 42s\n",
      "36: learn: 0.2592709\ttest: 0.2586772\tbestTest: 0.2586772 (36)\ttotal: 3m 18s\tremaining: 5m 37s\n",
      "37: learn: 0.257213\ttest: 0.2566092\tbestTest: 0.2566092 (37)\ttotal: 3m 23s\tremaining: 5m 32s\n",
      "38: learn: 0.2553301\ttest: 0.2547163\tbestTest: 0.2547163 (38)\ttotal: 3m 29s\tremaining: 5m 27s\n",
      "39: learn: 0.2536663\ttest: 0.2530441\tbestTest: 0.2530441 (39)\ttotal: 3m 34s\tremaining: 5m 21s\n",
      "40: learn: 0.2519302\ttest: 0.2512982\tbestTest: 0.2512982 (40)\ttotal: 3m 39s\tremaining: 5m 15s\n",
      "41: learn: 0.2504713\ttest: 0.2498301\tbestTest: 0.2498301 (41)\ttotal: 3m 44s\tremaining: 5m 10s\n",
      "42: learn: 0.2490618\ttest: 0.2484104\tbestTest: 0.2484104 (42)\ttotal: 3m 50s\tremaining: 5m 5s\n",
      "43: learn: 0.2476916\ttest: 0.2470322\tbestTest: 0.2470322 (43)\ttotal: 3m 55s\tremaining: 4m 59s\n",
      "44: learn: 0.2464219\ttest: 0.2457528\tbestTest: 0.2457528 (44)\ttotal: 4m\tremaining: 4m 54s\n",
      "45: learn: 0.2452079\ttest: 0.2445313\tbestTest: 0.2445313 (45)\ttotal: 4m 5s\tremaining: 4m 48s\n",
      "46: learn: 0.2440748\ttest: 0.2433883\tbestTest: 0.2433883 (46)\ttotal: 4m 10s\tremaining: 4m 42s\n",
      "47: learn: 0.242978\ttest: 0.2422804\tbestTest: 0.2422804 (47)\ttotal: 4m 15s\tremaining: 4m 37s\n",
      "48: learn: 0.2420328\ttest: 0.2413317\tbestTest: 0.2413317 (48)\ttotal: 4m 21s\tremaining: 4m 32s\n",
      "49: learn: 0.2412045\ttest: 0.2404948\tbestTest: 0.2404948 (49)\ttotal: 4m 26s\tremaining: 4m 26s\n",
      "50: learn: 0.2403874\ttest: 0.2396693\tbestTest: 0.2396693 (50)\ttotal: 4m 31s\tremaining: 4m 21s\n",
      "51: learn: 0.2396291\ttest: 0.2389055\tbestTest: 0.2389055 (51)\ttotal: 4m 37s\tremaining: 4m 16s\n",
      "52: learn: 0.2388266\ttest: 0.2380961\tbestTest: 0.2380961 (52)\ttotal: 4m 42s\tremaining: 4m 10s\n",
      "53: learn: 0.2381003\ttest: 0.2373626\tbestTest: 0.2373626 (53)\ttotal: 4m 47s\tremaining: 4m 5s\n",
      "54: learn: 0.2374538\ttest: 0.2367109\tbestTest: 0.2367109 (54)\ttotal: 4m 53s\tremaining: 4m\n",
      "55: learn: 0.2368144\ttest: 0.2360644\tbestTest: 0.2360644 (55)\ttotal: 4m 59s\tremaining: 3m 55s\n",
      "56: learn: 0.2361984\ttest: 0.2354443\tbestTest: 0.2354443 (56)\ttotal: 5m 4s\tremaining: 3m 49s\n",
      "57: learn: 0.235626\ttest: 0.2348652\tbestTest: 0.2348652 (57)\ttotal: 5m 9s\tremaining: 3m 43s\n",
      "58: learn: 0.2351133\ttest: 0.2343408\tbestTest: 0.2343408 (58)\ttotal: 5m 15s\tremaining: 3m 38s\n",
      "59: learn: 0.2345814\ttest: 0.2338057\tbestTest: 0.2338057 (59)\ttotal: 5m 19s\tremaining: 3m 33s\n",
      "60: learn: 0.234158\ttest: 0.2333797\tbestTest: 0.2333797 (60)\ttotal: 5m 26s\tremaining: 3m 28s\n",
      "61: learn: 0.2337028\ttest: 0.2329188\tbestTest: 0.2329188 (61)\ttotal: 5m 31s\tremaining: 3m 23s\n",
      "62: learn: 0.2332776\ttest: 0.2324921\tbestTest: 0.2324921 (62)\ttotal: 5m 36s\tremaining: 3m 17s\n",
      "63: learn: 0.2328993\ttest: 0.2321095\tbestTest: 0.2321095 (63)\ttotal: 5m 41s\tremaining: 3m 12s\n",
      "64: learn: 0.2325045\ttest: 0.2317107\tbestTest: 0.2317107 (64)\ttotal: 5m 47s\tremaining: 3m 6s\n",
      "65: learn: 0.2321595\ttest: 0.2313612\tbestTest: 0.2313612 (65)\ttotal: 5m 52s\tremaining: 3m 1s\n",
      "66: learn: 0.2318175\ttest: 0.2310134\tbestTest: 0.2310134 (66)\ttotal: 5m 57s\tremaining: 2m 56s\n",
      "67: learn: 0.231492\ttest: 0.2306869\tbestTest: 0.2306869 (67)\ttotal: 6m 2s\tremaining: 2m 50s\n",
      "68: learn: 0.2311971\ttest: 0.2303877\tbestTest: 0.2303877 (68)\ttotal: 6m 8s\tremaining: 2m 45s\n",
      "69: learn: 0.2308964\ttest: 0.2300838\tbestTest: 0.2300838 (69)\ttotal: 6m 13s\tremaining: 2m 40s\n",
      "70: learn: 0.2306142\ttest: 0.2297989\tbestTest: 0.2297989 (70)\ttotal: 6m 18s\tremaining: 2m 34s\n",
      "71: learn: 0.2303406\ttest: 0.2295227\tbestTest: 0.2295227 (71)\ttotal: 6m 23s\tremaining: 2m 29s\n",
      "72: learn: 0.2301014\ttest: 0.2292812\tbestTest: 0.2292812 (72)\ttotal: 6m 28s\tremaining: 2m 23s\n",
      "73: learn: 0.2298574\ttest: 0.2290346\tbestTest: 0.2290346 (73)\ttotal: 6m 34s\tremaining: 2m 18s\n",
      "74: learn: 0.2296242\ttest: 0.2287977\tbestTest: 0.2287977 (74)\ttotal: 6m 39s\tremaining: 2m 13s\n",
      "75: learn: 0.2294317\ttest: 0.2286036\tbestTest: 0.2286036 (75)\ttotal: 6m 44s\tremaining: 2m 7s\n",
      "76: learn: 0.2292495\ttest: 0.2284199\tbestTest: 0.2284199 (76)\ttotal: 6m 49s\tremaining: 2m 2s\n",
      "77: learn: 0.229047\ttest: 0.2282142\tbestTest: 0.2282142 (77)\ttotal: 6m 55s\tremaining: 1m 57s\n",
      "78: learn: 0.2288525\ttest: 0.2280168\tbestTest: 0.2280168 (78)\ttotal: 7m\tremaining: 1m 51s\n",
      "79: learn: 0.2286556\ttest: 0.2278168\tbestTest: 0.2278168 (79)\ttotal: 7m 5s\tremaining: 1m 46s\n",
      "80: learn: 0.228475\ttest: 0.2276345\tbestTest: 0.2276345 (80)\ttotal: 7m 9s\tremaining: 1m 40s\n",
      "81: learn: 0.2283159\ttest: 0.2274758\tbestTest: 0.2274758 (81)\ttotal: 7m 15s\tremaining: 1m 35s\n",
      "82: learn: 0.2281467\ttest: 0.2273032\tbestTest: 0.2273032 (82)\ttotal: 7m 20s\tremaining: 1m 30s\n",
      "83: learn: 0.2279999\ttest: 0.2271549\tbestTest: 0.2271549 (83)\ttotal: 7m 26s\tremaining: 1m 24s\n",
      "84: learn: 0.2278507\ttest: 0.2270032\tbestTest: 0.2270032 (84)\ttotal: 7m 31s\tremaining: 1m 19s\n",
      "85: learn: 0.2277192\ttest: 0.2268695\tbestTest: 0.2268695 (85)\ttotal: 7m 36s\tremaining: 1m 14s\n",
      "86: learn: 0.2275923\ttest: 0.2267391\tbestTest: 0.2267391 (86)\ttotal: 7m 42s\tremaining: 1m 9s\n",
      "87: learn: 0.2274614\ttest: 0.2266061\tbestTest: 0.2266061 (87)\ttotal: 7m 47s\tremaining: 1m 3s\n",
      "88: learn: 0.2273369\ttest: 0.22648\tbestTest: 0.22648 (88)\ttotal: 7m 52s\tremaining: 58.4s\n",
      "89: learn: 0.2272319\ttest: 0.2263727\tbestTest: 0.2263727 (89)\ttotal: 7m 58s\tremaining: 53.1s\n",
      "90: learn: 0.2270921\ttest: 0.2262329\tbestTest: 0.2262329 (90)\ttotal: 8m 4s\tremaining: 47.9s\n",
      "91: learn: 0.2269926\ttest: 0.2261304\tbestTest: 0.2261304 (91)\ttotal: 8m 9s\tremaining: 42.5s\n",
      "92: learn: 0.2268706\ttest: 0.2260081\tbestTest: 0.2260081 (92)\ttotal: 8m 14s\tremaining: 37.2s\n",
      "93: learn: 0.2267587\ttest: 0.2258963\tbestTest: 0.2258963 (93)\ttotal: 8m 19s\tremaining: 31.9s\n",
      "94: learn: 0.2266451\ttest: 0.2257822\tbestTest: 0.2257822 (94)\ttotal: 8m 25s\tremaining: 26.6s\n",
      "95: learn: 0.2265275\ttest: 0.225665\tbestTest: 0.225665 (95)\ttotal: 8m 30s\tremaining: 21.3s\n",
      "96: learn: 0.2264513\ttest: 0.2255871\tbestTest: 0.2255871 (96)\ttotal: 8m 36s\tremaining: 16s\n",
      "97: learn: 0.2263602\ttest: 0.2254951\tbestTest: 0.2254951 (97)\ttotal: 8m 41s\tremaining: 10.6s\n",
      "98: learn: 0.2262762\ttest: 0.2254093\tbestTest: 0.2254093 (98)\ttotal: 8m 46s\tremaining: 5.32s\n",
      "99: learn: 0.2261941\ttest: 0.2253246\tbestTest: 0.2253246 (99)\ttotal: 8m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2253245608\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_64_cat_split_16_bag_temp_1\n",
      "2018-03-13 22:28:59.879898\n",
      "train time given below\n",
      "0:12:29.829657\n",
      "2018-03-13 22:29:00.074520\n",
      "2018-03-13 22:29:00.078599\n",
      "GINI ISIT = 0.456933642558\n",
      "2018-03-13 22:30:31.852326\n",
      "GINI OSIT = 0.458370333417\n",
      "2018-03-13 22:31:10.293149\n",
      "GINI OSOT = 0.413166294172\n",
      "2018-03-13 22:31:22.038616\n",
      "2018-03-13 22:31:22.040627\n",
      "num split = 128\n",
      "2018-03-13 22:31:22.042065\n",
      "model train start\n",
      "2018-03-13 22:31:22.042304\n",
      "0: learn: 0.6581866\ttest: 0.6581573\tbestTest: 0.6581573 (0)\ttotal: 3.61s\tremaining: 5m 57s\n",
      "1: learn: 0.6256835\ttest: 0.6256275\tbestTest: 0.6256275 (1)\ttotal: 9.92s\tremaining: 8m 5s\n",
      "2: learn: 0.5950976\ttest: 0.5950213\tbestTest: 0.5950213 (2)\ttotal: 15.6s\tremaining: 8m 23s\n",
      "3: learn: 0.5671602\ttest: 0.5670661\tbestTest: 0.5670661 (3)\ttotal: 21.4s\tremaining: 8m 33s\n",
      "4: learn: 0.5415567\ttest: 0.5414338\tbestTest: 0.5414338 (4)\ttotal: 27.7s\tremaining: 8m 45s\n",
      "5: learn: 0.5173878\ttest: 0.5172488\tbestTest: 0.5172488 (5)\ttotal: 33.3s\tremaining: 8m 42s\n",
      "6: learn: 0.4958949\ttest: 0.4957409\tbestTest: 0.4957409 (6)\ttotal: 39.3s\tremaining: 8m 42s\n",
      "7: learn: 0.4754494\ttest: 0.4752687\tbestTest: 0.4752687 (7)\ttotal: 44.4s\tremaining: 8m 30s\n",
      "8: learn: 0.4569905\ttest: 0.4567955\tbestTest: 0.4567955 (8)\ttotal: 50.1s\tremaining: 8m 26s\n",
      "9: learn: 0.4403821\ttest: 0.4401601\tbestTest: 0.4401601 (9)\ttotal: 55.9s\tremaining: 8m 23s\n",
      "10: learn: 0.4249301\ttest: 0.4246959\tbestTest: 0.4246959 (10)\ttotal: 1m 1s\tremaining: 8m 20s\n",
      "11: learn: 0.4112644\ttest: 0.4110146\tbestTest: 0.4110146 (11)\ttotal: 1m 4s\tremaining: 7m 54s\n",
      "12: learn: 0.3976725\ttest: 0.3974036\tbestTest: 0.3974036 (12)\ttotal: 1m 10s\tremaining: 7m 52s\n",
      "13: learn: 0.384876\ttest: 0.3845835\tbestTest: 0.3845835 (13)\ttotal: 1m 15s\tremaining: 7m 44s\n",
      "14: learn: 0.3739876\ttest: 0.3736738\tbestTest: 0.3736738 (14)\ttotal: 1m 20s\tremaining: 7m 36s\n",
      "15: learn: 0.363417\ttest: 0.3630775\tbestTest: 0.3630775 (15)\ttotal: 1m 25s\tremaining: 7m 29s\n",
      "16: learn: 0.3535879\ttest: 0.3532286\tbestTest: 0.3532286 (16)\ttotal: 1m 30s\tremaining: 7m 21s\n",
      "17: learn: 0.3446133\ttest: 0.3442304\tbestTest: 0.3442304 (17)\ttotal: 1m 35s\tremaining: 7m 14s\n",
      "18: learn: 0.3367779\ttest: 0.336377\tbestTest: 0.336377 (18)\ttotal: 1m 40s\tremaining: 7m 10s\n",
      "19: learn: 0.3293672\ttest: 0.3289531\tbestTest: 0.3289531 (19)\ttotal: 1m 46s\tremaining: 7m 6s\n",
      "20: learn: 0.3220507\ttest: 0.3216187\tbestTest: 0.3216187 (20)\ttotal: 1m 51s\tremaining: 6m 59s\n",
      "21: learn: 0.3159512\ttest: 0.3155109\tbestTest: 0.3155109 (21)\ttotal: 1m 56s\tremaining: 6m 53s\n",
      "22: learn: 0.3103001\ttest: 0.3098481\tbestTest: 0.3098481 (22)\ttotal: 2m 1s\tremaining: 6m 47s\n",
      "23: learn: 0.3046916\ttest: 0.3042354\tbestTest: 0.3042354 (23)\ttotal: 2m 7s\tremaining: 6m 42s\n",
      "24: learn: 0.2993332\ttest: 0.2988653\tbestTest: 0.2988653 (24)\ttotal: 2m 12s\tremaining: 6m 37s\n",
      "25: learn: 0.2946375\ttest: 0.2941566\tbestTest: 0.2941566 (25)\ttotal: 2m 17s\tremaining: 6m 32s\n",
      "26: learn: 0.290001\ttest: 0.2895012\tbestTest: 0.2895012 (26)\ttotal: 2m 23s\tremaining: 6m 27s\n",
      "27: learn: 0.2856958\ttest: 0.2851807\tbestTest: 0.2851807 (27)\ttotal: 2m 28s\tremaining: 6m 21s\n",
      "28: learn: 0.2818412\ttest: 0.2813153\tbestTest: 0.2813153 (28)\ttotal: 2m 33s\tremaining: 6m 15s\n",
      "29: learn: 0.2784306\ttest: 0.2778959\tbestTest: 0.2778959 (29)\ttotal: 2m 38s\tremaining: 6m 10s\n",
      "30: learn: 0.2750889\ttest: 0.2745409\tbestTest: 0.2745409 (30)\ttotal: 2m 43s\tremaining: 6m 4s\n",
      "31: learn: 0.2719029\ttest: 0.2713436\tbestTest: 0.2713436 (31)\ttotal: 2m 49s\tremaining: 6m\n",
      "32: learn: 0.2689887\ttest: 0.2684204\tbestTest: 0.2684204 (32)\ttotal: 2m 54s\tremaining: 5m 53s\n",
      "33: learn: 0.266438\ttest: 0.2658549\tbestTest: 0.2658549 (33)\ttotal: 2m 58s\tremaining: 5m 47s\n",
      "34: learn: 0.2639633\ttest: 0.2633715\tbestTest: 0.2633715 (34)\ttotal: 3m 4s\tremaining: 5m 42s\n",
      "35: learn: 0.2616224\ttest: 0.2610196\tbestTest: 0.2610196 (35)\ttotal: 3m 10s\tremaining: 5m 37s\n",
      "36: learn: 0.2594971\ttest: 0.258884\tbestTest: 0.258884 (36)\ttotal: 3m 15s\tremaining: 5m 32s\n",
      "37: learn: 0.2574739\ttest: 0.2568514\tbestTest: 0.2568514 (37)\ttotal: 3m 20s\tremaining: 5m 26s\n",
      "38: learn: 0.2555676\ttest: 0.2549357\tbestTest: 0.2549357 (38)\ttotal: 3m 25s\tremaining: 5m 21s\n",
      "39: learn: 0.253698\ttest: 0.2530595\tbestTest: 0.2530595 (39)\ttotal: 3m 30s\tremaining: 5m 16s\n",
      "40: learn: 0.2520361\ttest: 0.2513944\tbestTest: 0.2513944 (40)\ttotal: 3m 36s\tremaining: 5m 11s\n",
      "41: learn: 0.2505819\ttest: 0.2499159\tbestTest: 0.2499159 (41)\ttotal: 3m 42s\tremaining: 5m 6s\n",
      "42: learn: 0.2491997\ttest: 0.2485236\tbestTest: 0.2485236 (42)\ttotal: 3m 47s\tremaining: 5m 1s\n",
      "43: learn: 0.2478933\ttest: 0.2472073\tbestTest: 0.2472073 (43)\ttotal: 3m 52s\tremaining: 4m 56s\n",
      "44: learn: 0.2465489\ttest: 0.2458534\tbestTest: 0.2458534 (44)\ttotal: 3m 57s\tremaining: 4m 50s\n",
      "45: learn: 0.2453125\ttest: 0.2446098\tbestTest: 0.2446098 (45)\ttotal: 4m 3s\tremaining: 4m 45s\n",
      "46: learn: 0.2441576\ttest: 0.2434469\tbestTest: 0.2434469 (46)\ttotal: 4m 8s\tremaining: 4m 40s\n",
      "47: learn: 0.2431815\ttest: 0.2424608\tbestTest: 0.2424608 (47)\ttotal: 4m 13s\tremaining: 4m 34s\n",
      "48: learn: 0.2422709\ttest: 0.2415422\tbestTest: 0.2415422 (48)\ttotal: 4m 19s\tremaining: 4m 30s\n",
      "49: learn: 0.2413936\ttest: 0.2406577\tbestTest: 0.2406577 (49)\ttotal: 4m 24s\tremaining: 4m 24s\n",
      "50: learn: 0.2405716\ttest: 0.2398301\tbestTest: 0.2398301 (50)\ttotal: 4m 30s\tremaining: 4m 19s\n",
      "51: learn: 0.2397193\ttest: 0.2389694\tbestTest: 0.2389694 (51)\ttotal: 4m 35s\tremaining: 4m 14s\n",
      "52: learn: 0.2389723\ttest: 0.2382157\tbestTest: 0.2382157 (52)\ttotal: 4m 40s\tremaining: 4m 9s\n",
      "53: learn: 0.2382273\ttest: 0.2374661\tbestTest: 0.2374661 (53)\ttotal: 4m 45s\tremaining: 4m 3s\n",
      "54: learn: 0.2375254\ttest: 0.2367574\tbestTest: 0.2367574 (54)\ttotal: 4m 51s\tremaining: 3m 58s\n",
      "55: learn: 0.2368653\ttest: 0.2360921\tbestTest: 0.2360921 (55)\ttotal: 4m 56s\tremaining: 3m 52s\n",
      "56: learn: 0.2362395\ttest: 0.2354616\tbestTest: 0.2354616 (56)\ttotal: 5m 1s\tremaining: 3m 47s\n",
      "57: learn: 0.2357208\ttest: 0.2349402\tbestTest: 0.2349402 (57)\ttotal: 5m 7s\tremaining: 3m 42s\n",
      "58: learn: 0.235146\ttest: 0.2343644\tbestTest: 0.2343644 (58)\ttotal: 5m 12s\tremaining: 3m 37s\n",
      "59: learn: 0.2346365\ttest: 0.2338522\tbestTest: 0.2338522 (59)\ttotal: 5m 18s\tremaining: 3m 32s\n",
      "60: learn: 0.2341617\ttest: 0.2333756\tbestTest: 0.2333756 (60)\ttotal: 5m 24s\tremaining: 3m 27s\n",
      "61: learn: 0.2337652\ttest: 0.2329756\tbestTest: 0.2329756 (61)\ttotal: 5m 30s\tremaining: 3m 22s\n",
      "62: learn: 0.2333296\ttest: 0.2325344\tbestTest: 0.2325344 (62)\ttotal: 5m 35s\tremaining: 3m 16s\n",
      "63: learn: 0.2329166\ttest: 0.2321179\tbestTest: 0.2321179 (63)\ttotal: 5m 40s\tremaining: 3m 11s\n",
      "64: learn: 0.2325349\ttest: 0.2317318\tbestTest: 0.2317318 (64)\ttotal: 5m 45s\tremaining: 3m 6s\n",
      "65: learn: 0.232186\ttest: 0.2313794\tbestTest: 0.2313794 (65)\ttotal: 5m 50s\tremaining: 3m\n",
      "66: learn: 0.2318369\ttest: 0.2310274\tbestTest: 0.2310274 (66)\ttotal: 5m 55s\tremaining: 2m 55s\n",
      "67: learn: 0.2314761\ttest: 0.2306621\tbestTest: 0.2306621 (67)\ttotal: 6m 1s\tremaining: 2m 50s\n",
      "68: learn: 0.2311896\ttest: 0.2303726\tbestTest: 0.2303726 (68)\ttotal: 6m 6s\tremaining: 2m 44s\n",
      "69: learn: 0.2308737\ttest: 0.2300541\tbestTest: 0.2300541 (69)\ttotal: 6m 12s\tremaining: 2m 39s\n",
      "70: learn: 0.2305987\ttest: 0.2297772\tbestTest: 0.2297772 (70)\ttotal: 6m 18s\tremaining: 2m 34s\n",
      "71: learn: 0.2303324\ttest: 0.2295079\tbestTest: 0.2295079 (71)\ttotal: 6m 23s\tremaining: 2m 29s\n",
      "72: learn: 0.2300738\ttest: 0.229247\tbestTest: 0.229247 (72)\ttotal: 6m 28s\tremaining: 2m 23s\n",
      "73: learn: 0.2298527\ttest: 0.2290249\tbestTest: 0.2290249 (73)\ttotal: 6m 34s\tremaining: 2m 18s\n",
      "74: learn: 0.2296187\ttest: 0.228789\tbestTest: 0.228789 (74)\ttotal: 6m 39s\tremaining: 2m 13s\n",
      "75: learn: 0.2293945\ttest: 0.2285614\tbestTest: 0.2285614 (75)\ttotal: 6m 44s\tremaining: 2m 7s\n",
      "76: learn: 0.2292082\ttest: 0.2283736\tbestTest: 0.2283736 (76)\ttotal: 6m 50s\tremaining: 2m 2s\n",
      "77: learn: 0.2289995\ttest: 0.228163\tbestTest: 0.228163 (77)\ttotal: 6m 55s\tremaining: 1m 57s\n",
      "78: learn: 0.228806\ttest: 0.2279667\tbestTest: 0.2279667 (78)\ttotal: 7m 1s\tremaining: 1m 51s\n",
      "79: learn: 0.2286308\ttest: 0.2277886\tbestTest: 0.2277886 (79)\ttotal: 7m 6s\tremaining: 1m 46s\n",
      "80: learn: 0.2284505\ttest: 0.227606\tbestTest: 0.227606 (80)\ttotal: 7m 11s\tremaining: 1m 41s\n",
      "81: learn: 0.2282775\ttest: 0.2274296\tbestTest: 0.2274296 (81)\ttotal: 7m 17s\tremaining: 1m 35s\n",
      "82: learn: 0.2281264\ttest: 0.2272761\tbestTest: 0.2272761 (82)\ttotal: 7m 22s\tremaining: 1m 30s\n",
      "83: learn: 0.2279852\ttest: 0.2271319\tbestTest: 0.2271319 (83)\ttotal: 7m 27s\tremaining: 1m 25s\n",
      "84: learn: 0.2278351\ttest: 0.2269788\tbestTest: 0.2269788 (84)\ttotal: 7m 32s\tremaining: 1m 19s\n",
      "85: learn: 0.2276969\ttest: 0.2268387\tbestTest: 0.2268387 (85)\ttotal: 7m 38s\tremaining: 1m 14s\n",
      "86: learn: 0.2275809\ttest: 0.2267215\tbestTest: 0.2267215 (86)\ttotal: 7m 44s\tremaining: 1m 9s\n",
      "87: learn: 0.2274593\ttest: 0.2265987\tbestTest: 0.2265987 (87)\ttotal: 7m 49s\tremaining: 1m 3s\n",
      "88: learn: 0.2273348\ttest: 0.2264713\tbestTest: 0.2264713 (88)\ttotal: 7m 54s\tremaining: 58.7s\n",
      "89: learn: 0.2272198\ttest: 0.2263548\tbestTest: 0.2263548 (89)\ttotal: 8m\tremaining: 53.4s\n",
      "90: learn: 0.2271203\ttest: 0.2262534\tbestTest: 0.2262534 (90)\ttotal: 8m 6s\tremaining: 48.1s\n",
      "91: learn: 0.227017\ttest: 0.2261477\tbestTest: 0.2261477 (91)\ttotal: 8m 11s\tremaining: 42.7s\n",
      "92: learn: 0.2269044\ttest: 0.2260345\tbestTest: 0.2260345 (92)\ttotal: 8m 16s\tremaining: 37.4s\n",
      "93: learn: 0.2268044\ttest: 0.2259342\tbestTest: 0.2259342 (93)\ttotal: 8m 21s\tremaining: 32s\n",
      "94: learn: 0.2267207\ttest: 0.2258502\tbestTest: 0.2258502 (94)\ttotal: 8m 26s\tremaining: 26.7s\n",
      "95: learn: 0.226623\ttest: 0.2257518\tbestTest: 0.2257518 (95)\ttotal: 8m 31s\tremaining: 21.3s\n",
      "96: learn: 0.226545\ttest: 0.2256733\tbestTest: 0.2256733 (96)\ttotal: 8m 37s\tremaining: 16s\n",
      "97: learn: 0.2264834\ttest: 0.2256097\tbestTest: 0.2256097 (97)\ttotal: 8m 43s\tremaining: 10.7s\n",
      "98: learn: 0.2263934\ttest: 0.2255184\tbestTest: 0.2255184 (98)\ttotal: 8m 48s\tremaining: 5.34s\n",
      "99: learn: 0.2263169\ttest: 0.2254396\tbestTest: 0.2254396 (99)\ttotal: 8m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254396103\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_16_bag_temp_1\n",
      "2018-03-13 22:44:16.775822\n",
      "train time given below\n",
      "0:12:54.733518\n",
      "2018-03-13 22:44:17.197419\n",
      "2018-03-13 22:44:17.201735\n",
      "GINI ISIT = 0.455322130277\n",
      "2018-03-13 22:45:54.478355\n",
      "GINI OSIT = 0.456847407704\n",
      "2018-03-13 22:46:33.121993\n",
      "GINI OSOT = 0.411085756609\n",
      "2018-03-13 22:46:45.321607\n",
      "2018-03-13 22:46:45.323643\n",
      "num split = 255\n",
      "2018-03-13 22:46:45.325240\n",
      "model train start\n",
      "2018-03-13 22:46:45.325464\n",
      "0: learn: 0.6581823\ttest: 0.6581524\tbestTest: 0.6581524 (0)\ttotal: 3.74s\tremaining: 6m 10s\n",
      "1: learn: 0.6256908\ttest: 0.6256303\tbestTest: 0.6256303 (1)\ttotal: 10.4s\tremaining: 8m 27s\n",
      "2: learn: 0.5951939\ttest: 0.5951155\tbestTest: 0.5951155 (2)\ttotal: 16.3s\tremaining: 8m 46s\n",
      "3: learn: 0.5672509\ttest: 0.5671549\tbestTest: 0.5671549 (3)\ttotal: 22.4s\tremaining: 8m 57s\n",
      "4: learn: 0.5420096\ttest: 0.5418923\tbestTest: 0.5418923 (4)\ttotal: 28.9s\tremaining: 9m 9s\n",
      "5: learn: 0.518162\ttest: 0.5180339\tbestTest: 0.5180339 (5)\ttotal: 34s\tremaining: 8m 52s\n",
      "6: learn: 0.4963503\ttest: 0.4962077\tbestTest: 0.4962077 (6)\ttotal: 39.4s\tremaining: 8m 43s\n",
      "7: learn: 0.4763638\ttest: 0.4762056\tbestTest: 0.4762056 (7)\ttotal: 44.8s\tremaining: 8m 35s\n",
      "8: learn: 0.4578852\ttest: 0.4577114\tbestTest: 0.4577114 (8)\ttotal: 50.2s\tremaining: 8m 27s\n",
      "9: learn: 0.4405104\ttest: 0.4403003\tbestTest: 0.4403003 (9)\ttotal: 55.8s\tremaining: 8m 21s\n",
      "10: learn: 0.425056\ttest: 0.4248308\tbestTest: 0.4248308 (10)\ttotal: 1m 1s\tremaining: 8m 16s\n",
      "11: learn: 0.4102389\ttest: 0.409991\tbestTest: 0.409991 (11)\ttotal: 1m 7s\tremaining: 8m 11s\n",
      "12: learn: 0.3967952\ttest: 0.3965273\tbestTest: 0.3965273 (12)\ttotal: 1m 12s\tremaining: 8m 4s\n",
      "13: learn: 0.3850968\ttest: 0.3848103\tbestTest: 0.3848103 (13)\ttotal: 1m 17s\tremaining: 7m 58s\n",
      "14: learn: 0.3737085\ttest: 0.3734132\tbestTest: 0.3734132 (14)\ttotal: 1m 23s\tremaining: 7m 52s\n",
      "15: learn: 0.3634591\ttest: 0.3631409\tbestTest: 0.3631409 (15)\ttotal: 1m 29s\tremaining: 7m 51s\n",
      "16: learn: 0.3538553\ttest: 0.3535219\tbestTest: 0.3535219 (16)\ttotal: 1m 35s\tremaining: 7m 44s\n",
      "17: learn: 0.345151\ttest: 0.3448037\tbestTest: 0.3448037 (17)\ttotal: 1m 40s\tremaining: 7m 39s\n",
      "18: learn: 0.3370387\ttest: 0.3366763\tbestTest: 0.3366763 (18)\ttotal: 1m 46s\tremaining: 7m 32s\n",
      "19: learn: 0.3293456\ttest: 0.3289642\tbestTest: 0.3289642 (19)\ttotal: 1m 51s\tremaining: 7m 25s\n",
      "20: learn: 0.3220823\ttest: 0.3216836\tbestTest: 0.3216836 (20)\ttotal: 1m 56s\tremaining: 7m 18s\n",
      "21: learn: 0.3160558\ttest: 0.315639\tbestTest: 0.315639 (21)\ttotal: 2m 1s\tremaining: 7m 11s\n",
      "22: learn: 0.3098958\ttest: 0.3094629\tbestTest: 0.3094629 (22)\ttotal: 2m 6s\tremaining: 7m 4s\n",
      "23: learn: 0.3044765\ttest: 0.3040296\tbestTest: 0.3040296 (23)\ttotal: 2m 12s\tremaining: 6m 59s\n",
      "24: learn: 0.2993415\ttest: 0.298884\tbestTest: 0.298884 (24)\ttotal: 2m 18s\tremaining: 6m 54s\n",
      "25: learn: 0.2944219\ttest: 0.2939475\tbestTest: 0.2939475 (25)\ttotal: 2m 23s\tremaining: 6m 47s\n",
      "26: learn: 0.2899375\ttest: 0.2894525\tbestTest: 0.2894525 (26)\ttotal: 2m 29s\tremaining: 6m 43s\n",
      "27: learn: 0.2858216\ttest: 0.2853203\tbestTest: 0.2853203 (27)\ttotal: 2m 34s\tremaining: 6m 37s\n",
      "28: learn: 0.2819574\ttest: 0.28144\tbestTest: 0.28144 (28)\ttotal: 2m 39s\tremaining: 6m 30s\n",
      "29: learn: 0.2784059\ttest: 0.2778829\tbestTest: 0.2778829 (29)\ttotal: 2m 45s\tremaining: 6m 25s\n",
      "30: learn: 0.2752297\ttest: 0.2746988\tbestTest: 0.2746988 (30)\ttotal: 2m 50s\tremaining: 6m 19s\n",
      "31: learn: 0.2721533\ttest: 0.2716081\tbestTest: 0.2716081 (31)\ttotal: 2m 55s\tremaining: 6m 13s\n",
      "32: learn: 0.2692266\ttest: 0.2686692\tbestTest: 0.2686692 (32)\ttotal: 3m 1s\tremaining: 6m 8s\n",
      "33: learn: 0.2666218\ttest: 0.2660523\tbestTest: 0.2660523 (33)\ttotal: 3m 6s\tremaining: 6m 2s\n",
      "34: learn: 0.2640831\ttest: 0.2635001\tbestTest: 0.2635001 (34)\ttotal: 3m 11s\tremaining: 5m 55s\n",
      "35: learn: 0.2617477\ttest: 0.2611555\tbestTest: 0.2611555 (35)\ttotal: 3m 16s\tremaining: 5m 49s\n",
      "36: learn: 0.2596139\ttest: 0.2590116\tbestTest: 0.2590116 (36)\ttotal: 3m 21s\tremaining: 5m 43s\n",
      "37: learn: 0.2574548\ttest: 0.2568402\tbestTest: 0.2568402 (37)\ttotal: 3m 26s\tremaining: 5m 37s\n",
      "38: learn: 0.2556235\ttest: 0.2550022\tbestTest: 0.2550022 (38)\ttotal: 3m 32s\tremaining: 5m 32s\n",
      "39: learn: 0.2538589\ttest: 0.2532268\tbestTest: 0.2532268 (39)\ttotal: 3m 37s\tremaining: 5m 25s\n",
      "40: learn: 0.2521643\ttest: 0.2515192\tbestTest: 0.2515192 (40)\ttotal: 3m 42s\tremaining: 5m 20s\n",
      "41: learn: 0.2505768\ttest: 0.249923\tbestTest: 0.249923 (41)\ttotal: 3m 48s\tremaining: 5m 15s\n",
      "42: learn: 0.2491292\ttest: 0.2484669\tbestTest: 0.2484669 (42)\ttotal: 3m 54s\tremaining: 5m 10s\n",
      "43: learn: 0.2478701\ttest: 0.2471998\tbestTest: 0.2471998 (43)\ttotal: 3m 59s\tremaining: 5m 4s\n",
      "44: learn: 0.2467326\ttest: 0.2460505\tbestTest: 0.2460505 (44)\ttotal: 4m 5s\tremaining: 4m 59s\n",
      "45: learn: 0.2454851\ttest: 0.2447922\tbestTest: 0.2447922 (45)\ttotal: 4m 10s\tremaining: 4m 54s\n",
      "46: learn: 0.2444168\ttest: 0.2437158\tbestTest: 0.2437158 (46)\ttotal: 4m 16s\tremaining: 4m 48s\n",
      "47: learn: 0.2433414\ttest: 0.2426353\tbestTest: 0.2426353 (47)\ttotal: 4m 21s\tremaining: 4m 42s\n",
      "48: learn: 0.242317\ttest: 0.2416025\tbestTest: 0.2416025 (48)\ttotal: 4m 26s\tremaining: 4m 36s\n",
      "49: learn: 0.2414002\ttest: 0.2406768\tbestTest: 0.2406768 (49)\ttotal: 4m 31s\tremaining: 4m 31s\n",
      "50: learn: 0.2404974\ttest: 0.2397661\tbestTest: 0.2397661 (50)\ttotal: 4m 36s\tremaining: 4m 25s\n",
      "51: learn: 0.2396781\ttest: 0.2389395\tbestTest: 0.2389395 (51)\ttotal: 4m 41s\tremaining: 4m 19s\n",
      "52: learn: 0.2389156\ttest: 0.2381527\tbestTest: 0.2381527 (52)\ttotal: 4m 47s\tremaining: 4m 14s\n",
      "53: learn: 0.2382567\ttest: 0.2374892\tbestTest: 0.2374892 (53)\ttotal: 4m 52s\tremaining: 4m 9s\n",
      "54: learn: 0.2375605\ttest: 0.2367881\tbestTest: 0.2367881 (54)\ttotal: 4m 58s\tremaining: 4m 4s\n",
      "55: learn: 0.2368743\ttest: 0.2360977\tbestTest: 0.2360977 (55)\ttotal: 5m 3s\tremaining: 3m 58s\n",
      "56: learn: 0.2363252\ttest: 0.2355454\tbestTest: 0.2355454 (56)\ttotal: 5m 9s\tremaining: 3m 53s\n",
      "57: learn: 0.2357277\ttest: 0.234943\tbestTest: 0.234943 (57)\ttotal: 5m 14s\tremaining: 3m 47s\n",
      "58: learn: 0.2352235\ttest: 0.2344337\tbestTest: 0.2344337 (58)\ttotal: 5m 19s\tremaining: 3m 41s\n",
      "59: learn: 0.2347132\ttest: 0.2339201\tbestTest: 0.2339201 (59)\ttotal: 5m 24s\tremaining: 3m 36s\n",
      "60: learn: 0.2342588\ttest: 0.2334626\tbestTest: 0.2334626 (60)\ttotal: 5m 29s\tremaining: 3m 30s\n",
      "61: learn: 0.2338281\ttest: 0.2330284\tbestTest: 0.2330284 (61)\ttotal: 5m 35s\tremaining: 3m 25s\n",
      "62: learn: 0.2334314\ttest: 0.2326283\tbestTest: 0.2326283 (62)\ttotal: 5m 41s\tremaining: 3m 20s\n",
      "63: learn: 0.233026\ttest: 0.2322193\tbestTest: 0.2322193 (63)\ttotal: 5m 46s\tremaining: 3m 14s\n",
      "64: learn: 0.2326614\ttest: 0.2318517\tbestTest: 0.2318517 (64)\ttotal: 5m 51s\tremaining: 3m 9s\n",
      "65: learn: 0.232299\ttest: 0.2314848\tbestTest: 0.2314848 (65)\ttotal: 5m 56s\tremaining: 3m 3s\n",
      "66: learn: 0.2319414\ttest: 0.2311221\tbestTest: 0.2311221 (66)\ttotal: 6m 2s\tremaining: 2m 58s\n",
      "67: learn: 0.2316688\ttest: 0.2308469\tbestTest: 0.2308469 (67)\ttotal: 6m 8s\tremaining: 2m 53s\n",
      "68: learn: 0.2313774\ttest: 0.2305547\tbestTest: 0.2305547 (68)\ttotal: 6m 13s\tremaining: 2m 47s\n",
      "69: learn: 0.2310926\ttest: 0.2302662\tbestTest: 0.2302662 (69)\ttotal: 6m 18s\tremaining: 2m 42s\n",
      "70: learn: 0.2308092\ttest: 0.2299793\tbestTest: 0.2299793 (70)\ttotal: 6m 23s\tremaining: 2m 36s\n",
      "71: learn: 0.2305579\ttest: 0.2297265\tbestTest: 0.2297265 (71)\ttotal: 6m 28s\tremaining: 2m 31s\n",
      "72: learn: 0.2303321\ttest: 0.2294978\tbestTest: 0.2294978 (72)\ttotal: 6m 34s\tremaining: 2m 25s\n",
      "73: learn: 0.2300957\ttest: 0.2292583\tbestTest: 0.2292583 (73)\ttotal: 6m 39s\tremaining: 2m 20s\n",
      "74: learn: 0.2298424\ttest: 0.2290032\tbestTest: 0.2290032 (74)\ttotal: 6m 45s\tremaining: 2m 15s\n",
      "75: learn: 0.2296111\ttest: 0.2287688\tbestTest: 0.2287688 (75)\ttotal: 6m 51s\tremaining: 2m 9s\n",
      "76: learn: 0.2294041\ttest: 0.2285594\tbestTest: 0.2285594 (76)\ttotal: 6m 56s\tremaining: 2m 4s\n",
      "77: learn: 0.2291916\ttest: 0.2283437\tbestTest: 0.2283437 (77)\ttotal: 7m 1s\tremaining: 1m 58s\n",
      "78: learn: 0.2289667\ttest: 0.2281183\tbestTest: 0.2281183 (78)\ttotal: 7m 6s\tremaining: 1m 53s\n",
      "79: learn: 0.2287987\ttest: 0.2279429\tbestTest: 0.2279429 (79)\ttotal: 7m 12s\tremaining: 1m 48s\n",
      "80: learn: 0.2286379\ttest: 0.2277799\tbestTest: 0.2277799 (80)\ttotal: 7m 17s\tremaining: 1m 42s\n",
      "81: learn: 0.2284698\ttest: 0.2276107\tbestTest: 0.2276107 (81)\ttotal: 7m 22s\tremaining: 1m 37s\n",
      "82: learn: 0.2283093\ttest: 0.2274497\tbestTest: 0.2274497 (82)\ttotal: 7m 28s\tremaining: 1m 31s\n",
      "83: learn: 0.2281595\ttest: 0.2272974\tbestTest: 0.2272974 (83)\ttotal: 7m 34s\tremaining: 1m 26s\n",
      "84: learn: 0.2280191\ttest: 0.2271543\tbestTest: 0.2271543 (84)\ttotal: 7m 39s\tremaining: 1m 21s\n",
      "85: learn: 0.2278877\ttest: 0.2270205\tbestTest: 0.2270205 (85)\ttotal: 7m 44s\tremaining: 1m 15s\n",
      "86: learn: 0.2277584\ttest: 0.2268904\tbestTest: 0.2268904 (86)\ttotal: 7m 50s\tremaining: 1m 10s\n",
      "87: learn: 0.2276374\ttest: 0.2267692\tbestTest: 0.2267692 (87)\ttotal: 7m 55s\tremaining: 1m 4s\n",
      "88: learn: 0.227496\ttest: 0.2266267\tbestTest: 0.2266267 (88)\ttotal: 8m\tremaining: 59.4s\n",
      "89: learn: 0.227392\ttest: 0.226521\tbestTest: 0.226521 (89)\ttotal: 8m 6s\tremaining: 54.1s\n",
      "90: learn: 0.2272851\ttest: 0.2264128\tbestTest: 0.2264128 (90)\ttotal: 8m 12s\tremaining: 48.7s\n",
      "91: learn: 0.227171\ttest: 0.2262988\tbestTest: 0.2262988 (91)\ttotal: 8m 17s\tremaining: 43.2s\n",
      "92: learn: 0.2270634\ttest: 0.2261905\tbestTest: 0.2261905 (92)\ttotal: 8m 22s\tremaining: 37.8s\n",
      "93: learn: 0.2269494\ttest: 0.226076\tbestTest: 0.226076 (93)\ttotal: 8m 28s\tremaining: 32.5s\n",
      "94: learn: 0.2268599\ttest: 0.2259856\tbestTest: 0.2259856 (94)\ttotal: 8m 33s\tremaining: 27s\n",
      "95: learn: 0.2267655\ttest: 0.225891\tbestTest: 0.225891 (95)\ttotal: 8m 38s\tremaining: 21.6s\n",
      "96: learn: 0.2266772\ttest: 0.2258012\tbestTest: 0.2258012 (96)\ttotal: 8m 43s\tremaining: 16.2s\n",
      "97: learn: 0.2265967\ttest: 0.2257199\tbestTest: 0.2257199 (97)\ttotal: 8m 49s\tremaining: 10.8s\n",
      "98: learn: 0.226513\ttest: 0.2256367\tbestTest: 0.2256367 (98)\ttotal: 8m 54s\tremaining: 5.4s\n",
      "99: learn: 0.2264321\ttest: 0.2255552\tbestTest: 0.2255552 (99)\ttotal: 8m 59s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.225555216\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_255_cat_split_16_bag_temp_1\n",
      "2018-03-13 23:00:31.818937\n",
      "train time given below\n",
      "0:13:46.493473\n",
      "2018-03-13 23:00:31.834674\n",
      "2018-03-13 23:00:31.838241\n",
      "GINI ISIT = 0.455057337161\n",
      "2018-03-13 23:02:07.686586\n",
      "GINI OSIT = 0.456448038832\n",
      "2018-03-13 23:02:46.812496\n",
      "GINI OSOT = 0.41194004472\n",
      "2018-03-13 23:02:58.931327\n",
      "2018-03-13 23:02:58.933372\n"
     ]
    }
   ],
   "source": [
    "# optimize num split\n",
    "\n",
    "for num_split in num_split_pv:\n",
    "    \n",
    "    print('num split = ' + str(num_split))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_def,\n",
    "                           lrn_rt = lrn_rt_def,\n",
    "                           dep = dep_def,\n",
    "                           l2_reg = l2_reg_def,\n",
    "                           num_split = num_split,\n",
    "                           cat_split = cat_split_def,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_def\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt_def\n",
    "    result_df_temp.loc[0,'depth'] = dep_def\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_def\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_def\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100   1          0.03     6                 1             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 5             128   \n",
       "0    100   1          0.03     6                10             128   \n",
       "0    100   1          0.03     6                50             128   \n",
       "0    100   1          0.03     6               100             128   \n",
       "0    100   1          0.03     6                 3               5   \n",
       "0    100   1          0.03     6                 3              10   \n",
       "0    100   1          0.03     6                 3              16   \n",
       "0    100   1          0.03     6                 3              32   \n",
       "0    100   1          0.03     6                 3              64   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             255   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical split = 5\n",
      "2018-03-13 23:02:59.019118\n",
      "model train start\n",
      "2018-03-13 23:02:59.019347\n",
      "0: learn: 0.6581866\ttest: 0.6581573\tbestTest: 0.6581573 (0)\ttotal: 3.61s\tremaining: 5m 57s\n",
      "1: learn: 0.6252668\ttest: 0.6252262\tbestTest: 0.6252262 (1)\ttotal: 9.54s\tremaining: 7m 47s\n",
      "2: learn: 0.5948417\ttest: 0.5947751\tbestTest: 0.5947751 (2)\ttotal: 15.5s\tremaining: 8m 21s\n",
      "3: learn: 0.5665218\ttest: 0.5664289\tbestTest: 0.5664289 (3)\ttotal: 21.4s\tremaining: 8m 34s\n",
      "4: learn: 0.5412846\ttest: 0.5411758\tbestTest: 0.5411758 (4)\ttotal: 27.6s\tremaining: 8m 45s\n",
      "5: learn: 0.517928\ttest: 0.5178035\tbestTest: 0.5178035 (5)\ttotal: 33.1s\tremaining: 8m 38s\n",
      "6: learn: 0.4967755\ttest: 0.4966319\tbestTest: 0.4966319 (6)\ttotal: 36.1s\tremaining: 7m 59s\n",
      "7: learn: 0.4766265\ttest: 0.4764526\tbestTest: 0.4764526 (7)\ttotal: 42.3s\tremaining: 8m 6s\n",
      "8: learn: 0.4577359\ttest: 0.4575408\tbestTest: 0.4575408 (8)\ttotal: 47.5s\tremaining: 8m\n",
      "9: learn: 0.440928\ttest: 0.4407172\tbestTest: 0.4407172 (9)\ttotal: 53.4s\tremaining: 8m\n",
      "10: learn: 0.4258073\ttest: 0.4255834\tbestTest: 0.4255834 (10)\ttotal: 59.6s\tremaining: 8m 1s\n",
      "11: learn: 0.4110747\ttest: 0.410828\tbestTest: 0.410828 (11)\ttotal: 1m 4s\tremaining: 7m 55s\n",
      "12: learn: 0.3977037\ttest: 0.3974418\tbestTest: 0.3974418 (12)\ttotal: 1m 10s\tremaining: 7m 53s\n",
      "13: learn: 0.3854558\ttest: 0.3851746\tbestTest: 0.3851746 (13)\ttotal: 1m 15s\tremaining: 7m 45s\n",
      "14: learn: 0.3737014\ttest: 0.3734051\tbestTest: 0.3734051 (14)\ttotal: 1m 20s\tremaining: 7m 37s\n",
      "15: learn: 0.3630256\ttest: 0.3627128\tbestTest: 0.3627128 (15)\ttotal: 1m 26s\tremaining: 7m 31s\n",
      "16: learn: 0.3532399\ttest: 0.352904\tbestTest: 0.352904 (16)\ttotal: 1m 31s\tremaining: 7m 25s\n",
      "17: learn: 0.3441826\ttest: 0.3438277\tbestTest: 0.3438277 (17)\ttotal: 1m 36s\tremaining: 7m 20s\n",
      "18: learn: 0.3356564\ttest: 0.3352822\tbestTest: 0.3352822 (18)\ttotal: 1m 41s\tremaining: 7m 13s\n",
      "19: learn: 0.3281433\ttest: 0.3277513\tbestTest: 0.3277513 (19)\ttotal: 1m 47s\tremaining: 7m 9s\n",
      "20: learn: 0.321564\ttest: 0.3211603\tbestTest: 0.3211603 (20)\ttotal: 1m 52s\tremaining: 7m 4s\n",
      "21: learn: 0.3155129\ttest: 0.3150912\tbestTest: 0.3150912 (21)\ttotal: 1m 59s\tremaining: 7m 2s\n",
      "22: learn: 0.3095721\ttest: 0.3091331\tbestTest: 0.3091331 (22)\ttotal: 2m 4s\tremaining: 6m 55s\n",
      "23: learn: 0.3043309\ttest: 0.3038786\tbestTest: 0.3038786 (23)\ttotal: 2m 10s\tremaining: 6m 52s\n",
      "24: learn: 0.2992755\ttest: 0.2988092\tbestTest: 0.2988092 (24)\ttotal: 2m 15s\tremaining: 6m 45s\n",
      "25: learn: 0.2943066\ttest: 0.2938235\tbestTest: 0.2938235 (25)\ttotal: 2m 20s\tremaining: 6m 40s\n",
      "26: learn: 0.2897377\ttest: 0.2892368\tbestTest: 0.2892368 (26)\ttotal: 2m 26s\tremaining: 6m 35s\n",
      "27: learn: 0.2854519\ttest: 0.284937\tbestTest: 0.284937 (27)\ttotal: 2m 31s\tremaining: 6m 29s\n",
      "28: learn: 0.281818\ttest: 0.2812865\tbestTest: 0.2812865 (28)\ttotal: 2m 37s\tremaining: 6m 24s\n",
      "29: learn: 0.2782538\ttest: 0.2777117\tbestTest: 0.2777117 (29)\ttotal: 2m 42s\tremaining: 6m 18s\n",
      "30: learn: 0.2749866\ttest: 0.2744337\tbestTest: 0.2744337 (30)\ttotal: 2m 47s\tremaining: 6m 12s\n",
      "31: learn: 0.2718525\ttest: 0.271283\tbestTest: 0.271283 (31)\ttotal: 2m 52s\tremaining: 6m 6s\n",
      "32: learn: 0.2688985\ttest: 0.2683159\tbestTest: 0.2683159 (32)\ttotal: 2m 58s\tremaining: 6m 1s\n",
      "33: learn: 0.2662509\ttest: 0.2656603\tbestTest: 0.2656603 (33)\ttotal: 3m 3s\tremaining: 5m 57s\n",
      "34: learn: 0.2637256\ttest: 0.2631201\tbestTest: 0.2631201 (34)\ttotal: 3m 9s\tremaining: 5m 51s\n",
      "35: learn: 0.2613832\ttest: 0.2607687\tbestTest: 0.2607687 (35)\ttotal: 3m 14s\tremaining: 5m 45s\n",
      "36: learn: 0.2592972\ttest: 0.2586709\tbestTest: 0.2586709 (36)\ttotal: 3m 19s\tremaining: 5m 39s\n",
      "37: learn: 0.2571879\ttest: 0.2565529\tbestTest: 0.2565529 (37)\ttotal: 3m 24s\tremaining: 5m 34s\n",
      "38: learn: 0.2554315\ttest: 0.2547898\tbestTest: 0.2547898 (38)\ttotal: 3m 30s\tremaining: 5m 29s\n",
      "39: learn: 0.2536794\ttest: 0.2530277\tbestTest: 0.2530277 (39)\ttotal: 3m 35s\tremaining: 5m 23s\n",
      "40: learn: 0.2521028\ttest: 0.2514415\tbestTest: 0.2514415 (40)\ttotal: 3m 40s\tremaining: 5m 17s\n",
      "41: learn: 0.2505824\ttest: 0.2499117\tbestTest: 0.2499117 (41)\ttotal: 3m 46s\tremaining: 5m 12s\n",
      "42: learn: 0.2491192\ttest: 0.2484403\tbestTest: 0.2484403 (42)\ttotal: 3m 51s\tremaining: 5m 6s\n",
      "43: learn: 0.2477615\ttest: 0.247073\tbestTest: 0.247073 (43)\ttotal: 3m 56s\tremaining: 5m 1s\n",
      "44: learn: 0.2464751\ttest: 0.2457756\tbestTest: 0.2457756 (44)\ttotal: 4m 1s\tremaining: 4m 55s\n",
      "45: learn: 0.2453923\ttest: 0.244683\tbestTest: 0.244683 (45)\ttotal: 4m 6s\tremaining: 4m 49s\n",
      "46: learn: 0.2442994\ttest: 0.2435822\tbestTest: 0.2435822 (46)\ttotal: 4m 11s\tremaining: 4m 43s\n",
      "47: learn: 0.2433129\ttest: 0.2425906\tbestTest: 0.2425906 (47)\ttotal: 4m 16s\tremaining: 4m 38s\n",
      "48: learn: 0.2423591\ttest: 0.241633\tbestTest: 0.241633 (48)\ttotal: 4m 22s\tremaining: 4m 32s\n",
      "49: learn: 0.2414928\ttest: 0.2407606\tbestTest: 0.2407606 (49)\ttotal: 4m 27s\tremaining: 4m 27s\n",
      "50: learn: 0.2406769\ttest: 0.2399398\tbestTest: 0.2399398 (50)\ttotal: 4m 33s\tremaining: 4m 22s\n",
      "51: learn: 0.2398277\ttest: 0.2390849\tbestTest: 0.2390849 (51)\ttotal: 4m 38s\tremaining: 4m 17s\n",
      "52: learn: 0.2390473\ttest: 0.2382989\tbestTest: 0.2382989 (52)\ttotal: 4m 43s\tremaining: 4m 11s\n",
      "53: learn: 0.2383465\ttest: 0.2375929\tbestTest: 0.2375929 (53)\ttotal: 4m 48s\tremaining: 4m 5s\n",
      "54: learn: 0.2376533\ttest: 0.2368953\tbestTest: 0.2368953 (54)\ttotal: 4m 54s\tremaining: 4m\n",
      "55: learn: 0.2370345\ttest: 0.2362698\tbestTest: 0.2362698 (55)\ttotal: 4m 59s\tremaining: 3m 54s\n",
      "56: learn: 0.236424\ttest: 0.2356545\tbestTest: 0.2356545 (56)\ttotal: 5m 4s\tremaining: 3m 49s\n",
      "57: learn: 0.235839\ttest: 0.2350648\tbestTest: 0.2350648 (57)\ttotal: 5m 9s\tremaining: 3m 44s\n",
      "58: learn: 0.2353575\ttest: 0.2345794\tbestTest: 0.2345794 (58)\ttotal: 5m 15s\tremaining: 3m 39s\n",
      "59: learn: 0.234881\ttest: 0.234096\tbestTest: 0.234096 (59)\ttotal: 5m 20s\tremaining: 3m 33s\n",
      "60: learn: 0.2344464\ttest: 0.2336566\tbestTest: 0.2336566 (60)\ttotal: 5m 25s\tremaining: 3m 28s\n",
      "61: learn: 0.234001\ttest: 0.2332077\tbestTest: 0.2332077 (61)\ttotal: 5m 30s\tremaining: 3m 22s\n",
      "62: learn: 0.2335995\ttest: 0.2328009\tbestTest: 0.2328009 (62)\ttotal: 5m 35s\tremaining: 3m 17s\n",
      "63: learn: 0.2331592\ttest: 0.2323562\tbestTest: 0.2323562 (63)\ttotal: 5m 40s\tremaining: 3m 11s\n",
      "64: learn: 0.2327852\ttest: 0.2319783\tbestTest: 0.2319783 (64)\ttotal: 5m 45s\tremaining: 3m 5s\n",
      "65: learn: 0.2324054\ttest: 0.2315945\tbestTest: 0.2315945 (65)\ttotal: 5m 50s\tremaining: 3m\n",
      "66: learn: 0.232044\ttest: 0.2312278\tbestTest: 0.2312278 (66)\ttotal: 5m 55s\tremaining: 2m 55s\n",
      "67: learn: 0.2317221\ttest: 0.2309011\tbestTest: 0.2309011 (67)\ttotal: 6m\tremaining: 2m 49s\n",
      "68: learn: 0.2314179\ttest: 0.2305924\tbestTest: 0.2305924 (68)\ttotal: 6m 5s\tremaining: 2m 44s\n",
      "69: learn: 0.2311273\ttest: 0.2302984\tbestTest: 0.2302984 (69)\ttotal: 6m 11s\tremaining: 2m 39s\n",
      "70: learn: 0.2308629\ttest: 0.2300313\tbestTest: 0.2300313 (70)\ttotal: 6m 16s\tremaining: 2m 33s\n",
      "71: learn: 0.2306264\ttest: 0.2297919\tbestTest: 0.2297919 (71)\ttotal: 6m 21s\tremaining: 2m 28s\n",
      "72: learn: 0.2303809\ttest: 0.2295419\tbestTest: 0.2295419 (72)\ttotal: 6m 26s\tremaining: 2m 23s\n",
      "73: learn: 0.2301358\ttest: 0.2292931\tbestTest: 0.2292931 (73)\ttotal: 6m 31s\tremaining: 2m 17s\n",
      "74: learn: 0.22991\ttest: 0.2290646\tbestTest: 0.2290646 (74)\ttotal: 6m 36s\tremaining: 2m 12s\n",
      "75: learn: 0.2297058\ttest: 0.228858\tbestTest: 0.228858 (75)\ttotal: 6m 42s\tremaining: 2m 7s\n",
      "76: learn: 0.2295128\ttest: 0.2286635\tbestTest: 0.2286635 (76)\ttotal: 6m 47s\tremaining: 2m 1s\n",
      "77: learn: 0.2293267\ttest: 0.2284736\tbestTest: 0.2284736 (77)\ttotal: 6m 52s\tremaining: 1m 56s\n",
      "78: learn: 0.2291136\ttest: 0.228262\tbestTest: 0.228262 (78)\ttotal: 6m 57s\tremaining: 1m 51s\n",
      "79: learn: 0.2289187\ttest: 0.2280651\tbestTest: 0.2280651 (79)\ttotal: 7m 2s\tremaining: 1m 45s\n",
      "80: learn: 0.2287738\ttest: 0.2279179\tbestTest: 0.2279179 (80)\ttotal: 7m 8s\tremaining: 1m 40s\n",
      "81: learn: 0.2286122\ttest: 0.2277539\tbestTest: 0.2277539 (81)\ttotal: 7m 13s\tremaining: 1m 35s\n",
      "82: learn: 0.2284922\ttest: 0.2276326\tbestTest: 0.2276326 (82)\ttotal: 7m 18s\tremaining: 1m 29s\n",
      "83: learn: 0.2283524\ttest: 0.2274889\tbestTest: 0.2274889 (83)\ttotal: 7m 24s\tremaining: 1m 24s\n",
      "84: learn: 0.2282098\ttest: 0.2273429\tbestTest: 0.2273429 (84)\ttotal: 7m 29s\tremaining: 1m 19s\n",
      "85: learn: 0.2280758\ttest: 0.2272064\tbestTest: 0.2272064 (85)\ttotal: 7m 34s\tremaining: 1m 14s\n",
      "86: learn: 0.2279597\ttest: 0.2270888\tbestTest: 0.2270888 (86)\ttotal: 7m 40s\tremaining: 1m 8s\n",
      "87: learn: 0.227836\ttest: 0.2269647\tbestTest: 0.2269647 (87)\ttotal: 7m 45s\tremaining: 1m 3s\n",
      "88: learn: 0.227711\ttest: 0.2268365\tbestTest: 0.2268365 (88)\ttotal: 7m 50s\tremaining: 58.2s\n",
      "89: learn: 0.2275925\ttest: 0.2267182\tbestTest: 0.2267182 (89)\ttotal: 7m 56s\tremaining: 52.9s\n",
      "90: learn: 0.2274778\ttest: 0.2266024\tbestTest: 0.2266024 (90)\ttotal: 8m 1s\tremaining: 47.6s\n",
      "91: learn: 0.2273489\ttest: 0.2264727\tbestTest: 0.2264727 (91)\ttotal: 8m 6s\tremaining: 42.3s\n",
      "92: learn: 0.2272031\ttest: 0.2263278\tbestTest: 0.2263278 (92)\ttotal: 8m 12s\tremaining: 37.1s\n",
      "93: learn: 0.2270967\ttest: 0.2262197\tbestTest: 0.2262197 (93)\ttotal: 8m 17s\tremaining: 31.7s\n",
      "94: learn: 0.2269971\ttest: 0.2261191\tbestTest: 0.2261191 (94)\ttotal: 8m 22s\tremaining: 26.4s\n",
      "95: learn: 0.2268781\ttest: 0.226\tbestTest: 0.226 (95)\ttotal: 8m 27s\tremaining: 21.1s\n",
      "96: learn: 0.226803\ttest: 0.2259245\tbestTest: 0.2259245 (96)\ttotal: 8m 32s\tremaining: 15.8s\n",
      "97: learn: 0.2267252\ttest: 0.2258453\tbestTest: 0.2258453 (97)\ttotal: 8m 38s\tremaining: 10.6s\n",
      "98: learn: 0.2266453\ttest: 0.2257645\tbestTest: 0.2257645 (98)\ttotal: 8m 43s\tremaining: 5.29s\n",
      "99: learn: 0.2265757\ttest: 0.2256941\tbestTest: 0.2256941 (99)\ttotal: 8m 49s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2256940526\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_5_bag_temp_1\n",
      "2018-03-13 23:15:46.619857\n",
      "train time given below\n",
      "0:12:47.600510\n",
      "2018-03-13 23:15:46.651568\n",
      "2018-03-13 23:15:46.655013\n",
      "GINI ISIT = 0.45184850015\n",
      "2018-03-13 23:17:20.432789\n",
      "GINI OSIT = 0.45362274336\n",
      "2018-03-13 23:17:57.244212\n",
      "GINI OSOT = 0.402904385163\n",
      "2018-03-13 23:18:08.828749\n",
      "2018-03-13 23:18:08.830713\n",
      "categorical split = 10\n",
      "2018-03-13 23:18:08.832081\n",
      "model train start\n",
      "2018-03-13 23:18:08.832361\n",
      "0: learn: 0.6581866\ttest: 0.6581573\tbestTest: 0.6581573 (0)\ttotal: 3.64s\tremaining: 6m\n",
      "1: learn: 0.625671\ttest: 0.6256336\tbestTest: 0.6256336 (1)\ttotal: 9.92s\tremaining: 8m 6s\n",
      "2: learn: 0.5955652\ttest: 0.5955005\tbestTest: 0.5955005 (2)\ttotal: 15.6s\tremaining: 8m 25s\n",
      "3: learn: 0.5674207\ttest: 0.5673386\tbestTest: 0.5673386 (3)\ttotal: 21.5s\tremaining: 8m 36s\n",
      "4: learn: 0.5418034\ttest: 0.5417231\tbestTest: 0.5417231 (4)\ttotal: 28s\tremaining: 8m 52s\n",
      "5: learn: 0.5176103\ttest: 0.5175118\tbestTest: 0.5175118 (5)\ttotal: 33.8s\tremaining: 8m 49s\n",
      "6: learn: 0.4961064\ttest: 0.4959908\tbestTest: 0.4959908 (6)\ttotal: 39.9s\tremaining: 8m 49s\n",
      "7: learn: 0.4757801\ttest: 0.4756361\tbestTest: 0.4756361 (7)\ttotal: 44.9s\tremaining: 8m 35s\n",
      "8: learn: 0.4572933\ttest: 0.4571323\tbestTest: 0.4571323 (8)\ttotal: 50.6s\tremaining: 8m 31s\n",
      "9: learn: 0.4406184\ttest: 0.4404293\tbestTest: 0.4404293 (9)\ttotal: 56.2s\tremaining: 8m 25s\n",
      "10: learn: 0.42509\ttest: 0.4248885\tbestTest: 0.4248885 (10)\ttotal: 1m 1s\tremaining: 8m 21s\n",
      "11: learn: 0.4114191\ttest: 0.4112002\tbestTest: 0.4112002 (11)\ttotal: 1m 4s\tremaining: 7m 55s\n",
      "12: learn: 0.3978631\ttest: 0.3976254\tbestTest: 0.3976254 (12)\ttotal: 1m 10s\tremaining: 7m 52s\n",
      "13: learn: 0.3856841\ttest: 0.3854282\tbestTest: 0.3854282 (13)\ttotal: 1m 16s\tremaining: 7m 48s\n",
      "14: learn: 0.3742447\ttest: 0.3739638\tbestTest: 0.3739638 (14)\ttotal: 1m 21s\tremaining: 7m 42s\n",
      "15: learn: 0.3634943\ttest: 0.3631913\tbestTest: 0.3631913 (15)\ttotal: 1m 26s\tremaining: 7m 35s\n",
      "16: learn: 0.3536973\ttest: 0.3533716\tbestTest: 0.3533716 (16)\ttotal: 1m 32s\tremaining: 7m 29s\n",
      "17: learn: 0.3451135\ttest: 0.3447729\tbestTest: 0.3447729 (17)\ttotal: 1m 37s\tremaining: 7m 22s\n",
      "18: learn: 0.3371657\ttest: 0.3368113\tbestTest: 0.3368113 (18)\ttotal: 1m 43s\tremaining: 7m 19s\n",
      "19: learn: 0.3297871\ttest: 0.3294252\tbestTest: 0.3294252 (19)\ttotal: 1m 49s\tremaining: 7m 19s\n",
      "20: learn: 0.3224869\ttest: 0.3221014\tbestTest: 0.3221014 (20)\ttotal: 1m 55s\tremaining: 7m 13s\n",
      "21: learn: 0.3158866\ttest: 0.3154866\tbestTest: 0.3154866 (21)\ttotal: 2m\tremaining: 7m 8s\n",
      "22: learn: 0.3100924\ttest: 0.3096779\tbestTest: 0.3096779 (22)\ttotal: 2m 6s\tremaining: 7m 2s\n",
      "23: learn: 0.3042413\ttest: 0.3038085\tbestTest: 0.3038085 (23)\ttotal: 2m 10s\tremaining: 6m 54s\n",
      "24: learn: 0.2991179\ttest: 0.298673\tbestTest: 0.298673 (24)\ttotal: 2m 16s\tremaining: 6m 48s\n",
      "25: learn: 0.2941422\ttest: 0.2936826\tbestTest: 0.2936826 (25)\ttotal: 2m 21s\tremaining: 6m 42s\n",
      "26: learn: 0.2897752\ttest: 0.2893071\tbestTest: 0.2893071 (26)\ttotal: 2m 27s\tremaining: 6m 37s\n",
      "27: learn: 0.2855293\ttest: 0.2850478\tbestTest: 0.2850478 (27)\ttotal: 2m 31s\tremaining: 6m 30s\n",
      "28: learn: 0.2817936\ttest: 0.2812976\tbestTest: 0.2812976 (28)\ttotal: 2m 37s\tremaining: 6m 24s\n",
      "29: learn: 0.2781307\ttest: 0.2776193\tbestTest: 0.2776193 (29)\ttotal: 2m 42s\tremaining: 6m 18s\n",
      "30: learn: 0.2749212\ttest: 0.2743988\tbestTest: 0.2743988 (30)\ttotal: 2m 47s\tremaining: 6m 13s\n",
      "31: learn: 0.2720384\ttest: 0.2715062\tbestTest: 0.2715062 (31)\ttotal: 2m 53s\tremaining: 6m 9s\n",
      "32: learn: 0.2693163\ttest: 0.2687756\tbestTest: 0.2687756 (32)\ttotal: 2m 58s\tremaining: 6m 3s\n",
      "33: learn: 0.2664844\ttest: 0.2659288\tbestTest: 0.2659288 (33)\ttotal: 3m 4s\tremaining: 5m 58s\n",
      "34: learn: 0.264023\ttest: 0.2634556\tbestTest: 0.2634556 (34)\ttotal: 3m 9s\tremaining: 5m 51s\n",
      "35: learn: 0.2616114\ttest: 0.2610304\tbestTest: 0.2610304 (35)\ttotal: 3m 14s\tremaining: 5m 46s\n",
      "36: learn: 0.2596284\ttest: 0.2590365\tbestTest: 0.2590365 (36)\ttotal: 3m 20s\tremaining: 5m 41s\n",
      "37: learn: 0.2575692\ttest: 0.2569699\tbestTest: 0.2569699 (37)\ttotal: 3m 25s\tremaining: 5m 36s\n",
      "38: learn: 0.2555961\ttest: 0.2549828\tbestTest: 0.2549828 (38)\ttotal: 3m 31s\tremaining: 5m 30s\n",
      "39: learn: 0.2537356\ttest: 0.2531112\tbestTest: 0.2531112 (39)\ttotal: 3m 36s\tremaining: 5m 24s\n",
      "40: learn: 0.2520364\ttest: 0.251402\tbestTest: 0.251402 (40)\ttotal: 3m 41s\tremaining: 5m 18s\n",
      "41: learn: 0.2505012\ttest: 0.2498567\tbestTest: 0.2498567 (41)\ttotal: 3m 46s\tremaining: 5m 13s\n",
      "42: learn: 0.2490296\ttest: 0.2483766\tbestTest: 0.2483766 (42)\ttotal: 3m 52s\tremaining: 5m 8s\n",
      "43: learn: 0.2477327\ttest: 0.2470722\tbestTest: 0.2470722 (43)\ttotal: 3m 57s\tremaining: 5m 2s\n",
      "44: learn: 0.2463861\ttest: 0.2457174\tbestTest: 0.2457174 (44)\ttotal: 4m 2s\tremaining: 4m 56s\n",
      "45: learn: 0.2453133\ttest: 0.2446375\tbestTest: 0.2446375 (45)\ttotal: 4m 8s\tremaining: 4m 51s\n",
      "46: learn: 0.2442404\ttest: 0.2435569\tbestTest: 0.2435569 (46)\ttotal: 4m 13s\tremaining: 4m 45s\n",
      "47: learn: 0.2432085\ttest: 0.242516\tbestTest: 0.242516 (47)\ttotal: 4m 18s\tremaining: 4m 40s\n",
      "48: learn: 0.2422068\ttest: 0.2415054\tbestTest: 0.2415054 (48)\ttotal: 4m 24s\tremaining: 4m 35s\n",
      "49: learn: 0.2413052\ttest: 0.2406002\tbestTest: 0.2406002 (49)\ttotal: 4m 29s\tremaining: 4m 29s\n",
      "50: learn: 0.2404614\ttest: 0.2397511\tbestTest: 0.2397511 (50)\ttotal: 4m 35s\tremaining: 4m 24s\n",
      "51: learn: 0.2397114\ttest: 0.2389944\tbestTest: 0.2389944 (51)\ttotal: 4m 40s\tremaining: 4m 18s\n",
      "52: learn: 0.2389639\ttest: 0.2382402\tbestTest: 0.2382402 (52)\ttotal: 4m 45s\tremaining: 4m 13s\n",
      "53: learn: 0.238263\ttest: 0.2375331\tbestTest: 0.2375331 (53)\ttotal: 4m 51s\tremaining: 4m 8s\n",
      "54: learn: 0.2375688\ttest: 0.2368348\tbestTest: 0.2368348 (54)\ttotal: 4m 57s\tremaining: 4m 3s\n",
      "55: learn: 0.2369176\ttest: 0.2361752\tbestTest: 0.2361752 (55)\ttotal: 5m 2s\tremaining: 3m 57s\n",
      "56: learn: 0.2362913\ttest: 0.2355453\tbestTest: 0.2355453 (56)\ttotal: 5m 7s\tremaining: 3m 51s\n",
      "57: learn: 0.2357104\ttest: 0.2349575\tbestTest: 0.2349575 (57)\ttotal: 5m 12s\tremaining: 3m 46s\n",
      "58: learn: 0.2351926\ttest: 0.2344338\tbestTest: 0.2344338 (58)\ttotal: 5m 17s\tremaining: 3m 40s\n",
      "59: learn: 0.2346723\ttest: 0.2339087\tbestTest: 0.2339087 (59)\ttotal: 5m 22s\tremaining: 3m 35s\n",
      "60: learn: 0.2342027\ttest: 0.2334343\tbestTest: 0.2334343 (60)\ttotal: 5m 28s\tremaining: 3m 30s\n",
      "61: learn: 0.2337383\ttest: 0.2329657\tbestTest: 0.2329657 (61)\ttotal: 5m 33s\tremaining: 3m 24s\n",
      "62: learn: 0.2332962\ttest: 0.2325176\tbestTest: 0.2325176 (62)\ttotal: 5m 38s\tremaining: 3m 18s\n",
      "63: learn: 0.2328941\ttest: 0.2321107\tbestTest: 0.2321107 (63)\ttotal: 5m 43s\tremaining: 3m 13s\n",
      "64: learn: 0.2325171\ttest: 0.2317295\tbestTest: 0.2317295 (64)\ttotal: 5m 48s\tremaining: 3m 7s\n",
      "65: learn: 0.2321978\ttest: 0.2314071\tbestTest: 0.2314071 (65)\ttotal: 5m 54s\tremaining: 3m 2s\n",
      "66: learn: 0.2318591\ttest: 0.2310654\tbestTest: 0.2310654 (66)\ttotal: 6m\tremaining: 2m 57s\n",
      "67: learn: 0.231542\ttest: 0.2307434\tbestTest: 0.2307434 (67)\ttotal: 6m 6s\tremaining: 2m 52s\n",
      "68: learn: 0.2312558\ttest: 0.2304571\tbestTest: 0.2304571 (68)\ttotal: 6m 11s\tremaining: 2m 46s\n",
      "69: learn: 0.2309724\ttest: 0.2301713\tbestTest: 0.2301713 (69)\ttotal: 6m 17s\tremaining: 2m 41s\n",
      "70: learn: 0.2307115\ttest: 0.2299074\tbestTest: 0.2299074 (70)\ttotal: 6m 23s\tremaining: 2m 36s\n",
      "71: learn: 0.2304433\ttest: 0.2296354\tbestTest: 0.2296354 (71)\ttotal: 6m 28s\tremaining: 2m 31s\n",
      "72: learn: 0.2302109\ttest: 0.2294005\tbestTest: 0.2294005 (72)\ttotal: 6m 34s\tremaining: 2m 25s\n",
      "73: learn: 0.2300026\ttest: 0.2291907\tbestTest: 0.2291907 (73)\ttotal: 6m 39s\tremaining: 2m 20s\n",
      "74: learn: 0.229791\ttest: 0.228978\tbestTest: 0.228978 (74)\ttotal: 6m 44s\tremaining: 2m 14s\n",
      "75: learn: 0.2295671\ttest: 0.2287497\tbestTest: 0.2287497 (75)\ttotal: 6m 49s\tremaining: 2m 9s\n",
      "76: learn: 0.2293783\ttest: 0.2285581\tbestTest: 0.2285581 (76)\ttotal: 6m 54s\tremaining: 2m 3s\n",
      "77: learn: 0.2291764\ttest: 0.2283532\tbestTest: 0.2283532 (77)\ttotal: 7m\tremaining: 1m 58s\n",
      "78: learn: 0.2289908\ttest: 0.2281645\tbestTest: 0.2281645 (78)\ttotal: 7m 5s\tremaining: 1m 53s\n",
      "79: learn: 0.2288165\ttest: 0.2279895\tbestTest: 0.2279895 (79)\ttotal: 7m 10s\tremaining: 1m 47s\n",
      "80: learn: 0.2286399\ttest: 0.2278097\tbestTest: 0.2278097 (80)\ttotal: 7m 15s\tremaining: 1m 42s\n",
      "81: learn: 0.2285063\ttest: 0.2276747\tbestTest: 0.2276747 (81)\ttotal: 7m 21s\tremaining: 1m 36s\n",
      "82: learn: 0.2283535\ttest: 0.2275211\tbestTest: 0.2275211 (82)\ttotal: 7m 26s\tremaining: 1m 31s\n",
      "83: learn: 0.2282089\ttest: 0.2273739\tbestTest: 0.2273739 (83)\ttotal: 7m 31s\tremaining: 1m 26s\n",
      "84: learn: 0.228074\ttest: 0.2272369\tbestTest: 0.2272369 (84)\ttotal: 7m 37s\tremaining: 1m 20s\n",
      "85: learn: 0.2279578\ttest: 0.22712\tbestTest: 0.22712 (85)\ttotal: 7m 42s\tremaining: 1m 15s\n",
      "86: learn: 0.2278058\ttest: 0.2269658\tbestTest: 0.2269658 (86)\ttotal: 7m 47s\tremaining: 1m 9s\n",
      "87: learn: 0.2276759\ttest: 0.2268356\tbestTest: 0.2268356 (87)\ttotal: 7m 53s\tremaining: 1m 4s\n",
      "88: learn: 0.2275542\ttest: 0.2267117\tbestTest: 0.2267117 (88)\ttotal: 7m 58s\tremaining: 59.2s\n",
      "89: learn: 0.2274419\ttest: 0.2265989\tbestTest: 0.2265989 (89)\ttotal: 8m 4s\tremaining: 53.8s\n",
      "90: learn: 0.2273222\ttest: 0.2264785\tbestTest: 0.2264785 (90)\ttotal: 8m 9s\tremaining: 48.4s\n",
      "91: learn: 0.2272204\ttest: 0.2263754\tbestTest: 0.2263754 (91)\ttotal: 8m 14s\tremaining: 43s\n",
      "92: learn: 0.2271192\ttest: 0.2262721\tbestTest: 0.2262721 (92)\ttotal: 8m 19s\tremaining: 37.6s\n",
      "93: learn: 0.2270207\ttest: 0.2261708\tbestTest: 0.2261708 (93)\ttotal: 8m 24s\tremaining: 32.2s\n",
      "94: learn: 0.2269407\ttest: 0.2260889\tbestTest: 0.2260889 (94)\ttotal: 8m 29s\tremaining: 26.8s\n",
      "95: learn: 0.226837\ttest: 0.2259833\tbestTest: 0.2259833 (95)\ttotal: 8m 35s\tremaining: 21.5s\n",
      "96: learn: 0.2267492\ttest: 0.2258926\tbestTest: 0.2258926 (96)\ttotal: 8m 40s\tremaining: 16.1s\n",
      "97: learn: 0.2266566\ttest: 0.2257991\tbestTest: 0.2257991 (97)\ttotal: 8m 45s\tremaining: 10.7s\n",
      "98: learn: 0.2265443\ttest: 0.2256876\tbestTest: 0.2256876 (98)\ttotal: 8m 50s\tremaining: 5.35s\n",
      "99: learn: 0.22647\ttest: 0.2256125\tbestTest: 0.2256125 (99)\ttotal: 8m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2256125484\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_10_bag_temp_1\n",
      "2018-03-13 23:31:00.718508\n",
      "train time given below\n",
      "0:12:51.886147\n",
      "2018-03-13 23:31:00.760489\n",
      "2018-03-13 23:31:00.764007\n",
      "GINI ISIT = 0.453603640633\n",
      "2018-03-13 23:32:32.896733\n",
      "GINI OSIT = 0.45483965388\n",
      "2018-03-13 23:33:11.733282\n",
      "GINI OSOT = 0.407005179559\n",
      "2018-03-13 23:33:23.568604\n",
      "2018-03-13 23:33:23.570582\n",
      "categorical split = 16\n",
      "2018-03-13 23:33:23.571968\n",
      "model train start\n",
      "2018-03-13 23:33:23.572191\n",
      "0: learn: 0.6581866\ttest: 0.6581573\tbestTest: 0.6581573 (0)\ttotal: 3.53s\tremaining: 5m 49s\n",
      "1: learn: 0.6256835\ttest: 0.6256275\tbestTest: 0.6256275 (1)\ttotal: 9.75s\tremaining: 7m 57s\n",
      "2: learn: 0.5950976\ttest: 0.5950213\tbestTest: 0.5950213 (2)\ttotal: 15.4s\tremaining: 8m 17s\n",
      "3: learn: 0.5671602\ttest: 0.5670661\tbestTest: 0.5670661 (3)\ttotal: 21.2s\tremaining: 8m 29s\n",
      "4: learn: 0.5415567\ttest: 0.5414338\tbestTest: 0.5414338 (4)\ttotal: 27.6s\tremaining: 8m 45s\n",
      "5: learn: 0.5173878\ttest: 0.5172488\tbestTest: 0.5172488 (5)\ttotal: 33.1s\tremaining: 8m 39s\n",
      "6: learn: 0.4958949\ttest: 0.4957409\tbestTest: 0.4957409 (6)\ttotal: 38.9s\tremaining: 8m 37s\n",
      "7: learn: 0.4754494\ttest: 0.4752687\tbestTest: 0.4752687 (7)\ttotal: 44.2s\tremaining: 8m 28s\n",
      "8: learn: 0.4569905\ttest: 0.4567955\tbestTest: 0.4567955 (8)\ttotal: 50.1s\tremaining: 8m 26s\n",
      "9: learn: 0.4403821\ttest: 0.4401601\tbestTest: 0.4401601 (9)\ttotal: 55.9s\tremaining: 8m 23s\n",
      "10: learn: 0.4249301\ttest: 0.4246959\tbestTest: 0.4246959 (10)\ttotal: 1m 2s\tremaining: 8m 21s\n",
      "11: learn: 0.4112644\ttest: 0.4110146\tbestTest: 0.4110146 (11)\ttotal: 1m 4s\tremaining: 7m 56s\n",
      "12: learn: 0.3976725\ttest: 0.3974036\tbestTest: 0.3974036 (12)\ttotal: 1m 10s\tremaining: 7m 54s\n",
      "13: learn: 0.384876\ttest: 0.3845835\tbestTest: 0.3845835 (13)\ttotal: 1m 16s\tremaining: 7m 47s\n",
      "14: learn: 0.3739876\ttest: 0.3736738\tbestTest: 0.3736738 (14)\ttotal: 1m 21s\tremaining: 7m 40s\n",
      "15: learn: 0.363417\ttest: 0.3630775\tbestTest: 0.3630775 (15)\ttotal: 1m 26s\tremaining: 7m 32s\n",
      "16: learn: 0.3535879\ttest: 0.3532286\tbestTest: 0.3532286 (16)\ttotal: 1m 31s\tremaining: 7m 25s\n",
      "17: learn: 0.3446133\ttest: 0.3442304\tbestTest: 0.3442304 (17)\ttotal: 1m 36s\tremaining: 7m 19s\n",
      "18: learn: 0.3367779\ttest: 0.336377\tbestTest: 0.336377 (18)\ttotal: 1m 42s\tremaining: 7m 15s\n",
      "19: learn: 0.3293672\ttest: 0.3289531\tbestTest: 0.3289531 (19)\ttotal: 1m 47s\tremaining: 7m 11s\n",
      "20: learn: 0.3220507\ttest: 0.3216187\tbestTest: 0.3216187 (20)\ttotal: 1m 52s\tremaining: 7m 5s\n",
      "21: learn: 0.3159512\ttest: 0.3155109\tbestTest: 0.3155109 (21)\ttotal: 1m 58s\tremaining: 6m 58s\n",
      "22: learn: 0.3103001\ttest: 0.3098481\tbestTest: 0.3098481 (22)\ttotal: 2m 3s\tremaining: 6m 52s\n",
      "23: learn: 0.3046916\ttest: 0.3042354\tbestTest: 0.3042354 (23)\ttotal: 2m 8s\tremaining: 6m 47s\n",
      "24: learn: 0.2993332\ttest: 0.2988653\tbestTest: 0.2988653 (24)\ttotal: 2m 14s\tremaining: 6m 42s\n",
      "25: learn: 0.2946375\ttest: 0.2941566\tbestTest: 0.2941566 (25)\ttotal: 2m 19s\tremaining: 6m 37s\n",
      "26: learn: 0.290001\ttest: 0.2895012\tbestTest: 0.2895012 (26)\ttotal: 2m 25s\tremaining: 6m 32s\n",
      "27: learn: 0.2856958\ttest: 0.2851807\tbestTest: 0.2851807 (27)\ttotal: 2m 30s\tremaining: 6m 26s\n",
      "28: learn: 0.2818412\ttest: 0.2813153\tbestTest: 0.2813153 (28)\ttotal: 2m 35s\tremaining: 6m 20s\n",
      "29: learn: 0.2784306\ttest: 0.2778959\tbestTest: 0.2778959 (29)\ttotal: 2m 41s\tremaining: 6m 16s\n",
      "30: learn: 0.2750889\ttest: 0.2745409\tbestTest: 0.2745409 (30)\ttotal: 2m 46s\tremaining: 6m 10s\n",
      "31: learn: 0.2719029\ttest: 0.2713436\tbestTest: 0.2713436 (31)\ttotal: 2m 51s\tremaining: 6m 4s\n",
      "32: learn: 0.2689887\ttest: 0.2684204\tbestTest: 0.2684204 (32)\ttotal: 2m 56s\tremaining: 5m 58s\n",
      "33: learn: 0.266438\ttest: 0.2658549\tbestTest: 0.2658549 (33)\ttotal: 3m 1s\tremaining: 5m 51s\n",
      "34: learn: 0.2639633\ttest: 0.2633715\tbestTest: 0.2633715 (34)\ttotal: 3m 6s\tremaining: 5m 46s\n",
      "35: learn: 0.2616224\ttest: 0.2610196\tbestTest: 0.2610196 (35)\ttotal: 3m 12s\tremaining: 5m 41s\n",
      "36: learn: 0.2594971\ttest: 0.258884\tbestTest: 0.258884 (36)\ttotal: 3m 17s\tremaining: 5m 36s\n",
      "37: learn: 0.2574739\ttest: 0.2568514\tbestTest: 0.2568514 (37)\ttotal: 3m 22s\tremaining: 5m 30s\n",
      "38: learn: 0.2555676\ttest: 0.2549357\tbestTest: 0.2549357 (38)\ttotal: 3m 27s\tremaining: 5m 24s\n",
      "39: learn: 0.253698\ttest: 0.2530595\tbestTest: 0.2530595 (39)\ttotal: 3m 32s\tremaining: 5m 19s\n",
      "40: learn: 0.2520361\ttest: 0.2513944\tbestTest: 0.2513944 (40)\ttotal: 3m 38s\tremaining: 5m 14s\n",
      "41: learn: 0.2505819\ttest: 0.2499159\tbestTest: 0.2499159 (41)\ttotal: 3m 44s\tremaining: 5m 9s\n",
      "42: learn: 0.2491997\ttest: 0.2485236\tbestTest: 0.2485236 (42)\ttotal: 3m 49s\tremaining: 5m 3s\n",
      "43: learn: 0.2478933\ttest: 0.2472073\tbestTest: 0.2472073 (43)\ttotal: 3m 54s\tremaining: 4m 59s\n",
      "44: learn: 0.2465489\ttest: 0.2458534\tbestTest: 0.2458534 (44)\ttotal: 4m\tremaining: 4m 53s\n",
      "45: learn: 0.2453125\ttest: 0.2446098\tbestTest: 0.2446098 (45)\ttotal: 4m 5s\tremaining: 4m 48s\n",
      "46: learn: 0.2441576\ttest: 0.2434469\tbestTest: 0.2434469 (46)\ttotal: 4m 10s\tremaining: 4m 42s\n",
      "47: learn: 0.2431815\ttest: 0.2424608\tbestTest: 0.2424608 (47)\ttotal: 4m 16s\tremaining: 4m 37s\n",
      "48: learn: 0.2422709\ttest: 0.2415422\tbestTest: 0.2415422 (48)\ttotal: 4m 21s\tremaining: 4m 32s\n",
      "49: learn: 0.2413936\ttest: 0.2406577\tbestTest: 0.2406577 (49)\ttotal: 4m 27s\tremaining: 4m 27s\n",
      "50: learn: 0.2405716\ttest: 0.2398301\tbestTest: 0.2398301 (50)\ttotal: 4m 32s\tremaining: 4m 21s\n",
      "51: learn: 0.2397193\ttest: 0.2389694\tbestTest: 0.2389694 (51)\ttotal: 4m 37s\tremaining: 4m 16s\n",
      "52: learn: 0.2389723\ttest: 0.2382157\tbestTest: 0.2382157 (52)\ttotal: 4m 43s\tremaining: 4m 11s\n",
      "53: learn: 0.2382273\ttest: 0.2374661\tbestTest: 0.2374661 (53)\ttotal: 4m 48s\tremaining: 4m 5s\n",
      "54: learn: 0.2375254\ttest: 0.2367574\tbestTest: 0.2367574 (54)\ttotal: 4m 53s\tremaining: 4m\n",
      "55: learn: 0.2368653\ttest: 0.2360921\tbestTest: 0.2360921 (55)\ttotal: 4m 58s\tremaining: 3m 54s\n",
      "56: learn: 0.2362395\ttest: 0.2354616\tbestTest: 0.2354616 (56)\ttotal: 5m 3s\tremaining: 3m 48s\n",
      "57: learn: 0.2357208\ttest: 0.2349402\tbestTest: 0.2349402 (57)\ttotal: 5m 9s\tremaining: 3m 43s\n",
      "58: learn: 0.235146\ttest: 0.2343644\tbestTest: 0.2343644 (58)\ttotal: 5m 14s\tremaining: 3m 38s\n",
      "59: learn: 0.2346365\ttest: 0.2338522\tbestTest: 0.2338522 (59)\ttotal: 5m 20s\tremaining: 3m 33s\n",
      "60: learn: 0.2341617\ttest: 0.2333756\tbestTest: 0.2333756 (60)\ttotal: 5m 26s\tremaining: 3m 28s\n",
      "61: learn: 0.2337652\ttest: 0.2329756\tbestTest: 0.2329756 (61)\ttotal: 5m 31s\tremaining: 3m 23s\n",
      "62: learn: 0.2333296\ttest: 0.2325344\tbestTest: 0.2325344 (62)\ttotal: 5m 36s\tremaining: 3m 17s\n",
      "63: learn: 0.2329166\ttest: 0.2321179\tbestTest: 0.2321179 (63)\ttotal: 5m 41s\tremaining: 3m 12s\n",
      "64: learn: 0.2325349\ttest: 0.2317318\tbestTest: 0.2317318 (64)\ttotal: 5m 46s\tremaining: 3m 6s\n",
      "65: learn: 0.232186\ttest: 0.2313794\tbestTest: 0.2313794 (65)\ttotal: 5m 52s\tremaining: 3m 1s\n",
      "66: learn: 0.2318369\ttest: 0.2310274\tbestTest: 0.2310274 (66)\ttotal: 5m 57s\tremaining: 2m 55s\n",
      "67: learn: 0.2314761\ttest: 0.2306621\tbestTest: 0.2306621 (67)\ttotal: 6m 3s\tremaining: 2m 50s\n",
      "68: learn: 0.2311896\ttest: 0.2303726\tbestTest: 0.2303726 (68)\ttotal: 6m 8s\tremaining: 2m 45s\n",
      "69: learn: 0.2308737\ttest: 0.2300541\tbestTest: 0.2300541 (69)\ttotal: 6m 14s\tremaining: 2m 40s\n",
      "70: learn: 0.2305987\ttest: 0.2297772\tbestTest: 0.2297772 (70)\ttotal: 6m 20s\tremaining: 2m 35s\n",
      "71: learn: 0.2303324\ttest: 0.2295079\tbestTest: 0.2295079 (71)\ttotal: 6m 25s\tremaining: 2m 29s\n",
      "72: learn: 0.2300738\ttest: 0.229247\tbestTest: 0.229247 (72)\ttotal: 6m 30s\tremaining: 2m 24s\n",
      "73: learn: 0.2298527\ttest: 0.2290249\tbestTest: 0.2290249 (73)\ttotal: 6m 36s\tremaining: 2m 19s\n",
      "74: learn: 0.2296187\ttest: 0.228789\tbestTest: 0.228789 (74)\ttotal: 6m 41s\tremaining: 2m 13s\n",
      "75: learn: 0.2293945\ttest: 0.2285614\tbestTest: 0.2285614 (75)\ttotal: 6m 47s\tremaining: 2m 8s\n",
      "76: learn: 0.2292082\ttest: 0.2283736\tbestTest: 0.2283736 (76)\ttotal: 6m 52s\tremaining: 2m 3s\n",
      "77: learn: 0.2289995\ttest: 0.228163\tbestTest: 0.228163 (77)\ttotal: 6m 58s\tremaining: 1m 57s\n",
      "78: learn: 0.228806\ttest: 0.2279667\tbestTest: 0.2279667 (78)\ttotal: 7m 3s\tremaining: 1m 52s\n",
      "79: learn: 0.2286308\ttest: 0.2277886\tbestTest: 0.2277886 (79)\ttotal: 7m 9s\tremaining: 1m 47s\n",
      "80: learn: 0.2284505\ttest: 0.227606\tbestTest: 0.227606 (80)\ttotal: 7m 13s\tremaining: 1m 41s\n",
      "81: learn: 0.2282775\ttest: 0.2274296\tbestTest: 0.2274296 (81)\ttotal: 7m 19s\tremaining: 1m 36s\n",
      "82: learn: 0.2281264\ttest: 0.2272761\tbestTest: 0.2272761 (82)\ttotal: 7m 24s\tremaining: 1m 31s\n",
      "83: learn: 0.2279852\ttest: 0.2271319\tbestTest: 0.2271319 (83)\ttotal: 7m 29s\tremaining: 1m 25s\n",
      "84: learn: 0.2278351\ttest: 0.2269788\tbestTest: 0.2269788 (84)\ttotal: 7m 35s\tremaining: 1m 20s\n",
      "85: learn: 0.2276969\ttest: 0.2268387\tbestTest: 0.2268387 (85)\ttotal: 7m 40s\tremaining: 1m 14s\n",
      "86: learn: 0.2275809\ttest: 0.2267215\tbestTest: 0.2267215 (86)\ttotal: 7m 46s\tremaining: 1m 9s\n",
      "87: learn: 0.2274593\ttest: 0.2265987\tbestTest: 0.2265987 (87)\ttotal: 7m 51s\tremaining: 1m 4s\n",
      "88: learn: 0.2273348\ttest: 0.2264713\tbestTest: 0.2264713 (88)\ttotal: 7m 56s\tremaining: 58.9s\n",
      "89: learn: 0.2272198\ttest: 0.2263548\tbestTest: 0.2263548 (89)\ttotal: 8m 2s\tremaining: 53.6s\n",
      "90: learn: 0.2271203\ttest: 0.2262534\tbestTest: 0.2262534 (90)\ttotal: 8m 7s\tremaining: 48.2s\n",
      "91: learn: 0.227017\ttest: 0.2261477\tbestTest: 0.2261477 (91)\ttotal: 8m 12s\tremaining: 42.8s\n",
      "92: learn: 0.2269044\ttest: 0.2260345\tbestTest: 0.2260345 (92)\ttotal: 8m 18s\tremaining: 37.5s\n",
      "93: learn: 0.2268044\ttest: 0.2259342\tbestTest: 0.2259342 (93)\ttotal: 8m 23s\tremaining: 32.1s\n",
      "94: learn: 0.2267207\ttest: 0.2258502\tbestTest: 0.2258502 (94)\ttotal: 8m 28s\tremaining: 26.8s\n",
      "95: learn: 0.226623\ttest: 0.2257518\tbestTest: 0.2257518 (95)\ttotal: 8m 33s\tremaining: 21.4s\n",
      "96: learn: 0.226545\ttest: 0.2256733\tbestTest: 0.2256733 (96)\ttotal: 8m 39s\tremaining: 16.1s\n",
      "97: learn: 0.2264834\ttest: 0.2256097\tbestTest: 0.2256097 (97)\ttotal: 8m 45s\tremaining: 10.7s\n",
      "98: learn: 0.2263934\ttest: 0.2255184\tbestTest: 0.2255184 (98)\ttotal: 8m 50s\tremaining: 5.35s\n",
      "99: learn: 0.2263169\ttest: 0.2254396\tbestTest: 0.2254396 (99)\ttotal: 8m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254396103\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_16_bag_temp_1\n",
      "2018-03-13 23:46:20.053515\n",
      "train time given below\n",
      "0:12:56.481324\n",
      "2018-03-13 23:46:20.509995\n",
      "2018-03-13 23:46:20.514479\n",
      "GINI ISIT = 0.455322130277\n",
      "2018-03-13 23:47:52.542674\n",
      "GINI OSIT = 0.456847407704\n",
      "2018-03-13 23:48:30.872948\n",
      "GINI OSOT = 0.411085756609\n",
      "2018-03-13 23:48:42.606414\n",
      "2018-03-13 23:48:42.608435\n",
      "categorical split = 32\n",
      "2018-03-13 23:48:42.609883\n",
      "model train start\n",
      "2018-03-13 23:48:42.610202\n",
      "0: learn: 0.6577818\ttest: 0.6577592\tbestTest: 0.6577592 (0)\ttotal: 5.89s\tremaining: 9m 43s\n",
      "1: learn: 0.6244793\ttest: 0.6244491\tbestTest: 0.6244491 (1)\ttotal: 12.2s\tremaining: 9m 56s\n",
      "2: learn: 0.5945032\ttest: 0.5944544\tbestTest: 0.5944544 (2)\ttotal: 17.9s\tremaining: 9m 38s\n",
      "3: learn: 0.5666726\ttest: 0.5665957\tbestTest: 0.5665957 (3)\ttotal: 23.1s\tremaining: 9m 13s\n",
      "4: learn: 0.5406981\ttest: 0.540595\tbestTest: 0.540595 (4)\ttotal: 29.4s\tremaining: 9m 18s\n",
      "5: learn: 0.5176984\ttest: 0.5175782\tbestTest: 0.5175782 (5)\ttotal: 32.5s\tremaining: 8m 28s\n",
      "6: learn: 0.4956837\ttest: 0.4955422\tbestTest: 0.4955422 (6)\ttotal: 37.6s\tremaining: 8m 19s\n",
      "7: learn: 0.475998\ttest: 0.475831\tbestTest: 0.475831 (7)\ttotal: 43.6s\tremaining: 8m 21s\n",
      "8: learn: 0.4573323\ttest: 0.4571485\tbestTest: 0.4571485 (8)\ttotal: 49s\tremaining: 8m 14s\n",
      "9: learn: 0.4400252\ttest: 0.4398131\tbestTest: 0.4398131 (9)\ttotal: 54.8s\tremaining: 8m 13s\n",
      "10: learn: 0.424244\ttest: 0.4240103\tbestTest: 0.4240103 (10)\ttotal: 1m\tremaining: 8m 7s\n",
      "11: learn: 0.4101672\ttest: 0.4099193\tbestTest: 0.4099193 (11)\ttotal: 1m 5s\tremaining: 8m 1s\n",
      "12: learn: 0.3970639\ttest: 0.3968017\tbestTest: 0.3968017 (12)\ttotal: 1m 10s\tremaining: 7m 50s\n",
      "13: learn: 0.3847925\ttest: 0.3845068\tbestTest: 0.3845068 (13)\ttotal: 1m 15s\tremaining: 7m 42s\n",
      "14: learn: 0.3735166\ttest: 0.37322\tbestTest: 0.37322 (14)\ttotal: 1m 20s\tremaining: 7m 37s\n",
      "15: learn: 0.3636502\ttest: 0.3633366\tbestTest: 0.3633366 (15)\ttotal: 1m 26s\tremaining: 7m 32s\n",
      "16: learn: 0.3541445\ttest: 0.3538115\tbestTest: 0.3538115 (16)\ttotal: 1m 31s\tremaining: 7m 25s\n",
      "17: learn: 0.3450874\ttest: 0.3447329\tbestTest: 0.3447329 (17)\ttotal: 1m 37s\tremaining: 7m 22s\n",
      "18: learn: 0.3369488\ttest: 0.3365795\tbestTest: 0.3365795 (18)\ttotal: 1m 41s\tremaining: 7m 14s\n",
      "19: learn: 0.3297485\ttest: 0.3293613\tbestTest: 0.3293613 (19)\ttotal: 1m 46s\tremaining: 7m 4s\n",
      "20: learn: 0.3225423\ttest: 0.3221385\tbestTest: 0.3221385 (20)\ttotal: 1m 51s\tremaining: 6m 58s\n",
      "21: learn: 0.3159298\ttest: 0.315511\tbestTest: 0.315511 (21)\ttotal: 1m 56s\tremaining: 6m 51s\n",
      "22: learn: 0.3099683\ttest: 0.3095342\tbestTest: 0.3095342 (22)\ttotal: 2m 1s\tremaining: 6m 46s\n",
      "23: learn: 0.3042226\ttest: 0.30377\tbestTest: 0.30377 (23)\ttotal: 2m 7s\tremaining: 6m 43s\n",
      "24: learn: 0.2990179\ttest: 0.2985504\tbestTest: 0.2985504 (24)\ttotal: 2m 12s\tremaining: 6m 38s\n",
      "25: learn: 0.2942514\ttest: 0.293775\tbestTest: 0.293775 (25)\ttotal: 2m 18s\tremaining: 6m 33s\n",
      "26: learn: 0.2897928\ttest: 0.2893043\tbestTest: 0.2893043 (26)\ttotal: 2m 23s\tremaining: 6m 28s\n",
      "27: learn: 0.2857439\ttest: 0.2852398\tbestTest: 0.2852398 (27)\ttotal: 2m 29s\tremaining: 6m 23s\n",
      "28: learn: 0.2817915\ttest: 0.2812721\tbestTest: 0.2812721 (28)\ttotal: 2m 34s\tremaining: 6m 17s\n",
      "29: learn: 0.2783526\ttest: 0.2778204\tbestTest: 0.2778204 (29)\ttotal: 2m 39s\tremaining: 6m 11s\n",
      "30: learn: 0.2749345\ttest: 0.2743875\tbestTest: 0.2743875 (30)\ttotal: 2m 44s\tremaining: 6m 6s\n",
      "31: learn: 0.2720078\ttest: 0.2714499\tbestTest: 0.2714499 (31)\ttotal: 2m 49s\tremaining: 6m\n",
      "32: learn: 0.2690976\ttest: 0.2685304\tbestTest: 0.2685304 (32)\ttotal: 2m 55s\tremaining: 5m 56s\n",
      "33: learn: 0.2663328\ttest: 0.2657502\tbestTest: 0.2657502 (33)\ttotal: 3m\tremaining: 5m 50s\n",
      "34: learn: 0.2639981\ttest: 0.2634071\tbestTest: 0.2634071 (34)\ttotal: 3m 6s\tremaining: 5m 45s\n",
      "35: learn: 0.2616797\ttest: 0.2610813\tbestTest: 0.2610813 (35)\ttotal: 3m 11s\tremaining: 5m 41s\n",
      "36: learn: 0.2595564\ttest: 0.2589467\tbestTest: 0.2589467 (36)\ttotal: 3m 16s\tremaining: 5m 34s\n",
      "37: learn: 0.257648\ttest: 0.2570353\tbestTest: 0.2570353 (37)\ttotal: 3m 21s\tremaining: 5m 29s\n",
      "38: learn: 0.255809\ttest: 0.2551848\tbestTest: 0.2551848 (38)\ttotal: 3m 27s\tremaining: 5m 24s\n",
      "39: learn: 0.2540315\ttest: 0.2533977\tbestTest: 0.2533977 (39)\ttotal: 3m 32s\tremaining: 5m 19s\n",
      "40: learn: 0.2522741\ttest: 0.2516305\tbestTest: 0.2516305 (40)\ttotal: 3m 38s\tremaining: 5m 14s\n",
      "41: learn: 0.2506554\ttest: 0.2500034\tbestTest: 0.2500034 (41)\ttotal: 3m 43s\tremaining: 5m 9s\n",
      "42: learn: 0.2492401\ttest: 0.2485824\tbestTest: 0.2485824 (42)\ttotal: 3m 49s\tremaining: 5m 4s\n",
      "43: learn: 0.2478743\ttest: 0.2472074\tbestTest: 0.2472074 (43)\ttotal: 3m 54s\tremaining: 4m 59s\n",
      "44: learn: 0.2465875\ttest: 0.2459123\tbestTest: 0.2459123 (44)\ttotal: 4m\tremaining: 4m 53s\n",
      "45: learn: 0.2455043\ttest: 0.2448202\tbestTest: 0.2448202 (45)\ttotal: 4m 6s\tremaining: 4m 48s\n",
      "46: learn: 0.2443984\ttest: 0.2437075\tbestTest: 0.2437075 (46)\ttotal: 4m 11s\tremaining: 4m 43s\n",
      "47: learn: 0.2434519\ttest: 0.2427538\tbestTest: 0.2427538 (47)\ttotal: 4m 16s\tremaining: 4m 38s\n",
      "48: learn: 0.2424125\ttest: 0.2417074\tbestTest: 0.2417074 (48)\ttotal: 4m 21s\tremaining: 4m 32s\n",
      "49: learn: 0.2415636\ttest: 0.2408538\tbestTest: 0.2408538 (49)\ttotal: 4m 26s\tremaining: 4m 26s\n",
      "50: learn: 0.2406612\ttest: 0.2399454\tbestTest: 0.2399454 (50)\ttotal: 4m 32s\tremaining: 4m 21s\n",
      "51: learn: 0.2398345\ttest: 0.2391139\tbestTest: 0.2391139 (51)\ttotal: 4m 38s\tremaining: 4m 16s\n",
      "52: learn: 0.2390529\ttest: 0.2383261\tbestTest: 0.2383261 (52)\ttotal: 4m 43s\tremaining: 4m 11s\n",
      "53: learn: 0.2383213\ttest: 0.2375872\tbestTest: 0.2375872 (53)\ttotal: 4m 48s\tremaining: 4m 5s\n",
      "54: learn: 0.2376331\ttest: 0.2368922\tbestTest: 0.2368922 (54)\ttotal: 4m 53s\tremaining: 3m 59s\n",
      "55: learn: 0.2370291\ttest: 0.2362842\tbestTest: 0.2362842 (55)\ttotal: 4m 59s\tremaining: 3m 55s\n",
      "56: learn: 0.2364107\ttest: 0.2356608\tbestTest: 0.2356608 (56)\ttotal: 5m 3s\tremaining: 3m 49s\n",
      "57: learn: 0.2358294\ttest: 0.2350736\tbestTest: 0.2350736 (57)\ttotal: 5m 9s\tremaining: 3m 43s\n",
      "58: learn: 0.2352661\ttest: 0.234505\tbestTest: 0.234505 (58)\ttotal: 5m 14s\tremaining: 3m 38s\n",
      "59: learn: 0.2347271\ttest: 0.2339615\tbestTest: 0.2339615 (59)\ttotal: 5m 19s\tremaining: 3m 33s\n",
      "60: learn: 0.2342777\ttest: 0.2335081\tbestTest: 0.2335081 (60)\ttotal: 5m 25s\tremaining: 3m 27s\n",
      "61: learn: 0.233881\ttest: 0.2331058\tbestTest: 0.2331058 (61)\ttotal: 5m 30s\tremaining: 3m 22s\n",
      "62: learn: 0.2334515\ttest: 0.2326693\tbestTest: 0.2326693 (62)\ttotal: 5m 36s\tremaining: 3m 17s\n",
      "63: learn: 0.2330361\ttest: 0.2322504\tbestTest: 0.2322504 (63)\ttotal: 5m 41s\tremaining: 3m 11s\n",
      "64: learn: 0.2326534\ttest: 0.2318651\tbestTest: 0.2318651 (64)\ttotal: 5m 46s\tremaining: 3m 6s\n",
      "65: learn: 0.2323096\ttest: 0.2315156\tbestTest: 0.2315156 (65)\ttotal: 5m 52s\tremaining: 3m 1s\n",
      "66: learn: 0.2319386\ttest: 0.231141\tbestTest: 0.231141 (66)\ttotal: 5m 57s\tremaining: 2m 56s\n",
      "67: learn: 0.2316188\ttest: 0.2308165\tbestTest: 0.2308165 (67)\ttotal: 6m 2s\tremaining: 2m 50s\n",
      "68: learn: 0.2313373\ttest: 0.230532\tbestTest: 0.230532 (68)\ttotal: 6m 7s\tremaining: 2m 45s\n",
      "69: learn: 0.231044\ttest: 0.230237\tbestTest: 0.230237 (69)\ttotal: 6m 13s\tremaining: 2m 40s\n",
      "70: learn: 0.2307712\ttest: 0.2299607\tbestTest: 0.2299607 (70)\ttotal: 6m 18s\tremaining: 2m 34s\n",
      "71: learn: 0.2304825\ttest: 0.2296695\tbestTest: 0.2296695 (71)\ttotal: 6m 24s\tremaining: 2m 29s\n",
      "72: learn: 0.2302401\ttest: 0.2294227\tbestTest: 0.2294227 (72)\ttotal: 6m 29s\tremaining: 2m 23s\n",
      "73: learn: 0.2300314\ttest: 0.2292108\tbestTest: 0.2292108 (73)\ttotal: 6m 34s\tremaining: 2m 18s\n",
      "74: learn: 0.2297977\ttest: 0.2289735\tbestTest: 0.2289735 (74)\ttotal: 6m 39s\tremaining: 2m 13s\n",
      "75: learn: 0.2295738\ttest: 0.2287475\tbestTest: 0.2287475 (75)\ttotal: 6m 45s\tremaining: 2m 8s\n",
      "76: learn: 0.229368\ttest: 0.2285375\tbestTest: 0.2285375 (76)\ttotal: 6m 50s\tremaining: 2m 2s\n",
      "77: learn: 0.2291987\ttest: 0.2283652\tbestTest: 0.2283652 (77)\ttotal: 6m 56s\tremaining: 1m 57s\n",
      "78: learn: 0.2290197\ttest: 0.2281846\tbestTest: 0.2281846 (78)\ttotal: 7m 1s\tremaining: 1m 52s\n",
      "79: learn: 0.2288314\ttest: 0.2279945\tbestTest: 0.2279945 (79)\ttotal: 7m 6s\tremaining: 1m 46s\n",
      "80: learn: 0.2286508\ttest: 0.2278117\tbestTest: 0.2278117 (80)\ttotal: 7m 12s\tremaining: 1m 41s\n",
      "81: learn: 0.2284595\ttest: 0.2276196\tbestTest: 0.2276196 (81)\ttotal: 7m 17s\tremaining: 1m 36s\n",
      "82: learn: 0.2283218\ttest: 0.227478\tbestTest: 0.227478 (82)\ttotal: 7m 23s\tremaining: 1m 30s\n",
      "83: learn: 0.2281638\ttest: 0.2273181\tbestTest: 0.2273181 (83)\ttotal: 7m 29s\tremaining: 1m 25s\n",
      "84: learn: 0.2280147\ttest: 0.2271674\tbestTest: 0.2271674 (84)\ttotal: 7m 34s\tremaining: 1m 20s\n",
      "85: learn: 0.2278739\ttest: 0.2270249\tbestTest: 0.2270249 (85)\ttotal: 7m 40s\tremaining: 1m 14s\n",
      "86: learn: 0.2277388\ttest: 0.2268874\tbestTest: 0.2268874 (86)\ttotal: 7m 45s\tremaining: 1m 9s\n",
      "87: learn: 0.2276168\ttest: 0.2267611\tbestTest: 0.2267611 (87)\ttotal: 7m 50s\tremaining: 1m 4s\n",
      "88: learn: 0.2275137\ttest: 0.2266561\tbestTest: 0.2266561 (88)\ttotal: 7m 55s\tremaining: 58.8s\n",
      "89: learn: 0.2273968\ttest: 0.2265381\tbestTest: 0.2265381 (89)\ttotal: 8m\tremaining: 53.4s\n",
      "90: learn: 0.227304\ttest: 0.2264437\tbestTest: 0.2264437 (90)\ttotal: 8m 6s\tremaining: 48.1s\n",
      "91: learn: 0.2271977\ttest: 0.2263373\tbestTest: 0.2263373 (91)\ttotal: 8m 11s\tremaining: 42.7s\n",
      "92: learn: 0.2270823\ttest: 0.2262207\tbestTest: 0.2262207 (92)\ttotal: 8m 17s\tremaining: 37.4s\n",
      "93: learn: 0.2269858\ttest: 0.2261226\tbestTest: 0.2261226 (93)\ttotal: 8m 22s\tremaining: 32.1s\n",
      "94: learn: 0.2268957\ttest: 0.2260301\tbestTest: 0.2260301 (94)\ttotal: 8m 27s\tremaining: 26.7s\n",
      "95: learn: 0.2268017\ttest: 0.2259358\tbestTest: 0.2259358 (95)\ttotal: 8m 33s\tremaining: 21.4s\n",
      "96: learn: 0.2267103\ttest: 0.2258441\tbestTest: 0.2258441 (96)\ttotal: 8m 38s\tremaining: 16s\n",
      "97: learn: 0.2266215\ttest: 0.2257548\tbestTest: 0.2257548 (97)\ttotal: 8m 43s\tremaining: 10.7s\n",
      "98: learn: 0.2265567\ttest: 0.2256886\tbestTest: 0.2256886 (98)\ttotal: 8m 49s\tremaining: 5.34s\n",
      "99: learn: 0.2264808\ttest: 0.2256112\tbestTest: 0.2256112 (99)\ttotal: 8m 54s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2256112373\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_32_bag_temp_1\n",
      "2018-03-14 00:01:35.835775\n",
      "train time given below\n",
      "0:12:53.225573\n",
      "2018-03-14 00:01:35.839799\n",
      "2018-03-14 00:01:35.843369\n",
      "GINI ISIT = 0.453114504424\n",
      "2018-03-14 00:03:08.233469\n",
      "GINI OSIT = 0.454387622196\n",
      "2018-03-14 00:03:45.835721\n",
      "GINI OSOT = 0.405824408069\n",
      "2018-03-14 00:03:57.555885\n",
      "2018-03-14 00:03:57.557852\n",
      "categorical split = 64\n",
      "2018-03-14 00:03:57.559271\n",
      "model train start\n",
      "2018-03-14 00:03:57.559505\n",
      "0: learn: 0.6576624\ttest: 0.6576426\tbestTest: 0.6576426 (0)\ttotal: 5.79s\tremaining: 9m 33s\n",
      "1: learn: 0.6248533\ttest: 0.6248084\tbestTest: 0.6248084 (1)\ttotal: 11.6s\tremaining: 9m 29s\n",
      "2: learn: 0.5948405\ttest: 0.5948011\tbestTest: 0.5948011 (2)\ttotal: 17.4s\tremaining: 9m 23s\n",
      "3: learn: 0.5675824\ttest: 0.5675285\tbestTest: 0.5675285 (3)\ttotal: 23.4s\tremaining: 9m 21s\n",
      "4: learn: 0.5419087\ttest: 0.541834\tbestTest: 0.541834 (4)\ttotal: 28.9s\tremaining: 9m 9s\n",
      "5: learn: 0.5177785\ttest: 0.5176858\tbestTest: 0.5176858 (5)\ttotal: 34.5s\tremaining: 9m 1s\n",
      "6: learn: 0.4958991\ttest: 0.4957791\tbestTest: 0.4957791 (6)\ttotal: 40.4s\tremaining: 8m 56s\n",
      "7: learn: 0.4754788\ttest: 0.4753409\tbestTest: 0.4753409 (7)\ttotal: 45.8s\tremaining: 8m 47s\n",
      "8: learn: 0.4566726\ttest: 0.4565053\tbestTest: 0.4565053 (8)\ttotal: 51s\tremaining: 8m 35s\n",
      "9: learn: 0.4395401\ttest: 0.4393548\tbestTest: 0.4393548 (9)\ttotal: 56.4s\tremaining: 8m 27s\n",
      "10: learn: 0.4241522\ttest: 0.423952\tbestTest: 0.423952 (10)\ttotal: 1m 1s\tremaining: 8m 18s\n",
      "11: learn: 0.4095356\ttest: 0.4093138\tbestTest: 0.4093138 (11)\ttotal: 1m 6s\tremaining: 8m 7s\n",
      "12: learn: 0.3966567\ttest: 0.3964144\tbestTest: 0.3964144 (12)\ttotal: 1m 11s\tremaining: 7m 58s\n",
      "13: learn: 0.384164\ttest: 0.383902\tbestTest: 0.383902 (13)\ttotal: 1m 17s\tremaining: 7m 53s\n",
      "14: learn: 0.373075\ttest: 0.3727942\tbestTest: 0.3727942 (14)\ttotal: 1m 22s\tremaining: 7m 45s\n",
      "15: learn: 0.362933\ttest: 0.3626337\tbestTest: 0.3626337 (15)\ttotal: 1m 27s\tremaining: 7m 37s\n",
      "16: learn: 0.353739\ttest: 0.3534185\tbestTest: 0.3534185 (16)\ttotal: 1m 32s\tremaining: 7m 33s\n",
      "17: learn: 0.3447881\ttest: 0.344447\tbestTest: 0.344447 (17)\ttotal: 1m 37s\tremaining: 7m 26s\n",
      "18: learn: 0.3363118\ttest: 0.335951\tbestTest: 0.335951 (18)\ttotal: 1m 43s\tremaining: 7m 19s\n",
      "19: learn: 0.3289943\ttest: 0.3286234\tbestTest: 0.3286234 (19)\ttotal: 1m 48s\tremaining: 7m 13s\n",
      "20: learn: 0.3219604\ttest: 0.3215712\tbestTest: 0.3215712 (20)\ttotal: 1m 53s\tremaining: 7m 6s\n",
      "21: learn: 0.3153914\ttest: 0.3149896\tbestTest: 0.3149896 (21)\ttotal: 1m 58s\tremaining: 7m 1s\n",
      "22: learn: 0.3095599\ttest: 0.3091427\tbestTest: 0.3091427 (22)\ttotal: 2m 4s\tremaining: 6m 55s\n",
      "23: learn: 0.3041803\ttest: 0.3037459\tbestTest: 0.3037459 (23)\ttotal: 2m 9s\tremaining: 6m 51s\n",
      "24: learn: 0.2989251\ttest: 0.2984735\tbestTest: 0.2984735 (24)\ttotal: 2m 14s\tremaining: 6m 44s\n",
      "25: learn: 0.2943694\ttest: 0.2939067\tbestTest: 0.2939067 (25)\ttotal: 2m 20s\tremaining: 6m 39s\n",
      "26: learn: 0.290124\ttest: 0.2896435\tbestTest: 0.2896435 (26)\ttotal: 2m 25s\tremaining: 6m 33s\n",
      "27: learn: 0.2859116\ttest: 0.2854177\tbestTest: 0.2854177 (27)\ttotal: 2m 30s\tremaining: 6m 26s\n",
      "28: learn: 0.2819387\ttest: 0.2814371\tbestTest: 0.2814371 (28)\ttotal: 2m 35s\tremaining: 6m 20s\n",
      "29: learn: 0.278352\ttest: 0.2778357\tbestTest: 0.2778357 (29)\ttotal: 2m 40s\tremaining: 6m 14s\n",
      "30: learn: 0.2749224\ttest: 0.2743933\tbestTest: 0.2743933 (30)\ttotal: 2m 46s\tremaining: 6m 10s\n",
      "31: learn: 0.2717277\ttest: 0.2711871\tbestTest: 0.2711871 (31)\ttotal: 2m 51s\tremaining: 6m 3s\n",
      "32: learn: 0.2690358\ttest: 0.2684841\tbestTest: 0.2684841 (32)\ttotal: 2m 56s\tremaining: 5m 58s\n",
      "33: learn: 0.2663363\ttest: 0.2657725\tbestTest: 0.2657725 (33)\ttotal: 3m 2s\tremaining: 5m 54s\n",
      "34: learn: 0.2639386\ttest: 0.2633657\tbestTest: 0.2633657 (34)\ttotal: 3m 7s\tremaining: 5m 49s\n",
      "35: learn: 0.2616816\ttest: 0.2611012\tbestTest: 0.2611012 (35)\ttotal: 3m 13s\tremaining: 5m 43s\n",
      "36: learn: 0.2596066\ttest: 0.2590125\tbestTest: 0.2590125 (36)\ttotal: 3m 18s\tremaining: 5m 38s\n",
      "37: learn: 0.2575624\ttest: 0.2569571\tbestTest: 0.2569571 (37)\ttotal: 3m 24s\tremaining: 5m 32s\n",
      "38: learn: 0.255602\ttest: 0.2549864\tbestTest: 0.2549864 (38)\ttotal: 3m 29s\tremaining: 5m 27s\n",
      "39: learn: 0.2538021\ttest: 0.2531751\tbestTest: 0.2531751 (39)\ttotal: 3m 34s\tremaining: 5m 21s\n",
      "40: learn: 0.2522911\ttest: 0.251656\tbestTest: 0.251656 (40)\ttotal: 3m 40s\tremaining: 5m 17s\n",
      "41: learn: 0.2506924\ttest: 0.2500454\tbestTest: 0.2500454 (41)\ttotal: 3m 45s\tremaining: 5m 11s\n",
      "42: learn: 0.2492235\ttest: 0.2485684\tbestTest: 0.2485684 (42)\ttotal: 3m 51s\tremaining: 5m 6s\n",
      "43: learn: 0.2478355\ttest: 0.2471707\tbestTest: 0.2471707 (43)\ttotal: 3m 56s\tremaining: 5m 1s\n",
      "44: learn: 0.246587\ttest: 0.2459137\tbestTest: 0.2459137 (44)\ttotal: 4m 2s\tremaining: 4m 56s\n",
      "45: learn: 0.2454454\ttest: 0.2447647\tbestTest: 0.2447647 (45)\ttotal: 4m 8s\tremaining: 4m 51s\n",
      "46: learn: 0.2442735\ttest: 0.2435835\tbestTest: 0.2435835 (46)\ttotal: 4m 13s\tremaining: 4m 45s\n",
      "47: learn: 0.2432393\ttest: 0.2425446\tbestTest: 0.2425446 (47)\ttotal: 4m 18s\tremaining: 4m 40s\n",
      "48: learn: 0.2422767\ttest: 0.2415764\tbestTest: 0.2415764 (48)\ttotal: 4m 24s\tremaining: 4m 35s\n",
      "49: learn: 0.2413588\ttest: 0.2406526\tbestTest: 0.2406526 (49)\ttotal: 4m 30s\tremaining: 4m 30s\n",
      "50: learn: 0.2405077\ttest: 0.2397978\tbestTest: 0.2397978 (50)\ttotal: 4m 35s\tremaining: 4m 25s\n",
      "51: learn: 0.2396715\ttest: 0.2389552\tbestTest: 0.2389552 (51)\ttotal: 4m 40s\tremaining: 4m 19s\n",
      "52: learn: 0.2388897\ttest: 0.2381682\tbestTest: 0.2381682 (52)\ttotal: 4m 45s\tremaining: 4m 13s\n",
      "53: learn: 0.2381743\ttest: 0.2374435\tbestTest: 0.2374435 (53)\ttotal: 4m 50s\tremaining: 4m 7s\n",
      "54: learn: 0.2375345\ttest: 0.2367975\tbestTest: 0.2367975 (54)\ttotal: 4m 56s\tremaining: 4m 2s\n",
      "55: learn: 0.2368843\ttest: 0.2361421\tbestTest: 0.2361421 (55)\ttotal: 5m 1s\tremaining: 3m 56s\n",
      "56: learn: 0.2362626\ttest: 0.2355159\tbestTest: 0.2355159 (56)\ttotal: 5m 6s\tremaining: 3m 51s\n",
      "57: learn: 0.2357361\ttest: 0.2349851\tbestTest: 0.2349851 (57)\ttotal: 5m 11s\tremaining: 3m 45s\n",
      "58: learn: 0.2352018\ttest: 0.2344465\tbestTest: 0.2344465 (58)\ttotal: 5m 16s\tremaining: 3m 40s\n",
      "59: learn: 0.2347057\ttest: 0.2339437\tbestTest: 0.2339437 (59)\ttotal: 5m 21s\tremaining: 3m 34s\n",
      "60: learn: 0.2342313\ttest: 0.2334648\tbestTest: 0.2334648 (60)\ttotal: 5m 26s\tremaining: 3m 29s\n",
      "61: learn: 0.2337839\ttest: 0.2330119\tbestTest: 0.2330119 (61)\ttotal: 5m 32s\tremaining: 3m 23s\n",
      "62: learn: 0.2333842\ttest: 0.2326097\tbestTest: 0.2326097 (62)\ttotal: 5m 38s\tremaining: 3m 18s\n",
      "63: learn: 0.2329583\ttest: 0.2321781\tbestTest: 0.2321781 (63)\ttotal: 5m 43s\tremaining: 3m 13s\n",
      "64: learn: 0.2325611\ttest: 0.2317752\tbestTest: 0.2317752 (64)\ttotal: 5m 48s\tremaining: 3m 7s\n",
      "65: learn: 0.2321744\ttest: 0.2313835\tbestTest: 0.2313835 (65)\ttotal: 5m 53s\tremaining: 3m 2s\n",
      "66: learn: 0.2318445\ttest: 0.2310491\tbestTest: 0.2310491 (66)\ttotal: 5m 59s\tremaining: 2m 57s\n",
      "67: learn: 0.2315273\ttest: 0.2307262\tbestTest: 0.2307262 (67)\ttotal: 6m 4s\tremaining: 2m 51s\n",
      "68: learn: 0.2312559\ttest: 0.2304536\tbestTest: 0.2304536 (68)\ttotal: 6m 9s\tremaining: 2m 46s\n",
      "69: learn: 0.2309486\ttest: 0.2301428\tbestTest: 0.2301428 (69)\ttotal: 6m 14s\tremaining: 2m 40s\n",
      "70: learn: 0.2307001\ttest: 0.2298901\tbestTest: 0.2298901 (70)\ttotal: 6m 20s\tremaining: 2m 35s\n",
      "71: learn: 0.2304314\ttest: 0.2296149\tbestTest: 0.2296149 (71)\ttotal: 6m 26s\tremaining: 2m 30s\n",
      "72: learn: 0.2301879\ttest: 0.2293684\tbestTest: 0.2293684 (72)\ttotal: 6m 31s\tremaining: 2m 24s\n",
      "73: learn: 0.2299137\ttest: 0.2290928\tbestTest: 0.2290928 (73)\ttotal: 6m 36s\tremaining: 2m 19s\n",
      "74: learn: 0.2296961\ttest: 0.2288719\tbestTest: 0.2288719 (74)\ttotal: 6m 42s\tremaining: 2m 14s\n",
      "75: learn: 0.2294741\ttest: 0.2286464\tbestTest: 0.2286464 (75)\ttotal: 6m 47s\tremaining: 2m 8s\n",
      "76: learn: 0.2292603\ttest: 0.2284306\tbestTest: 0.2284306 (76)\ttotal: 6m 52s\tremaining: 2m 3s\n",
      "77: learn: 0.2290573\ttest: 0.228224\tbestTest: 0.228224 (77)\ttotal: 6m 57s\tremaining: 1m 57s\n",
      "78: learn: 0.2288757\ttest: 0.22804\tbestTest: 0.22804 (78)\ttotal: 7m 2s\tremaining: 1m 52s\n",
      "79: learn: 0.2286994\ttest: 0.2278603\tbestTest: 0.2278603 (79)\ttotal: 7m 8s\tremaining: 1m 47s\n",
      "80: learn: 0.2284875\ttest: 0.2276467\tbestTest: 0.2276467 (80)\ttotal: 7m 13s\tremaining: 1m 41s\n",
      "81: learn: 0.2283416\ttest: 0.2274983\tbestTest: 0.2274983 (81)\ttotal: 7m 19s\tremaining: 1m 36s\n",
      "82: learn: 0.228202\ttest: 0.2273581\tbestTest: 0.2273581 (82)\ttotal: 7m 24s\tremaining: 1m 31s\n",
      "83: learn: 0.2280503\ttest: 0.2272065\tbestTest: 0.2272065 (83)\ttotal: 7m 30s\tremaining: 1m 25s\n",
      "84: learn: 0.2279158\ttest: 0.2270703\tbestTest: 0.2270703 (84)\ttotal: 7m 35s\tremaining: 1m 20s\n",
      "85: learn: 0.227778\ttest: 0.2269304\tbestTest: 0.2269304 (85)\ttotal: 7m 40s\tremaining: 1m 14s\n",
      "86: learn: 0.227651\ttest: 0.2268025\tbestTest: 0.2268025 (86)\ttotal: 7m 45s\tremaining: 1m 9s\n",
      "87: learn: 0.2275299\ttest: 0.2266808\tbestTest: 0.2266808 (87)\ttotal: 7m 51s\tremaining: 1m 4s\n",
      "88: learn: 0.2274167\ttest: 0.2265667\tbestTest: 0.2265667 (88)\ttotal: 7m 56s\tremaining: 58.9s\n",
      "89: learn: 0.2273018\ttest: 0.2264508\tbestTest: 0.2264508 (89)\ttotal: 8m 1s\tremaining: 53.5s\n",
      "90: learn: 0.227155\ttest: 0.2263045\tbestTest: 0.2263045 (90)\ttotal: 8m 6s\tremaining: 48.1s\n",
      "91: learn: 0.2270447\ttest: 0.2261933\tbestTest: 0.2261933 (91)\ttotal: 8m 11s\tremaining: 42.7s\n",
      "92: learn: 0.22696\ttest: 0.226108\tbestTest: 0.226108 (92)\ttotal: 8m 16s\tremaining: 37.3s\n",
      "93: learn: 0.2268553\ttest: 0.2260026\tbestTest: 0.2260026 (93)\ttotal: 8m 21s\tremaining: 32s\n",
      "94: learn: 0.2267662\ttest: 0.2259122\tbestTest: 0.2259122 (94)\ttotal: 8m 26s\tremaining: 26.7s\n",
      "95: learn: 0.2266803\ttest: 0.2258251\tbestTest: 0.2258251 (95)\ttotal: 8m 31s\tremaining: 21.3s\n",
      "96: learn: 0.2265659\ttest: 0.2257119\tbestTest: 0.2257119 (96)\ttotal: 8m 37s\tremaining: 16s\n",
      "97: learn: 0.2264751\ttest: 0.2256187\tbestTest: 0.2256187 (97)\ttotal: 8m 42s\tremaining: 10.7s\n",
      "98: learn: 0.2263967\ttest: 0.2255402\tbestTest: 0.2255402 (98)\ttotal: 8m 48s\tremaining: 5.33s\n",
      "99: learn: 0.2263157\ttest: 0.2254572\tbestTest: 0.2254572 (99)\ttotal: 8m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254571568\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_64_bag_temp_1\n",
      "2018-03-14 00:16:48.760167\n",
      "train time given below\n",
      "0:12:51.200662\n",
      "2018-03-14 00:16:48.768508\n",
      "2018-03-14 00:16:48.772123\n",
      "GINI ISIT = 0.455130478253\n",
      "2018-03-14 00:18:21.445835\n",
      "GINI OSIT = 0.456310950015\n",
      "2018-03-14 00:18:59.625236\n",
      "GINI OSOT = 0.409631239796\n",
      "2018-03-14 00:19:11.594828\n",
      "2018-03-14 00:19:11.596726\n",
      "categorical split = 128\n",
      "2018-03-14 00:19:11.598110\n",
      "model train start\n",
      "2018-03-14 00:19:11.598331\n",
      "0: learn: 0.6581866\ttest: 0.6581573\tbestTest: 0.6581573 (0)\ttotal: 3.59s\tremaining: 5m 55s\n",
      "1: learn: 0.6254278\ttest: 0.6253928\tbestTest: 0.6253928 (1)\ttotal: 9.5s\tremaining: 7m 45s\n",
      "2: learn: 0.5949448\ttest: 0.5948869\tbestTest: 0.5948869 (2)\ttotal: 14.4s\tremaining: 7m 46s\n",
      "3: learn: 0.5676836\ttest: 0.5675985\tbestTest: 0.5675985 (3)\ttotal: 20.2s\tremaining: 8m 4s\n",
      "4: learn: 0.5423101\ttest: 0.5422035\tbestTest: 0.5422035 (4)\ttotal: 26s\tremaining: 8m 14s\n",
      "5: learn: 0.518615\ttest: 0.5184895\tbestTest: 0.5184895 (5)\ttotal: 32s\tremaining: 8m 21s\n",
      "6: learn: 0.4963122\ttest: 0.4961565\tbestTest: 0.4961565 (6)\ttotal: 37.1s\tremaining: 8m 12s\n",
      "7: learn: 0.4763265\ttest: 0.4761504\tbestTest: 0.4761504 (7)\ttotal: 43s\tremaining: 8m 14s\n",
      "8: learn: 0.4578648\ttest: 0.457665\tbestTest: 0.457665 (8)\ttotal: 48.8s\tremaining: 8m 13s\n",
      "9: learn: 0.4406974\ttest: 0.4404814\tbestTest: 0.4404814 (9)\ttotal: 54.4s\tremaining: 8m 9s\n",
      "10: learn: 0.424793\ttest: 0.4245504\tbestTest: 0.4245504 (10)\ttotal: 60s\tremaining: 8m 5s\n",
      "11: learn: 0.4101957\ttest: 0.4099289\tbestTest: 0.4099289 (11)\ttotal: 1m 4s\tremaining: 7m 54s\n",
      "12: learn: 0.3970551\ttest: 0.3967683\tbestTest: 0.3967683 (12)\ttotal: 1m 9s\tremaining: 7m 45s\n",
      "13: learn: 0.3852465\ttest: 0.3849483\tbestTest: 0.3849483 (13)\ttotal: 1m 15s\tremaining: 7m 43s\n",
      "14: learn: 0.3737689\ttest: 0.3734572\tbestTest: 0.3734572 (14)\ttotal: 1m 20s\tremaining: 7m 38s\n",
      "15: learn: 0.363302\ttest: 0.3629762\tbestTest: 0.3629762 (15)\ttotal: 1m 26s\tremaining: 7m 31s\n",
      "16: learn: 0.3540244\ttest: 0.3536817\tbestTest: 0.3536817 (16)\ttotal: 1m 31s\tremaining: 7m 25s\n",
      "17: learn: 0.3448887\ttest: 0.344528\tbestTest: 0.344528 (17)\ttotal: 1m 36s\tremaining: 7m 18s\n",
      "18: learn: 0.337171\ttest: 0.3367874\tbestTest: 0.3367874 (18)\ttotal: 1m 41s\tremaining: 7m 12s\n",
      "19: learn: 0.3294414\ttest: 0.32904\tbestTest: 0.32904 (19)\ttotal: 1m 47s\tremaining: 7m 8s\n",
      "20: learn: 0.3222969\ttest: 0.3218818\tbestTest: 0.3218818 (20)\ttotal: 1m 52s\tremaining: 7m 1s\n",
      "21: learn: 0.3159374\ttest: 0.3155066\tbestTest: 0.3155066 (21)\ttotal: 1m 57s\tremaining: 6m 58s\n",
      "22: learn: 0.3098875\ttest: 0.3094477\tbestTest: 0.3094477 (22)\ttotal: 2m 3s\tremaining: 6m 54s\n",
      "23: learn: 0.3041494\ttest: 0.303695\tbestTest: 0.303695 (23)\ttotal: 2m 8s\tremaining: 6m 48s\n",
      "24: learn: 0.2989155\ttest: 0.2984437\tbestTest: 0.2984437 (24)\ttotal: 2m 13s\tremaining: 6m 41s\n",
      "25: learn: 0.2943076\ttest: 0.2938229\tbestTest: 0.2938229 (25)\ttotal: 2m 19s\tremaining: 6m 35s\n",
      "26: learn: 0.2901069\ttest: 0.2896115\tbestTest: 0.2896115 (26)\ttotal: 2m 24s\tremaining: 6m 31s\n",
      "27: learn: 0.2858358\ttest: 0.2853261\tbestTest: 0.2853261 (27)\ttotal: 2m 29s\tremaining: 6m 25s\n",
      "28: learn: 0.281807\ttest: 0.2812847\tbestTest: 0.2812847 (28)\ttotal: 2m 35s\tremaining: 6m 19s\n",
      "29: learn: 0.2781137\ttest: 0.2775819\tbestTest: 0.2775819 (29)\ttotal: 2m 40s\tremaining: 6m 14s\n",
      "30: learn: 0.2750457\ttest: 0.274504\tbestTest: 0.274504 (30)\ttotal: 2m 46s\tremaining: 6m 9s\n",
      "31: learn: 0.271929\ttest: 0.2713732\tbestTest: 0.2713732 (31)\ttotal: 2m 51s\tremaining: 6m 4s\n",
      "32: learn: 0.2692828\ttest: 0.2687171\tbestTest: 0.2687171 (32)\ttotal: 2m 57s\tremaining: 5m 59s\n",
      "33: learn: 0.2665365\ttest: 0.265961\tbestTest: 0.265961 (33)\ttotal: 3m 2s\tremaining: 5m 54s\n",
      "34: learn: 0.2639715\ttest: 0.2633946\tbestTest: 0.2633946 (34)\ttotal: 3m 8s\tremaining: 5m 50s\n",
      "35: learn: 0.2615179\ttest: 0.2609305\tbestTest: 0.2609305 (35)\ttotal: 3m 13s\tremaining: 5m 44s\n",
      "36: learn: 0.2594244\ttest: 0.2588283\tbestTest: 0.2588283 (36)\ttotal: 3m 19s\tremaining: 5m 40s\n",
      "37: learn: 0.2573954\ttest: 0.2567874\tbestTest: 0.2567874 (37)\ttotal: 3m 24s\tremaining: 5m 33s\n",
      "38: learn: 0.2554121\ttest: 0.2547909\tbestTest: 0.2547909 (38)\ttotal: 3m 30s\tremaining: 5m 28s\n",
      "39: learn: 0.25375\ttest: 0.2531188\tbestTest: 0.2531188 (39)\ttotal: 3m 35s\tremaining: 5m 23s\n",
      "40: learn: 0.2521086\ttest: 0.2514708\tbestTest: 0.2514708 (40)\ttotal: 3m 40s\tremaining: 5m 17s\n",
      "41: learn: 0.250472\ttest: 0.2498264\tbestTest: 0.2498264 (41)\ttotal: 3m 45s\tremaining: 5m 11s\n",
      "42: learn: 0.2490461\ttest: 0.2483927\tbestTest: 0.2483927 (42)\ttotal: 3m 50s\tremaining: 5m 6s\n",
      "43: learn: 0.2477575\ttest: 0.2470958\tbestTest: 0.2470958 (43)\ttotal: 3m 56s\tremaining: 5m 1s\n",
      "44: learn: 0.2465425\ttest: 0.245873\tbestTest: 0.245873 (44)\ttotal: 4m 1s\tremaining: 4m 55s\n",
      "45: learn: 0.245427\ttest: 0.2447504\tbestTest: 0.2447504 (45)\ttotal: 4m 6s\tremaining: 4m 49s\n",
      "46: learn: 0.2442284\ttest: 0.2435437\tbestTest: 0.2435437 (46)\ttotal: 4m 12s\tremaining: 4m 44s\n",
      "47: learn: 0.2432636\ttest: 0.2425683\tbestTest: 0.2425683 (47)\ttotal: 4m 18s\tremaining: 4m 39s\n",
      "48: learn: 0.2423095\ttest: 0.2416092\tbestTest: 0.2416092 (48)\ttotal: 4m 23s\tremaining: 4m 34s\n",
      "49: learn: 0.2413372\ttest: 0.2406284\tbestTest: 0.2406284 (49)\ttotal: 4m 28s\tremaining: 4m 28s\n",
      "50: learn: 0.2404767\ttest: 0.2397619\tbestTest: 0.2397619 (50)\ttotal: 4m 33s\tremaining: 4m 23s\n",
      "51: learn: 0.2396404\ttest: 0.2389195\tbestTest: 0.2389195 (51)\ttotal: 4m 38s\tremaining: 4m 17s\n",
      "52: learn: 0.238926\ttest: 0.2382022\tbestTest: 0.2382022 (52)\ttotal: 4m 44s\tremaining: 4m 12s\n",
      "53: learn: 0.2382827\ttest: 0.2375525\tbestTest: 0.2375525 (53)\ttotal: 4m 50s\tremaining: 4m 7s\n",
      "54: learn: 0.2376015\ttest: 0.2368658\tbestTest: 0.2368658 (54)\ttotal: 4m 57s\tremaining: 4m 3s\n",
      "55: learn: 0.2369419\ttest: 0.2361988\tbestTest: 0.2361988 (55)\ttotal: 5m 2s\tremaining: 3m 57s\n",
      "56: learn: 0.236317\ttest: 0.2355695\tbestTest: 0.2355695 (56)\ttotal: 5m 6s\tremaining: 3m 51s\n",
      "57: learn: 0.2357215\ttest: 0.2349681\tbestTest: 0.2349681 (57)\ttotal: 5m 11s\tremaining: 3m 45s\n",
      "58: learn: 0.2351638\ttest: 0.2344052\tbestTest: 0.2344052 (58)\ttotal: 5m 16s\tremaining: 3m 39s\n",
      "59: learn: 0.2346776\ttest: 0.2339159\tbestTest: 0.2339159 (59)\ttotal: 5m 21s\tremaining: 3m 34s\n",
      "60: learn: 0.2342119\ttest: 0.2334464\tbestTest: 0.2334464 (60)\ttotal: 5m 27s\tremaining: 3m 29s\n",
      "61: learn: 0.2338152\ttest: 0.2330452\tbestTest: 0.2330452 (61)\ttotal: 5m 32s\tremaining: 3m 24s\n",
      "62: learn: 0.2333574\ttest: 0.232582\tbestTest: 0.232582 (62)\ttotal: 5m 38s\tremaining: 3m 18s\n",
      "63: learn: 0.2330129\ttest: 0.2322348\tbestTest: 0.2322348 (63)\ttotal: 5m 43s\tremaining: 3m 13s\n",
      "64: learn: 0.232611\ttest: 0.2318294\tbestTest: 0.2318294 (64)\ttotal: 5m 48s\tremaining: 3m 7s\n",
      "65: learn: 0.2322513\ttest: 0.231466\tbestTest: 0.231466 (65)\ttotal: 5m 54s\tremaining: 3m 2s\n",
      "66: learn: 0.2319482\ttest: 0.2311603\tbestTest: 0.2311603 (66)\ttotal: 6m\tremaining: 2m 57s\n",
      "67: learn: 0.2316054\ttest: 0.2308138\tbestTest: 0.2308138 (67)\ttotal: 6m 5s\tremaining: 2m 52s\n",
      "68: learn: 0.2313025\ttest: 0.230509\tbestTest: 0.230509 (68)\ttotal: 6m 11s\tremaining: 2m 46s\n",
      "69: learn: 0.2309919\ttest: 0.2301943\tbestTest: 0.2301943 (69)\ttotal: 6m 15s\tremaining: 2m 41s\n",
      "70: learn: 0.2306927\ttest: 0.2298911\tbestTest: 0.2298911 (70)\ttotal: 6m 21s\tremaining: 2m 35s\n",
      "71: learn: 0.2304117\ttest: 0.2296048\tbestTest: 0.2296048 (71)\ttotal: 6m 26s\tremaining: 2m 30s\n",
      "72: learn: 0.2301525\ttest: 0.2293434\tbestTest: 0.2293434 (72)\ttotal: 6m 31s\tremaining: 2m 24s\n",
      "73: learn: 0.229905\ttest: 0.2290925\tbestTest: 0.2290925 (73)\ttotal: 6m 37s\tremaining: 2m 19s\n",
      "74: learn: 0.2296891\ttest: 0.2288736\tbestTest: 0.2288736 (74)\ttotal: 6m 42s\tremaining: 2m 14s\n",
      "75: learn: 0.2294704\ttest: 0.2286529\tbestTest: 0.2286529 (75)\ttotal: 6m 47s\tremaining: 2m 8s\n",
      "76: learn: 0.2292694\ttest: 0.2284497\tbestTest: 0.2284497 (76)\ttotal: 6m 52s\tremaining: 2m 3s\n",
      "77: learn: 0.2290926\ttest: 0.2282719\tbestTest: 0.2282719 (77)\ttotal: 6m 57s\tremaining: 1m 57s\n",
      "78: learn: 0.2289067\ttest: 0.2280835\tbestTest: 0.2280835 (78)\ttotal: 7m 3s\tremaining: 1m 52s\n",
      "79: learn: 0.2287544\ttest: 0.2279301\tbestTest: 0.2279301 (79)\ttotal: 7m 8s\tremaining: 1m 47s\n",
      "80: learn: 0.2285672\ttest: 0.2277399\tbestTest: 0.2277399 (80)\ttotal: 7m 13s\tremaining: 1m 41s\n",
      "81: learn: 0.2283947\ttest: 0.227565\tbestTest: 0.227565 (81)\ttotal: 7m 18s\tremaining: 1m 36s\n",
      "82: learn: 0.2282514\ttest: 0.2274214\tbestTest: 0.2274214 (82)\ttotal: 7m 24s\tremaining: 1m 31s\n",
      "83: learn: 0.228117\ttest: 0.2272853\tbestTest: 0.2272853 (83)\ttotal: 7m 29s\tremaining: 1m 25s\n",
      "84: learn: 0.2279925\ttest: 0.2271586\tbestTest: 0.2271586 (84)\ttotal: 7m 34s\tremaining: 1m 20s\n",
      "85: learn: 0.2278513\ttest: 0.2270156\tbestTest: 0.2270156 (85)\ttotal: 7m 40s\tremaining: 1m 15s\n",
      "86: learn: 0.2277286\ttest: 0.2268896\tbestTest: 0.2268896 (86)\ttotal: 7m 46s\tremaining: 1m 9s\n",
      "87: learn: 0.2275905\ttest: 0.2267489\tbestTest: 0.2267489 (87)\ttotal: 7m 52s\tremaining: 1m 4s\n",
      "88: learn: 0.2274752\ttest: 0.2266316\tbestTest: 0.2266316 (88)\ttotal: 7m 57s\tremaining: 59s\n",
      "89: learn: 0.2273835\ttest: 0.2265368\tbestTest: 0.2265368 (89)\ttotal: 8m 3s\tremaining: 53.7s\n",
      "90: learn: 0.2272869\ttest: 0.2264392\tbestTest: 0.2264392 (90)\ttotal: 8m 8s\tremaining: 48.3s\n",
      "91: learn: 0.2271799\ttest: 0.2263302\tbestTest: 0.2263302 (91)\ttotal: 8m 13s\tremaining: 42.9s\n",
      "92: learn: 0.2270722\ttest: 0.2262221\tbestTest: 0.2262221 (92)\ttotal: 8m 18s\tremaining: 37.5s\n",
      "93: learn: 0.2269713\ttest: 0.2261202\tbestTest: 0.2261202 (93)\ttotal: 8m 23s\tremaining: 32.2s\n",
      "94: learn: 0.2268861\ttest: 0.2260333\tbestTest: 0.2260333 (94)\ttotal: 8m 28s\tremaining: 26.8s\n",
      "95: learn: 0.2267764\ttest: 0.2259234\tbestTest: 0.2259234 (95)\ttotal: 8m 33s\tremaining: 21.4s\n",
      "96: learn: 0.226685\ttest: 0.2258313\tbestTest: 0.2258313 (96)\ttotal: 8m 38s\tremaining: 16s\n",
      "97: learn: 0.2265965\ttest: 0.225741\tbestTest: 0.225741 (97)\ttotal: 8m 44s\tremaining: 10.7s\n",
      "98: learn: 0.2265027\ttest: 0.2256458\tbestTest: 0.2256458 (98)\ttotal: 8m 49s\tremaining: 5.35s\n",
      "99: learn: 0.2264298\ttest: 0.225572\tbestTest: 0.225572 (99)\ttotal: 8m 54s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2255719944\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_128_bag_temp_1\n",
      "2018-03-14 00:32:05.886991\n",
      "train time given below\n",
      "0:12:54.288660\n",
      "2018-03-14 00:32:06.214930\n",
      "2018-03-14 00:32:06.219215\n",
      "GINI ISIT = 0.454683859795\n",
      "2018-03-14 00:33:35.899869\n",
      "GINI OSIT = 0.456024341159\n",
      "2018-03-14 00:34:16.169135\n",
      "GINI OSOT = 0.408098376883\n",
      "2018-03-14 00:34:28.198947\n",
      "2018-03-14 00:34:28.201143\n",
      "categorical split = 255\n",
      "2018-03-14 00:34:28.202536\n",
      "model train start\n",
      "2018-03-14 00:34:28.202765\n",
      "0: learn: 0.6577561\ttest: 0.6577323\tbestTest: 0.6577323 (0)\ttotal: 6.06s\tremaining: 9m 59s\n",
      "1: learn: 0.6249396\ttest: 0.6248912\tbestTest: 0.6248912 (1)\ttotal: 12.2s\tremaining: 9m 55s\n",
      "2: learn: 0.594956\ttest: 0.5949012\tbestTest: 0.5949012 (2)\ttotal: 18.4s\tremaining: 9m 55s\n",
      "3: learn: 0.5676856\ttest: 0.5676155\tbestTest: 0.5676155 (3)\ttotal: 24.5s\tremaining: 9m 47s\n",
      "4: learn: 0.5419998\ttest: 0.54191\tbestTest: 0.54191 (4)\ttotal: 30.3s\tremaining: 9m 34s\n",
      "5: learn: 0.5187964\ttest: 0.5186763\tbestTest: 0.5186763 (5)\ttotal: 32.3s\tremaining: 8m 25s\n",
      "6: learn: 0.4968221\ttest: 0.4966767\tbestTest: 0.4966767 (6)\ttotal: 37.5s\tremaining: 8m 18s\n",
      "7: learn: 0.4763423\ttest: 0.4761711\tbestTest: 0.4761711 (7)\ttotal: 43.2s\tremaining: 8m 16s\n",
      "8: learn: 0.4574979\ttest: 0.4573178\tbestTest: 0.4573178 (8)\ttotal: 48.3s\tremaining: 8m 8s\n",
      "9: learn: 0.440166\ttest: 0.4399732\tbestTest: 0.4399732 (9)\ttotal: 53.5s\tremaining: 8m 1s\n",
      "10: learn: 0.4249403\ttest: 0.4247359\tbestTest: 0.4247359 (10)\ttotal: 59.7s\tremaining: 8m 2s\n",
      "11: learn: 0.4101776\ttest: 0.409949\tbestTest: 0.409949 (11)\ttotal: 1m 5s\tremaining: 7m 57s\n",
      "12: learn: 0.3970891\ttest: 0.3968437\tbestTest: 0.3968437 (12)\ttotal: 1m 10s\tremaining: 7m 48s\n",
      "13: learn: 0.3844157\ttest: 0.38415\tbestTest: 0.38415 (13)\ttotal: 1m 15s\tremaining: 7m 42s\n",
      "14: learn: 0.373575\ttest: 0.3732894\tbestTest: 0.3732894 (14)\ttotal: 1m 20s\tremaining: 7m 35s\n",
      "15: learn: 0.3635034\ttest: 0.3632032\tbestTest: 0.3632032 (15)\ttotal: 1m 25s\tremaining: 7m 30s\n",
      "16: learn: 0.3536331\ttest: 0.3533151\tbestTest: 0.3533151 (16)\ttotal: 1m 31s\tremaining: 7m 25s\n",
      "17: learn: 0.3450796\ttest: 0.344751\tbestTest: 0.344751 (17)\ttotal: 1m 37s\tremaining: 7m 23s\n",
      "18: learn: 0.3366723\ttest: 0.3363257\tbestTest: 0.3363257 (18)\ttotal: 1m 42s\tremaining: 7m 16s\n",
      "19: learn: 0.3291044\ttest: 0.3287421\tbestTest: 0.3287421 (19)\ttotal: 1m 48s\tremaining: 7m 12s\n",
      "20: learn: 0.3219109\ttest: 0.3215278\tbestTest: 0.3215278 (20)\ttotal: 1m 53s\tremaining: 7m 5s\n",
      "21: learn: 0.3157652\ttest: 0.3153666\tbestTest: 0.3153666 (21)\ttotal: 1m 58s\tremaining: 7m 1s\n",
      "22: learn: 0.3097287\ttest: 0.3093127\tbestTest: 0.3093127 (22)\ttotal: 2m 4s\tremaining: 6m 58s\n",
      "23: learn: 0.3039778\ttest: 0.3035487\tbestTest: 0.3035487 (23)\ttotal: 2m 9s\tremaining: 6m 51s\n",
      "24: learn: 0.2986962\ttest: 0.2982484\tbestTest: 0.2982484 (24)\ttotal: 2m 15s\tremaining: 6m 46s\n",
      "25: learn: 0.2937746\ttest: 0.2933139\tbestTest: 0.2933139 (25)\ttotal: 2m 21s\tremaining: 6m 41s\n",
      "26: learn: 0.2897287\ttest: 0.2892555\tbestTest: 0.2892555 (26)\ttotal: 2m 27s\tremaining: 6m 37s\n",
      "27: learn: 0.2855955\ttest: 0.2851091\tbestTest: 0.2851091 (27)\ttotal: 2m 32s\tremaining: 6m 32s\n",
      "28: learn: 0.2816384\ttest: 0.2811334\tbestTest: 0.2811334 (28)\ttotal: 2m 37s\tremaining: 6m 25s\n",
      "29: learn: 0.2781485\ttest: 0.2776372\tbestTest: 0.2776372 (29)\ttotal: 2m 42s\tremaining: 6m 19s\n",
      "30: learn: 0.2748286\ttest: 0.2743073\tbestTest: 0.2743073 (30)\ttotal: 2m 48s\tremaining: 6m 14s\n",
      "31: learn: 0.2716608\ttest: 0.2711261\tbestTest: 0.2711261 (31)\ttotal: 2m 53s\tremaining: 6m 7s\n",
      "32: learn: 0.2687245\ttest: 0.2681795\tbestTest: 0.2681795 (32)\ttotal: 2m 58s\tremaining: 6m 2s\n",
      "33: learn: 0.2661501\ttest: 0.265593\tbestTest: 0.265593 (33)\ttotal: 3m 3s\tremaining: 5m 57s\n",
      "34: learn: 0.2636886\ttest: 0.2631212\tbestTest: 0.2631212 (34)\ttotal: 3m 8s\tremaining: 5m 50s\n",
      "35: learn: 0.2613144\ttest: 0.2607312\tbestTest: 0.2607312 (35)\ttotal: 3m 13s\tremaining: 5m 44s\n",
      "36: learn: 0.2590324\ttest: 0.2584369\tbestTest: 0.2584369 (36)\ttotal: 3m 19s\tremaining: 5m 39s\n",
      "37: learn: 0.2569933\ttest: 0.256388\tbestTest: 0.256388 (37)\ttotal: 3m 24s\tremaining: 5m 34s\n",
      "38: learn: 0.2553057\ttest: 0.2546918\tbestTest: 0.2546918 (38)\ttotal: 3m 30s\tremaining: 5m 28s\n",
      "39: learn: 0.2535738\ttest: 0.2529535\tbestTest: 0.2529535 (39)\ttotal: 3m 35s\tremaining: 5m 23s\n",
      "40: learn: 0.2518623\ttest: 0.2512312\tbestTest: 0.2512312 (40)\ttotal: 3m 41s\tremaining: 5m 18s\n",
      "41: learn: 0.2503089\ttest: 0.2496668\tbestTest: 0.2496668 (41)\ttotal: 3m 46s\tremaining: 5m 12s\n",
      "42: learn: 0.2489773\ttest: 0.2483264\tbestTest: 0.2483264 (42)\ttotal: 3m 52s\tremaining: 5m 8s\n",
      "43: learn: 0.2475897\ttest: 0.246932\tbestTest: 0.246932 (43)\ttotal: 3m 57s\tremaining: 5m 2s\n",
      "44: learn: 0.2464376\ttest: 0.2457733\tbestTest: 0.2457733 (44)\ttotal: 4m 2s\tremaining: 4m 56s\n",
      "45: learn: 0.2452333\ttest: 0.2445613\tbestTest: 0.2445613 (45)\ttotal: 4m 7s\tremaining: 4m 50s\n",
      "46: learn: 0.2440588\ttest: 0.2433797\tbestTest: 0.2433797 (46)\ttotal: 4m 12s\tremaining: 4m 44s\n",
      "47: learn: 0.2430199\ttest: 0.2423338\tbestTest: 0.2423338 (47)\ttotal: 4m 17s\tremaining: 4m 39s\n",
      "48: learn: 0.2420051\ttest: 0.2413109\tbestTest: 0.2413109 (48)\ttotal: 4m 22s\tremaining: 4m 33s\n",
      "49: learn: 0.2410783\ttest: 0.2403752\tbestTest: 0.2403752 (49)\ttotal: 4m 27s\tremaining: 4m 27s\n",
      "50: learn: 0.2401609\ttest: 0.2394521\tbestTest: 0.2394521 (50)\ttotal: 4m 32s\tremaining: 4m 21s\n",
      "51: learn: 0.2393357\ttest: 0.2386194\tbestTest: 0.2386194 (51)\ttotal: 4m 37s\tremaining: 4m 16s\n",
      "52: learn: 0.2385729\ttest: 0.2378484\tbestTest: 0.2378484 (52)\ttotal: 4m 42s\tremaining: 4m 10s\n",
      "53: learn: 0.2379123\ttest: 0.237183\tbestTest: 0.237183 (53)\ttotal: 4m 47s\tremaining: 4m 5s\n",
      "54: learn: 0.2372305\ttest: 0.2364951\tbestTest: 0.2364951 (54)\ttotal: 4m 52s\tremaining: 3m 59s\n",
      "55: learn: 0.2366104\ttest: 0.2358694\tbestTest: 0.2358694 (55)\ttotal: 4m 57s\tremaining: 3m 54s\n",
      "56: learn: 0.2360342\ttest: 0.2352877\tbestTest: 0.2352877 (56)\ttotal: 5m 3s\tremaining: 3m 48s\n",
      "57: learn: 0.2354702\ttest: 0.2347182\tbestTest: 0.2347182 (57)\ttotal: 5m 8s\tremaining: 3m 43s\n",
      "58: learn: 0.2349233\ttest: 0.2341684\tbestTest: 0.2341684 (58)\ttotal: 5m 13s\tremaining: 3m 38s\n",
      "59: learn: 0.2345056\ttest: 0.2337453\tbestTest: 0.2337453 (59)\ttotal: 5m 19s\tremaining: 3m 33s\n",
      "60: learn: 0.2340428\ttest: 0.2332786\tbestTest: 0.2332786 (60)\ttotal: 5m 24s\tremaining: 3m 27s\n",
      "61: learn: 0.2336388\ttest: 0.2328695\tbestTest: 0.2328695 (61)\ttotal: 5m 30s\tremaining: 3m 22s\n",
      "62: learn: 0.2331985\ttest: 0.2324247\tbestTest: 0.2324247 (62)\ttotal: 5m 36s\tremaining: 3m 17s\n",
      "63: learn: 0.2327963\ttest: 0.2320189\tbestTest: 0.2320189 (63)\ttotal: 5m 41s\tremaining: 3m 11s\n",
      "64: learn: 0.2324267\ttest: 0.2316458\tbestTest: 0.2316458 (64)\ttotal: 5m 45s\tremaining: 3m 6s\n",
      "65: learn: 0.232068\ttest: 0.2312833\tbestTest: 0.2312833 (65)\ttotal: 5m 51s\tremaining: 3m 1s\n",
      "66: learn: 0.2317418\ttest: 0.2309532\tbestTest: 0.2309532 (66)\ttotal: 5m 57s\tremaining: 2m 55s\n",
      "67: learn: 0.2313825\ttest: 0.2305918\tbestTest: 0.2305918 (67)\ttotal: 6m 2s\tremaining: 2m 50s\n",
      "68: learn: 0.2310962\ttest: 0.2303037\tbestTest: 0.2303037 (68)\ttotal: 6m 7s\tremaining: 2m 45s\n",
      "69: learn: 0.2307947\ttest: 0.2299988\tbestTest: 0.2299988 (69)\ttotal: 6m 12s\tremaining: 2m 39s\n",
      "70: learn: 0.2305202\ttest: 0.2297212\tbestTest: 0.2297212 (70)\ttotal: 6m 17s\tremaining: 2m 34s\n",
      "71: learn: 0.2302834\ttest: 0.229481\tbestTest: 0.229481 (71)\ttotal: 6m 23s\tremaining: 2m 29s\n",
      "72: learn: 0.2300503\ttest: 0.2292452\tbestTest: 0.2292452 (72)\ttotal: 6m 28s\tremaining: 2m 23s\n",
      "73: learn: 0.2297954\ttest: 0.228988\tbestTest: 0.228988 (73)\ttotal: 6m 33s\tremaining: 2m 18s\n",
      "74: learn: 0.2295848\ttest: 0.228775\tbestTest: 0.228775 (74)\ttotal: 6m 39s\tremaining: 2m 13s\n",
      "75: learn: 0.2293696\ttest: 0.2285571\tbestTest: 0.2285571 (75)\ttotal: 6m 44s\tremaining: 2m 7s\n",
      "76: learn: 0.229208\ttest: 0.2283939\tbestTest: 0.2283939 (76)\ttotal: 6m 49s\tremaining: 2m 2s\n",
      "77: learn: 0.2290312\ttest: 0.2282162\tbestTest: 0.2282162 (77)\ttotal: 6m 55s\tremaining: 1m 57s\n",
      "78: learn: 0.2288316\ttest: 0.2280123\tbestTest: 0.2280123 (78)\ttotal: 7m\tremaining: 1m 51s\n",
      "79: learn: 0.2286633\ttest: 0.2278408\tbestTest: 0.2278408 (79)\ttotal: 7m 5s\tremaining: 1m 46s\n",
      "80: learn: 0.2284864\ttest: 0.2276623\tbestTest: 0.2276623 (80)\ttotal: 7m 10s\tremaining: 1m 40s\n",
      "81: learn: 0.2283305\ttest: 0.2275043\tbestTest: 0.2275043 (81)\ttotal: 7m 16s\tremaining: 1m 35s\n",
      "82: learn: 0.2281629\ttest: 0.2273329\tbestTest: 0.2273329 (82)\ttotal: 7m 21s\tremaining: 1m 30s\n",
      "83: learn: 0.2280217\ttest: 0.2271908\tbestTest: 0.2271908 (83)\ttotal: 7m 26s\tremaining: 1m 24s\n",
      "84: learn: 0.2278701\ttest: 0.2270384\tbestTest: 0.2270384 (84)\ttotal: 7m 31s\tremaining: 1m 19s\n",
      "85: learn: 0.2277339\ttest: 0.2269005\tbestTest: 0.2269005 (85)\ttotal: 7m 36s\tremaining: 1m 14s\n",
      "86: learn: 0.2275998\ttest: 0.2267657\tbestTest: 0.2267657 (86)\ttotal: 7m 41s\tremaining: 1m 8s\n",
      "87: learn: 0.2274757\ttest: 0.2266387\tbestTest: 0.2266387 (87)\ttotal: 7m 46s\tremaining: 1m 3s\n",
      "88: learn: 0.2273747\ttest: 0.2265348\tbestTest: 0.2265348 (88)\ttotal: 7m 51s\tremaining: 58.3s\n",
      "89: learn: 0.2272729\ttest: 0.2264326\tbestTest: 0.2264326 (89)\ttotal: 7m 57s\tremaining: 53s\n",
      "90: learn: 0.2271719\ttest: 0.2263286\tbestTest: 0.2263286 (90)\ttotal: 8m 2s\tremaining: 47.7s\n",
      "91: learn: 0.2270765\ttest: 0.2262316\tbestTest: 0.2262316 (91)\ttotal: 8m 8s\tremaining: 42.4s\n",
      "92: learn: 0.2269587\ttest: 0.2261112\tbestTest: 0.2261112 (92)\ttotal: 8m 14s\tremaining: 37.2s\n",
      "93: learn: 0.2268613\ttest: 0.2260112\tbestTest: 0.2260112 (93)\ttotal: 8m 19s\tremaining: 31.9s\n",
      "94: learn: 0.2267681\ttest: 0.2259178\tbestTest: 0.2259178 (94)\ttotal: 8m 24s\tremaining: 26.6s\n",
      "95: learn: 0.2266723\ttest: 0.2258208\tbestTest: 0.2258208 (95)\ttotal: 8m 29s\tremaining: 21.2s\n",
      "96: learn: 0.2265855\ttest: 0.225733\tbestTest: 0.225733 (96)\ttotal: 8m 34s\tremaining: 15.9s\n",
      "97: learn: 0.2264992\ttest: 0.2256444\tbestTest: 0.2256444 (97)\ttotal: 8m 40s\tremaining: 10.6s\n",
      "98: learn: 0.2264092\ttest: 0.2255546\tbestTest: 0.2255546 (98)\ttotal: 8m 45s\tremaining: 5.3s\n",
      "99: learn: 0.2263276\ttest: 0.2254714\tbestTest: 0.2254714 (99)\ttotal: 8m 50s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254714164\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_128_cat_split_255_bag_temp_1\n",
      "2018-03-14 00:47:20.123191\n",
      "train time given below\n",
      "0:12:51.920426\n",
      "2018-03-14 00:47:20.134721\n",
      "2018-03-14 00:47:20.138173\n"
     ]
    }
   ],
   "source": [
    "# optimize cat_split\n",
    "\n",
    "for cat_split in cat_split_pv:\n",
    "    \n",
    "    print('categorical split = ' + str(cat_split))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_def,\n",
    "                           lrn_rt = lrn_rt_def,\n",
    "                           dep = dep_def,\n",
    "                           l2_reg = l2_reg_def,\n",
    "                           num_split = num_split_def,\n",
    "                           cat_split = cat_split,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_def\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt_def\n",
    "    result_df_temp.loc[0,'depth'] = dep_def\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_def\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_def\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451849</td>\n",
       "      <td>0.453623</td>\n",
       "      <td>0.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.45484</td>\n",
       "      <td>0.407005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>0.405824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45513</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454684</td>\n",
       "      <td>0.456024</td>\n",
       "      <td>0.408098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455045</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.40867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100   1          0.03     6                 1             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 5             128   \n",
       "0    100   1          0.03     6                10             128   \n",
       "0    100   1          0.03     6                50             128   \n",
       "0    100   1          0.03     6               100             128   \n",
       "0    100   1          0.03     6                 3               5   \n",
       "0    100   1          0.03     6                 3              10   \n",
       "0    100   1          0.03     6                 3              16   \n",
       "0    100   1          0.03     6                 3              32   \n",
       "0    100   1          0.03     6                 3              64   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             255   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "0    100   1          0.03     6                 3             128   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  \n",
       "0                 5                   1  0.451849  0.453623  0.402904  \n",
       "0                10                   1  0.453604   0.45484  0.407005  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                32                   1  0.453115  0.454388  0.405824  \n",
       "0                64                   1   0.45513  0.456311  0.409631  \n",
       "0               128                   1  0.454684  0.456024  0.408098  \n",
       "0               255                   1  0.455045  0.456244   0.40867  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal values of l2 regularization, num split and cat split\n",
    "\n",
    "l2_reg_opt = 3\n",
    "num_split_opt = 16\n",
    "cat_split_opt = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsm = 0.5\n",
      "2018-03-14 02:46:08.656184\n",
      "model train start\n",
      "2018-03-14 02:46:08.656482\n",
      "0: learn: 0.6576293\ttest: 0.6576216\tbestTest: 0.6576216 (0)\ttotal: 4.03s\tremaining: 6m 39s\n",
      "1: learn: 0.6250101\ttest: 0.62498\tbestTest: 0.62498 (1)\ttotal: 7.96s\tremaining: 6m 30s\n",
      "2: learn: 0.594552\ttest: 0.5944916\tbestTest: 0.5944916 (2)\ttotal: 11.4s\tremaining: 6m 9s\n",
      "3: learn: 0.5669279\ttest: 0.5668616\tbestTest: 0.5668616 (3)\ttotal: 15.3s\tremaining: 6m 7s\n",
      "4: learn: 0.5412846\ttest: 0.541197\tbestTest: 0.541197 (4)\ttotal: 18.6s\tremaining: 5m 53s\n",
      "5: learn: 0.5180619\ttest: 0.5179514\tbestTest: 0.5179514 (5)\ttotal: 22.6s\tremaining: 5m 54s\n",
      "6: learn: 0.4963988\ttest: 0.4962657\tbestTest: 0.4962657 (6)\ttotal: 26.5s\tremaining: 5m 52s\n",
      "7: learn: 0.477112\ttest: 0.4769599\tbestTest: 0.4769599 (7)\ttotal: 29.3s\tremaining: 5m 36s\n",
      "8: learn: 0.4582156\ttest: 0.4580416\tbestTest: 0.4580416 (8)\ttotal: 33.5s\tremaining: 5m 38s\n",
      "9: learn: 0.4412257\ttest: 0.4410259\tbestTest: 0.4410259 (9)\ttotal: 36.8s\tremaining: 5m 31s\n",
      "10: learn: 0.4254376\ttest: 0.4252119\tbestTest: 0.4252119 (10)\ttotal: 40.9s\tremaining: 5m 30s\n",
      "11: learn: 0.410969\ttest: 0.4107255\tbestTest: 0.4107255 (11)\ttotal: 44.2s\tremaining: 5m 24s\n",
      "12: learn: 0.3980034\ttest: 0.3977406\tbestTest: 0.3977406 (12)\ttotal: 47.6s\tremaining: 5m 18s\n",
      "13: learn: 0.3852531\ttest: 0.384967\tbestTest: 0.384967 (13)\ttotal: 50.7s\tremaining: 5m 11s\n",
      "14: learn: 0.3736342\ttest: 0.3733254\tbestTest: 0.3733254 (14)\ttotal: 54s\tremaining: 5m 6s\n",
      "15: learn: 0.3635792\ttest: 0.3632528\tbestTest: 0.3632528 (15)\ttotal: 57.7s\tremaining: 5m 2s\n",
      "16: learn: 0.3537309\ttest: 0.3533915\tbestTest: 0.3533915 (16)\ttotal: 1m 1s\tremaining: 4m 59s\n",
      "17: learn: 0.3447908\ttest: 0.3444359\tbestTest: 0.3444359 (17)\ttotal: 1m 5s\tremaining: 4m 57s\n",
      "18: learn: 0.3373589\ttest: 0.3369872\tbestTest: 0.3369872 (18)\ttotal: 1m 6s\tremaining: 4m 45s\n",
      "19: learn: 0.3298035\ttest: 0.3294167\tbestTest: 0.3294167 (19)\ttotal: 1m 10s\tremaining: 4m 40s\n",
      "20: learn: 0.3230553\ttest: 0.3226235\tbestTest: 0.3226235 (20)\ttotal: 1m 14s\tremaining: 4m 38s\n",
      "21: learn: 0.3166037\ttest: 0.316151\tbestTest: 0.316151 (21)\ttotal: 1m 17s\tremaining: 4m 34s\n",
      "22: learn: 0.3108468\ttest: 0.3103854\tbestTest: 0.3103854 (22)\ttotal: 1m 21s\tremaining: 4m 33s\n",
      "23: learn: 0.3051456\ttest: 0.3046742\tbestTest: 0.3046742 (23)\ttotal: 1m 25s\tremaining: 4m 30s\n",
      "24: learn: 0.299798\ttest: 0.299308\tbestTest: 0.299308 (24)\ttotal: 1m 29s\tremaining: 4m 27s\n",
      "25: learn: 0.2948209\ttest: 0.2943177\tbestTest: 0.2943177 (25)\ttotal: 1m 32s\tremaining: 4m 23s\n",
      "26: learn: 0.2908534\ttest: 0.2903395\tbestTest: 0.2903395 (26)\ttotal: 1m 34s\tremaining: 4m 15s\n",
      "27: learn: 0.2865305\ttest: 0.2860024\tbestTest: 0.2860024 (27)\ttotal: 1m 37s\tremaining: 4m 11s\n",
      "28: learn: 0.2823943\ttest: 0.2818521\tbestTest: 0.2818521 (28)\ttotal: 1m 41s\tremaining: 4m 8s\n",
      "29: learn: 0.2790624\ttest: 0.2785087\tbestTest: 0.2785087 (29)\ttotal: 1m 45s\tremaining: 4m 6s\n",
      "30: learn: 0.2757313\ttest: 0.2751712\tbestTest: 0.2751712 (30)\ttotal: 1m 49s\tremaining: 4m 4s\n",
      "31: learn: 0.2725181\ttest: 0.2719437\tbestTest: 0.2719437 (31)\ttotal: 1m 53s\tremaining: 4m 1s\n",
      "32: learn: 0.2697229\ttest: 0.2691352\tbestTest: 0.2691352 (32)\ttotal: 1m 56s\tremaining: 3m 57s\n",
      "33: learn: 0.267071\ttest: 0.2664743\tbestTest: 0.2664743 (33)\ttotal: 2m\tremaining: 3m 54s\n",
      "34: learn: 0.2645677\ttest: 0.2639614\tbestTest: 0.2639614 (34)\ttotal: 2m 3s\tremaining: 3m 49s\n",
      "35: learn: 0.2621888\ttest: 0.2615734\tbestTest: 0.2615734 (35)\ttotal: 2m 7s\tremaining: 3m 46s\n",
      "36: learn: 0.2600407\ttest: 0.2594191\tbestTest: 0.2594191 (36)\ttotal: 2m 11s\tremaining: 3m 43s\n",
      "37: learn: 0.2579325\ttest: 0.2572999\tbestTest: 0.2572999 (37)\ttotal: 2m 14s\tremaining: 3m 40s\n",
      "38: learn: 0.2559948\ttest: 0.2553556\tbestTest: 0.2553556 (38)\ttotal: 2m 19s\tremaining: 3m 37s\n",
      "39: learn: 0.2541428\ttest: 0.253499\tbestTest: 0.253499 (39)\ttotal: 2m 22s\tremaining: 3m 34s\n",
      "40: learn: 0.2524735\ttest: 0.2518229\tbestTest: 0.2518229 (40)\ttotal: 2m 26s\tremaining: 3m 30s\n",
      "41: learn: 0.2509711\ttest: 0.2503152\tbestTest: 0.2503152 (41)\ttotal: 2m 30s\tremaining: 3m 27s\n",
      "42: learn: 0.2495519\ttest: 0.2488892\tbestTest: 0.2488892 (42)\ttotal: 2m 34s\tremaining: 3m 24s\n",
      "43: learn: 0.2481471\ttest: 0.2474766\tbestTest: 0.2474766 (43)\ttotal: 2m 37s\tremaining: 3m 20s\n",
      "44: learn: 0.2468468\ttest: 0.2461643\tbestTest: 0.2461643 (44)\ttotal: 2m 41s\tremaining: 3m 17s\n",
      "45: learn: 0.2456341\ttest: 0.2449419\tbestTest: 0.2449419 (45)\ttotal: 2m 45s\tremaining: 3m 13s\n",
      "46: learn: 0.2445045\ttest: 0.2438036\tbestTest: 0.2438036 (46)\ttotal: 2m 49s\tremaining: 3m 10s\n",
      "47: learn: 0.2434847\ttest: 0.2427751\tbestTest: 0.2427751 (47)\ttotal: 2m 52s\tremaining: 3m 7s\n",
      "48: learn: 0.2425438\ttest: 0.2418302\tbestTest: 0.2418302 (48)\ttotal: 2m 56s\tremaining: 3m 4s\n",
      "49: learn: 0.2416029\ttest: 0.2408844\tbestTest: 0.2408844 (49)\ttotal: 3m\tremaining: 3m\n",
      "50: learn: 0.2407035\ttest: 0.2399771\tbestTest: 0.2399771 (50)\ttotal: 3m 3s\tremaining: 2m 56s\n",
      "51: learn: 0.2398643\ttest: 0.2391328\tbestTest: 0.2391328 (51)\ttotal: 3m 7s\tremaining: 2m 53s\n",
      "52: learn: 0.2390944\ttest: 0.2383547\tbestTest: 0.2383547 (52)\ttotal: 3m 11s\tremaining: 2m 49s\n",
      "53: learn: 0.2384447\ttest: 0.2376784\tbestTest: 0.2376784 (53)\ttotal: 3m 15s\tremaining: 2m 46s\n",
      "54: learn: 0.23777\ttest: 0.2370002\tbestTest: 0.2370002 (54)\ttotal: 3m 18s\tremaining: 2m 42s\n",
      "55: learn: 0.237099\ttest: 0.2363254\tbestTest: 0.2363254 (55)\ttotal: 3m 22s\tremaining: 2m 39s\n",
      "56: learn: 0.2365014\ttest: 0.2357221\tbestTest: 0.2357221 (56)\ttotal: 3m 26s\tremaining: 2m 35s\n",
      "57: learn: 0.2359616\ttest: 0.2351767\tbestTest: 0.2351767 (57)\ttotal: 3m 29s\tremaining: 2m 31s\n",
      "58: learn: 0.2354427\ttest: 0.2346543\tbestTest: 0.2346543 (58)\ttotal: 3m 33s\tremaining: 2m 28s\n",
      "59: learn: 0.2349309\ttest: 0.2341381\tbestTest: 0.2341381 (59)\ttotal: 3m 36s\tremaining: 2m 24s\n",
      "60: learn: 0.2344385\ttest: 0.2336418\tbestTest: 0.2336418 (60)\ttotal: 3m 40s\tremaining: 2m 21s\n",
      "61: learn: 0.2339768\ttest: 0.2331755\tbestTest: 0.2331755 (61)\ttotal: 3m 44s\tremaining: 2m 17s\n",
      "62: learn: 0.2335375\ttest: 0.2327316\tbestTest: 0.2327316 (62)\ttotal: 3m 47s\tremaining: 2m 13s\n",
      "63: learn: 0.2331322\ttest: 0.2323203\tbestTest: 0.2323203 (63)\ttotal: 3m 51s\tremaining: 2m 10s\n",
      "64: learn: 0.2327883\ttest: 0.2319743\tbestTest: 0.2319743 (64)\ttotal: 3m 55s\tremaining: 2m 6s\n",
      "65: learn: 0.2324091\ttest: 0.2315903\tbestTest: 0.2315903 (65)\ttotal: 3m 58s\tremaining: 2m 2s\n",
      "66: learn: 0.2320539\ttest: 0.2312332\tbestTest: 0.2312332 (66)\ttotal: 4m 2s\tremaining: 1m 59s\n",
      "67: learn: 0.2317368\ttest: 0.2309141\tbestTest: 0.2309141 (67)\ttotal: 4m 6s\tremaining: 1m 55s\n",
      "68: learn: 0.231415\ttest: 0.2305889\tbestTest: 0.2305889 (68)\ttotal: 4m 10s\tremaining: 1m 52s\n",
      "69: learn: 0.2311046\ttest: 0.2302765\tbestTest: 0.2302765 (69)\ttotal: 4m 13s\tremaining: 1m 48s\n",
      "70: learn: 0.230821\ttest: 0.2299888\tbestTest: 0.2299888 (70)\ttotal: 4m 16s\tremaining: 1m 44s\n",
      "71: learn: 0.2305798\ttest: 0.2297442\tbestTest: 0.2297442 (71)\ttotal: 4m 20s\tremaining: 1m 41s\n",
      "72: learn: 0.2303386\ttest: 0.2295007\tbestTest: 0.2295007 (72)\ttotal: 4m 23s\tremaining: 1m 37s\n",
      "73: learn: 0.2300694\ttest: 0.2292292\tbestTest: 0.2292292 (73)\ttotal: 4m 27s\tremaining: 1m 33s\n",
      "74: learn: 0.2298548\ttest: 0.2290117\tbestTest: 0.2290117 (74)\ttotal: 4m 31s\tremaining: 1m 30s\n",
      "75: learn: 0.2296423\ttest: 0.2287966\tbestTest: 0.2287966 (75)\ttotal: 4m 34s\tremaining: 1m 26s\n",
      "76: learn: 0.2294283\ttest: 0.2285812\tbestTest: 0.2285812 (76)\ttotal: 4m 38s\tremaining: 1m 23s\n",
      "77: learn: 0.2292189\ttest: 0.2283684\tbestTest: 0.2283684 (77)\ttotal: 4m 42s\tremaining: 1m 19s\n",
      "78: learn: 0.2290415\ttest: 0.228188\tbestTest: 0.228188 (78)\ttotal: 4m 45s\tremaining: 1m 15s\n",
      "79: learn: 0.228875\ttest: 0.2280194\tbestTest: 0.2280194 (79)\ttotal: 4m 49s\tremaining: 1m 12s\n",
      "80: learn: 0.2287055\ttest: 0.2278487\tbestTest: 0.2278487 (80)\ttotal: 4m 53s\tremaining: 1m 8s\n",
      "81: learn: 0.2285202\ttest: 0.2276615\tbestTest: 0.2276615 (81)\ttotal: 4m 56s\tremaining: 1m 5s\n",
      "82: learn: 0.2283568\ttest: 0.2274944\tbestTest: 0.2274944 (82)\ttotal: 5m\tremaining: 1m 1s\n",
      "83: learn: 0.2282219\ttest: 0.2273577\tbestTest: 0.2273577 (83)\ttotal: 5m 4s\tremaining: 57.9s\n",
      "84: learn: 0.2280804\ttest: 0.2272154\tbestTest: 0.2272154 (84)\ttotal: 5m 8s\tremaining: 54.4s\n",
      "85: learn: 0.2279612\ttest: 0.2270942\tbestTest: 0.2270942 (85)\ttotal: 5m 12s\tremaining: 50.8s\n",
      "86: learn: 0.2278201\ttest: 0.2269526\tbestTest: 0.2269526 (86)\ttotal: 5m 15s\tremaining: 47.1s\n",
      "87: learn: 0.2277002\ttest: 0.2268315\tbestTest: 0.2268315 (87)\ttotal: 5m 19s\tremaining: 43.5s\n",
      "88: learn: 0.2275799\ttest: 0.2267106\tbestTest: 0.2267106 (88)\ttotal: 5m 23s\tremaining: 39.9s\n",
      "89: learn: 0.2274739\ttest: 0.2266037\tbestTest: 0.2266037 (89)\ttotal: 5m 27s\tremaining: 36.4s\n",
      "90: learn: 0.2273654\ttest: 0.2264932\tbestTest: 0.2264932 (90)\ttotal: 5m 30s\tremaining: 32.7s\n",
      "91: learn: 0.2272665\ttest: 0.2263923\tbestTest: 0.2263923 (91)\ttotal: 5m 33s\tremaining: 29s\n",
      "92: learn: 0.2271798\ttest: 0.2263043\tbestTest: 0.2263043 (92)\ttotal: 5m 37s\tremaining: 25.4s\n",
      "93: learn: 0.2270866\ttest: 0.2262097\tbestTest: 0.2262097 (93)\ttotal: 5m 40s\tremaining: 21.8s\n",
      "94: learn: 0.2269907\ttest: 0.2261126\tbestTest: 0.2261126 (94)\ttotal: 5m 44s\tremaining: 18.1s\n",
      "95: learn: 0.226906\ttest: 0.226028\tbestTest: 0.226028 (95)\ttotal: 5m 48s\tremaining: 14.5s\n",
      "96: learn: 0.2268196\ttest: 0.2259401\tbestTest: 0.2259401 (96)\ttotal: 5m 52s\tremaining: 10.9s\n",
      "97: learn: 0.2267264\ttest: 0.2258471\tbestTest: 0.2258471 (97)\ttotal: 5m 55s\tremaining: 7.26s\n",
      "98: learn: 0.226655\ttest: 0.2257754\tbestTest: 0.2257754 (98)\ttotal: 5m 59s\tremaining: 3.63s\n",
      "99: learn: 0.2265632\ttest: 0.2256816\tbestTest: 0.2256816 (99)\ttotal: 6m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2256815838\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.5_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 02:55:43.930855\n",
      "train time given below\n",
      "0:09:35.274373\n",
      "2018-03-14 02:55:43.937489\n",
      "2018-03-14 02:55:43.940902\n",
      "GINI ISIT = 0.453359661991\n",
      "2018-03-14 02:57:17.153438\n",
      "GINI OSIT = 0.454691666026\n",
      "2018-03-14 02:57:55.280505\n",
      "GINI OSOT = 0.408261400119\n",
      "2018-03-14 02:58:07.091401\n",
      "2018-03-14 02:58:07.093395\n",
      "rsm = 0.6\n",
      "2018-03-14 02:58:07.094832\n",
      "model train start\n",
      "2018-03-14 02:58:07.095072\n",
      "0: learn: 0.6580344\ttest: 0.6580134\tbestTest: 0.6580134 (0)\ttotal: 4.26s\tremaining: 7m 2s\n",
      "1: learn: 0.6248188\ttest: 0.6248016\tbestTest: 0.6248016 (1)\ttotal: 8.38s\tremaining: 6m 50s\n",
      "2: learn: 0.594933\ttest: 0.5948914\tbestTest: 0.5948914 (2)\ttotal: 12.5s\tremaining: 6m 45s\n",
      "3: learn: 0.5662596\ttest: 0.5661887\tbestTest: 0.5661887 (3)\ttotal: 16.5s\tremaining: 6m 35s\n",
      "4: learn: 0.5402375\ttest: 0.5401443\tbestTest: 0.5401443 (4)\ttotal: 20.3s\tremaining: 6m 24s\n",
      "5: learn: 0.5169085\ttest: 0.5167901\tbestTest: 0.5167901 (5)\ttotal: 23.4s\tremaining: 6m 7s\n",
      "6: learn: 0.4950983\ttest: 0.4949524\tbestTest: 0.4949524 (6)\ttotal: 27.1s\tremaining: 6m\n",
      "7: learn: 0.4752794\ttest: 0.4751265\tbestTest: 0.4751265 (7)\ttotal: 31.4s\tremaining: 6m 1s\n",
      "8: learn: 0.4566986\ttest: 0.4565177\tbestTest: 0.4565177 (8)\ttotal: 35.1s\tremaining: 5m 54s\n",
      "9: learn: 0.4401131\ttest: 0.4399084\tbestTest: 0.4399084 (9)\ttotal: 38.8s\tremaining: 5m 49s\n",
      "10: learn: 0.4249716\ttest: 0.424753\tbestTest: 0.424753 (10)\ttotal: 42.5s\tremaining: 5m 43s\n",
      "11: learn: 0.4102732\ttest: 0.4100325\tbestTest: 0.4100325 (11)\ttotal: 46.4s\tremaining: 5m 39s\n",
      "12: learn: 0.3966872\ttest: 0.3964305\tbestTest: 0.3964305 (12)\ttotal: 50.5s\tremaining: 5m 38s\n",
      "13: learn: 0.3844176\ttest: 0.3841415\tbestTest: 0.3841415 (13)\ttotal: 54.4s\tremaining: 5m 34s\n",
      "14: learn: 0.3733868\ttest: 0.3730985\tbestTest: 0.3730985 (14)\ttotal: 58.4s\tremaining: 5m 31s\n",
      "15: learn: 0.3628627\ttest: 0.362562\tbestTest: 0.362562 (15)\ttotal: 1m 2s\tremaining: 5m 25s\n",
      "16: learn: 0.3531056\ttest: 0.3527859\tbestTest: 0.3527859 (16)\ttotal: 1m 5s\tremaining: 5m 22s\n",
      "17: learn: 0.3439917\ttest: 0.3436504\tbestTest: 0.3436504 (17)\ttotal: 1m 9s\tremaining: 5m 18s\n",
      "18: learn: 0.3361371\ttest: 0.3357785\tbestTest: 0.3357785 (18)\ttotal: 1m 12s\tremaining: 5m 7s\n",
      "19: learn: 0.3284371\ttest: 0.3280611\tbestTest: 0.3280611 (19)\ttotal: 1m 16s\tremaining: 5m 4s\n",
      "20: learn: 0.3217007\ttest: 0.3213058\tbestTest: 0.3213058 (20)\ttotal: 1m 19s\tremaining: 5m\n",
      "21: learn: 0.3150842\ttest: 0.3146719\tbestTest: 0.3146719 (21)\ttotal: 1m 23s\tremaining: 4m 56s\n",
      "22: learn: 0.3092732\ttest: 0.3088438\tbestTest: 0.3088438 (22)\ttotal: 1m 27s\tremaining: 4m 53s\n",
      "23: learn: 0.3037938\ttest: 0.3033474\tbestTest: 0.3033474 (23)\ttotal: 1m 31s\tremaining: 4m 50s\n",
      "24: learn: 0.2987155\ttest: 0.2982592\tbestTest: 0.2982592 (24)\ttotal: 1m 36s\tremaining: 4m 48s\n",
      "25: learn: 0.2939436\ttest: 0.2934724\tbestTest: 0.2934724 (25)\ttotal: 1m 39s\tremaining: 4m 44s\n",
      "26: learn: 0.289587\ttest: 0.2891024\tbestTest: 0.2891024 (26)\ttotal: 1m 43s\tremaining: 4m 40s\n",
      "27: learn: 0.2854666\ttest: 0.2849677\tbestTest: 0.2849677 (27)\ttotal: 1m 47s\tremaining: 4m 36s\n",
      "28: learn: 0.2816316\ttest: 0.2811203\tbestTest: 0.2811203 (28)\ttotal: 1m 51s\tremaining: 4m 32s\n",
      "29: learn: 0.2779439\ttest: 0.2774231\tbestTest: 0.2774231 (29)\ttotal: 1m 54s\tremaining: 4m 28s\n",
      "30: learn: 0.2746215\ttest: 0.2740903\tbestTest: 0.2740903 (30)\ttotal: 1m 58s\tremaining: 4m 24s\n",
      "31: learn: 0.2714769\ttest: 0.2709317\tbestTest: 0.2709317 (31)\ttotal: 2m 2s\tremaining: 4m 21s\n",
      "32: learn: 0.2687351\ttest: 0.2681811\tbestTest: 0.2681811 (32)\ttotal: 2m 6s\tremaining: 4m 17s\n",
      "33: learn: 0.2660922\ttest: 0.2655266\tbestTest: 0.2655266 (33)\ttotal: 2m 10s\tremaining: 4m 14s\n",
      "34: learn: 0.2637128\ttest: 0.2631414\tbestTest: 0.2631414 (34)\ttotal: 2m 15s\tremaining: 4m 10s\n",
      "35: learn: 0.2614389\ttest: 0.260855\tbestTest: 0.260855 (35)\ttotal: 2m 18s\tremaining: 4m 6s\n",
      "36: learn: 0.2592655\ttest: 0.25867\tbestTest: 0.25867 (36)\ttotal: 2m 23s\tremaining: 4m 3s\n",
      "37: learn: 0.2572582\ttest: 0.2566496\tbestTest: 0.2566496 (37)\ttotal: 2m 26s\tremaining: 3m 59s\n",
      "38: learn: 0.2554781\ttest: 0.2548585\tbestTest: 0.2548585 (38)\ttotal: 2m 30s\tremaining: 3m 55s\n",
      "39: learn: 0.2536622\ttest: 0.2530338\tbestTest: 0.2530338 (39)\ttotal: 2m 34s\tremaining: 3m 51s\n",
      "40: learn: 0.2520764\ttest: 0.2514373\tbestTest: 0.2514373 (40)\ttotal: 2m 38s\tremaining: 3m 48s\n",
      "41: learn: 0.2505423\ttest: 0.2498956\tbestTest: 0.2498956 (41)\ttotal: 2m 42s\tremaining: 3m 44s\n",
      "42: learn: 0.2490323\ttest: 0.2483737\tbestTest: 0.2483737 (42)\ttotal: 2m 46s\tremaining: 3m 40s\n",
      "43: learn: 0.24767\ttest: 0.2470014\tbestTest: 0.2470014 (43)\ttotal: 2m 50s\tremaining: 3m 37s\n",
      "44: learn: 0.2464871\ttest: 0.2458145\tbestTest: 0.2458145 (44)\ttotal: 2m 54s\tremaining: 3m 33s\n",
      "45: learn: 0.2452744\ttest: 0.2445923\tbestTest: 0.2445923 (45)\ttotal: 2m 59s\tremaining: 3m 30s\n",
      "46: learn: 0.2441403\ttest: 0.2434484\tbestTest: 0.2434484 (46)\ttotal: 3m 3s\tremaining: 3m 26s\n",
      "47: learn: 0.2431706\ttest: 0.2424732\tbestTest: 0.2424732 (47)\ttotal: 3m 7s\tremaining: 3m 22s\n",
      "48: learn: 0.2421604\ttest: 0.2414564\tbestTest: 0.2414564 (48)\ttotal: 3m 11s\tremaining: 3m 19s\n",
      "49: learn: 0.2411811\ttest: 0.2404678\tbestTest: 0.2404678 (49)\ttotal: 3m 15s\tremaining: 3m 15s\n",
      "50: learn: 0.2403771\ttest: 0.2396568\tbestTest: 0.2396568 (50)\ttotal: 3m 19s\tremaining: 3m 11s\n",
      "51: learn: 0.2395193\ttest: 0.2387922\tbestTest: 0.2387922 (51)\ttotal: 3m 23s\tremaining: 3m 7s\n",
      "52: learn: 0.2387511\ttest: 0.2380182\tbestTest: 0.2380182 (52)\ttotal: 3m 26s\tremaining: 3m 3s\n",
      "53: learn: 0.2380443\ttest: 0.2373034\tbestTest: 0.2373034 (53)\ttotal: 3m 30s\tremaining: 2m 59s\n",
      "54: learn: 0.2374145\ttest: 0.2366706\tbestTest: 0.2366706 (54)\ttotal: 3m 34s\tremaining: 2m 55s\n",
      "55: learn: 0.2367903\ttest: 0.2360425\tbestTest: 0.2360425 (55)\ttotal: 3m 38s\tremaining: 2m 51s\n",
      "56: learn: 0.2362151\ttest: 0.2354602\tbestTest: 0.2354602 (56)\ttotal: 3m 42s\tremaining: 2m 47s\n",
      "57: learn: 0.2356293\ttest: 0.2348686\tbestTest: 0.2348686 (57)\ttotal: 3m 45s\tremaining: 2m 43s\n",
      "58: learn: 0.2350961\ttest: 0.2343277\tbestTest: 0.2343277 (58)\ttotal: 3m 49s\tremaining: 2m 39s\n",
      "59: learn: 0.2345661\ttest: 0.2337948\tbestTest: 0.2337948 (59)\ttotal: 3m 53s\tremaining: 2m 35s\n",
      "60: learn: 0.2341491\ttest: 0.2333733\tbestTest: 0.2333733 (60)\ttotal: 3m 58s\tremaining: 2m 32s\n",
      "61: learn: 0.2337596\ttest: 0.2329783\tbestTest: 0.2329783 (61)\ttotal: 4m 2s\tremaining: 2m 28s\n",
      "62: learn: 0.2333249\ttest: 0.2325408\tbestTest: 0.2325408 (62)\ttotal: 4m 7s\tremaining: 2m 25s\n",
      "63: learn: 0.2329355\ttest: 0.2321466\tbestTest: 0.2321466 (63)\ttotal: 4m 10s\tremaining: 2m 21s\n",
      "64: learn: 0.232556\ttest: 0.2317626\tbestTest: 0.2317626 (64)\ttotal: 4m 14s\tremaining: 2m 17s\n",
      "65: learn: 0.2321688\ttest: 0.2313729\tbestTest: 0.2313729 (65)\ttotal: 4m 18s\tremaining: 2m 13s\n",
      "66: learn: 0.2318421\ttest: 0.2310429\tbestTest: 0.2310429 (66)\ttotal: 4m 22s\tremaining: 2m 9s\n",
      "67: learn: 0.2315576\ttest: 0.2307551\tbestTest: 0.2307551 (67)\ttotal: 4m 26s\tremaining: 2m 5s\n",
      "68: learn: 0.2312487\ttest: 0.230443\tbestTest: 0.230443 (68)\ttotal: 4m 30s\tremaining: 2m 1s\n",
      "69: learn: 0.2309463\ttest: 0.2301377\tbestTest: 0.2301377 (69)\ttotal: 4m 34s\tremaining: 1m 57s\n",
      "70: learn: 0.2306528\ttest: 0.2298427\tbestTest: 0.2298427 (70)\ttotal: 4m 38s\tremaining: 1m 53s\n",
      "71: learn: 0.230412\ttest: 0.2295985\tbestTest: 0.2295985 (71)\ttotal: 4m 42s\tremaining: 1m 49s\n",
      "72: learn: 0.2301591\ttest: 0.2293402\tbestTest: 0.2293402 (72)\ttotal: 4m 46s\tremaining: 1m 45s\n",
      "73: learn: 0.2298914\ttest: 0.2290705\tbestTest: 0.2290705 (73)\ttotal: 4m 49s\tremaining: 1m 41s\n",
      "74: learn: 0.2296583\ttest: 0.2288342\tbestTest: 0.2288342 (74)\ttotal: 4m 53s\tremaining: 1m 37s\n",
      "75: learn: 0.2294589\ttest: 0.2286325\tbestTest: 0.2286325 (75)\ttotal: 4m 57s\tremaining: 1m 33s\n",
      "76: learn: 0.2292293\ttest: 0.2284022\tbestTest: 0.2284022 (76)\ttotal: 5m 1s\tremaining: 1m 30s\n",
      "77: learn: 0.2290282\ttest: 0.2281959\tbestTest: 0.2281959 (77)\ttotal: 5m 5s\tremaining: 1m 26s\n",
      "78: learn: 0.2288495\ttest: 0.2280148\tbestTest: 0.2280148 (78)\ttotal: 5m 9s\tremaining: 1m 22s\n",
      "79: learn: 0.2287006\ttest: 0.2278636\tbestTest: 0.2278636 (79)\ttotal: 5m 13s\tremaining: 1m 18s\n",
      "80: learn: 0.2285362\ttest: 0.2276978\tbestTest: 0.2276978 (80)\ttotal: 5m 17s\tremaining: 1m 14s\n",
      "81: learn: 0.2283638\ttest: 0.2275217\tbestTest: 0.2275217 (81)\ttotal: 5m 21s\tremaining: 1m 10s\n",
      "82: learn: 0.2282224\ttest: 0.2273792\tbestTest: 0.2273792 (82)\ttotal: 5m 25s\tremaining: 1m 6s\n",
      "83: learn: 0.2280632\ttest: 0.2272174\tbestTest: 0.2272174 (83)\ttotal: 5m 29s\tremaining: 1m 2s\n",
      "84: learn: 0.227923\ttest: 0.2270749\tbestTest: 0.2270749 (84)\ttotal: 5m 33s\tremaining: 58.8s\n",
      "85: learn: 0.2278068\ttest: 0.226952\tbestTest: 0.226952 (85)\ttotal: 5m 37s\tremaining: 54.9s\n",
      "86: learn: 0.2276929\ttest: 0.226838\tbestTest: 0.226838 (86)\ttotal: 5m 41s\tremaining: 51s\n",
      "87: learn: 0.2275568\ttest: 0.2267009\tbestTest: 0.2267009 (87)\ttotal: 5m 44s\tremaining: 47s\n",
      "88: learn: 0.2274246\ttest: 0.2265663\tbestTest: 0.2265663 (88)\ttotal: 5m 49s\tremaining: 43.1s\n",
      "89: learn: 0.2272771\ttest: 0.2264194\tbestTest: 0.2264194 (89)\ttotal: 5m 52s\tremaining: 39.2s\n",
      "90: learn: 0.2271708\ttest: 0.2263125\tbestTest: 0.2263125 (90)\ttotal: 5m 56s\tremaining: 35.3s\n",
      "91: learn: 0.2270603\ttest: 0.226199\tbestTest: 0.226199 (91)\ttotal: 6m\tremaining: 31.4s\n",
      "92: learn: 0.226941\ttest: 0.2260785\tbestTest: 0.2260785 (92)\ttotal: 6m 4s\tremaining: 27.5s\n",
      "93: learn: 0.2268477\ttest: 0.2259848\tbestTest: 0.2259848 (93)\ttotal: 6m 8s\tremaining: 23.5s\n",
      "94: learn: 0.2267484\ttest: 0.2258858\tbestTest: 0.2258858 (94)\ttotal: 6m 12s\tremaining: 19.6s\n",
      "95: learn: 0.226653\ttest: 0.2257893\tbestTest: 0.2257893 (95)\ttotal: 6m 16s\tremaining: 15.7s\n",
      "96: learn: 0.2265797\ttest: 0.2257141\tbestTest: 0.2257141 (96)\ttotal: 6m 21s\tremaining: 11.8s\n",
      "97: learn: 0.2264884\ttest: 0.2256216\tbestTest: 0.2256216 (97)\ttotal: 6m 25s\tremaining: 7.86s\n",
      "98: learn: 0.2264149\ttest: 0.225547\tbestTest: 0.225547 (98)\ttotal: 6m 30s\tremaining: 3.94s\n",
      "99: learn: 0.2263301\ttest: 0.2254616\tbestTest: 0.2254616 (99)\ttotal: 6m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254615812\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.6_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 03:08:02.159856\n",
      "train time given below\n",
      "0:09:55.064784\n",
      "2018-03-14 03:08:02.160470\n",
      "2018-03-14 03:08:02.163969\n",
      "GINI ISIT = 0.454922084977\n",
      "2018-03-14 03:09:35.150873\n",
      "GINI OSIT = 0.4561089516\n",
      "2018-03-14 03:10:13.584449\n",
      "GINI OSOT = 0.410751480272\n",
      "2018-03-14 03:10:25.642556\n",
      "2018-03-14 03:10:25.644494\n",
      "rsm = 0.7\n",
      "2018-03-14 03:10:25.645910\n",
      "model train start\n",
      "2018-03-14 03:10:25.646136\n",
      "0: learn: 0.6573213\ttest: 0.6573013\tbestTest: 0.6573013 (0)\ttotal: 4.7s\tremaining: 7m 45s\n",
      "1: learn: 0.6247545\ttest: 0.6247094\tbestTest: 0.6247094 (1)\ttotal: 9.78s\tremaining: 7m 59s\n",
      "2: learn: 0.5944417\ttest: 0.5943809\tbestTest: 0.5943809 (2)\ttotal: 14.9s\tremaining: 8m 1s\n",
      "3: learn: 0.5669269\ttest: 0.5668427\tbestTest: 0.5668427 (3)\ttotal: 20s\tremaining: 8m\n",
      "4: learn: 0.5415403\ttest: 0.5414358\tbestTest: 0.5414358 (4)\ttotal: 24.6s\tremaining: 7m 47s\n",
      "5: learn: 0.5175146\ttest: 0.5174017\tbestTest: 0.5174017 (5)\ttotal: 29.5s\tremaining: 7m 41s\n",
      "6: learn: 0.4955204\ttest: 0.4953806\tbestTest: 0.4953806 (6)\ttotal: 34.4s\tremaining: 7m 36s\n",
      "7: learn: 0.4750893\ttest: 0.4749286\tbestTest: 0.4749286 (7)\ttotal: 39s\tremaining: 7m 28s\n",
      "8: learn: 0.457004\ttest: 0.4568221\tbestTest: 0.4568221 (8)\ttotal: 43.3s\tremaining: 7m 17s\n",
      "9: learn: 0.4399832\ttest: 0.4397802\tbestTest: 0.4397802 (9)\ttotal: 47.8s\tremaining: 7m 10s\n",
      "10: learn: 0.4240323\ttest: 0.4238082\tbestTest: 0.4238082 (10)\ttotal: 52.2s\tremaining: 7m 2s\n",
      "11: learn: 0.4097203\ttest: 0.4094823\tbestTest: 0.4094823 (11)\ttotal: 56.4s\tremaining: 6m 53s\n",
      "12: learn: 0.3963909\ttest: 0.3961433\tbestTest: 0.3961433 (12)\ttotal: 1m 1s\tremaining: 6m 48s\n",
      "13: learn: 0.3847167\ttest: 0.3844571\tbestTest: 0.3844571 (13)\ttotal: 1m 5s\tremaining: 6m 42s\n",
      "14: learn: 0.3731288\ttest: 0.3728474\tbestTest: 0.3728474 (14)\ttotal: 1m 9s\tremaining: 6m 34s\n",
      "15: learn: 0.3627766\ttest: 0.3624785\tbestTest: 0.3624785 (15)\ttotal: 1m 13s\tremaining: 6m 27s\n",
      "16: learn: 0.353473\ttest: 0.3531559\tbestTest: 0.3531559 (16)\ttotal: 1m 18s\tremaining: 6m 22s\n",
      "17: learn: 0.34494\ttest: 0.3446161\tbestTest: 0.3446161 (17)\ttotal: 1m 22s\tremaining: 6m 14s\n",
      "18: learn: 0.3367036\ttest: 0.3363619\tbestTest: 0.3363619 (18)\ttotal: 1m 26s\tremaining: 6m 8s\n",
      "19: learn: 0.3287813\ttest: 0.328415\tbestTest: 0.328415 (19)\ttotal: 1m 30s\tremaining: 6m 1s\n",
      "20: learn: 0.322222\ttest: 0.3218392\tbestTest: 0.3218392 (20)\ttotal: 1m 34s\tremaining: 5m 56s\n",
      "21: learn: 0.3155023\ttest: 0.3151004\tbestTest: 0.3151004 (21)\ttotal: 1m 39s\tremaining: 5m 51s\n",
      "22: learn: 0.3094262\ttest: 0.3090105\tbestTest: 0.3090105 (22)\ttotal: 1m 43s\tremaining: 5m 45s\n",
      "23: learn: 0.3042093\ttest: 0.3037785\tbestTest: 0.3037785 (23)\ttotal: 1m 47s\tremaining: 5m 39s\n",
      "24: learn: 0.2989427\ttest: 0.2984954\tbestTest: 0.2984954 (24)\ttotal: 1m 51s\tremaining: 5m 34s\n",
      "25: learn: 0.2942936\ttest: 0.2938319\tbestTest: 0.2938319 (25)\ttotal: 1m 55s\tremaining: 5m 29s\n",
      "26: learn: 0.2897225\ttest: 0.2892438\tbestTest: 0.2892438 (26)\ttotal: 2m\tremaining: 5m 24s\n",
      "27: learn: 0.2855736\ttest: 0.2850793\tbestTest: 0.2850793 (27)\ttotal: 2m 5s\tremaining: 5m 21s\n",
      "28: learn: 0.2816725\ttest: 0.2811636\tbestTest: 0.2811636 (28)\ttotal: 2m 9s\tremaining: 5m 17s\n",
      "29: learn: 0.2782753\ttest: 0.277752\tbestTest: 0.277752 (29)\ttotal: 2m 14s\tremaining: 5m 13s\n",
      "30: learn: 0.2750335\ttest: 0.2745002\tbestTest: 0.2745002 (30)\ttotal: 2m 18s\tremaining: 5m 9s\n",
      "31: learn: 0.2718791\ttest: 0.2713096\tbestTest: 0.2713096 (31)\ttotal: 2m 23s\tremaining: 5m 5s\n",
      "32: learn: 0.2690094\ttest: 0.2684315\tbestTest: 0.2684315 (32)\ttotal: 2m 28s\tremaining: 5m 1s\n",
      "33: learn: 0.2662309\ttest: 0.2656389\tbestTest: 0.2656389 (33)\ttotal: 2m 32s\tremaining: 4m 55s\n",
      "34: learn: 0.2637706\ttest: 0.2631765\tbestTest: 0.2631765 (34)\ttotal: 2m 36s\tremaining: 4m 51s\n",
      "35: learn: 0.2616268\ttest: 0.2610215\tbestTest: 0.2610215 (35)\ttotal: 2m 41s\tremaining: 4m 47s\n",
      "36: learn: 0.2595186\ttest: 0.2589042\tbestTest: 0.2589042 (36)\ttotal: 2m 45s\tremaining: 4m 42s\n",
      "37: learn: 0.2576331\ttest: 0.2570104\tbestTest: 0.2570104 (37)\ttotal: 2m 50s\tremaining: 4m 37s\n",
      "38: learn: 0.2556891\ttest: 0.2550547\tbestTest: 0.2550547 (38)\ttotal: 2m 54s\tremaining: 4m 32s\n",
      "39: learn: 0.2538393\ttest: 0.2531921\tbestTest: 0.2531921 (39)\ttotal: 2m 58s\tremaining: 4m 27s\n",
      "40: learn: 0.2521944\ttest: 0.251539\tbestTest: 0.251539 (40)\ttotal: 3m 3s\tremaining: 4m 23s\n",
      "41: learn: 0.2507586\ttest: 0.2500931\tbestTest: 0.2500931 (41)\ttotal: 3m 8s\tremaining: 4m 20s\n",
      "42: learn: 0.2492787\ttest: 0.2486072\tbestTest: 0.2486072 (42)\ttotal: 3m 13s\tremaining: 4m 15s\n",
      "43: learn: 0.2478041\ttest: 0.2471245\tbestTest: 0.2471245 (43)\ttotal: 3m 17s\tremaining: 4m 10s\n",
      "44: learn: 0.2465712\ttest: 0.2458838\tbestTest: 0.2458838 (44)\ttotal: 3m 21s\tremaining: 4m 6s\n",
      "45: learn: 0.2454137\ttest: 0.2447172\tbestTest: 0.2447172 (45)\ttotal: 3m 26s\tremaining: 4m 2s\n",
      "46: learn: 0.2443527\ttest: 0.243649\tbestTest: 0.243649 (46)\ttotal: 3m 30s\tremaining: 3m 57s\n",
      "47: learn: 0.2433199\ttest: 0.242608\tbestTest: 0.242608 (47)\ttotal: 3m 34s\tremaining: 3m 52s\n",
      "48: learn: 0.2423282\ttest: 0.2416086\tbestTest: 0.2416086 (48)\ttotal: 3m 39s\tremaining: 3m 48s\n",
      "49: learn: 0.24142\ttest: 0.2406943\tbestTest: 0.2406943 (49)\ttotal: 3m 43s\tremaining: 3m 43s\n",
      "50: learn: 0.2405099\ttest: 0.2397778\tbestTest: 0.2397778 (50)\ttotal: 3m 48s\tremaining: 3m 39s\n",
      "51: learn: 0.2396334\ttest: 0.2388926\tbestTest: 0.2388926 (51)\ttotal: 3m 52s\tremaining: 3m 34s\n",
      "52: learn: 0.238857\ttest: 0.2381096\tbestTest: 0.2381096 (52)\ttotal: 3m 57s\tremaining: 3m 30s\n",
      "53: learn: 0.2380699\ttest: 0.2373145\tbestTest: 0.2373145 (53)\ttotal: 4m 1s\tremaining: 3m 25s\n",
      "54: learn: 0.237465\ttest: 0.2367031\tbestTest: 0.2367031 (54)\ttotal: 4m 6s\tremaining: 3m 21s\n",
      "55: learn: 0.2368108\ttest: 0.2360438\tbestTest: 0.2360438 (55)\ttotal: 4m 10s\tremaining: 3m 16s\n",
      "56: learn: 0.2361976\ttest: 0.2354248\tbestTest: 0.2354248 (56)\ttotal: 4m 14s\tremaining: 3m 12s\n",
      "57: learn: 0.2356159\ttest: 0.2348384\tbestTest: 0.2348384 (57)\ttotal: 4m 18s\tremaining: 3m 7s\n",
      "58: learn: 0.2350919\ttest: 0.2343118\tbestTest: 0.2343118 (58)\ttotal: 4m 23s\tremaining: 3m 3s\n",
      "59: learn: 0.2346029\ttest: 0.2338183\tbestTest: 0.2338183 (59)\ttotal: 4m 27s\tremaining: 2m 58s\n",
      "60: learn: 0.2341112\ttest: 0.233323\tbestTest: 0.233323 (60)\ttotal: 4m 32s\tremaining: 2m 53s\n",
      "61: learn: 0.2336706\ttest: 0.2328794\tbestTest: 0.2328794 (61)\ttotal: 4m 36s\tremaining: 2m 49s\n",
      "62: learn: 0.2332294\ttest: 0.2324337\tbestTest: 0.2324337 (62)\ttotal: 4m 40s\tremaining: 2m 44s\n",
      "63: learn: 0.2328382\ttest: 0.2320266\tbestTest: 0.2320266 (63)\ttotal: 4m 45s\tremaining: 2m 40s\n",
      "64: learn: 0.2324821\ttest: 0.2316683\tbestTest: 0.2316683 (64)\ttotal: 4m 49s\tremaining: 2m 36s\n",
      "65: learn: 0.2321199\ttest: 0.2313025\tbestTest: 0.2313025 (65)\ttotal: 4m 54s\tremaining: 2m 31s\n",
      "66: learn: 0.231826\ttest: 0.2310062\tbestTest: 0.2310062 (66)\ttotal: 4m 58s\tremaining: 2m 27s\n",
      "67: learn: 0.2314872\ttest: 0.2306649\tbestTest: 0.2306649 (67)\ttotal: 5m 2s\tremaining: 2m 22s\n",
      "68: learn: 0.2311744\ttest: 0.2303496\tbestTest: 0.2303496 (68)\ttotal: 5m 7s\tremaining: 2m 17s\n",
      "69: learn: 0.2309094\ttest: 0.2300821\tbestTest: 0.2300821 (69)\ttotal: 5m 11s\tremaining: 2m 13s\n",
      "70: learn: 0.2306243\ttest: 0.2297937\tbestTest: 0.2297937 (70)\ttotal: 5m 15s\tremaining: 2m 8s\n",
      "71: learn: 0.230374\ttest: 0.2295418\tbestTest: 0.2295418 (71)\ttotal: 5m 20s\tremaining: 2m 4s\n",
      "72: learn: 0.2301465\ttest: 0.2293109\tbestTest: 0.2293109 (72)\ttotal: 5m 24s\tremaining: 2m\n",
      "73: learn: 0.2298979\ttest: 0.2290604\tbestTest: 0.2290604 (73)\ttotal: 5m 28s\tremaining: 1m 55s\n",
      "74: learn: 0.2296782\ttest: 0.2288377\tbestTest: 0.2288377 (74)\ttotal: 5m 33s\tremaining: 1m 51s\n",
      "75: learn: 0.2294866\ttest: 0.228647\tbestTest: 0.228647 (75)\ttotal: 5m 37s\tremaining: 1m 46s\n",
      "76: learn: 0.2292886\ttest: 0.2284468\tbestTest: 0.2284468 (76)\ttotal: 5m 42s\tremaining: 1m 42s\n",
      "77: learn: 0.229102\ttest: 0.2282592\tbestTest: 0.2282592 (77)\ttotal: 5m 47s\tremaining: 1m 37s\n",
      "78: learn: 0.2289253\ttest: 0.2280795\tbestTest: 0.2280795 (78)\ttotal: 5m 51s\tremaining: 1m 33s\n",
      "79: learn: 0.228772\ttest: 0.2279217\tbestTest: 0.2279217 (79)\ttotal: 5m 56s\tremaining: 1m 29s\n",
      "80: learn: 0.2285947\ttest: 0.227742\tbestTest: 0.227742 (80)\ttotal: 6m\tremaining: 1m 24s\n",
      "81: learn: 0.2284337\ttest: 0.2275791\tbestTest: 0.2275791 (81)\ttotal: 6m 5s\tremaining: 1m 20s\n",
      "82: learn: 0.2282851\ttest: 0.2274288\tbestTest: 0.2274288 (82)\ttotal: 6m 9s\tremaining: 1m 15s\n",
      "83: learn: 0.2281602\ttest: 0.2273032\tbestTest: 0.2273032 (83)\ttotal: 6m 13s\tremaining: 1m 11s\n",
      "84: learn: 0.2280253\ttest: 0.2271679\tbestTest: 0.2271679 (84)\ttotal: 6m 18s\tremaining: 1m 6s\n",
      "85: learn: 0.2278867\ttest: 0.2270283\tbestTest: 0.2270283 (85)\ttotal: 6m 22s\tremaining: 1m 2s\n",
      "86: learn: 0.2277532\ttest: 0.2268933\tbestTest: 0.2268933 (86)\ttotal: 6m 27s\tremaining: 57.9s\n",
      "87: learn: 0.2276365\ttest: 0.2267766\tbestTest: 0.2267766 (87)\ttotal: 6m 31s\tremaining: 53.4s\n",
      "88: learn: 0.2275059\ttest: 0.2266449\tbestTest: 0.2266449 (88)\ttotal: 6m 36s\tremaining: 48.9s\n",
      "89: learn: 0.2273549\ttest: 0.2264939\tbestTest: 0.2264939 (89)\ttotal: 6m 40s\tremaining: 44.5s\n",
      "90: learn: 0.2272411\ttest: 0.226379\tbestTest: 0.226379 (90)\ttotal: 6m 45s\tremaining: 40.1s\n",
      "91: learn: 0.2270921\ttest: 0.2262291\tbestTest: 0.2262291 (91)\ttotal: 6m 49s\tremaining: 35.6s\n",
      "92: learn: 0.2269934\ttest: 0.2261303\tbestTest: 0.2261303 (92)\ttotal: 6m 53s\tremaining: 31.1s\n",
      "93: learn: 0.2268872\ttest: 0.2260234\tbestTest: 0.2260234 (93)\ttotal: 6m 58s\tremaining: 26.7s\n",
      "94: learn: 0.2267595\ttest: 0.2258963\tbestTest: 0.2258963 (94)\ttotal: 7m 2s\tremaining: 22.2s\n",
      "95: learn: 0.2266639\ttest: 0.2257997\tbestTest: 0.2257997 (95)\ttotal: 7m 6s\tremaining: 17.8s\n",
      "96: learn: 0.2265909\ttest: 0.2257258\tbestTest: 0.2257258 (96)\ttotal: 7m 10s\tremaining: 13.3s\n",
      "97: learn: 0.2265004\ttest: 0.225635\tbestTest: 0.225635 (97)\ttotal: 7m 14s\tremaining: 8.87s\n",
      "98: learn: 0.226376\ttest: 0.2255115\tbestTest: 0.2255115 (98)\ttotal: 7m 18s\tremaining: 4.43s\n",
      "99: learn: 0.2263045\ttest: 0.2254369\tbestTest: 0.2254369 (99)\ttotal: 7m 23s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254368584\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.7_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 03:21:13.597470\n",
      "train time given below\n",
      "0:10:47.951334\n",
      "2018-03-14 03:21:13.598274\n",
      "2018-03-14 03:21:13.601867\n",
      "GINI ISIT = 0.456207729955\n",
      "2018-03-14 03:22:47.131249\n",
      "GINI OSIT = 0.45754537048\n",
      "2018-03-14 03:23:26.389742\n",
      "GINI OSOT = 0.412350171804\n",
      "2018-03-14 03:23:38.432191\n",
      "2018-03-14 03:23:38.434161\n",
      "rsm = 0.75\n",
      "2018-03-14 03:23:38.435581\n",
      "model train start\n",
      "2018-03-14 03:23:38.435769\n",
      "0: learn: 0.6580908\ttest: 0.6580709\tbestTest: 0.6580709 (0)\ttotal: 4.31s\tremaining: 7m 7s\n",
      "1: learn: 0.6248962\ttest: 0.6248694\tbestTest: 0.6248694 (1)\ttotal: 9.1s\tremaining: 7m 26s\n",
      "2: learn: 0.5947098\ttest: 0.5946643\tbestTest: 0.5946643 (2)\ttotal: 13.3s\tremaining: 7m 8s\n",
      "3: learn: 0.566398\ttest: 0.5663295\tbestTest: 0.5663295 (3)\ttotal: 17.7s\tremaining: 7m 4s\n",
      "4: learn: 0.5408985\ttest: 0.5408031\tbestTest: 0.5408031 (4)\ttotal: 22.4s\tremaining: 7m 5s\n",
      "5: learn: 0.5168344\ttest: 0.5167247\tbestTest: 0.5167247 (5)\ttotal: 27.3s\tremaining: 7m 7s\n",
      "6: learn: 0.4948639\ttest: 0.4947283\tbestTest: 0.4947283 (6)\ttotal: 32s\tremaining: 7m 5s\n",
      "7: learn: 0.4748949\ttest: 0.4747368\tbestTest: 0.4747368 (7)\ttotal: 36.8s\tremaining: 7m 2s\n",
      "8: learn: 0.4562453\ttest: 0.4560698\tbestTest: 0.4560698 (8)\ttotal: 41.3s\tremaining: 6m 57s\n",
      "9: learn: 0.4392951\ttest: 0.439097\tbestTest: 0.439097 (9)\ttotal: 46.4s\tremaining: 6m 57s\n",
      "10: learn: 0.4239241\ttest: 0.4237049\tbestTest: 0.4237049 (10)\ttotal: 51.4s\tremaining: 6m 56s\n",
      "11: learn: 0.4094533\ttest: 0.4092184\tbestTest: 0.4092184 (11)\ttotal: 56.4s\tremaining: 6m 53s\n",
      "12: learn: 0.3964145\ttest: 0.3961621\tbestTest: 0.3961621 (12)\ttotal: 1m 1s\tremaining: 6m 50s\n",
      "13: learn: 0.385048\ttest: 0.3847793\tbestTest: 0.3847793 (13)\ttotal: 1m 3s\tremaining: 6m 32s\n",
      "14: learn: 0.3734655\ttest: 0.3731734\tbestTest: 0.3731734 (14)\ttotal: 1m 8s\tremaining: 6m 27s\n",
      "15: learn: 0.3632122\ttest: 0.3628982\tbestTest: 0.3628982 (15)\ttotal: 1m 13s\tremaining: 6m 25s\n",
      "16: learn: 0.3536682\ttest: 0.3533407\tbestTest: 0.3533407 (16)\ttotal: 1m 18s\tremaining: 6m 22s\n",
      "17: learn: 0.3451627\ttest: 0.3448143\tbestTest: 0.3448143 (17)\ttotal: 1m 22s\tremaining: 6m 17s\n",
      "18: learn: 0.3371599\ttest: 0.3367942\tbestTest: 0.3367942 (18)\ttotal: 1m 27s\tremaining: 6m 12s\n",
      "19: learn: 0.3298667\ttest: 0.3295073\tbestTest: 0.3295073 (19)\ttotal: 1m 31s\tremaining: 6m 7s\n",
      "20: learn: 0.3230413\ttest: 0.3226675\tbestTest: 0.3226675 (20)\ttotal: 1m 36s\tremaining: 6m 4s\n",
      "21: learn: 0.3163189\ttest: 0.315925\tbestTest: 0.315925 (21)\ttotal: 1m 41s\tremaining: 5m 59s\n",
      "22: learn: 0.3100653\ttest: 0.3096537\tbestTest: 0.3096537 (22)\ttotal: 1m 45s\tremaining: 5m 53s\n",
      "23: learn: 0.3043167\ttest: 0.3038872\tbestTest: 0.3038872 (23)\ttotal: 1m 50s\tremaining: 5m 50s\n",
      "24: learn: 0.2989754\ttest: 0.2985279\tbestTest: 0.2985279 (24)\ttotal: 1m 54s\tremaining: 5m 44s\n",
      "25: learn: 0.2940538\ttest: 0.2935899\tbestTest: 0.2935899 (25)\ttotal: 1m 59s\tremaining: 5m 39s\n",
      "26: learn: 0.2895884\ttest: 0.2891147\tbestTest: 0.2891147 (26)\ttotal: 2m 4s\tremaining: 5m 35s\n",
      "27: learn: 0.2854212\ttest: 0.2849297\tbestTest: 0.2849297 (27)\ttotal: 2m 8s\tremaining: 5m 29s\n",
      "28: learn: 0.281737\ttest: 0.2812363\tbestTest: 0.2812363 (28)\ttotal: 2m 13s\tremaining: 5m 25s\n",
      "29: learn: 0.2782761\ttest: 0.2777634\tbestTest: 0.2777634 (29)\ttotal: 2m 17s\tremaining: 5m 20s\n",
      "30: learn: 0.2748585\ttest: 0.2743311\tbestTest: 0.2743311 (30)\ttotal: 2m 21s\tremaining: 5m 15s\n",
      "31: learn: 0.2717337\ttest: 0.2711914\tbestTest: 0.2711914 (31)\ttotal: 2m 25s\tremaining: 5m 10s\n",
      "32: learn: 0.2687527\ttest: 0.2681975\tbestTest: 0.2681975 (32)\ttotal: 2m 30s\tremaining: 5m 5s\n",
      "33: learn: 0.2660402\ttest: 0.2654683\tbestTest: 0.2654683 (33)\ttotal: 2m 34s\tremaining: 4m 59s\n",
      "34: learn: 0.2634962\ttest: 0.2629174\tbestTest: 0.2629174 (34)\ttotal: 2m 39s\tremaining: 4m 55s\n",
      "35: learn: 0.2613143\ttest: 0.2607251\tbestTest: 0.2607251 (35)\ttotal: 2m 44s\tremaining: 4m 52s\n",
      "36: learn: 0.2591582\ttest: 0.2585584\tbestTest: 0.2585584 (36)\ttotal: 2m 48s\tremaining: 4m 47s\n",
      "37: learn: 0.2572398\ttest: 0.2566318\tbestTest: 0.2566318 (37)\ttotal: 2m 53s\tremaining: 4m 43s\n",
      "38: learn: 0.2555371\ttest: 0.2549178\tbestTest: 0.2549178 (38)\ttotal: 2m 58s\tremaining: 4m 38s\n",
      "39: learn: 0.2538525\ttest: 0.2532275\tbestTest: 0.2532275 (39)\ttotal: 3m 3s\tremaining: 4m 34s\n",
      "40: learn: 0.2521783\ttest: 0.2515442\tbestTest: 0.2515442 (40)\ttotal: 3m 7s\tremaining: 4m 29s\n",
      "41: learn: 0.2506101\ttest: 0.2499694\tbestTest: 0.2499694 (41)\ttotal: 3m 11s\tremaining: 4m 25s\n",
      "42: learn: 0.2490942\ttest: 0.2484442\tbestTest: 0.2484442 (42)\ttotal: 3m 16s\tremaining: 4m 19s\n",
      "43: learn: 0.247693\ttest: 0.2470315\tbestTest: 0.2470315 (43)\ttotal: 3m 21s\tremaining: 4m 15s\n",
      "44: learn: 0.2463978\ttest: 0.2457267\tbestTest: 0.2457267 (44)\ttotal: 3m 25s\tremaining: 4m 11s\n",
      "45: learn: 0.2452345\ttest: 0.244555\tbestTest: 0.244555 (45)\ttotal: 3m 29s\tremaining: 4m 6s\n",
      "46: learn: 0.2441255\ttest: 0.2434373\tbestTest: 0.2434373 (46)\ttotal: 3m 34s\tremaining: 4m 1s\n",
      "47: learn: 0.2431463\ttest: 0.2424535\tbestTest: 0.2424535 (47)\ttotal: 3m 39s\tremaining: 3m 57s\n",
      "48: learn: 0.2422389\ttest: 0.2415423\tbestTest: 0.2415423 (48)\ttotal: 3m 44s\tremaining: 3m 53s\n",
      "49: learn: 0.2412575\ttest: 0.2405514\tbestTest: 0.2405514 (49)\ttotal: 3m 48s\tremaining: 3m 48s\n",
      "50: learn: 0.2404609\ttest: 0.239747\tbestTest: 0.239747 (50)\ttotal: 3m 52s\tremaining: 3m 43s\n",
      "51: learn: 0.2396355\ttest: 0.2389143\tbestTest: 0.2389143 (51)\ttotal: 3m 56s\tremaining: 3m 38s\n",
      "52: learn: 0.2389313\ttest: 0.2382042\tbestTest: 0.2382042 (52)\ttotal: 4m 1s\tremaining: 3m 34s\n",
      "53: learn: 0.2381935\ttest: 0.2374604\tbestTest: 0.2374604 (53)\ttotal: 4m 5s\tremaining: 3m 29s\n",
      "54: learn: 0.2374855\ttest: 0.2367442\tbestTest: 0.2367442 (54)\ttotal: 4m 10s\tremaining: 3m 24s\n",
      "55: learn: 0.2369167\ttest: 0.2361702\tbestTest: 0.2361702 (55)\ttotal: 4m 15s\tremaining: 3m 20s\n",
      "56: learn: 0.2363024\ttest: 0.2355492\tbestTest: 0.2355492 (56)\ttotal: 4m 19s\tremaining: 3m 15s\n",
      "57: learn: 0.2357291\ttest: 0.2349715\tbestTest: 0.2349715 (57)\ttotal: 4m 23s\tremaining: 3m 11s\n",
      "58: learn: 0.2352085\ttest: 0.2344465\tbestTest: 0.2344465 (58)\ttotal: 4m 28s\tremaining: 3m 6s\n",
      "59: learn: 0.2347055\ttest: 0.2339398\tbestTest: 0.2339398 (59)\ttotal: 4m 33s\tremaining: 3m 2s\n",
      "60: learn: 0.2342281\ttest: 0.2334573\tbestTest: 0.2334573 (60)\ttotal: 4m 37s\tremaining: 2m 57s\n",
      "61: learn: 0.2338418\ttest: 0.2330674\tbestTest: 0.2330674 (61)\ttotal: 4m 41s\tremaining: 2m 52s\n",
      "62: learn: 0.2334063\ttest: 0.2326245\tbestTest: 0.2326245 (62)\ttotal: 4m 46s\tremaining: 2m 48s\n",
      "63: learn: 0.2330054\ttest: 0.2322178\tbestTest: 0.2322178 (63)\ttotal: 4m 50s\tremaining: 2m 43s\n",
      "64: learn: 0.2325968\ttest: 0.2318026\tbestTest: 0.2318026 (64)\ttotal: 4m 54s\tremaining: 2m 38s\n",
      "65: learn: 0.2322354\ttest: 0.2314365\tbestTest: 0.2314365 (65)\ttotal: 4m 59s\tremaining: 2m 34s\n",
      "66: learn: 0.2318752\ttest: 0.2310719\tbestTest: 0.2310719 (66)\ttotal: 5m 4s\tremaining: 2m 29s\n",
      "67: learn: 0.2315927\ttest: 0.2307853\tbestTest: 0.2307853 (67)\ttotal: 5m 8s\tremaining: 2m 25s\n",
      "68: learn: 0.2312938\ttest: 0.2304833\tbestTest: 0.2304833 (68)\ttotal: 5m 13s\tremaining: 2m 20s\n",
      "69: learn: 0.2309912\ttest: 0.2301768\tbestTest: 0.2301768 (69)\ttotal: 5m 17s\tremaining: 2m 16s\n",
      "70: learn: 0.2307461\ttest: 0.2299286\tbestTest: 0.2299286 (70)\ttotal: 5m 22s\tremaining: 2m 11s\n",
      "71: learn: 0.2305069\ttest: 0.2296867\tbestTest: 0.2296867 (71)\ttotal: 5m 26s\tremaining: 2m 7s\n",
      "72: learn: 0.2302454\ttest: 0.2294205\tbestTest: 0.2294205 (72)\ttotal: 5m 31s\tremaining: 2m 2s\n",
      "73: learn: 0.2300108\ttest: 0.2291817\tbestTest: 0.2291817 (73)\ttotal: 5m 35s\tremaining: 1m 57s\n",
      "74: learn: 0.229759\ttest: 0.2289255\tbestTest: 0.2289255 (74)\ttotal: 5m 40s\tremaining: 1m 53s\n",
      "75: learn: 0.2295249\ttest: 0.2286892\tbestTest: 0.2286892 (75)\ttotal: 5m 44s\tremaining: 1m 48s\n",
      "76: learn: 0.2293135\ttest: 0.2284748\tbestTest: 0.2284748 (76)\ttotal: 5m 49s\tremaining: 1m 44s\n",
      "77: learn: 0.2291428\ttest: 0.2282961\tbestTest: 0.2282961 (77)\ttotal: 5m 54s\tremaining: 1m 40s\n",
      "78: learn: 0.2289421\ttest: 0.2280935\tbestTest: 0.2280935 (78)\ttotal: 5m 59s\tremaining: 1m 35s\n",
      "79: learn: 0.2287646\ttest: 0.2279137\tbestTest: 0.2279137 (79)\ttotal: 6m 3s\tremaining: 1m 30s\n",
      "80: learn: 0.2286065\ttest: 0.2277517\tbestTest: 0.2277517 (80)\ttotal: 6m 8s\tremaining: 1m 26s\n",
      "81: learn: 0.2284361\ttest: 0.2275794\tbestTest: 0.2275794 (81)\ttotal: 6m 12s\tremaining: 1m 21s\n",
      "82: learn: 0.2282784\ttest: 0.2274198\tbestTest: 0.2274198 (82)\ttotal: 6m 17s\tremaining: 1m 17s\n",
      "83: learn: 0.2281241\ttest: 0.2272626\tbestTest: 0.2272626 (83)\ttotal: 6m 21s\tremaining: 1m 12s\n",
      "84: learn: 0.2279898\ttest: 0.2271278\tbestTest: 0.2271278 (84)\ttotal: 6m 26s\tremaining: 1m 8s\n",
      "85: learn: 0.227865\ttest: 0.2270016\tbestTest: 0.2270016 (85)\ttotal: 6m 30s\tremaining: 1m 3s\n",
      "86: learn: 0.2277505\ttest: 0.2268847\tbestTest: 0.2268847 (86)\ttotal: 6m 36s\tremaining: 59.2s\n",
      "87: learn: 0.2276226\ttest: 0.2267564\tbestTest: 0.2267564 (87)\ttotal: 6m 41s\tremaining: 54.7s\n",
      "88: learn: 0.227515\ttest: 0.2266467\tbestTest: 0.2266467 (88)\ttotal: 6m 45s\tremaining: 50.1s\n",
      "89: learn: 0.2273435\ttest: 0.2264754\tbestTest: 0.2264754 (89)\ttotal: 6m 49s\tremaining: 45.5s\n",
      "90: learn: 0.2272191\ttest: 0.2263486\tbestTest: 0.2263486 (90)\ttotal: 6m 54s\tremaining: 41s\n",
      "91: learn: 0.22711\ttest: 0.2262391\tbestTest: 0.2262391 (91)\ttotal: 6m 59s\tremaining: 36.4s\n",
      "92: learn: 0.227006\ttest: 0.2261332\tbestTest: 0.2261332 (92)\ttotal: 7m 4s\tremaining: 31.9s\n",
      "93: learn: 0.2269029\ttest: 0.2260287\tbestTest: 0.2260287 (93)\ttotal: 7m 8s\tremaining: 27.4s\n",
      "94: learn: 0.2268199\ttest: 0.2259443\tbestTest: 0.2259443 (94)\ttotal: 7m 13s\tremaining: 22.8s\n",
      "95: learn: 0.2267236\ttest: 0.2258468\tbestTest: 0.2258468 (95)\ttotal: 7m 18s\tremaining: 18.3s\n",
      "96: learn: 0.2266389\ttest: 0.225761\tbestTest: 0.225761 (96)\ttotal: 7m 22s\tremaining: 13.7s\n",
      "97: learn: 0.2265544\ttest: 0.2256767\tbestTest: 0.2256767 (97)\ttotal: 7m 26s\tremaining: 9.12s\n",
      "98: learn: 0.2264438\ttest: 0.2255657\tbestTest: 0.2255657 (98)\ttotal: 7m 31s\tremaining: 4.56s\n",
      "99: learn: 0.2263428\ttest: 0.2254658\tbestTest: 0.2254658 (99)\ttotal: 7m 35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254658196\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.75_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 03:34:33.016013\n",
      "train time given below\n",
      "0:10:54.580244\n",
      "2018-03-14 03:34:33.044234\n",
      "2018-03-14 03:34:33.047792\n",
      "GINI ISIT = 0.454800961777\n",
      "2018-03-14 03:36:06.756262\n",
      "GINI OSIT = 0.456263270087\n",
      "2018-03-14 03:36:45.183860\n",
      "GINI OSOT = 0.41162167261\n",
      "2018-03-14 03:36:56.964525\n",
      "2018-03-14 03:36:56.966524\n",
      "rsm = 0.8\n",
      "2018-03-14 03:36:56.967953\n",
      "model train start\n",
      "2018-03-14 03:36:56.968185\n",
      "0: learn: 0.6573434\ttest: 0.6573291\tbestTest: 0.6573291 (0)\ttotal: 5.23s\tremaining: 8m 38s\n",
      "1: learn: 0.6241461\ttest: 0.624102\tbestTest: 0.624102 (1)\ttotal: 10.1s\tremaining: 8m 15s\n",
      "2: learn: 0.5941897\ttest: 0.5941329\tbestTest: 0.5941329 (2)\ttotal: 14.8s\tremaining: 7m 59s\n",
      "3: learn: 0.565906\ttest: 0.5658203\tbestTest: 0.5658203 (3)\ttotal: 19.2s\tremaining: 7m 40s\n",
      "4: learn: 0.5405892\ttest: 0.5404882\tbestTest: 0.5404882 (4)\ttotal: 24.3s\tremaining: 7m 41s\n",
      "5: learn: 0.5169661\ttest: 0.516844\tbestTest: 0.516844 (5)\ttotal: 29s\tremaining: 7m 34s\n",
      "6: learn: 0.4951111\ttest: 0.4949723\tbestTest: 0.4949723 (6)\ttotal: 33.6s\tremaining: 7m 26s\n",
      "7: learn: 0.4748213\ttest: 0.4746422\tbestTest: 0.4746422 (7)\ttotal: 39.1s\tremaining: 7m 29s\n",
      "8: learn: 0.4560341\ttest: 0.4558466\tbestTest: 0.4558466 (8)\ttotal: 44.4s\tremaining: 7m 29s\n",
      "9: learn: 0.439132\ttest: 0.4389181\tbestTest: 0.4389181 (9)\ttotal: 49.4s\tremaining: 7m 24s\n",
      "10: learn: 0.4235946\ttest: 0.4233643\tbestTest: 0.4233643 (10)\ttotal: 53.9s\tremaining: 7m 16s\n",
      "11: learn: 0.4090437\ttest: 0.4087906\tbestTest: 0.4087906 (11)\ttotal: 58.1s\tremaining: 7m 6s\n",
      "12: learn: 0.3964081\ttest: 0.3961354\tbestTest: 0.3961354 (12)\ttotal: 1m 3s\tremaining: 7m 4s\n",
      "13: learn: 0.3841866\ttest: 0.3839083\tbestTest: 0.3839083 (13)\ttotal: 1m 7s\tremaining: 6m 56s\n",
      "14: learn: 0.3732468\ttest: 0.3729546\tbestTest: 0.3729546 (14)\ttotal: 1m 12s\tremaining: 6m 49s\n",
      "15: learn: 0.3627287\ttest: 0.3624226\tbestTest: 0.3624226 (15)\ttotal: 1m 16s\tremaining: 6m 42s\n",
      "16: learn: 0.3530915\ttest: 0.3527706\tbestTest: 0.3527706 (16)\ttotal: 1m 20s\tremaining: 6m 35s\n",
      "17: learn: 0.3443784\ttest: 0.3440342\tbestTest: 0.3440342 (17)\ttotal: 1m 26s\tremaining: 6m 33s\n",
      "18: learn: 0.336092\ttest: 0.3357291\tbestTest: 0.3357291 (18)\ttotal: 1m 30s\tremaining: 6m 27s\n",
      "19: learn: 0.3285764\ttest: 0.3281905\tbestTest: 0.3281905 (19)\ttotal: 1m 35s\tremaining: 6m 21s\n",
      "20: learn: 0.3213607\ttest: 0.3209614\tbestTest: 0.3209614 (20)\ttotal: 1m 40s\tremaining: 6m 16s\n",
      "21: learn: 0.315475\ttest: 0.3150582\tbestTest: 0.3150582 (21)\ttotal: 1m 42s\tremaining: 6m 2s\n",
      "22: learn: 0.3094346\ttest: 0.3089998\tbestTest: 0.3089998 (22)\ttotal: 1m 46s\tremaining: 5m 57s\n",
      "23: learn: 0.3043306\ttest: 0.3038796\tbestTest: 0.3038796 (23)\ttotal: 1m 52s\tremaining: 5m 56s\n",
      "24: learn: 0.2990231\ttest: 0.2985595\tbestTest: 0.2985595 (24)\ttotal: 1m 57s\tremaining: 5m 52s\n",
      "25: learn: 0.2941267\ttest: 0.2936448\tbestTest: 0.2936448 (25)\ttotal: 2m 1s\tremaining: 5m 47s\n",
      "26: learn: 0.2899577\ttest: 0.2894632\tbestTest: 0.2894632 (26)\ttotal: 2m 6s\tremaining: 5m 42s\n",
      "27: learn: 0.2858377\ttest: 0.2853305\tbestTest: 0.2853305 (27)\ttotal: 2m 11s\tremaining: 5m 37s\n",
      "28: learn: 0.2818846\ttest: 0.2813657\tbestTest: 0.2813657 (28)\ttotal: 2m 16s\tremaining: 5m 33s\n",
      "29: learn: 0.2783496\ttest: 0.2778167\tbestTest: 0.2778167 (29)\ttotal: 2m 20s\tremaining: 5m 28s\n",
      "30: learn: 0.2749092\ttest: 0.2743634\tbestTest: 0.2743634 (30)\ttotal: 2m 25s\tremaining: 5m 23s\n",
      "31: learn: 0.2717932\ttest: 0.2712336\tbestTest: 0.2712336 (31)\ttotal: 2m 29s\tremaining: 5m 18s\n",
      "32: learn: 0.2689814\ttest: 0.2684144\tbestTest: 0.2684144 (32)\ttotal: 2m 34s\tremaining: 5m 13s\n",
      "33: learn: 0.2663194\ttest: 0.2657417\tbestTest: 0.2657417 (33)\ttotal: 2m 39s\tremaining: 5m 9s\n",
      "34: learn: 0.2637534\ttest: 0.263163\tbestTest: 0.263163 (34)\ttotal: 2m 44s\tremaining: 5m 5s\n",
      "35: learn: 0.261374\ttest: 0.2607708\tbestTest: 0.2607708 (35)\ttotal: 2m 49s\tremaining: 5m 1s\n",
      "36: learn: 0.2591398\ttest: 0.2585274\tbestTest: 0.2585274 (36)\ttotal: 2m 54s\tremaining: 4m 56s\n",
      "37: learn: 0.2572459\ttest: 0.2566319\tbestTest: 0.2566319 (37)\ttotal: 2m 58s\tremaining: 4m 51s\n",
      "38: learn: 0.2553399\ttest: 0.2547162\tbestTest: 0.2547162 (38)\ttotal: 3m 3s\tremaining: 4m 47s\n",
      "39: learn: 0.253597\ttest: 0.2529192\tbestTest: 0.2529192 (39)\ttotal: 3m 8s\tremaining: 4m 43s\n",
      "40: learn: 0.2519245\ttest: 0.2512409\tbestTest: 0.2512409 (40)\ttotal: 3m 13s\tremaining: 4m 38s\n",
      "41: learn: 0.2503295\ttest: 0.2496385\tbestTest: 0.2496385 (41)\ttotal: 3m 18s\tremaining: 4m 33s\n",
      "42: learn: 0.2489612\ttest: 0.2482661\tbestTest: 0.2482661 (42)\ttotal: 3m 22s\tremaining: 4m 28s\n",
      "43: learn: 0.2476927\ttest: 0.2469924\tbestTest: 0.2469924 (43)\ttotal: 3m 27s\tremaining: 4m 24s\n",
      "44: learn: 0.2464093\ttest: 0.2457031\tbestTest: 0.2457031 (44)\ttotal: 3m 32s\tremaining: 4m 19s\n",
      "45: learn: 0.2451987\ttest: 0.2444858\tbestTest: 0.2444858 (45)\ttotal: 3m 36s\tremaining: 4m 14s\n",
      "46: learn: 0.2440832\ttest: 0.2433649\tbestTest: 0.2433649 (46)\ttotal: 3m 41s\tremaining: 4m 10s\n",
      "47: learn: 0.2430322\ttest: 0.2423067\tbestTest: 0.2423067 (47)\ttotal: 3m 47s\tremaining: 4m 6s\n",
      "48: learn: 0.2420207\ttest: 0.2412865\tbestTest: 0.2412865 (48)\ttotal: 3m 51s\tremaining: 4m 1s\n",
      "49: learn: 0.2411406\ttest: 0.2404016\tbestTest: 0.2404016 (49)\ttotal: 3m 56s\tremaining: 3m 56s\n",
      "50: learn: 0.2402784\ttest: 0.239532\tbestTest: 0.239532 (50)\ttotal: 4m 1s\tremaining: 3m 51s\n",
      "51: learn: 0.2395461\ttest: 0.2387993\tbestTest: 0.2387993 (51)\ttotal: 4m 6s\tremaining: 3m 47s\n",
      "52: learn: 0.2387323\ttest: 0.2379826\tbestTest: 0.2379826 (52)\ttotal: 4m 11s\tremaining: 3m 42s\n",
      "53: learn: 0.238013\ttest: 0.2372568\tbestTest: 0.2372568 (53)\ttotal: 4m 16s\tremaining: 3m 38s\n",
      "54: learn: 0.2373582\ttest: 0.2365953\tbestTest: 0.2365953 (54)\ttotal: 4m 21s\tremaining: 3m 33s\n",
      "55: learn: 0.2366682\ttest: 0.2358989\tbestTest: 0.2358989 (55)\ttotal: 4m 25s\tremaining: 3m 28s\n",
      "56: learn: 0.2360764\ttest: 0.2353032\tbestTest: 0.2353032 (56)\ttotal: 4m 30s\tremaining: 3m 23s\n",
      "57: learn: 0.2354808\ttest: 0.234701\tbestTest: 0.234701 (57)\ttotal: 4m 35s\tremaining: 3m 19s\n",
      "58: learn: 0.2349785\ttest: 0.2341936\tbestTest: 0.2341936 (58)\ttotal: 4m 39s\tremaining: 3m 14s\n",
      "59: learn: 0.2345265\ttest: 0.2337386\tbestTest: 0.2337386 (59)\ttotal: 4m 44s\tremaining: 3m 9s\n",
      "60: learn: 0.234046\ttest: 0.2332542\tbestTest: 0.2332542 (60)\ttotal: 4m 49s\tremaining: 3m 5s\n",
      "61: learn: 0.2336025\ttest: 0.2328071\tbestTest: 0.2328071 (61)\ttotal: 4m 54s\tremaining: 3m\n",
      "62: learn: 0.2331837\ttest: 0.2323858\tbestTest: 0.2323858 (62)\ttotal: 4m 59s\tremaining: 2m 55s\n",
      "63: learn: 0.2327582\ttest: 0.2319563\tbestTest: 0.2319563 (63)\ttotal: 5m 4s\tremaining: 2m 51s\n",
      "64: learn: 0.2324102\ttest: 0.2316037\tbestTest: 0.2316037 (64)\ttotal: 5m 8s\tremaining: 2m 46s\n",
      "65: learn: 0.2320443\ttest: 0.2312322\tbestTest: 0.2312322 (65)\ttotal: 5m 13s\tremaining: 2m 41s\n",
      "66: learn: 0.2316964\ttest: 0.2308817\tbestTest: 0.2308817 (66)\ttotal: 5m 17s\tremaining: 2m 36s\n",
      "67: learn: 0.2313983\ttest: 0.2305808\tbestTest: 0.2305808 (67)\ttotal: 5m 22s\tremaining: 2m 31s\n",
      "68: learn: 0.2310825\ttest: 0.2302616\tbestTest: 0.2302616 (68)\ttotal: 5m 27s\tremaining: 2m 26s\n",
      "69: learn: 0.2308075\ttest: 0.2299814\tbestTest: 0.2299814 (69)\ttotal: 5m 31s\tremaining: 2m 22s\n",
      "70: learn: 0.2305143\ttest: 0.2296863\tbestTest: 0.2296863 (70)\ttotal: 5m 36s\tremaining: 2m 17s\n",
      "71: learn: 0.2302631\ttest: 0.2294329\tbestTest: 0.2294329 (71)\ttotal: 5m 41s\tremaining: 2m 12s\n",
      "72: learn: 0.229997\ttest: 0.2291663\tbestTest: 0.2291663 (72)\ttotal: 5m 46s\tremaining: 2m 8s\n",
      "73: learn: 0.2297758\ttest: 0.2289422\tbestTest: 0.2289422 (73)\ttotal: 5m 51s\tremaining: 2m 3s\n",
      "74: learn: 0.2295504\ttest: 0.2287144\tbestTest: 0.2287144 (74)\ttotal: 5m 55s\tremaining: 1m 58s\n",
      "75: learn: 0.229351\ttest: 0.2285121\tbestTest: 0.2285121 (75)\ttotal: 6m 1s\tremaining: 1m 54s\n",
      "76: learn: 0.2291185\ttest: 0.2282781\tbestTest: 0.2282781 (76)\ttotal: 6m 5s\tremaining: 1m 49s\n",
      "77: learn: 0.2289252\ttest: 0.2280825\tbestTest: 0.2280825 (77)\ttotal: 6m 10s\tremaining: 1m 44s\n",
      "78: learn: 0.2287528\ttest: 0.2279091\tbestTest: 0.2279091 (78)\ttotal: 6m 15s\tremaining: 1m 39s\n",
      "79: learn: 0.2285809\ttest: 0.227733\tbestTest: 0.227733 (79)\ttotal: 6m 20s\tremaining: 1m 35s\n",
      "80: learn: 0.2284219\ttest: 0.2275728\tbestTest: 0.2275728 (80)\ttotal: 6m 24s\tremaining: 1m 30s\n",
      "81: learn: 0.2282803\ttest: 0.2274293\tbestTest: 0.2274293 (81)\ttotal: 6m 30s\tremaining: 1m 25s\n",
      "82: learn: 0.2281132\ttest: 0.2272611\tbestTest: 0.2272611 (82)\ttotal: 6m 34s\tremaining: 1m 20s\n",
      "83: learn: 0.2279627\ttest: 0.2271105\tbestTest: 0.2271105 (83)\ttotal: 6m 39s\tremaining: 1m 16s\n",
      "84: learn: 0.2278145\ttest: 0.2269599\tbestTest: 0.2269599 (84)\ttotal: 6m 43s\tremaining: 1m 11s\n",
      "85: learn: 0.227689\ttest: 0.2268339\tbestTest: 0.2268339 (85)\ttotal: 6m 48s\tremaining: 1m 6s\n",
      "86: learn: 0.2275539\ttest: 0.226698\tbestTest: 0.226698 (86)\ttotal: 6m 52s\tremaining: 1m 1s\n",
      "87: learn: 0.227412\ttest: 0.2265548\tbestTest: 0.2265548 (87)\ttotal: 6m 57s\tremaining: 57s\n",
      "88: learn: 0.2273135\ttest: 0.2264547\tbestTest: 0.2264547 (88)\ttotal: 7m 2s\tremaining: 52.3s\n",
      "89: learn: 0.2272002\ttest: 0.2263403\tbestTest: 0.2263403 (89)\ttotal: 7m 7s\tremaining: 47.5s\n",
      "90: learn: 0.2270862\ttest: 0.2262256\tbestTest: 0.2262256 (90)\ttotal: 7m 12s\tremaining: 42.8s\n",
      "91: learn: 0.2269743\ttest: 0.2261131\tbestTest: 0.2261131 (91)\ttotal: 7m 17s\tremaining: 38s\n",
      "92: learn: 0.226873\ttest: 0.2260104\tbestTest: 0.2260104 (92)\ttotal: 7m 21s\tremaining: 33.2s\n",
      "93: learn: 0.2267787\ttest: 0.2259143\tbestTest: 0.2259143 (93)\ttotal: 7m 26s\tremaining: 28.5s\n",
      "94: learn: 0.2266868\ttest: 0.2258209\tbestTest: 0.2258209 (94)\ttotal: 7m 30s\tremaining: 23.7s\n",
      "95: learn: 0.2265926\ttest: 0.2257247\tbestTest: 0.2257247 (95)\ttotal: 7m 35s\tremaining: 19s\n",
      "96: learn: 0.2265078\ttest: 0.2256391\tbestTest: 0.2256391 (96)\ttotal: 7m 40s\tremaining: 14.2s\n",
      "97: learn: 0.2264149\ttest: 0.2255437\tbestTest: 0.2255437 (97)\ttotal: 7m 44s\tremaining: 9.49s\n",
      "98: learn: 0.226345\ttest: 0.2254734\tbestTest: 0.2254734 (98)\ttotal: 7m 49s\tremaining: 4.74s\n",
      "99: learn: 0.2262742\ttest: 0.2254018\tbestTest: 0.2254018 (99)\ttotal: 7m 54s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254018005\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.8_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 03:48:18.157048\n",
      "train time given below\n",
      "0:11:21.188863\n",
      "2018-03-14 03:48:18.158638\n",
      "2018-03-14 03:48:18.162351\n",
      "GINI ISIT = 0.456170424428\n",
      "2018-03-14 03:49:55.685033\n",
      "GINI OSIT = 0.457538664404\n",
      "2018-03-14 03:50:34.846745\n",
      "GINI OSOT = 0.411126327979\n",
      "2018-03-14 03:50:46.977995\n",
      "2018-03-14 03:50:46.979947\n",
      "rsm = 0.85\n",
      "2018-03-14 03:50:46.981423\n",
      "model train start\n",
      "2018-03-14 03:50:46.981675\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 5.49s\tremaining: 9m 3s\n",
      "1: learn: 0.6246208\ttest: 0.6245847\tbestTest: 0.6245847 (1)\ttotal: 10.9s\tremaining: 8m 55s\n",
      "2: learn: 0.5946127\ttest: 0.5945499\tbestTest: 0.5945499 (2)\ttotal: 16.3s\tremaining: 8m 48s\n",
      "3: learn: 0.5671899\ttest: 0.5671115\tbestTest: 0.5671115 (3)\ttotal: 22.5s\tremaining: 8m 59s\n",
      "4: learn: 0.5413315\ttest: 0.5412325\tbestTest: 0.5412325 (4)\ttotal: 27.8s\tremaining: 8m 48s\n",
      "5: learn: 0.5176855\ttest: 0.517555\tbestTest: 0.517555 (5)\ttotal: 33.3s\tremaining: 8m 41s\n",
      "6: learn: 0.4955908\ttest: 0.4954434\tbestTest: 0.4954434 (6)\ttotal: 38.7s\tremaining: 8m 34s\n",
      "7: learn: 0.4754866\ttest: 0.4753306\tbestTest: 0.4753306 (7)\ttotal: 43.5s\tremaining: 8m 20s\n",
      "8: learn: 0.4569312\ttest: 0.4567565\tbestTest: 0.4567565 (8)\ttotal: 48.2s\tremaining: 8m 7s\n",
      "9: learn: 0.4397636\ttest: 0.4395709\tbestTest: 0.4395709 (9)\ttotal: 53.9s\tremaining: 8m 4s\n",
      "10: learn: 0.4246773\ttest: 0.4244609\tbestTest: 0.4244609 (10)\ttotal: 59.9s\tremaining: 8m 4s\n",
      "11: learn: 0.4107796\ttest: 0.4105415\tbestTest: 0.4105415 (11)\ttotal: 1m 2s\tremaining: 7m 38s\n",
      "12: learn: 0.3973422\ttest: 0.3970896\tbestTest: 0.3970896 (12)\ttotal: 1m 8s\tremaining: 7m 35s\n",
      "13: learn: 0.3849222\ttest: 0.3846532\tbestTest: 0.3846532 (13)\ttotal: 1m 12s\tremaining: 7m 26s\n",
      "14: learn: 0.3733676\ttest: 0.3730739\tbestTest: 0.3730739 (14)\ttotal: 1m 17s\tremaining: 7m 19s\n",
      "15: learn: 0.3628323\ttest: 0.3625217\tbestTest: 0.3625217 (15)\ttotal: 1m 22s\tremaining: 7m 10s\n",
      "16: learn: 0.3533874\ttest: 0.3530628\tbestTest: 0.3530628 (16)\ttotal: 1m 26s\tremaining: 7m 4s\n",
      "17: learn: 0.3442928\ttest: 0.3439469\tbestTest: 0.3439469 (17)\ttotal: 1m 31s\tremaining: 6m 55s\n",
      "18: learn: 0.3362487\ttest: 0.3358825\tbestTest: 0.3358825 (18)\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "19: learn: 0.3284989\ttest: 0.3281057\tbestTest: 0.3281057 (19)\ttotal: 1m 41s\tremaining: 6m 46s\n",
      "20: learn: 0.3216065\ttest: 0.3212061\tbestTest: 0.3212061 (20)\ttotal: 1m 46s\tremaining: 6m 41s\n",
      "21: learn: 0.3152186\ttest: 0.3148105\tbestTest: 0.3148105 (21)\ttotal: 1m 52s\tremaining: 6m 37s\n",
      "22: learn: 0.3096159\ttest: 0.3091926\tbestTest: 0.3091926 (22)\ttotal: 1m 57s\tremaining: 6m 31s\n",
      "23: learn: 0.3042068\ttest: 0.3037673\tbestTest: 0.3037673 (23)\ttotal: 2m 2s\tremaining: 6m 28s\n",
      "24: learn: 0.298906\ttest: 0.2984494\tbestTest: 0.2984494 (24)\ttotal: 2m 7s\tremaining: 6m 22s\n",
      "25: learn: 0.2944728\ttest: 0.2940039\tbestTest: 0.2940039 (25)\ttotal: 2m 12s\tremaining: 6m 16s\n",
      "26: learn: 0.2897973\ttest: 0.2893116\tbestTest: 0.2893116 (26)\ttotal: 2m 16s\tremaining: 6m 10s\n",
      "27: learn: 0.2855463\ttest: 0.2850461\tbestTest: 0.2850461 (27)\ttotal: 2m 21s\tremaining: 6m 4s\n",
      "28: learn: 0.2816708\ttest: 0.2811558\tbestTest: 0.2811558 (28)\ttotal: 2m 26s\tremaining: 5m 58s\n",
      "29: learn: 0.2782756\ttest: 0.2777467\tbestTest: 0.2777467 (29)\ttotal: 2m 31s\tremaining: 5m 53s\n",
      "30: learn: 0.2748764\ttest: 0.2743358\tbestTest: 0.2743358 (30)\ttotal: 2m 36s\tremaining: 5m 47s\n",
      "31: learn: 0.2717013\ttest: 0.2711165\tbestTest: 0.2711165 (31)\ttotal: 2m 41s\tremaining: 5m 42s\n",
      "32: learn: 0.268688\ttest: 0.2680896\tbestTest: 0.2680896 (32)\ttotal: 2m 45s\tremaining: 5m 36s\n",
      "33: learn: 0.2661437\ttest: 0.2655366\tbestTest: 0.2655366 (33)\ttotal: 2m 50s\tremaining: 5m 30s\n",
      "34: learn: 0.2638136\ttest: 0.2631968\tbestTest: 0.2631968 (34)\ttotal: 2m 54s\tremaining: 5m 24s\n",
      "35: learn: 0.261605\ttest: 0.2609809\tbestTest: 0.2609809 (35)\ttotal: 2m 59s\tremaining: 5m 19s\n",
      "36: learn: 0.2595084\ttest: 0.2588755\tbestTest: 0.2588755 (36)\ttotal: 3m 4s\tremaining: 5m 14s\n",
      "37: learn: 0.2573841\ttest: 0.2567389\tbestTest: 0.2567389 (37)\ttotal: 3m 9s\tremaining: 5m 9s\n",
      "38: learn: 0.2555279\ttest: 0.2548802\tbestTest: 0.2548802 (38)\ttotal: 3m 14s\tremaining: 5m 4s\n",
      "39: learn: 0.2537557\ttest: 0.2530985\tbestTest: 0.2530985 (39)\ttotal: 3m 19s\tremaining: 4m 59s\n",
      "40: learn: 0.252063\ttest: 0.2514016\tbestTest: 0.2514016 (40)\ttotal: 3m 23s\tremaining: 4m 53s\n",
      "41: learn: 0.2504286\ttest: 0.2497629\tbestTest: 0.2497629 (41)\ttotal: 3m 29s\tremaining: 4m 48s\n",
      "42: learn: 0.2489857\ttest: 0.2483136\tbestTest: 0.2483136 (42)\ttotal: 3m 33s\tremaining: 4m 43s\n",
      "43: learn: 0.247612\ttest: 0.2469316\tbestTest: 0.2469316 (43)\ttotal: 3m 38s\tremaining: 4m 37s\n",
      "44: learn: 0.2463287\ttest: 0.2456404\tbestTest: 0.2456404 (44)\ttotal: 3m 43s\tremaining: 4m 32s\n",
      "45: learn: 0.2451238\ttest: 0.2444292\tbestTest: 0.2444292 (45)\ttotal: 3m 47s\tremaining: 4m 27s\n",
      "46: learn: 0.2439819\ttest: 0.2432444\tbestTest: 0.2432444 (46)\ttotal: 3m 53s\tremaining: 4m 23s\n",
      "47: learn: 0.2429657\ttest: 0.2422273\tbestTest: 0.2422273 (47)\ttotal: 3m 59s\tremaining: 4m 18s\n",
      "48: learn: 0.2420242\ttest: 0.2412818\tbestTest: 0.2412818 (48)\ttotal: 4m 3s\tremaining: 4m 13s\n",
      "49: learn: 0.2410859\ttest: 0.2403403\tbestTest: 0.2403403 (49)\ttotal: 4m 8s\tremaining: 4m 8s\n",
      "50: learn: 0.2402901\ttest: 0.2395419\tbestTest: 0.2395419 (50)\ttotal: 4m 13s\tremaining: 4m 3s\n",
      "51: learn: 0.2394966\ttest: 0.2387424\tbestTest: 0.2387424 (51)\ttotal: 4m 18s\tremaining: 3m 59s\n",
      "52: learn: 0.2387207\ttest: 0.2379593\tbestTest: 0.2379593 (52)\ttotal: 4m 23s\tremaining: 3m 53s\n",
      "53: learn: 0.2380488\ttest: 0.2372821\tbestTest: 0.2372821 (53)\ttotal: 4m 29s\tremaining: 3m 49s\n",
      "54: learn: 0.237367\ttest: 0.2365926\tbestTest: 0.2365926 (54)\ttotal: 4m 33s\tremaining: 3m 43s\n",
      "55: learn: 0.2367244\ttest: 0.2359464\tbestTest: 0.2359464 (55)\ttotal: 4m 38s\tremaining: 3m 38s\n",
      "56: learn: 0.2361421\ttest: 0.2353603\tbestTest: 0.2353603 (56)\ttotal: 4m 43s\tremaining: 3m 33s\n",
      "57: learn: 0.2356092\ttest: 0.2348228\tbestTest: 0.2348228 (57)\ttotal: 4m 48s\tremaining: 3m 28s\n",
      "58: learn: 0.2351138\ttest: 0.2343264\tbestTest: 0.2343264 (58)\ttotal: 4m 53s\tremaining: 3m 23s\n",
      "59: learn: 0.234606\ttest: 0.233814\tbestTest: 0.233814 (59)\ttotal: 4m 57s\tremaining: 3m 18s\n",
      "60: learn: 0.2341415\ttest: 0.2333439\tbestTest: 0.2333439 (60)\ttotal: 5m 2s\tremaining: 3m 13s\n",
      "61: learn: 0.2336912\ttest: 0.2328881\tbestTest: 0.2328881 (61)\ttotal: 5m 7s\tremaining: 3m 8s\n",
      "62: learn: 0.2333059\ttest: 0.2325006\tbestTest: 0.2325006 (62)\ttotal: 5m 12s\tremaining: 3m 3s\n",
      "63: learn: 0.2328979\ttest: 0.2320902\tbestTest: 0.2320902 (63)\ttotal: 5m 16s\tremaining: 2m 58s\n",
      "64: learn: 0.232498\ttest: 0.231687\tbestTest: 0.231687 (64)\ttotal: 5m 22s\tremaining: 2m 53s\n",
      "65: learn: 0.2321619\ttest: 0.2313513\tbestTest: 0.2313513 (65)\ttotal: 5m 27s\tremaining: 2m 48s\n",
      "66: learn: 0.231846\ttest: 0.2310316\tbestTest: 0.2310316 (66)\ttotal: 5m 33s\tremaining: 2m 44s\n",
      "67: learn: 0.2315138\ttest: 0.2306943\tbestTest: 0.2306943 (67)\ttotal: 5m 38s\tremaining: 2m 39s\n",
      "68: learn: 0.2311943\ttest: 0.230371\tbestTest: 0.230371 (68)\ttotal: 5m 42s\tremaining: 2m 34s\n",
      "69: learn: 0.2308674\ttest: 0.2300423\tbestTest: 0.2300423 (69)\ttotal: 5m 47s\tremaining: 2m 28s\n",
      "70: learn: 0.2305828\ttest: 0.2297561\tbestTest: 0.2297561 (70)\ttotal: 5m 51s\tremaining: 2m 23s\n",
      "71: learn: 0.2303331\ttest: 0.2295076\tbestTest: 0.2295076 (71)\ttotal: 5m 56s\tremaining: 2m 18s\n",
      "72: learn: 0.2300738\ttest: 0.2292455\tbestTest: 0.2292455 (72)\ttotal: 6m 1s\tremaining: 2m 13s\n",
      "73: learn: 0.2298357\ttest: 0.2290069\tbestTest: 0.2290069 (73)\ttotal: 6m 6s\tremaining: 2m 8s\n",
      "74: learn: 0.2295871\ttest: 0.2287549\tbestTest: 0.2287549 (74)\ttotal: 6m 11s\tremaining: 2m 3s\n",
      "75: learn: 0.2293932\ttest: 0.2285571\tbestTest: 0.2285571 (75)\ttotal: 6m 17s\tremaining: 1m 59s\n",
      "76: learn: 0.229172\ttest: 0.2283335\tbestTest: 0.2283335 (76)\ttotal: 6m 23s\tremaining: 1m 54s\n",
      "77: learn: 0.2289697\ttest: 0.2281322\tbestTest: 0.2281322 (77)\ttotal: 6m 28s\tremaining: 1m 49s\n",
      "78: learn: 0.2287967\ttest: 0.2279553\tbestTest: 0.2279553 (78)\ttotal: 6m 33s\tremaining: 1m 44s\n",
      "79: learn: 0.2286238\ttest: 0.2277805\tbestTest: 0.2277805 (79)\ttotal: 6m 38s\tremaining: 1m 39s\n",
      "80: learn: 0.2284546\ttest: 0.2276104\tbestTest: 0.2276104 (80)\ttotal: 6m 42s\tremaining: 1m 34s\n",
      "81: learn: 0.2282963\ttest: 0.2274502\tbestTest: 0.2274502 (81)\ttotal: 6m 48s\tremaining: 1m 29s\n",
      "82: learn: 0.228134\ttest: 0.2272865\tbestTest: 0.2272865 (82)\ttotal: 6m 52s\tremaining: 1m 24s\n",
      "83: learn: 0.2279876\ttest: 0.2271382\tbestTest: 0.2271382 (83)\ttotal: 6m 57s\tremaining: 1m 19s\n",
      "84: learn: 0.2278536\ttest: 0.227003\tbestTest: 0.227003 (84)\ttotal: 7m 2s\tremaining: 1m 14s\n",
      "85: learn: 0.2277218\ttest: 0.2268687\tbestTest: 0.2268687 (85)\ttotal: 7m 7s\tremaining: 1m 9s\n",
      "86: learn: 0.227596\ttest: 0.2267423\tbestTest: 0.2267423 (86)\ttotal: 7m 12s\tremaining: 1m 4s\n",
      "87: learn: 0.2274592\ttest: 0.2266042\tbestTest: 0.2266042 (87)\ttotal: 7m 17s\tremaining: 59.7s\n",
      "88: learn: 0.2273448\ttest: 0.2264869\tbestTest: 0.2264869 (88)\ttotal: 7m 22s\tremaining: 54.7s\n",
      "89: learn: 0.2272221\ttest: 0.226362\tbestTest: 0.226362 (89)\ttotal: 7m 27s\tremaining: 49.7s\n",
      "90: learn: 0.2271088\ttest: 0.2262478\tbestTest: 0.2262478 (90)\ttotal: 7m 32s\tremaining: 44.7s\n",
      "91: learn: 0.2270112\ttest: 0.2261491\tbestTest: 0.2261491 (91)\ttotal: 7m 37s\tremaining: 39.7s\n",
      "92: learn: 0.2268981\ttest: 0.2260338\tbestTest: 0.2260338 (92)\ttotal: 7m 42s\tremaining: 34.8s\n",
      "93: learn: 0.2268125\ttest: 0.2259473\tbestTest: 0.2259473 (93)\ttotal: 7m 47s\tremaining: 29.8s\n",
      "94: learn: 0.2267097\ttest: 0.2258438\tbestTest: 0.2258438 (94)\ttotal: 7m 52s\tremaining: 24.9s\n",
      "95: learn: 0.2266195\ttest: 0.2257527\tbestTest: 0.2257527 (95)\ttotal: 7m 57s\tremaining: 19.9s\n",
      "96: learn: 0.2265016\ttest: 0.2256356\tbestTest: 0.2256356 (96)\ttotal: 8m 1s\tremaining: 14.9s\n",
      "97: learn: 0.2264181\ttest: 0.2255508\tbestTest: 0.2255508 (97)\ttotal: 8m 7s\tremaining: 9.94s\n",
      "98: learn: 0.2263337\ttest: 0.2254649\tbestTest: 0.2254649 (98)\ttotal: 8m 11s\tremaining: 4.97s\n",
      "99: learn: 0.2262613\ttest: 0.2253915\tbestTest: 0.2253915 (99)\ttotal: 8m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2253914748\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 04:02:33.061918\n",
      "train time given below\n",
      "0:11:46.080243\n",
      "2018-03-14 04:02:33.080667\n",
      "2018-03-14 04:02:33.084225\n",
      "GINI ISIT = 0.456550293521\n",
      "2018-03-14 04:04:03.605802\n",
      "GINI OSIT = 0.457718454984\n",
      "2018-03-14 04:04:42.008470\n",
      "GINI OSOT = 0.408875124366\n",
      "2018-03-14 04:04:53.813705\n",
      "2018-03-14 04:04:53.815627\n",
      "rsm = 0.9\n",
      "2018-03-14 04:04:53.817017\n",
      "model train start\n",
      "2018-03-14 04:04:53.817236\n",
      "0: learn: 0.6574995\ttest: 0.6574605\tbestTest: 0.6574605 (0)\ttotal: 5.41s\tremaining: 8m 55s\n",
      "1: learn: 0.6240859\ttest: 0.6240168\tbestTest: 0.6240168 (1)\ttotal: 10.5s\tremaining: 8m 33s\n",
      "2: learn: 0.5934975\ttest: 0.5934045\tbestTest: 0.5934045 (2)\ttotal: 15.3s\tremaining: 8m 13s\n",
      "3: learn: 0.5657243\ttest: 0.5656113\tbestTest: 0.5656113 (3)\ttotal: 20.8s\tremaining: 8m 18s\n",
      "4: learn: 0.540306\ttest: 0.5401838\tbestTest: 0.5401838 (4)\ttotal: 26.5s\tremaining: 8m 23s\n",
      "5: learn: 0.51709\ttest: 0.5169516\tbestTest: 0.5169516 (5)\ttotal: 32.7s\tremaining: 8m 32s\n",
      "6: learn: 0.4956111\ttest: 0.4954559\tbestTest: 0.4954559 (6)\ttotal: 38.7s\tremaining: 8m 34s\n",
      "7: learn: 0.4753642\ttest: 0.4751855\tbestTest: 0.4751855 (7)\ttotal: 43.6s\tremaining: 8m 21s\n",
      "8: learn: 0.4571225\ttest: 0.4569308\tbestTest: 0.4569308 (8)\ttotal: 48.6s\tremaining: 8m 11s\n",
      "9: learn: 0.4402244\ttest: 0.4400188\tbestTest: 0.4400188 (9)\ttotal: 53.9s\tremaining: 8m 4s\n",
      "10: learn: 0.4245742\ttest: 0.424347\tbestTest: 0.424347 (10)\ttotal: 59s\tremaining: 7m 57s\n",
      "11: learn: 0.4102032\ttest: 0.4099633\tbestTest: 0.4099633 (11)\ttotal: 1m 4s\tremaining: 7m 51s\n",
      "12: learn: 0.3965629\ttest: 0.396297\tbestTest: 0.396297 (12)\ttotal: 1m 9s\tremaining: 7m 44s\n",
      "13: learn: 0.3845601\ttest: 0.3842719\tbestTest: 0.3842719 (13)\ttotal: 1m 14s\tremaining: 7m 37s\n",
      "14: learn: 0.3733974\ttest: 0.3730954\tbestTest: 0.3730954 (14)\ttotal: 1m 19s\tremaining: 7m 30s\n",
      "15: learn: 0.3627778\ttest: 0.3624592\tbestTest: 0.3624592 (15)\ttotal: 1m 24s\tremaining: 7m 26s\n",
      "16: learn: 0.3533883\ttest: 0.3530511\tbestTest: 0.3530511 (16)\ttotal: 1m 29s\tremaining: 7m 19s\n",
      "17: learn: 0.3444386\ttest: 0.344082\tbestTest: 0.344082 (17)\ttotal: 1m 34s\tremaining: 7m 11s\n",
      "18: learn: 0.3361378\ttest: 0.3357655\tbestTest: 0.3357655 (18)\ttotal: 1m 40s\tremaining: 7m 6s\n",
      "19: learn: 0.3282995\ttest: 0.3279081\tbestTest: 0.3279081 (19)\ttotal: 1m 45s\tremaining: 7m 2s\n",
      "20: learn: 0.3215004\ttest: 0.3210924\tbestTest: 0.3210924 (20)\ttotal: 1m 50s\tremaining: 6m 56s\n",
      "21: learn: 0.3149547\ttest: 0.3145296\tbestTest: 0.3145296 (21)\ttotal: 1m 55s\tremaining: 6m 51s\n",
      "22: learn: 0.3092229\ttest: 0.3087875\tbestTest: 0.3087875 (22)\ttotal: 2m\tremaining: 6m 44s\n",
      "23: learn: 0.303506\ttest: 0.3030504\tbestTest: 0.3030504 (23)\ttotal: 2m 5s\tremaining: 6m 36s\n",
      "24: learn: 0.2984237\ttest: 0.2979522\tbestTest: 0.2979522 (24)\ttotal: 2m 10s\tremaining: 6m 30s\n",
      "25: learn: 0.2936496\ttest: 0.2931661\tbestTest: 0.2931661 (25)\ttotal: 2m 15s\tremaining: 6m 24s\n",
      "26: learn: 0.28911\ttest: 0.2886097\tbestTest: 0.2886097 (26)\ttotal: 2m 19s\tremaining: 6m 17s\n",
      "27: learn: 0.2851587\ttest: 0.2846497\tbestTest: 0.2846497 (27)\ttotal: 2m 24s\tremaining: 6m 11s\n",
      "28: learn: 0.2812382\ttest: 0.2807173\tbestTest: 0.2807173 (28)\ttotal: 2m 29s\tremaining: 6m 5s\n",
      "29: learn: 0.2777566\ttest: 0.2772294\tbestTest: 0.2772294 (29)\ttotal: 2m 34s\tremaining: 6m 1s\n",
      "30: learn: 0.2746015\ttest: 0.2740617\tbestTest: 0.2740617 (30)\ttotal: 2m 39s\tremaining: 5m 55s\n",
      "31: learn: 0.2716358\ttest: 0.2710864\tbestTest: 0.2710864 (31)\ttotal: 2m 44s\tremaining: 5m 49s\n",
      "32: learn: 0.2688241\ttest: 0.2682633\tbestTest: 0.2682633 (32)\ttotal: 2m 50s\tremaining: 5m 45s\n",
      "33: learn: 0.2662926\ttest: 0.2657211\tbestTest: 0.2657211 (33)\ttotal: 2m 56s\tremaining: 5m 42s\n",
      "34: learn: 0.2638314\ttest: 0.2632505\tbestTest: 0.2632505 (34)\ttotal: 3m 1s\tremaining: 5m 37s\n",
      "35: learn: 0.2614948\ttest: 0.2609077\tbestTest: 0.2609077 (35)\ttotal: 3m 6s\tremaining: 5m 31s\n",
      "36: learn: 0.259294\ttest: 0.2586986\tbestTest: 0.2586986 (36)\ttotal: 3m 11s\tremaining: 5m 25s\n",
      "37: learn: 0.257146\ttest: 0.2565374\tbestTest: 0.2565374 (37)\ttotal: 3m 16s\tremaining: 5m 20s\n",
      "38: learn: 0.2552283\ttest: 0.2546107\tbestTest: 0.2546107 (38)\ttotal: 3m 20s\tremaining: 5m 14s\n",
      "39: learn: 0.2535575\ttest: 0.2529302\tbestTest: 0.2529302 (39)\ttotal: 3m 25s\tremaining: 5m 8s\n",
      "40: learn: 0.2520524\ttest: 0.2514176\tbestTest: 0.2514176 (40)\ttotal: 3m 30s\tremaining: 5m 3s\n",
      "41: learn: 0.2505414\ttest: 0.2498949\tbestTest: 0.2498949 (41)\ttotal: 3m 35s\tremaining: 4m 58s\n",
      "42: learn: 0.2491181\ttest: 0.2484662\tbestTest: 0.2484662 (42)\ttotal: 3m 40s\tremaining: 4m 52s\n",
      "43: learn: 0.247752\ttest: 0.2470909\tbestTest: 0.2470909 (43)\ttotal: 3m 45s\tremaining: 4m 47s\n",
      "44: learn: 0.2464432\ttest: 0.2457754\tbestTest: 0.2457754 (44)\ttotal: 3m 50s\tremaining: 4m 41s\n",
      "45: learn: 0.245261\ttest: 0.2445857\tbestTest: 0.2445857 (45)\ttotal: 3m 56s\tremaining: 4m 37s\n",
      "46: learn: 0.2440997\ttest: 0.2434154\tbestTest: 0.2434154 (46)\ttotal: 4m 1s\tremaining: 4m 32s\n",
      "47: learn: 0.2430615\ttest: 0.2423707\tbestTest: 0.2423707 (47)\ttotal: 4m 7s\tremaining: 4m 27s\n",
      "48: learn: 0.2420827\ttest: 0.241383\tbestTest: 0.241383 (48)\ttotal: 4m 12s\tremaining: 4m 22s\n",
      "49: learn: 0.2411708\ttest: 0.2404677\tbestTest: 0.2404677 (49)\ttotal: 4m 17s\tremaining: 4m 17s\n",
      "50: learn: 0.2402926\ttest: 0.239583\tbestTest: 0.239583 (50)\ttotal: 4m 22s\tremaining: 4m 11s\n",
      "51: learn: 0.2395279\ttest: 0.2388146\tbestTest: 0.2388146 (51)\ttotal: 4m 27s\tremaining: 4m 6s\n",
      "52: learn: 0.2387541\ttest: 0.2380336\tbestTest: 0.2380336 (52)\ttotal: 4m 32s\tremaining: 4m 1s\n",
      "53: learn: 0.2380264\ttest: 0.2373031\tbestTest: 0.2373031 (53)\ttotal: 4m 38s\tremaining: 3m 56s\n",
      "54: learn: 0.2373152\ttest: 0.2365851\tbestTest: 0.2365851 (54)\ttotal: 4m 42s\tremaining: 3m 51s\n",
      "55: learn: 0.2367131\ttest: 0.2359775\tbestTest: 0.2359775 (55)\ttotal: 4m 47s\tremaining: 3m 45s\n",
      "56: learn: 0.2360995\ttest: 0.2353572\tbestTest: 0.2353572 (56)\ttotal: 4m 52s\tremaining: 3m 40s\n",
      "57: learn: 0.2355605\ttest: 0.2348111\tbestTest: 0.2348111 (57)\ttotal: 4m 57s\tremaining: 3m 35s\n",
      "58: learn: 0.2350142\ttest: 0.2342584\tbestTest: 0.2342584 (58)\ttotal: 5m 2s\tremaining: 3m 30s\n",
      "59: learn: 0.2345322\ttest: 0.2337722\tbestTest: 0.2337722 (59)\ttotal: 5m 7s\tremaining: 3m 25s\n",
      "60: learn: 0.2340564\ttest: 0.2332912\tbestTest: 0.2332912 (60)\ttotal: 5m 12s\tremaining: 3m 19s\n",
      "61: learn: 0.2336218\ttest: 0.232852\tbestTest: 0.232852 (61)\ttotal: 5m 17s\tremaining: 3m 14s\n",
      "62: learn: 0.2331998\ttest: 0.2324241\tbestTest: 0.2324241 (62)\ttotal: 5m 22s\tremaining: 3m 9s\n",
      "63: learn: 0.2328029\ttest: 0.2320228\tbestTest: 0.2320228 (63)\ttotal: 5m 26s\tremaining: 3m 3s\n",
      "64: learn: 0.2324567\ttest: 0.2316717\tbestTest: 0.2316717 (64)\ttotal: 5m 32s\tremaining: 2m 59s\n",
      "65: learn: 0.2320792\ttest: 0.2312892\tbestTest: 0.2312892 (65)\ttotal: 5m 37s\tremaining: 2m 53s\n",
      "66: learn: 0.2317492\ttest: 0.2309553\tbestTest: 0.2309553 (66)\ttotal: 5m 42s\tremaining: 2m 48s\n",
      "67: learn: 0.2314134\ttest: 0.2306153\tbestTest: 0.2306153 (67)\ttotal: 5m 47s\tremaining: 2m 43s\n",
      "68: learn: 0.2311011\ttest: 0.2302983\tbestTest: 0.2302983 (68)\ttotal: 5m 52s\tremaining: 2m 38s\n",
      "69: learn: 0.2308348\ttest: 0.2300289\tbestTest: 0.2300289 (69)\ttotal: 5m 57s\tremaining: 2m 33s\n",
      "70: learn: 0.2305578\ttest: 0.2297491\tbestTest: 0.2297491 (70)\ttotal: 6m 2s\tremaining: 2m 28s\n",
      "71: learn: 0.2302856\ttest: 0.2294741\tbestTest: 0.2294741 (71)\ttotal: 6m 7s\tremaining: 2m 22s\n",
      "72: learn: 0.2300408\ttest: 0.2292216\tbestTest: 0.2292216 (72)\ttotal: 6m 12s\tremaining: 2m 17s\n",
      "73: learn: 0.229839\ttest: 0.2290173\tbestTest: 0.2290173 (73)\ttotal: 6m 18s\tremaining: 2m 13s\n",
      "74: learn: 0.2296248\ttest: 0.2288021\tbestTest: 0.2288021 (74)\ttotal: 6m 23s\tremaining: 2m 7s\n",
      "75: learn: 0.2293954\ttest: 0.2285632\tbestTest: 0.2285632 (75)\ttotal: 6m 28s\tremaining: 2m 2s\n",
      "76: learn: 0.229189\ttest: 0.2283587\tbestTest: 0.2283587 (76)\ttotal: 6m 34s\tremaining: 1m 57s\n",
      "77: learn: 0.2289787\ttest: 0.2281452\tbestTest: 0.2281452 (77)\ttotal: 6m 39s\tremaining: 1m 52s\n",
      "78: learn: 0.2287764\ttest: 0.2279398\tbestTest: 0.2279398 (78)\ttotal: 6m 44s\tremaining: 1m 47s\n",
      "79: learn: 0.2285912\ttest: 0.2277515\tbestTest: 0.2277515 (79)\ttotal: 6m 48s\tremaining: 1m 42s\n",
      "80: learn: 0.2284377\ttest: 0.2275962\tbestTest: 0.2275962 (80)\ttotal: 6m 53s\tremaining: 1m 37s\n",
      "81: learn: 0.2282792\ttest: 0.2274359\tbestTest: 0.2274359 (81)\ttotal: 6m 58s\tremaining: 1m 31s\n",
      "82: learn: 0.2281145\ttest: 0.2272701\tbestTest: 0.2272701 (82)\ttotal: 7m 3s\tremaining: 1m 26s\n",
      "83: learn: 0.2279581\ttest: 0.227112\tbestTest: 0.227112 (83)\ttotal: 7m 8s\tremaining: 1m 21s\n",
      "84: learn: 0.2278126\ttest: 0.2269633\tbestTest: 0.2269633 (84)\ttotal: 7m 13s\tremaining: 1m 16s\n",
      "85: learn: 0.2276841\ttest: 0.2268331\tbestTest: 0.2268331 (85)\ttotal: 7m 19s\tremaining: 1m 11s\n",
      "86: learn: 0.2275746\ttest: 0.2267218\tbestTest: 0.2267218 (86)\ttotal: 7m 24s\tremaining: 1m 6s\n",
      "87: learn: 0.2274683\ttest: 0.2266145\tbestTest: 0.2266145 (87)\ttotal: 7m 29s\tremaining: 1m 1s\n",
      "88: learn: 0.2273445\ttest: 0.226489\tbestTest: 0.226489 (88)\ttotal: 7m 34s\tremaining: 56.2s\n",
      "89: learn: 0.2272246\ttest: 0.226368\tbestTest: 0.226368 (89)\ttotal: 7m 39s\tremaining: 51s\n",
      "90: learn: 0.227121\ttest: 0.2262628\tbestTest: 0.2262628 (90)\ttotal: 7m 44s\tremaining: 46s\n",
      "91: learn: 0.227028\ttest: 0.2261672\tbestTest: 0.2261672 (91)\ttotal: 7m 49s\tremaining: 40.8s\n",
      "92: learn: 0.2269289\ttest: 0.2260669\tbestTest: 0.2260669 (92)\ttotal: 7m 54s\tremaining: 35.7s\n",
      "93: learn: 0.2268359\ttest: 0.2259717\tbestTest: 0.2259717 (93)\ttotal: 7m 59s\tremaining: 30.6s\n",
      "94: learn: 0.2267372\ttest: 0.2258724\tbestTest: 0.2258724 (94)\ttotal: 8m 4s\tremaining: 25.5s\n",
      "95: learn: 0.2266455\ttest: 0.225779\tbestTest: 0.225779 (95)\ttotal: 8m 9s\tremaining: 20.4s\n",
      "96: learn: 0.2265509\ttest: 0.2256863\tbestTest: 0.2256863 (96)\ttotal: 8m 14s\tremaining: 15.3s\n",
      "97: learn: 0.226457\ttest: 0.2255916\tbestTest: 0.2255916 (97)\ttotal: 8m 20s\tremaining: 10.2s\n",
      "98: learn: 0.2263856\ttest: 0.2255194\tbestTest: 0.2255194 (98)\ttotal: 8m 25s\tremaining: 5.1s\n",
      "99: learn: 0.2263005\ttest: 0.2254322\tbestTest: 0.2254322 (99)\ttotal: 8m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254322373\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.9_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 04:16:50.886635\n",
      "train time given below\n",
      "0:11:57.069399\n",
      "2018-03-14 04:16:50.998099\n",
      "2018-03-14 04:16:51.002179\n",
      "GINI ISIT = 0.456421724291\n",
      "2018-03-14 04:18:21.980285\n",
      "GINI OSIT = 0.45767858701\n",
      "2018-03-14 04:19:00.305351\n",
      "GINI OSOT = 0.409276015588\n",
      "2018-03-14 04:19:12.063495\n",
      "2018-03-14 04:19:12.065483\n",
      "rsm = 1\n",
      "2018-03-14 04:19:12.066845\n",
      "model train start\n",
      "2018-03-14 04:19:12.067139\n",
      "0: learn: 0.6579359\ttest: 0.6579092\tbestTest: 0.6579092 (0)\ttotal: 5.59s\tremaining: 9m 13s\n",
      "1: learn: 0.624899\ttest: 0.624848\tbestTest: 0.624848 (1)\ttotal: 12.4s\tremaining: 10m 5s\n",
      "2: learn: 0.5950034\ttest: 0.5949273\tbestTest: 0.5949273 (2)\ttotal: 18.1s\tremaining: 9m 45s\n",
      "3: learn: 0.5670981\ttest: 0.5670047\tbestTest: 0.5670047 (3)\ttotal: 24.3s\tremaining: 9m 43s\n",
      "4: learn: 0.5420128\ttest: 0.5419054\tbestTest: 0.5419054 (4)\ttotal: 29.3s\tremaining: 9m 17s\n",
      "5: learn: 0.5178153\ttest: 0.5176891\tbestTest: 0.5176891 (5)\ttotal: 34.6s\tremaining: 9m 2s\n",
      "6: learn: 0.4960914\ttest: 0.495943\tbestTest: 0.495943 (6)\ttotal: 40.4s\tremaining: 8m 56s\n",
      "7: learn: 0.4755843\ttest: 0.4754047\tbestTest: 0.4754047 (7)\ttotal: 45.5s\tremaining: 8m 43s\n",
      "8: learn: 0.4576218\ttest: 0.4574191\tbestTest: 0.4574191 (8)\ttotal: 51.1s\tremaining: 8m 36s\n",
      "9: learn: 0.4407079\ttest: 0.440484\tbestTest: 0.440484 (9)\ttotal: 57.4s\tremaining: 8m 36s\n",
      "10: learn: 0.4249302\ttest: 0.4246871\tbestTest: 0.4246871 (10)\ttotal: 1m 2s\tremaining: 8m 26s\n",
      "11: learn: 0.4106045\ttest: 0.4103454\tbestTest: 0.4103454 (11)\ttotal: 1m 7s\tremaining: 8m 17s\n",
      "12: learn: 0.3974\ttest: 0.3971215\tbestTest: 0.3971215 (12)\ttotal: 1m 13s\tremaining: 8m 12s\n",
      "13: learn: 0.3848198\ttest: 0.3845182\tbestTest: 0.3845182 (13)\ttotal: 1m 18s\tremaining: 8m 5s\n",
      "14: learn: 0.3732353\ttest: 0.3729541\tbestTest: 0.3729541 (14)\ttotal: 1m 24s\tremaining: 7m 57s\n",
      "15: learn: 0.3627998\ttest: 0.3624976\tbestTest: 0.3624976 (15)\ttotal: 1m 29s\tremaining: 7m 50s\n",
      "16: learn: 0.3536091\ttest: 0.3532901\tbestTest: 0.3532901 (16)\ttotal: 1m 35s\tremaining: 7m 46s\n",
      "17: learn: 0.3450204\ttest: 0.3446879\tbestTest: 0.3446879 (17)\ttotal: 1m 41s\tremaining: 7m 42s\n",
      "18: learn: 0.3368413\ttest: 0.3364927\tbestTest: 0.3364927 (18)\ttotal: 1m 46s\tremaining: 7m 35s\n",
      "19: learn: 0.3299815\ttest: 0.3296151\tbestTest: 0.3296151 (19)\ttotal: 1m 48s\tremaining: 7m 12s\n",
      "20: learn: 0.3229986\ttest: 0.3226159\tbestTest: 0.3226159 (20)\ttotal: 1m 53s\tremaining: 7m 8s\n",
      "21: learn: 0.3163858\ttest: 0.3159979\tbestTest: 0.3159979 (21)\ttotal: 1m 59s\tremaining: 7m 3s\n",
      "22: learn: 0.3101483\ttest: 0.3097391\tbestTest: 0.3097391 (22)\ttotal: 2m 4s\tremaining: 6m 57s\n",
      "23: learn: 0.3044584\ttest: 0.3040412\tbestTest: 0.3040412 (23)\ttotal: 2m 9s\tremaining: 6m 51s\n",
      "24: learn: 0.299203\ttest: 0.2987651\tbestTest: 0.2987651 (24)\ttotal: 2m 14s\tremaining: 6m 44s\n",
      "25: learn: 0.2945475\ttest: 0.2940914\tbestTest: 0.2940914 (25)\ttotal: 2m 20s\tremaining: 6m 39s\n",
      "26: learn: 0.2899007\ttest: 0.2894277\tbestTest: 0.2894277 (26)\ttotal: 2m 25s\tremaining: 6m 34s\n",
      "27: learn: 0.2858475\ttest: 0.2853619\tbestTest: 0.2853619 (27)\ttotal: 2m 30s\tremaining: 6m 27s\n",
      "28: learn: 0.2820945\ttest: 0.2815949\tbestTest: 0.2815949 (28)\ttotal: 2m 36s\tremaining: 6m 23s\n",
      "29: learn: 0.2785602\ttest: 0.2780493\tbestTest: 0.2780493 (29)\ttotal: 2m 42s\tremaining: 6m 19s\n",
      "30: learn: 0.2751875\ttest: 0.2746614\tbestTest: 0.2746614 (30)\ttotal: 2m 48s\tremaining: 6m 13s\n",
      "31: learn: 0.2720585\ttest: 0.2715165\tbestTest: 0.2715165 (31)\ttotal: 2m 53s\tremaining: 6m 8s\n",
      "32: learn: 0.269241\ttest: 0.2686836\tbestTest: 0.2686836 (32)\ttotal: 2m 58s\tremaining: 6m 2s\n",
      "33: learn: 0.2664896\ttest: 0.2659234\tbestTest: 0.2659234 (33)\ttotal: 3m 4s\tremaining: 5m 58s\n",
      "34: learn: 0.2639268\ttest: 0.2633465\tbestTest: 0.2633465 (34)\ttotal: 3m 9s\tremaining: 5m 52s\n",
      "35: learn: 0.2617196\ttest: 0.2611286\tbestTest: 0.2611286 (35)\ttotal: 3m 15s\tremaining: 5m 47s\n",
      "36: learn: 0.2596207\ttest: 0.2590196\tbestTest: 0.2590196 (36)\ttotal: 3m 20s\tremaining: 5m 41s\n",
      "37: learn: 0.2576167\ttest: 0.2570048\tbestTest: 0.2570048 (37)\ttotal: 3m 26s\tremaining: 5m 36s\n",
      "38: learn: 0.2558583\ttest: 0.2552354\tbestTest: 0.2552354 (38)\ttotal: 3m 31s\tremaining: 5m 31s\n",
      "39: learn: 0.2540025\ttest: 0.2533718\tbestTest: 0.2533718 (39)\ttotal: 3m 37s\tremaining: 5m 26s\n",
      "40: learn: 0.2522446\ttest: 0.2516049\tbestTest: 0.2516049 (40)\ttotal: 3m 42s\tremaining: 5m 20s\n",
      "41: learn: 0.2507126\ttest: 0.2500657\tbestTest: 0.2500657 (41)\ttotal: 3m 48s\tremaining: 5m 15s\n",
      "42: learn: 0.2492274\ttest: 0.2485744\tbestTest: 0.2485744 (42)\ttotal: 3m 54s\tremaining: 5m 11s\n",
      "43: learn: 0.2478402\ttest: 0.2471786\tbestTest: 0.2471786 (43)\ttotal: 4m\tremaining: 5m 5s\n",
      "44: learn: 0.2465939\ttest: 0.2459262\tbestTest: 0.2459262 (44)\ttotal: 4m 5s\tremaining: 5m\n",
      "45: learn: 0.2453199\ttest: 0.2446424\tbestTest: 0.2446424 (45)\ttotal: 4m 11s\tremaining: 4m 54s\n",
      "46: learn: 0.2442374\ttest: 0.2435539\tbestTest: 0.2435539 (46)\ttotal: 4m 17s\tremaining: 4m 49s\n",
      "47: learn: 0.2431476\ttest: 0.2424553\tbestTest: 0.2424553 (47)\ttotal: 4m 22s\tremaining: 4m 44s\n",
      "48: learn: 0.2422106\ttest: 0.241513\tbestTest: 0.241513 (48)\ttotal: 4m 27s\tremaining: 4m 38s\n",
      "49: learn: 0.2412777\ttest: 0.2405711\tbestTest: 0.2405711 (49)\ttotal: 4m 32s\tremaining: 4m 32s\n",
      "50: learn: 0.2404054\ttest: 0.2396922\tbestTest: 0.2396922 (50)\ttotal: 4m 37s\tremaining: 4m 26s\n",
      "51: learn: 0.2396035\ttest: 0.2388807\tbestTest: 0.2388807 (51)\ttotal: 4m 42s\tremaining: 4m 21s\n",
      "52: learn: 0.2388421\ttest: 0.238102\tbestTest: 0.238102 (52)\ttotal: 4m 48s\tremaining: 4m 15s\n",
      "53: learn: 0.2381679\ttest: 0.237426\tbestTest: 0.237426 (53)\ttotal: 4m 54s\tremaining: 4m 10s\n",
      "54: learn: 0.2375314\ttest: 0.2367855\tbestTest: 0.2367855 (54)\ttotal: 4m 59s\tremaining: 4m 5s\n",
      "55: learn: 0.2369017\ttest: 0.2361515\tbestTest: 0.2361515 (55)\ttotal: 5m 5s\tremaining: 3m 59s\n",
      "56: learn: 0.2362995\ttest: 0.2355464\tbestTest: 0.2355464 (56)\ttotal: 5m 10s\tremaining: 3m 54s\n",
      "57: learn: 0.2357192\ttest: 0.2349628\tbestTest: 0.2349628 (57)\ttotal: 5m 15s\tremaining: 3m 48s\n",
      "58: learn: 0.2351568\ttest: 0.234393\tbestTest: 0.234393 (58)\ttotal: 5m 20s\tremaining: 3m 42s\n",
      "59: learn: 0.2346892\ttest: 0.2339218\tbestTest: 0.2339218 (59)\ttotal: 5m 26s\tremaining: 3m 37s\n",
      "60: learn: 0.2342109\ttest: 0.2334398\tbestTest: 0.2334398 (60)\ttotal: 5m 31s\tremaining: 3m 32s\n",
      "61: learn: 0.2337846\ttest: 0.2330079\tbestTest: 0.2330079 (61)\ttotal: 5m 37s\tremaining: 3m 26s\n",
      "62: learn: 0.2333499\ttest: 0.2325669\tbestTest: 0.2325669 (62)\ttotal: 5m 43s\tremaining: 3m 21s\n",
      "63: learn: 0.2329711\ttest: 0.2321826\tbestTest: 0.2321826 (63)\ttotal: 5m 49s\tremaining: 3m 16s\n",
      "64: learn: 0.2325808\ttest: 0.2317879\tbestTest: 0.2317879 (64)\ttotal: 5m 54s\tremaining: 3m 10s\n",
      "65: learn: 0.2322154\ttest: 0.231417\tbestTest: 0.231417 (65)\ttotal: 5m 59s\tremaining: 3m 5s\n",
      "66: learn: 0.231851\ttest: 0.2310475\tbestTest: 0.2310475 (66)\ttotal: 6m 5s\tremaining: 2m 59s\n",
      "67: learn: 0.231571\ttest: 0.2307639\tbestTest: 0.2307639 (67)\ttotal: 6m 11s\tremaining: 2m 54s\n",
      "68: learn: 0.2312536\ttest: 0.230443\tbestTest: 0.230443 (68)\ttotal: 6m 16s\tremaining: 2m 49s\n",
      "69: learn: 0.2309617\ttest: 0.230146\tbestTest: 0.230146 (69)\ttotal: 6m 21s\tremaining: 2m 43s\n",
      "70: learn: 0.2306804\ttest: 0.2298643\tbestTest: 0.2298643 (70)\ttotal: 6m 27s\tremaining: 2m 38s\n",
      "71: learn: 0.2304155\ttest: 0.2295959\tbestTest: 0.2295959 (71)\ttotal: 6m 32s\tremaining: 2m 32s\n",
      "72: learn: 0.2301868\ttest: 0.2293642\tbestTest: 0.2293642 (72)\ttotal: 6m 38s\tremaining: 2m 27s\n",
      "73: learn: 0.2299484\ttest: 0.2291239\tbestTest: 0.2291239 (73)\ttotal: 6m 43s\tremaining: 2m 21s\n",
      "74: learn: 0.2297041\ttest: 0.2288767\tbestTest: 0.2288767 (74)\ttotal: 6m 49s\tremaining: 2m 16s\n",
      "75: learn: 0.2295014\ttest: 0.2286674\tbestTest: 0.2286674 (75)\ttotal: 6m 55s\tremaining: 2m 11s\n",
      "76: learn: 0.2292903\ttest: 0.2284539\tbestTest: 0.2284539 (76)\ttotal: 7m\tremaining: 2m 5s\n",
      "77: learn: 0.2291047\ttest: 0.2282658\tbestTest: 0.2282658 (77)\ttotal: 7m 6s\tremaining: 2m\n",
      "78: learn: 0.2289199\ttest: 0.22808\tbestTest: 0.22808 (78)\ttotal: 7m 11s\tremaining: 1m 54s\n",
      "79: learn: 0.2287286\ttest: 0.2278871\tbestTest: 0.2278871 (79)\ttotal: 7m 16s\tremaining: 1m 49s\n",
      "80: learn: 0.2285607\ttest: 0.2277171\tbestTest: 0.2277171 (80)\ttotal: 7m 21s\tremaining: 1m 43s\n",
      "81: learn: 0.2284021\ttest: 0.2275566\tbestTest: 0.2275566 (81)\ttotal: 7m 27s\tremaining: 1m 38s\n",
      "82: learn: 0.2282403\ttest: 0.2273916\tbestTest: 0.2273916 (82)\ttotal: 7m 32s\tremaining: 1m 32s\n",
      "83: learn: 0.2281045\ttest: 0.2272548\tbestTest: 0.2272548 (83)\ttotal: 7m 38s\tremaining: 1m 27s\n",
      "84: learn: 0.2279637\ttest: 0.2271128\tbestTest: 0.2271128 (84)\ttotal: 7m 44s\tremaining: 1m 21s\n",
      "85: learn: 0.2278316\ttest: 0.2269778\tbestTest: 0.2269778 (85)\ttotal: 7m 49s\tremaining: 1m 16s\n",
      "86: learn: 0.2276897\ttest: 0.2268349\tbestTest: 0.2268349 (86)\ttotal: 7m 54s\tremaining: 1m 10s\n",
      "87: learn: 0.2275461\ttest: 0.2266905\tbestTest: 0.2266905 (87)\ttotal: 8m\tremaining: 1m 5s\n",
      "88: learn: 0.2274098\ttest: 0.2265529\tbestTest: 0.2265529 (88)\ttotal: 8m 6s\tremaining: 1m\n",
      "89: learn: 0.2272851\ttest: 0.2264272\tbestTest: 0.2264272 (89)\ttotal: 8m 11s\tremaining: 54.6s\n",
      "90: learn: 0.227148\ttest: 0.2262905\tbestTest: 0.2262905 (90)\ttotal: 8m 17s\tremaining: 49.2s\n",
      "91: learn: 0.2270497\ttest: 0.22619\tbestTest: 0.22619 (91)\ttotal: 8m 22s\tremaining: 43.7s\n",
      "92: learn: 0.2269441\ttest: 0.2260816\tbestTest: 0.2260816 (92)\ttotal: 8m 28s\tremaining: 38.3s\n",
      "93: learn: 0.2268528\ttest: 0.2259877\tbestTest: 0.2259877 (93)\ttotal: 8m 33s\tremaining: 32.8s\n",
      "94: learn: 0.2267555\ttest: 0.2258904\tbestTest: 0.2258904 (94)\ttotal: 8m 38s\tremaining: 27.3s\n",
      "95: learn: 0.2266565\ttest: 0.2257885\tbestTest: 0.2257885 (95)\ttotal: 8m 44s\tremaining: 21.8s\n",
      "96: learn: 0.226566\ttest: 0.2256963\tbestTest: 0.2256963 (96)\ttotal: 8m 49s\tremaining: 16.4s\n",
      "97: learn: 0.2264897\ttest: 0.2256193\tbestTest: 0.2256193 (97)\ttotal: 8m 54s\tremaining: 10.9s\n",
      "98: learn: 0.2264173\ttest: 0.2255461\tbestTest: 0.2255461 (98)\ttotal: 9m\tremaining: 5.46s\n",
      "99: learn: 0.2263146\ttest: 0.2254435\tbestTest: 0.2254435 (99)\ttotal: 9m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2254435069\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_1_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 04:31:31.308512\n",
      "train time given below\n",
      "0:12:19.241373\n",
      "2018-03-14 04:31:31.309106\n",
      "2018-03-14 04:31:31.312625\n",
      "GINI ISIT = 0.456057466662\n",
      "2018-03-14 04:34:06.307295\n",
      "GINI OSIT = 0.457324649713\n",
      "2018-03-14 04:35:20.495386\n",
      "GINI OSOT = 0.411554144757\n",
      "2018-03-14 04:35:43.891112\n",
      "2018-03-14 04:35:43.894078\n"
     ]
    }
   ],
   "source": [
    "#optimize rsm\n",
    "\n",
    "for rsm in rsm_pv:\n",
    "    \n",
    "    print('rsm = ' + str(rsm))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm,\n",
    "                           lrn_rt = lrn_rt_def,\n",
    "                           dep = dep_def,\n",
    "                           l2_reg = l2_reg_opt,\n",
    "                           num_split = num_split_opt,\n",
    "                           cat_split = cat_split_opt,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt_def\n",
    "    result_df_temp.loc[0,'depth'] = dep_def\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_opt\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_opt\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_opt\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451849</td>\n",
       "      <td>0.453623</td>\n",
       "      <td>0.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.45484</td>\n",
       "      <td>0.407005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>0.405824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45513</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454684</td>\n",
       "      <td>0.456024</td>\n",
       "      <td>0.408098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455045</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.40867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45336</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.408261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454922</td>\n",
       "      <td>0.456109</td>\n",
       "      <td>0.410751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456208</td>\n",
       "      <td>0.457545</td>\n",
       "      <td>0.41235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454801</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>0.411622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45617</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.411126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.409276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree   rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100     1          0.03     6                 1             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 5             128   \n",
       "0    100     1          0.03     6                10             128   \n",
       "0    100     1          0.03     6                50             128   \n",
       "0    100     1          0.03     6               100             128   \n",
       "0    100     1          0.03     6                 3               5   \n",
       "0    100     1          0.03     6                 3              10   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              32   \n",
       "0    100     1          0.03     6                 3              64   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             255   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100   0.5          0.03     6                 3              16   \n",
       "0    100   0.6          0.03     6                 3              16   \n",
       "0    100   0.7          0.03     6                 3              16   \n",
       "0    100  0.75          0.03     6                 3              16   \n",
       "0    100   0.8          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100   0.9          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  \n",
       "0                 5                   1  0.451849  0.453623  0.402904  \n",
       "0                10                   1  0.453604   0.45484  0.407005  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                32                   1  0.453115  0.454388  0.405824  \n",
       "0                64                   1   0.45513  0.456311  0.409631  \n",
       "0               128                   1  0.454684  0.456024  0.408098  \n",
       "0               255                   1  0.455045  0.456244   0.40867  \n",
       "0                16                   1   0.45336  0.454692  0.408261  \n",
       "0                16                   1  0.454922  0.456109  0.410751  \n",
       "0                16                   1  0.456208  0.457545   0.41235  \n",
       "0                16                   1  0.454801  0.456263  0.411622  \n",
       "0                16                   1   0.45617  0.457539  0.411126  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.456422  0.457679  0.409276  \n",
       "0                16                   1  0.456057  0.457325  0.411554  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsm_opt = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 4\n",
      "2018-03-14 19:49:17.751723\n",
      "model train start\n",
      "2018-03-14 19:49:17.752032\n",
      "0: learn: 0.6576823\ttest: 0.6576681\tbestTest: 0.6576681 (0)\ttotal: 4s\tremaining: 6m 36s\n",
      "1: learn: 0.6258327\ttest: 0.6257934\tbestTest: 0.6257934 (1)\ttotal: 5.8s\tremaining: 4m 44s\n",
      "2: learn: 0.5950844\ttest: 0.5950194\tbestTest: 0.5950194 (2)\ttotal: 9.34s\tremaining: 5m 1s\n",
      "3: learn: 0.5676072\ttest: 0.5675085\tbestTest: 0.5675085 (3)\ttotal: 12.8s\tremaining: 5m 7s\n",
      "4: learn: 0.5421193\ttest: 0.5420098\tbestTest: 0.5420098 (4)\ttotal: 16.3s\tremaining: 5m 9s\n",
      "5: learn: 0.5182641\ttest: 0.5181224\tbestTest: 0.5181224 (5)\ttotal: 20.1s\tremaining: 5m 14s\n",
      "6: learn: 0.4964392\ttest: 0.4962873\tbestTest: 0.4962873 (6)\ttotal: 23.5s\tremaining: 5m 12s\n",
      "7: learn: 0.4759728\ttest: 0.4757967\tbestTest: 0.4757967 (7)\ttotal: 26.9s\tremaining: 5m 8s\n",
      "8: learn: 0.4582327\ttest: 0.458041\tbestTest: 0.458041 (8)\ttotal: 30.8s\tremaining: 5m 11s\n",
      "9: learn: 0.4413273\ttest: 0.4411192\tbestTest: 0.4411192 (9)\ttotal: 34s\tremaining: 5m 6s\n",
      "10: learn: 0.4255398\ttest: 0.4253074\tbestTest: 0.4253074 (10)\ttotal: 37.4s\tremaining: 5m 2s\n",
      "11: learn: 0.4114988\ttest: 0.4112425\tbestTest: 0.4112425 (11)\ttotal: 40.7s\tremaining: 4m 58s\n",
      "12: learn: 0.3981317\ttest: 0.3978582\tbestTest: 0.3978582 (12)\ttotal: 44.5s\tremaining: 4m 58s\n",
      "13: learn: 0.3859297\ttest: 0.3856396\tbestTest: 0.3856396 (13)\ttotal: 47.6s\tremaining: 4m 52s\n",
      "14: learn: 0.3749709\ttest: 0.3746701\tbestTest: 0.3746701 (14)\ttotal: 51.1s\tremaining: 4m 49s\n",
      "15: learn: 0.3646259\ttest: 0.3643102\tbestTest: 0.3643102 (15)\ttotal: 54.4s\tremaining: 4m 45s\n",
      "16: learn: 0.3552288\ttest: 0.3548911\tbestTest: 0.3548911 (16)\ttotal: 58.1s\tremaining: 4m 43s\n",
      "17: learn: 0.3468347\ttest: 0.3464795\tbestTest: 0.3464795 (17)\ttotal: 1m 1s\tremaining: 4m 40s\n",
      "18: learn: 0.3385518\ttest: 0.3381803\tbestTest: 0.3381803 (18)\ttotal: 1m 4s\tremaining: 4m 36s\n",
      "19: learn: 0.3312288\ttest: 0.3308391\tbestTest: 0.3308391 (19)\ttotal: 1m 7s\tremaining: 4m 31s\n",
      "20: learn: 0.3241083\ttest: 0.3237005\tbestTest: 0.3237005 (20)\ttotal: 1m 11s\tremaining: 4m 28s\n",
      "21: learn: 0.3179498\ttest: 0.3175234\tbestTest: 0.3175234 (21)\ttotal: 1m 14s\tremaining: 4m 25s\n",
      "22: learn: 0.3118751\ttest: 0.3114329\tbestTest: 0.3114329 (22)\ttotal: 1m 18s\tremaining: 4m 21s\n",
      "23: learn: 0.3063122\ttest: 0.3058521\tbestTest: 0.3058521 (23)\ttotal: 1m 21s\tremaining: 4m 17s\n",
      "24: learn: 0.3010284\ttest: 0.300555\tbestTest: 0.300555 (24)\ttotal: 1m 24s\tremaining: 4m 14s\n",
      "25: learn: 0.2961949\ttest: 0.2957101\tbestTest: 0.2957101 (25)\ttotal: 1m 27s\tremaining: 4m 10s\n",
      "26: learn: 0.2919695\ttest: 0.2914691\tbestTest: 0.2914691 (26)\ttotal: 1m 31s\tremaining: 4m 6s\n",
      "27: learn: 0.2878151\ttest: 0.2872998\tbestTest: 0.2872998 (27)\ttotal: 1m 34s\tremaining: 4m 4s\n",
      "28: learn: 0.284132\ttest: 0.283604\tbestTest: 0.283604 (28)\ttotal: 1m 38s\tremaining: 4m\n",
      "29: learn: 0.2806401\ttest: 0.2800101\tbestTest: 0.2800101 (29)\ttotal: 1m 42s\tremaining: 3m 58s\n",
      "30: learn: 0.2771221\ttest: 0.2764793\tbestTest: 0.2764793 (30)\ttotal: 1m 45s\tremaining: 3m 55s\n",
      "31: learn: 0.2742137\ttest: 0.2735634\tbestTest: 0.2735634 (31)\ttotal: 1m 49s\tremaining: 3m 52s\n",
      "32: learn: 0.2713987\ttest: 0.2707414\tbestTest: 0.2707414 (32)\ttotal: 1m 53s\tremaining: 3m 49s\n",
      "33: learn: 0.2686041\ttest: 0.2679364\tbestTest: 0.2679364 (33)\ttotal: 1m 56s\tremaining: 3m 46s\n",
      "34: learn: 0.2659262\ttest: 0.2652494\tbestTest: 0.2652494 (34)\ttotal: 1m 59s\tremaining: 3m 42s\n",
      "35: learn: 0.2636724\ttest: 0.2629905\tbestTest: 0.2629905 (35)\ttotal: 2m 3s\tremaining: 3m 39s\n",
      "36: learn: 0.2614856\ttest: 0.2607953\tbestTest: 0.2607953 (36)\ttotal: 2m 6s\tremaining: 3m 35s\n",
      "37: learn: 0.2594121\ttest: 0.2587166\tbestTest: 0.2587166 (37)\ttotal: 2m 9s\tremaining: 3m 31s\n",
      "38: learn: 0.2574087\ttest: 0.2567071\tbestTest: 0.2567071 (38)\ttotal: 2m 13s\tremaining: 3m 28s\n",
      "39: learn: 0.2557943\ttest: 0.255083\tbestTest: 0.255083 (39)\ttotal: 2m 16s\tremaining: 3m 24s\n",
      "40: learn: 0.2540565\ttest: 0.2533374\tbestTest: 0.2533374 (40)\ttotal: 2m 19s\tremaining: 3m 21s\n",
      "41: learn: 0.2524587\ttest: 0.2517323\tbestTest: 0.2517323 (41)\ttotal: 2m 23s\tremaining: 3m 18s\n",
      "42: learn: 0.2510053\ttest: 0.2502703\tbestTest: 0.2502703 (42)\ttotal: 2m 26s\tremaining: 3m 14s\n",
      "43: learn: 0.2496188\ttest: 0.2488802\tbestTest: 0.2488802 (43)\ttotal: 2m 30s\tremaining: 3m 11s\n",
      "44: learn: 0.2484775\ttest: 0.2477315\tbestTest: 0.2477315 (44)\ttotal: 2m 33s\tremaining: 3m 8s\n",
      "45: learn: 0.2472498\ttest: 0.2464954\tbestTest: 0.2464954 (45)\ttotal: 2m 37s\tremaining: 3m 4s\n",
      "46: learn: 0.246232\ttest: 0.2454748\tbestTest: 0.2454748 (46)\ttotal: 2m 40s\tremaining: 3m 1s\n",
      "47: learn: 0.2451278\ttest: 0.2443622\tbestTest: 0.2443622 (47)\ttotal: 2m 44s\tremaining: 2m 57s\n",
      "48: learn: 0.2441871\ttest: 0.2434157\tbestTest: 0.2434157 (48)\ttotal: 2m 47s\tremaining: 2m 54s\n",
      "49: learn: 0.2433698\ttest: 0.2425965\tbestTest: 0.2425965 (49)\ttotal: 2m 50s\tremaining: 2m 50s\n",
      "50: learn: 0.2424613\ttest: 0.2416807\tbestTest: 0.2416807 (50)\ttotal: 2m 54s\tremaining: 2m 47s\n",
      "51: learn: 0.2416049\ttest: 0.2408166\tbestTest: 0.2408166 (51)\ttotal: 2m 57s\tremaining: 2m 43s\n",
      "52: learn: 0.2408307\ttest: 0.2400376\tbestTest: 0.2400376 (52)\ttotal: 3m\tremaining: 2m 40s\n",
      "53: learn: 0.2401433\ttest: 0.2393439\tbestTest: 0.2393439 (53)\ttotal: 3m 3s\tremaining: 2m 36s\n",
      "54: learn: 0.2394535\ttest: 0.238652\tbestTest: 0.238652 (54)\ttotal: 3m 7s\tremaining: 2m 33s\n",
      "55: learn: 0.2388856\ttest: 0.2380797\tbestTest: 0.2380797 (55)\ttotal: 3m 11s\tremaining: 2m 30s\n",
      "56: learn: 0.238317\ttest: 0.2375095\tbestTest: 0.2375095 (56)\ttotal: 3m 15s\tremaining: 2m 27s\n",
      "57: learn: 0.2377669\ttest: 0.2369546\tbestTest: 0.2369546 (57)\ttotal: 3m 18s\tremaining: 2m 23s\n",
      "58: learn: 0.2372557\ttest: 0.2364394\tbestTest: 0.2364394 (58)\ttotal: 3m 21s\tremaining: 2m 20s\n",
      "59: learn: 0.2367152\ttest: 0.2358928\tbestTest: 0.2358928 (59)\ttotal: 3m 25s\tremaining: 2m 16s\n",
      "60: learn: 0.236227\ttest: 0.2353993\tbestTest: 0.2353993 (60)\ttotal: 3m 28s\tremaining: 2m 13s\n",
      "61: learn: 0.2357466\ttest: 0.2349129\tbestTest: 0.2349129 (61)\ttotal: 3m 32s\tremaining: 2m 9s\n",
      "62: learn: 0.2353611\ttest: 0.2345152\tbestTest: 0.2345152 (62)\ttotal: 3m 35s\tremaining: 2m 6s\n",
      "63: learn: 0.2349284\ttest: 0.2340788\tbestTest: 0.2340788 (63)\ttotal: 3m 39s\tremaining: 2m 3s\n",
      "64: learn: 0.2345238\ttest: 0.2336711\tbestTest: 0.2336711 (64)\ttotal: 3m 42s\tremaining: 1m 59s\n",
      "65: learn: 0.2341604\ttest: 0.2333046\tbestTest: 0.2333046 (65)\ttotal: 3m 45s\tremaining: 1m 56s\n",
      "66: learn: 0.2338604\ttest: 0.2330001\tbestTest: 0.2330001 (66)\ttotal: 3m 49s\tremaining: 1m 52s\n",
      "67: learn: 0.2335543\ttest: 0.2326912\tbestTest: 0.2326912 (67)\ttotal: 3m 52s\tremaining: 1m 49s\n",
      "68: learn: 0.2333072\ttest: 0.2324413\tbestTest: 0.2324413 (68)\ttotal: 3m 56s\tremaining: 1m 46s\n",
      "69: learn: 0.2330014\ttest: 0.2321322\tbestTest: 0.2321322 (69)\ttotal: 3m 59s\tremaining: 1m 42s\n",
      "70: learn: 0.2327123\ttest: 0.2318433\tbestTest: 0.2318433 (70)\ttotal: 4m 3s\tremaining: 1m 39s\n",
      "71: learn: 0.2324667\ttest: 0.2315943\tbestTest: 0.2315943 (71)\ttotal: 4m 6s\tremaining: 1m 36s\n",
      "72: learn: 0.2322448\ttest: 0.2313719\tbestTest: 0.2313719 (72)\ttotal: 4m 10s\tremaining: 1m 32s\n",
      "73: learn: 0.2319929\ttest: 0.2311176\tbestTest: 0.2311176 (73)\ttotal: 4m 13s\tremaining: 1m 29s\n",
      "74: learn: 0.231769\ttest: 0.2308918\tbestTest: 0.2308918 (74)\ttotal: 4m 16s\tremaining: 1m 25s\n",
      "75: learn: 0.2315276\ttest: 0.2306459\tbestTest: 0.2306459 (75)\ttotal: 4m 20s\tremaining: 1m 22s\n",
      "76: learn: 0.2313247\ttest: 0.2304404\tbestTest: 0.2304404 (76)\ttotal: 4m 23s\tremaining: 1m 18s\n",
      "77: learn: 0.2311385\ttest: 0.2302523\tbestTest: 0.2302523 (77)\ttotal: 4m 27s\tremaining: 1m 15s\n",
      "78: learn: 0.2309348\ttest: 0.2300453\tbestTest: 0.2300453 (78)\ttotal: 4m 30s\tremaining: 1m 11s\n",
      "79: learn: 0.2307393\ttest: 0.2298493\tbestTest: 0.2298493 (79)\ttotal: 4m 33s\tremaining: 1m 8s\n",
      "80: learn: 0.230576\ttest: 0.229683\tbestTest: 0.229683 (80)\ttotal: 4m 36s\tremaining: 1m 4s\n",
      "81: learn: 0.2304176\ttest: 0.2295231\tbestTest: 0.2295231 (81)\ttotal: 4m 40s\tremaining: 1m 1s\n",
      "82: learn: 0.2302821\ttest: 0.2293851\tbestTest: 0.2293851 (82)\ttotal: 4m 43s\tremaining: 58.1s\n",
      "83: learn: 0.2301326\ttest: 0.2292341\tbestTest: 0.2292341 (83)\ttotal: 4m 46s\tremaining: 54.6s\n",
      "84: learn: 0.2299969\ttest: 0.2290975\tbestTest: 0.2290975 (84)\ttotal: 4m 50s\tremaining: 51.3s\n",
      "85: learn: 0.2298524\ttest: 0.2289512\tbestTest: 0.2289512 (85)\ttotal: 4m 53s\tremaining: 47.8s\n",
      "86: learn: 0.2297019\ttest: 0.2288\tbestTest: 0.2288 (86)\ttotal: 4m 56s\tremaining: 44.4s\n",
      "87: learn: 0.2295688\ttest: 0.2286662\tbestTest: 0.2286662 (87)\ttotal: 5m\tremaining: 41s\n",
      "88: learn: 0.2294773\ttest: 0.2285736\tbestTest: 0.2285736 (88)\ttotal: 5m 4s\tremaining: 37.6s\n",
      "89: learn: 0.2293584\ttest: 0.2284532\tbestTest: 0.2284532 (89)\ttotal: 5m 7s\tremaining: 34.2s\n",
      "90: learn: 0.2292454\ttest: 0.2283367\tbestTest: 0.2283367 (90)\ttotal: 5m 11s\tremaining: 30.8s\n",
      "91: learn: 0.2291496\ttest: 0.2282369\tbestTest: 0.2282369 (91)\ttotal: 5m 14s\tremaining: 27.3s\n",
      "92: learn: 0.2290269\ttest: 0.2281129\tbestTest: 0.2281129 (92)\ttotal: 5m 17s\tremaining: 23.9s\n",
      "93: learn: 0.2289117\ttest: 0.2279965\tbestTest: 0.2279965 (93)\ttotal: 5m 21s\tremaining: 20.5s\n",
      "94: learn: 0.2288117\ttest: 0.2278958\tbestTest: 0.2278958 (94)\ttotal: 5m 24s\tremaining: 17.1s\n",
      "95: learn: 0.2287165\ttest: 0.2277988\tbestTest: 0.2277988 (95)\ttotal: 5m 27s\tremaining: 13.6s\n",
      "96: learn: 0.2286118\ttest: 0.2276912\tbestTest: 0.2276912 (96)\ttotal: 5m 30s\tremaining: 10.2s\n",
      "97: learn: 0.2285226\ttest: 0.2275994\tbestTest: 0.2275994 (97)\ttotal: 5m 33s\tremaining: 6.82s\n",
      "98: learn: 0.2284284\ttest: 0.2275026\tbestTest: 0.2275026 (98)\ttotal: 5m 37s\tremaining: 3.41s\n",
      "99: learn: 0.2283377\ttest: 0.2274118\tbestTest: 0.2274118 (99)\ttotal: 5m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2274117789\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_4_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 19:58:12.697608\n",
      "train time given below\n",
      "0:08:54.945576\n",
      "2018-03-14 19:58:12.716585\n",
      "2018-03-14 19:58:12.720062\n",
      "GINI ISIT = 0.441065576495\n",
      "2018-03-14 19:59:42.371722\n",
      "GINI OSIT = 0.442914625441\n",
      "2018-03-14 20:00:19.314716\n",
      "GINI OSOT = 0.396311797225\n",
      "2018-03-14 20:00:30.770820\n",
      "2018-03-14 20:00:30.772911\n",
      "depth = 5\n",
      "2018-03-14 20:00:30.774315\n",
      "model train start\n",
      "2018-03-14 20:00:30.774553\n",
      "0: learn: 0.6574441\ttest: 0.6574289\tbestTest: 0.6574289 (0)\ttotal: 4.6s\tremaining: 7m 35s\n",
      "1: learn: 0.6250767\ttest: 0.6250291\tbestTest: 0.6250291 (1)\ttotal: 9.17s\tremaining: 7m 29s\n",
      "2: learn: 0.5953179\ttest: 0.5953237\tbestTest: 0.5953237 (2)\ttotal: 13.6s\tremaining: 7m 21s\n",
      "3: learn: 0.5671675\ttest: 0.5671492\tbestTest: 0.5671492 (3)\ttotal: 17.8s\tremaining: 7m 6s\n",
      "4: learn: 0.5422131\ttest: 0.542164\tbestTest: 0.542164 (4)\ttotal: 22s\tremaining: 6m 57s\n",
      "5: learn: 0.5185973\ttest: 0.5185223\tbestTest: 0.5185223 (5)\ttotal: 26.3s\tremaining: 6m 52s\n",
      "6: learn: 0.4970443\ttest: 0.4969426\tbestTest: 0.4969426 (6)\ttotal: 31s\tremaining: 6m 51s\n",
      "7: learn: 0.4774069\ttest: 0.4772846\tbestTest: 0.4772846 (7)\ttotal: 33.5s\tremaining: 6m 25s\n",
      "8: learn: 0.458479\ttest: 0.4583274\tbestTest: 0.4583274 (8)\ttotal: 37.6s\tremaining: 6m 20s\n",
      "9: learn: 0.4414255\ttest: 0.4412487\tbestTest: 0.4412487 (9)\ttotal: 42.1s\tremaining: 6m 18s\n",
      "10: learn: 0.4252055\ttest: 0.4250033\tbestTest: 0.4250033 (10)\ttotal: 45.9s\tremaining: 6m 11s\n",
      "11: learn: 0.4112517\ttest: 0.41111\tbestTest: 0.41111 (11)\ttotal: 50.5s\tremaining: 6m 10s\n",
      "12: learn: 0.3976817\ttest: 0.3975241\tbestTest: 0.3975241 (12)\ttotal: 55s\tremaining: 6m 8s\n",
      "13: learn: 0.3852931\ttest: 0.3851098\tbestTest: 0.3851098 (13)\ttotal: 59.1s\tremaining: 6m 2s\n",
      "14: learn: 0.3742287\ttest: 0.374022\tbestTest: 0.374022 (14)\ttotal: 1m 3s\tremaining: 5m 58s\n",
      "15: learn: 0.3639485\ttest: 0.3637174\tbestTest: 0.3637174 (15)\ttotal: 1m 7s\tremaining: 5m 52s\n",
      "16: learn: 0.3542981\ttest: 0.3540558\tbestTest: 0.3540558 (16)\ttotal: 1m 11s\tremaining: 5m 50s\n",
      "17: learn: 0.3456153\ttest: 0.3453544\tbestTest: 0.3453544 (17)\ttotal: 1m 16s\tremaining: 5m 47s\n",
      "18: learn: 0.3375612\ttest: 0.3372795\tbestTest: 0.3372795 (18)\ttotal: 1m 20s\tremaining: 5m 42s\n",
      "19: learn: 0.3298108\ttest: 0.3295062\tbestTest: 0.3295062 (19)\ttotal: 1m 24s\tremaining: 5m 39s\n",
      "20: learn: 0.3228851\ttest: 0.3225593\tbestTest: 0.3225593 (20)\ttotal: 1m 28s\tremaining: 5m 34s\n",
      "21: learn: 0.3166136\ttest: 0.3162701\tbestTest: 0.3162701 (21)\ttotal: 1m 33s\tremaining: 5m 31s\n",
      "22: learn: 0.3105646\ttest: 0.3102026\tbestTest: 0.3102026 (22)\ttotal: 1m 37s\tremaining: 5m 26s\n",
      "23: learn: 0.3047619\ttest: 0.3043765\tbestTest: 0.3043765 (23)\ttotal: 1m 41s\tremaining: 5m 20s\n",
      "24: learn: 0.2996198\ttest: 0.2992157\tbestTest: 0.2992157 (24)\ttotal: 1m 45s\tremaining: 5m 15s\n",
      "25: learn: 0.294892\ttest: 0.294469\tbestTest: 0.294469 (25)\ttotal: 1m 49s\tremaining: 5m 12s\n",
      "26: learn: 0.2904844\ttest: 0.2900441\tbestTest: 0.2900441 (26)\ttotal: 1m 54s\tremaining: 5m 8s\n",
      "27: learn: 0.2863803\ttest: 0.28593\tbestTest: 0.28593 (27)\ttotal: 1m 58s\tremaining: 5m 4s\n",
      "28: learn: 0.2823766\ttest: 0.2819057\tbestTest: 0.2819057 (28)\ttotal: 2m 2s\tremaining: 4m 59s\n",
      "29: learn: 0.2786963\ttest: 0.2782069\tbestTest: 0.2782069 (29)\ttotal: 2m 6s\tremaining: 4m 54s\n",
      "30: learn: 0.2755491\ttest: 0.2750455\tbestTest: 0.2750455 (30)\ttotal: 2m 10s\tremaining: 4m 49s\n",
      "31: learn: 0.272353\ttest: 0.2718354\tbestTest: 0.2718354 (31)\ttotal: 2m 13s\tremaining: 4m 44s\n",
      "32: learn: 0.2696392\ttest: 0.2691084\tbestTest: 0.2691084 (32)\ttotal: 2m 18s\tremaining: 4m 40s\n",
      "33: learn: 0.2669034\ttest: 0.2663547\tbestTest: 0.2663547 (33)\ttotal: 2m 22s\tremaining: 4m 35s\n",
      "34: learn: 0.2644229\ttest: 0.263862\tbestTest: 0.263862 (34)\ttotal: 2m 26s\tremaining: 4m 31s\n",
      "35: learn: 0.2620121\ttest: 0.2614392\tbestTest: 0.2614392 (35)\ttotal: 2m 30s\tremaining: 4m 27s\n",
      "36: learn: 0.2600675\ttest: 0.259485\tbestTest: 0.259485 (36)\ttotal: 2m 35s\tremaining: 4m 25s\n",
      "37: learn: 0.2581899\ttest: 0.2575925\tbestTest: 0.2575925 (37)\ttotal: 2m 40s\tremaining: 4m 21s\n",
      "38: learn: 0.2563405\ttest: 0.2557358\tbestTest: 0.2557358 (38)\ttotal: 2m 44s\tremaining: 4m 17s\n",
      "39: learn: 0.2544948\ttest: 0.2538801\tbestTest: 0.2538801 (39)\ttotal: 2m 48s\tremaining: 4m 12s\n",
      "40: learn: 0.2528648\ttest: 0.2522372\tbestTest: 0.2522372 (40)\ttotal: 2m 52s\tremaining: 4m 7s\n",
      "41: learn: 0.2514248\ttest: 0.2507858\tbestTest: 0.2507858 (41)\ttotal: 2m 56s\tremaining: 4m 3s\n",
      "42: learn: 0.2501013\ttest: 0.2494328\tbestTest: 0.2494328 (42)\ttotal: 3m\tremaining: 3m 59s\n",
      "43: learn: 0.248655\ttest: 0.2479778\tbestTest: 0.2479778 (43)\ttotal: 3m 4s\tremaining: 3m 54s\n",
      "44: learn: 0.247328\ttest: 0.2466403\tbestTest: 0.2466403 (44)\ttotal: 3m 9s\tremaining: 3m 51s\n",
      "45: learn: 0.2461107\ttest: 0.2454086\tbestTest: 0.2454086 (45)\ttotal: 3m 13s\tremaining: 3m 47s\n",
      "46: learn: 0.2449826\ttest: 0.2442719\tbestTest: 0.2442719 (46)\ttotal: 3m 17s\tremaining: 3m 42s\n",
      "47: learn: 0.2440512\ttest: 0.2433325\tbestTest: 0.2433325 (47)\ttotal: 3m 21s\tremaining: 3m 38s\n",
      "48: learn: 0.2431139\ttest: 0.2423877\tbestTest: 0.2423877 (48)\ttotal: 3m 25s\tremaining: 3m 34s\n",
      "49: learn: 0.2421521\ttest: 0.2414159\tbestTest: 0.2414159 (49)\ttotal: 3m 29s\tremaining: 3m 29s\n",
      "50: learn: 0.2412625\ttest: 0.2405202\tbestTest: 0.2405202 (50)\ttotal: 3m 33s\tremaining: 3m 25s\n",
      "51: learn: 0.2404516\ttest: 0.2397044\tbestTest: 0.2397044 (51)\ttotal: 3m 37s\tremaining: 3m 20s\n",
      "52: learn: 0.2396918\ttest: 0.2389386\tbestTest: 0.2389386 (52)\ttotal: 3m 41s\tremaining: 3m 16s\n",
      "53: learn: 0.2389639\ttest: 0.2382054\tbestTest: 0.2382054 (53)\ttotal: 3m 45s\tremaining: 3m 12s\n",
      "54: learn: 0.2383169\ttest: 0.2375504\tbestTest: 0.2375504 (54)\ttotal: 3m 49s\tremaining: 3m 7s\n",
      "55: learn: 0.2376484\ttest: 0.2368755\tbestTest: 0.2368755 (55)\ttotal: 3m 53s\tremaining: 3m 3s\n",
      "56: learn: 0.2370975\ttest: 0.2363213\tbestTest: 0.2363213 (56)\ttotal: 3m 57s\tremaining: 2m 59s\n",
      "57: learn: 0.2365494\ttest: 0.2357673\tbestTest: 0.2357673 (57)\ttotal: 4m 1s\tremaining: 2m 55s\n",
      "58: learn: 0.2360256\ttest: 0.2352368\tbestTest: 0.2352368 (58)\ttotal: 4m 5s\tremaining: 2m 50s\n",
      "59: learn: 0.2355059\ttest: 0.2347147\tbestTest: 0.2347147 (59)\ttotal: 4m 10s\tremaining: 2m 46s\n",
      "60: learn: 0.2350886\ttest: 0.2342941\tbestTest: 0.2342941 (60)\ttotal: 4m 14s\tremaining: 2m 42s\n",
      "61: learn: 0.2346204\ttest: 0.2338188\tbestTest: 0.2338188 (61)\ttotal: 4m 18s\tremaining: 2m 38s\n",
      "62: learn: 0.2341764\ttest: 0.2333702\tbestTest: 0.2333702 (62)\ttotal: 4m 22s\tremaining: 2m 34s\n",
      "63: learn: 0.2337698\ttest: 0.2329458\tbestTest: 0.2329458 (63)\ttotal: 4m 26s\tremaining: 2m 30s\n",
      "64: learn: 0.2333955\ttest: 0.2325677\tbestTest: 0.2325677 (64)\ttotal: 4m 31s\tremaining: 2m 25s\n",
      "65: learn: 0.2330917\ttest: 0.2322606\tbestTest: 0.2322606 (65)\ttotal: 4m 35s\tremaining: 2m 21s\n",
      "66: learn: 0.232749\ttest: 0.2319141\tbestTest: 0.2319141 (66)\ttotal: 4m 39s\tremaining: 2m 17s\n",
      "67: learn: 0.2324278\ttest: 0.2315929\tbestTest: 0.2315929 (67)\ttotal: 4m 43s\tremaining: 2m 13s\n",
      "68: learn: 0.2321484\ttest: 0.2313086\tbestTest: 0.2313086 (68)\ttotal: 4m 48s\tremaining: 2m 9s\n",
      "69: learn: 0.2318619\ttest: 0.2310168\tbestTest: 0.2310168 (69)\ttotal: 4m 51s\tremaining: 2m 5s\n",
      "70: learn: 0.2315765\ttest: 0.2307287\tbestTest: 0.2307287 (70)\ttotal: 4m 55s\tremaining: 2m\n",
      "71: learn: 0.231296\ttest: 0.2304457\tbestTest: 0.2304457 (71)\ttotal: 4m 59s\tremaining: 1m 56s\n",
      "72: learn: 0.2310658\ttest: 0.2302108\tbestTest: 0.2302108 (72)\ttotal: 5m 3s\tremaining: 1m 52s\n",
      "73: learn: 0.2308403\ttest: 0.2299849\tbestTest: 0.2299849 (73)\ttotal: 5m 7s\tremaining: 1m 48s\n",
      "74: learn: 0.2306129\ttest: 0.2297558\tbestTest: 0.2297558 (74)\ttotal: 5m 12s\tremaining: 1m 44s\n",
      "75: learn: 0.2304024\ttest: 0.2295447\tbestTest: 0.2295447 (75)\ttotal: 5m 16s\tremaining: 1m 40s\n",
      "76: learn: 0.2301895\ttest: 0.2293275\tbestTest: 0.2293275 (76)\ttotal: 5m 20s\tremaining: 1m 35s\n",
      "77: learn: 0.2299788\ttest: 0.2291142\tbestTest: 0.2291142 (77)\ttotal: 5m 25s\tremaining: 1m 31s\n",
      "78: learn: 0.2298027\ttest: 0.2289372\tbestTest: 0.2289372 (78)\ttotal: 5m 29s\tremaining: 1m 27s\n",
      "79: learn: 0.2296008\ttest: 0.2287312\tbestTest: 0.2287312 (79)\ttotal: 5m 33s\tremaining: 1m 23s\n",
      "80: learn: 0.229446\ttest: 0.2285725\tbestTest: 0.2285725 (80)\ttotal: 5m 37s\tremaining: 1m 19s\n",
      "81: learn: 0.2292545\ttest: 0.2283793\tbestTest: 0.2283793 (81)\ttotal: 5m 42s\tremaining: 1m 15s\n",
      "82: learn: 0.2291027\ttest: 0.2282266\tbestTest: 0.2282266 (82)\ttotal: 5m 46s\tremaining: 1m 10s\n",
      "83: learn: 0.2289629\ttest: 0.2280834\tbestTest: 0.2280834 (83)\ttotal: 5m 50s\tremaining: 1m 6s\n",
      "84: learn: 0.2288062\ttest: 0.2279258\tbestTest: 0.2279258 (84)\ttotal: 5m 54s\tremaining: 1m 2s\n",
      "85: learn: 0.228671\ttest: 0.2277885\tbestTest: 0.2277885 (85)\ttotal: 5m 58s\tremaining: 58.4s\n",
      "86: learn: 0.2285364\ttest: 0.2276521\tbestTest: 0.2276521 (86)\ttotal: 6m 2s\tremaining: 54.2s\n",
      "87: learn: 0.2284006\ttest: 0.2275128\tbestTest: 0.2275128 (87)\ttotal: 6m 6s\tremaining: 50s\n",
      "88: learn: 0.2282861\ttest: 0.2273955\tbestTest: 0.2273955 (88)\ttotal: 6m 10s\tremaining: 45.8s\n",
      "89: learn: 0.2281879\ttest: 0.2272972\tbestTest: 0.2272972 (89)\ttotal: 6m 15s\tremaining: 41.7s\n",
      "90: learn: 0.2280638\ttest: 0.2271695\tbestTest: 0.2271695 (90)\ttotal: 6m 19s\tremaining: 37.5s\n",
      "91: learn: 0.2279559\ttest: 0.2270609\tbestTest: 0.2270609 (91)\ttotal: 6m 23s\tremaining: 33.4s\n",
      "92: learn: 0.2278649\ttest: 0.226967\tbestTest: 0.226967 (92)\ttotal: 6m 28s\tremaining: 29.2s\n",
      "93: learn: 0.2277337\ttest: 0.2268371\tbestTest: 0.2268371 (93)\ttotal: 6m 32s\tremaining: 25.1s\n",
      "94: learn: 0.2276463\ttest: 0.2267486\tbestTest: 0.2267486 (94)\ttotal: 6m 36s\tremaining: 20.9s\n",
      "95: learn: 0.2275396\ttest: 0.2266407\tbestTest: 0.2266407 (95)\ttotal: 6m 40s\tremaining: 16.7s\n",
      "96: learn: 0.2274499\ttest: 0.2265507\tbestTest: 0.2265507 (96)\ttotal: 6m 45s\tremaining: 12.5s\n",
      "97: learn: 0.2273534\ttest: 0.2264529\tbestTest: 0.2264529 (97)\ttotal: 6m 49s\tremaining: 8.35s\n",
      "98: learn: 0.2272697\ttest: 0.2263684\tbestTest: 0.2263684 (98)\ttotal: 6m 53s\tremaining: 4.17s\n",
      "99: learn: 0.2271813\ttest: 0.226278\tbestTest: 0.226278 (99)\ttotal: 6m 56s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2262779981\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_5_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 20:10:43.333621\n",
      "train time given below\n",
      "0:10:12.559068\n",
      "2018-03-14 20:10:43.520752\n",
      "2018-03-14 20:10:43.524475\n",
      "GINI ISIT = 0.44943786145\n",
      "2018-03-14 20:12:15.520130\n",
      "GINI OSIT = 0.450992066905\n",
      "2018-03-14 20:12:53.592542\n",
      "GINI OSOT = 0.404413109433\n",
      "2018-03-14 20:13:05.391612\n",
      "2018-03-14 20:13:05.393515\n",
      "depth = 6\n",
      "2018-03-14 20:13:05.394846\n",
      "model train start\n",
      "2018-03-14 20:13:05.395108\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 5.44s\tremaining: 8m 58s\n",
      "1: learn: 0.6246208\ttest: 0.6245847\tbestTest: 0.6245847 (1)\ttotal: 10.8s\tremaining: 8m 48s\n",
      "2: learn: 0.5946127\ttest: 0.5945499\tbestTest: 0.5945499 (2)\ttotal: 16.1s\tremaining: 8m 41s\n",
      "3: learn: 0.5671899\ttest: 0.5671115\tbestTest: 0.5671115 (3)\ttotal: 22.2s\tremaining: 8m 53s\n",
      "4: learn: 0.5413315\ttest: 0.5412325\tbestTest: 0.5412325 (4)\ttotal: 27.6s\tremaining: 8m 43s\n",
      "5: learn: 0.5176855\ttest: 0.517555\tbestTest: 0.517555 (5)\ttotal: 33.1s\tremaining: 8m 38s\n",
      "6: learn: 0.4955908\ttest: 0.4954434\tbestTest: 0.4954434 (6)\ttotal: 38.4s\tremaining: 8m 30s\n",
      "7: learn: 0.4754866\ttest: 0.4753306\tbestTest: 0.4753306 (7)\ttotal: 43.1s\tremaining: 8m 15s\n",
      "8: learn: 0.4569312\ttest: 0.4567565\tbestTest: 0.4567565 (8)\ttotal: 47.6s\tremaining: 8m 1s\n",
      "9: learn: 0.4397636\ttest: 0.4395709\tbestTest: 0.4395709 (9)\ttotal: 53s\tremaining: 7m 57s\n",
      "10: learn: 0.4246773\ttest: 0.4244609\tbestTest: 0.4244609 (10)\ttotal: 59s\tremaining: 7m 56s\n",
      "11: learn: 0.4107796\ttest: 0.4105415\tbestTest: 0.4105415 (11)\ttotal: 1m 1s\tremaining: 7m 31s\n",
      "12: learn: 0.3973422\ttest: 0.3970896\tbestTest: 0.3970896 (12)\ttotal: 1m 7s\tremaining: 7m 28s\n",
      "13: learn: 0.3849222\ttest: 0.3846532\tbestTest: 0.3846532 (13)\ttotal: 1m 11s\tremaining: 7m 21s\n",
      "14: learn: 0.3733676\ttest: 0.3730739\tbestTest: 0.3730739 (14)\ttotal: 1m 16s\tremaining: 7m 14s\n",
      "15: learn: 0.3628323\ttest: 0.3625217\tbestTest: 0.3625217 (15)\ttotal: 1m 21s\tremaining: 7m 6s\n",
      "16: learn: 0.3533874\ttest: 0.3530628\tbestTest: 0.3530628 (16)\ttotal: 1m 25s\tremaining: 6m 59s\n",
      "17: learn: 0.3442928\ttest: 0.3439469\tbestTest: 0.3439469 (17)\ttotal: 1m 30s\tremaining: 6m 52s\n",
      "18: learn: 0.3362487\ttest: 0.3358825\tbestTest: 0.3358825 (18)\ttotal: 1m 35s\tremaining: 6m 46s\n",
      "19: learn: 0.3284989\ttest: 0.3281057\tbestTest: 0.3281057 (19)\ttotal: 1m 40s\tremaining: 6m 42s\n",
      "20: learn: 0.3216065\ttest: 0.3212061\tbestTest: 0.3212061 (20)\ttotal: 1m 45s\tremaining: 6m 37s\n",
      "21: learn: 0.3152186\ttest: 0.3148105\tbestTest: 0.3148105 (21)\ttotal: 1m 50s\tremaining: 6m 33s\n",
      "22: learn: 0.3096159\ttest: 0.3091926\tbestTest: 0.3091926 (22)\ttotal: 1m 55s\tremaining: 6m 26s\n",
      "23: learn: 0.3042068\ttest: 0.3037673\tbestTest: 0.3037673 (23)\ttotal: 2m 1s\tremaining: 6m 23s\n",
      "24: learn: 0.298906\ttest: 0.2984494\tbestTest: 0.2984494 (24)\ttotal: 2m 5s\tremaining: 6m 17s\n",
      "25: learn: 0.2944728\ttest: 0.2940039\tbestTest: 0.2940039 (25)\ttotal: 2m 10s\tremaining: 6m 12s\n",
      "26: learn: 0.2897973\ttest: 0.2893116\tbestTest: 0.2893116 (26)\ttotal: 2m 15s\tremaining: 6m 6s\n",
      "27: learn: 0.2855463\ttest: 0.2850461\tbestTest: 0.2850461 (27)\ttotal: 2m 20s\tremaining: 6m 1s\n",
      "28: learn: 0.2816708\ttest: 0.2811558\tbestTest: 0.2811558 (28)\ttotal: 2m 25s\tremaining: 5m 55s\n",
      "29: learn: 0.2782756\ttest: 0.2777467\tbestTest: 0.2777467 (29)\ttotal: 2m 30s\tremaining: 5m 50s\n",
      "30: learn: 0.2748764\ttest: 0.2743358\tbestTest: 0.2743358 (30)\ttotal: 2m 34s\tremaining: 5m 44s\n",
      "31: learn: 0.2717013\ttest: 0.2711165\tbestTest: 0.2711165 (31)\ttotal: 2m 39s\tremaining: 5m 39s\n",
      "32: learn: 0.268688\ttest: 0.2680896\tbestTest: 0.2680896 (32)\ttotal: 2m 44s\tremaining: 5m 34s\n",
      "33: learn: 0.2661437\ttest: 0.2655366\tbestTest: 0.2655366 (33)\ttotal: 2m 49s\tremaining: 5m 28s\n",
      "34: learn: 0.2638136\ttest: 0.2631968\tbestTest: 0.2631968 (34)\ttotal: 2m 53s\tremaining: 5m 22s\n",
      "35: learn: 0.261605\ttest: 0.2609809\tbestTest: 0.2609809 (35)\ttotal: 2m 58s\tremaining: 5m 17s\n",
      "36: learn: 0.2595084\ttest: 0.2588755\tbestTest: 0.2588755 (36)\ttotal: 3m 3s\tremaining: 5m 12s\n",
      "37: learn: 0.2573841\ttest: 0.2567389\tbestTest: 0.2567389 (37)\ttotal: 3m 8s\tremaining: 5m 7s\n",
      "38: learn: 0.2555279\ttest: 0.2548802\tbestTest: 0.2548802 (38)\ttotal: 3m 13s\tremaining: 5m 2s\n",
      "39: learn: 0.2537557\ttest: 0.2530985\tbestTest: 0.2530985 (39)\ttotal: 3m 18s\tremaining: 4m 57s\n",
      "40: learn: 0.252063\ttest: 0.2514016\tbestTest: 0.2514016 (40)\ttotal: 3m 22s\tremaining: 4m 51s\n",
      "41: learn: 0.2504286\ttest: 0.2497629\tbestTest: 0.2497629 (41)\ttotal: 3m 27s\tremaining: 4m 47s\n",
      "42: learn: 0.2489857\ttest: 0.2483136\tbestTest: 0.2483136 (42)\ttotal: 3m 32s\tremaining: 4m 41s\n",
      "43: learn: 0.247612\ttest: 0.2469316\tbestTest: 0.2469316 (43)\ttotal: 3m 37s\tremaining: 4m 36s\n",
      "44: learn: 0.2463287\ttest: 0.2456404\tbestTest: 0.2456404 (44)\ttotal: 3m 41s\tremaining: 4m 31s\n",
      "45: learn: 0.2451238\ttest: 0.2444292\tbestTest: 0.2444292 (45)\ttotal: 3m 46s\tremaining: 4m 25s\n",
      "46: learn: 0.2439819\ttest: 0.2432444\tbestTest: 0.2432444 (46)\ttotal: 3m 52s\tremaining: 4m 21s\n",
      "47: learn: 0.2429657\ttest: 0.2422273\tbestTest: 0.2422273 (47)\ttotal: 3m 57s\tremaining: 4m 17s\n",
      "48: learn: 0.2420242\ttest: 0.2412818\tbestTest: 0.2412818 (48)\ttotal: 4m 2s\tremaining: 4m 11s\n",
      "49: learn: 0.2410859\ttest: 0.2403403\tbestTest: 0.2403403 (49)\ttotal: 4m 6s\tremaining: 4m 6s\n",
      "50: learn: 0.2402901\ttest: 0.2395419\tbestTest: 0.2395419 (50)\ttotal: 4m 12s\tremaining: 4m 2s\n",
      "51: learn: 0.2394966\ttest: 0.2387424\tbestTest: 0.2387424 (51)\ttotal: 4m 17s\tremaining: 3m 57s\n",
      "52: learn: 0.2387207\ttest: 0.2379593\tbestTest: 0.2379593 (52)\ttotal: 4m 21s\tremaining: 3m 52s\n",
      "53: learn: 0.2380488\ttest: 0.2372821\tbestTest: 0.2372821 (53)\ttotal: 4m 27s\tremaining: 3m 47s\n",
      "54: learn: 0.237367\ttest: 0.2365926\tbestTest: 0.2365926 (54)\ttotal: 4m 31s\tremaining: 3m 42s\n",
      "55: learn: 0.2367244\ttest: 0.2359464\tbestTest: 0.2359464 (55)\ttotal: 4m 36s\tremaining: 3m 37s\n",
      "56: learn: 0.2361421\ttest: 0.2353603\tbestTest: 0.2353603 (56)\ttotal: 4m 41s\tremaining: 3m 32s\n",
      "57: learn: 0.2356092\ttest: 0.2348228\tbestTest: 0.2348228 (57)\ttotal: 4m 46s\tremaining: 3m 27s\n",
      "58: learn: 0.2351138\ttest: 0.2343264\tbestTest: 0.2343264 (58)\ttotal: 4m 50s\tremaining: 3m 22s\n",
      "59: learn: 0.234606\ttest: 0.233814\tbestTest: 0.233814 (59)\ttotal: 4m 55s\tremaining: 3m 17s\n",
      "60: learn: 0.2341415\ttest: 0.2333439\tbestTest: 0.2333439 (60)\ttotal: 5m\tremaining: 3m 12s\n",
      "61: learn: 0.2336912\ttest: 0.2328881\tbestTest: 0.2328881 (61)\ttotal: 5m 5s\tremaining: 3m 7s\n",
      "62: learn: 0.2333059\ttest: 0.2325006\tbestTest: 0.2325006 (62)\ttotal: 5m 10s\tremaining: 3m 2s\n",
      "63: learn: 0.2328979\ttest: 0.2320902\tbestTest: 0.2320902 (63)\ttotal: 5m 14s\tremaining: 2m 57s\n",
      "64: learn: 0.232498\ttest: 0.231687\tbestTest: 0.231687 (64)\ttotal: 5m 20s\tremaining: 2m 52s\n",
      "65: learn: 0.2321619\ttest: 0.2313513\tbestTest: 0.2313513 (65)\ttotal: 5m 25s\tremaining: 2m 47s\n",
      "66: learn: 0.231846\ttest: 0.2310316\tbestTest: 0.2310316 (66)\ttotal: 5m 31s\tremaining: 2m 43s\n",
      "67: learn: 0.2315138\ttest: 0.2306943\tbestTest: 0.2306943 (67)\ttotal: 5m 35s\tremaining: 2m 38s\n",
      "68: learn: 0.2311943\ttest: 0.230371\tbestTest: 0.230371 (68)\ttotal: 5m 40s\tremaining: 2m 32s\n",
      "69: learn: 0.2308674\ttest: 0.2300423\tbestTest: 0.2300423 (69)\ttotal: 5m 45s\tremaining: 2m 27s\n",
      "70: learn: 0.2305828\ttest: 0.2297561\tbestTest: 0.2297561 (70)\ttotal: 5m 49s\tremaining: 2m 22s\n",
      "71: learn: 0.2303331\ttest: 0.2295076\tbestTest: 0.2295076 (71)\ttotal: 5m 54s\tremaining: 2m 17s\n",
      "72: learn: 0.2300738\ttest: 0.2292455\tbestTest: 0.2292455 (72)\ttotal: 5m 59s\tremaining: 2m 12s\n",
      "73: learn: 0.2298357\ttest: 0.2290069\tbestTest: 0.2290069 (73)\ttotal: 6m 4s\tremaining: 2m 8s\n",
      "74: learn: 0.2295871\ttest: 0.2287549\tbestTest: 0.2287549 (74)\ttotal: 6m 9s\tremaining: 2m 3s\n",
      "75: learn: 0.2293932\ttest: 0.2285571\tbestTest: 0.2285571 (75)\ttotal: 6m 15s\tremaining: 1m 58s\n",
      "76: learn: 0.229172\ttest: 0.2283335\tbestTest: 0.2283335 (76)\ttotal: 6m 20s\tremaining: 1m 53s\n",
      "77: learn: 0.2289697\ttest: 0.2281322\tbestTest: 0.2281322 (77)\ttotal: 6m 26s\tremaining: 1m 48s\n",
      "78: learn: 0.2287967\ttest: 0.2279553\tbestTest: 0.2279553 (78)\ttotal: 6m 31s\tremaining: 1m 43s\n",
      "79: learn: 0.2286238\ttest: 0.2277805\tbestTest: 0.2277805 (79)\ttotal: 6m 35s\tremaining: 1m 38s\n",
      "80: learn: 0.2284546\ttest: 0.2276104\tbestTest: 0.2276104 (80)\ttotal: 6m 40s\tremaining: 1m 33s\n",
      "81: learn: 0.2282963\ttest: 0.2274502\tbestTest: 0.2274502 (81)\ttotal: 6m 45s\tremaining: 1m 29s\n",
      "82: learn: 0.228134\ttest: 0.2272865\tbestTest: 0.2272865 (82)\ttotal: 6m 50s\tremaining: 1m 24s\n",
      "83: learn: 0.2279876\ttest: 0.2271382\tbestTest: 0.2271382 (83)\ttotal: 6m 54s\tremaining: 1m 19s\n",
      "84: learn: 0.2278536\ttest: 0.227003\tbestTest: 0.227003 (84)\ttotal: 6m 59s\tremaining: 1m 14s\n",
      "85: learn: 0.2277218\ttest: 0.2268687\tbestTest: 0.2268687 (85)\ttotal: 7m 4s\tremaining: 1m 9s\n",
      "86: learn: 0.227596\ttest: 0.2267423\tbestTest: 0.2267423 (86)\ttotal: 7m 9s\tremaining: 1m 4s\n",
      "87: learn: 0.2274592\ttest: 0.2266042\tbestTest: 0.2266042 (87)\ttotal: 7m 14s\tremaining: 59.3s\n",
      "88: learn: 0.2273448\ttest: 0.2264869\tbestTest: 0.2264869 (88)\ttotal: 7m 19s\tremaining: 54.4s\n",
      "89: learn: 0.2272221\ttest: 0.226362\tbestTest: 0.226362 (89)\ttotal: 7m 24s\tremaining: 49.4s\n",
      "90: learn: 0.2271088\ttest: 0.2262478\tbestTest: 0.2262478 (90)\ttotal: 7m 29s\tremaining: 44.4s\n",
      "91: learn: 0.2270112\ttest: 0.2261491\tbestTest: 0.2261491 (91)\ttotal: 7m 33s\tremaining: 39.5s\n",
      "92: learn: 0.2268981\ttest: 0.2260338\tbestTest: 0.2260338 (92)\ttotal: 7m 39s\tremaining: 34.6s\n",
      "93: learn: 0.2268125\ttest: 0.2259473\tbestTest: 0.2259473 (93)\ttotal: 7m 43s\tremaining: 29.6s\n",
      "94: learn: 0.2267097\ttest: 0.2258438\tbestTest: 0.2258438 (94)\ttotal: 7m 48s\tremaining: 24.7s\n",
      "95: learn: 0.2266195\ttest: 0.2257527\tbestTest: 0.2257527 (95)\ttotal: 7m 53s\tremaining: 19.7s\n",
      "96: learn: 0.2265016\ttest: 0.2256356\tbestTest: 0.2256356 (96)\ttotal: 7m 57s\tremaining: 14.8s\n",
      "97: learn: 0.2264181\ttest: 0.2255508\tbestTest: 0.2255508 (97)\ttotal: 8m 3s\tremaining: 9.86s\n",
      "98: learn: 0.2263337\ttest: 0.2254649\tbestTest: 0.2254649 (98)\ttotal: 8m 7s\tremaining: 4.93s\n",
      "99: learn: 0.2262613\ttest: 0.2253915\tbestTest: 0.2253915 (99)\ttotal: 8m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2253914748\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_6_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 20:24:45.081043\n",
      "train time given below\n",
      "0:11:39.685935\n",
      "2018-03-14 20:24:45.081582\n",
      "2018-03-14 20:24:45.085117\n",
      "GINI ISIT = 0.456550293521\n",
      "2018-03-14 20:26:13.865741\n",
      "GINI OSIT = 0.457718454984\n",
      "2018-03-14 20:26:52.220891\n",
      "GINI OSOT = 0.408875124366\n",
      "2018-03-14 20:27:04.035357\n",
      "2018-03-14 20:27:04.037289\n",
      "depth = 7\n",
      "2018-03-14 20:27:04.038669\n",
      "model train start\n",
      "2018-03-14 20:27:04.038899\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 6.28s\tremaining: 10m 21s\n",
      "1: learn: 0.6247149\ttest: 0.624678\tbestTest: 0.624678 (1)\ttotal: 12.2s\tremaining: 9m 59s\n",
      "2: learn: 0.59386\ttest: 0.5937869\tbestTest: 0.5937869 (2)\ttotal: 17.7s\tremaining: 9m 33s\n",
      "3: learn: 0.5659399\ttest: 0.5658513\tbestTest: 0.5658513 (3)\ttotal: 23.5s\tremaining: 9m 24s\n",
      "4: learn: 0.5396766\ttest: 0.53956\tbestTest: 0.53956 (4)\ttotal: 28.8s\tremaining: 9m 6s\n",
      "5: learn: 0.5162287\ttest: 0.5160883\tbestTest: 0.5160883 (5)\ttotal: 34.9s\tremaining: 9m 6s\n",
      "6: learn: 0.494396\ttest: 0.4942406\tbestTest: 0.4942406 (6)\ttotal: 40.5s\tremaining: 8m 58s\n",
      "7: learn: 0.4739638\ttest: 0.4737887\tbestTest: 0.4737887 (7)\ttotal: 46.1s\tremaining: 8m 49s\n",
      "8: learn: 0.4558057\ttest: 0.4556194\tbestTest: 0.4556194 (8)\ttotal: 52.2s\tremaining: 8m 48s\n",
      "9: learn: 0.438434\ttest: 0.4382275\tbestTest: 0.4382275 (9)\ttotal: 58.3s\tremaining: 8m 45s\n",
      "10: learn: 0.4227035\ttest: 0.4224839\tbestTest: 0.4224839 (10)\ttotal: 1m 3s\tremaining: 8m 37s\n",
      "11: learn: 0.4080366\ttest: 0.4077975\tbestTest: 0.4077975 (11)\ttotal: 1m 9s\tremaining: 8m 28s\n",
      "12: learn: 0.3946329\ttest: 0.3943746\tbestTest: 0.3943746 (12)\ttotal: 1m 14s\tremaining: 8m 19s\n",
      "13: learn: 0.3827013\ttest: 0.3824251\tbestTest: 0.3824251 (13)\ttotal: 1m 20s\tremaining: 8m 13s\n",
      "14: learn: 0.3719358\ttest: 0.3716401\tbestTest: 0.3716401 (14)\ttotal: 1m 25s\tremaining: 8m 4s\n",
      "15: learn: 0.3616664\ttest: 0.3613599\tbestTest: 0.3613599 (15)\ttotal: 1m 31s\tremaining: 7m 59s\n",
      "16: learn: 0.3525219\ttest: 0.352201\tbestTest: 0.352201 (16)\ttotal: 1m 36s\tremaining: 7m 53s\n",
      "17: learn: 0.3437059\ttest: 0.343369\tbestTest: 0.343369 (17)\ttotal: 1m 42s\tremaining: 7m 49s\n",
      "18: learn: 0.3356258\ttest: 0.3352755\tbestTest: 0.3352755 (18)\ttotal: 1m 48s\tremaining: 7m 42s\n",
      "19: learn: 0.3279811\ttest: 0.3276197\tbestTest: 0.3276197 (19)\ttotal: 1m 54s\tremaining: 7m 37s\n",
      "20: learn: 0.3210876\ttest: 0.3207063\tbestTest: 0.3207063 (20)\ttotal: 1m 59s\tremaining: 7m 31s\n",
      "21: learn: 0.314441\ttest: 0.3140444\tbestTest: 0.3140444 (21)\ttotal: 2m 5s\tremaining: 7m 24s\n",
      "22: learn: 0.3086238\ttest: 0.3082068\tbestTest: 0.3082068 (22)\ttotal: 2m 11s\tremaining: 7m 18s\n",
      "23: learn: 0.3029735\ttest: 0.3025413\tbestTest: 0.3025413 (23)\ttotal: 2m 16s\tremaining: 7m 12s\n",
      "24: learn: 0.2977079\ttest: 0.2972633\tbestTest: 0.2972633 (24)\ttotal: 2m 23s\tremaining: 7m 9s\n",
      "25: learn: 0.2929239\ttest: 0.2924665\tbestTest: 0.2924665 (25)\ttotal: 2m 28s\tremaining: 7m 3s\n",
      "26: learn: 0.2886942\ttest: 0.2882243\tbestTest: 0.2882243 (26)\ttotal: 2m 34s\tremaining: 6m 56s\n",
      "27: learn: 0.2846867\ttest: 0.284205\tbestTest: 0.284205 (27)\ttotal: 2m 39s\tremaining: 6m 49s\n",
      "28: learn: 0.2806298\ttest: 0.2801331\tbestTest: 0.2801331 (28)\ttotal: 2m 44s\tremaining: 6m 43s\n",
      "29: learn: 0.2772985\ttest: 0.2767931\tbestTest: 0.2767931 (29)\ttotal: 2m 50s\tremaining: 6m 38s\n",
      "30: learn: 0.2738996\ttest: 0.2733813\tbestTest: 0.2733813 (30)\ttotal: 2m 56s\tremaining: 6m 32s\n",
      "31: learn: 0.2707548\ttest: 0.2702262\tbestTest: 0.2702262 (31)\ttotal: 3m 1s\tremaining: 6m 26s\n",
      "32: learn: 0.2680102\ttest: 0.2674682\tbestTest: 0.2674682 (32)\ttotal: 3m 7s\tremaining: 6m 21s\n",
      "33: learn: 0.265475\ttest: 0.2649268\tbestTest: 0.2649268 (33)\ttotal: 3m 14s\tremaining: 6m 16s\n",
      "34: learn: 0.2630186\ttest: 0.2624579\tbestTest: 0.2624579 (34)\ttotal: 3m 20s\tremaining: 6m 11s\n",
      "35: learn: 0.2606746\ttest: 0.2601011\tbestTest: 0.2601011 (35)\ttotal: 3m 25s\tremaining: 6m 5s\n",
      "36: learn: 0.2584899\ttest: 0.2579046\tbestTest: 0.2579046 (36)\ttotal: 3m 31s\tremaining: 5m 59s\n",
      "37: learn: 0.2564975\ttest: 0.2559016\tbestTest: 0.2559016 (37)\ttotal: 3m 36s\tremaining: 5m 53s\n",
      "38: learn: 0.2546229\ttest: 0.2540173\tbestTest: 0.2540173 (38)\ttotal: 3m 42s\tremaining: 5m 48s\n",
      "39: learn: 0.2529007\ttest: 0.2522864\tbestTest: 0.2522864 (39)\ttotal: 3m 48s\tremaining: 5m 43s\n",
      "40: learn: 0.2511681\ttest: 0.2505466\tbestTest: 0.2505466 (40)\ttotal: 3m 54s\tremaining: 5m 37s\n",
      "41: learn: 0.2496469\ttest: 0.2490202\tbestTest: 0.2490202 (41)\ttotal: 3m 59s\tremaining: 5m 30s\n",
      "42: learn: 0.2483108\ttest: 0.2476751\tbestTest: 0.2476751 (42)\ttotal: 4m 5s\tremaining: 5m 26s\n",
      "43: learn: 0.2469279\ttest: 0.2462833\tbestTest: 0.2462833 (43)\ttotal: 4m 12s\tremaining: 5m 20s\n",
      "44: learn: 0.2457045\ttest: 0.2450545\tbestTest: 0.2450545 (44)\ttotal: 4m 17s\tremaining: 5m 15s\n",
      "45: learn: 0.2444658\ttest: 0.2438093\tbestTest: 0.2438093 (45)\ttotal: 4m 23s\tremaining: 5m 9s\n",
      "46: learn: 0.2433393\ttest: 0.2426742\tbestTest: 0.2426742 (46)\ttotal: 4m 28s\tremaining: 5m 3s\n",
      "47: learn: 0.2422725\ttest: 0.241599\tbestTest: 0.241599 (47)\ttotal: 4m 33s\tremaining: 4m 56s\n",
      "48: learn: 0.2412615\ttest: 0.2405809\tbestTest: 0.2405809 (48)\ttotal: 4m 39s\tremaining: 4m 50s\n",
      "49: learn: 0.24036\ttest: 0.2396782\tbestTest: 0.2396782 (49)\ttotal: 4m 45s\tremaining: 4m 45s\n",
      "50: learn: 0.239468\ttest: 0.2387805\tbestTest: 0.2387805 (50)\ttotal: 4m 52s\tremaining: 4m 40s\n",
      "51: learn: 0.2386839\ttest: 0.2379908\tbestTest: 0.2379908 (51)\ttotal: 4m 57s\tremaining: 4m 34s\n",
      "52: learn: 0.2379526\ttest: 0.2372551\tbestTest: 0.2372551 (52)\ttotal: 5m 3s\tremaining: 4m 29s\n",
      "53: learn: 0.2372659\ttest: 0.2365641\tbestTest: 0.2365641 (53)\ttotal: 5m 9s\tremaining: 4m 23s\n",
      "54: learn: 0.2365809\ttest: 0.2358698\tbestTest: 0.2358698 (54)\ttotal: 5m 15s\tremaining: 4m 17s\n",
      "55: learn: 0.2360134\ttest: 0.2352979\tbestTest: 0.2352979 (55)\ttotal: 5m 20s\tremaining: 4m 11s\n",
      "56: learn: 0.2353964\ttest: 0.2346772\tbestTest: 0.2346772 (56)\ttotal: 5m 26s\tremaining: 4m 6s\n",
      "57: learn: 0.2348291\ttest: 0.2341043\tbestTest: 0.2341043 (57)\ttotal: 5m 32s\tremaining: 4m\n",
      "58: learn: 0.2343054\ttest: 0.2335756\tbestTest: 0.2335756 (58)\ttotal: 5m 37s\tremaining: 3m 54s\n",
      "59: learn: 0.2338104\ttest: 0.2330757\tbestTest: 0.2330757 (59)\ttotal: 5m 43s\tremaining: 3m 48s\n",
      "60: learn: 0.2333317\ttest: 0.2325942\tbestTest: 0.2325942 (60)\ttotal: 5m 48s\tremaining: 3m 43s\n",
      "61: learn: 0.2329418\ttest: 0.2321993\tbestTest: 0.2321993 (61)\ttotal: 5m 54s\tremaining: 3m 37s\n",
      "62: learn: 0.2325774\ttest: 0.2318311\tbestTest: 0.2318311 (62)\ttotal: 6m\tremaining: 3m 31s\n",
      "63: learn: 0.2321782\ttest: 0.231426\tbestTest: 0.231426 (63)\ttotal: 6m 5s\tremaining: 3m 25s\n",
      "64: learn: 0.231783\ttest: 0.2310278\tbestTest: 0.2310278 (64)\ttotal: 6m 11s\tremaining: 3m 19s\n",
      "65: learn: 0.2313866\ttest: 0.2306275\tbestTest: 0.2306275 (65)\ttotal: 6m 16s\tremaining: 3m 13s\n",
      "66: learn: 0.2310427\ttest: 0.2302779\tbestTest: 0.2302779 (66)\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "67: learn: 0.2307201\ttest: 0.2299507\tbestTest: 0.2299507 (67)\ttotal: 6m 27s\tremaining: 3m 2s\n",
      "68: learn: 0.2303833\ttest: 0.2296115\tbestTest: 0.2296115 (68)\ttotal: 6m 33s\tremaining: 2m 56s\n",
      "69: learn: 0.2300931\ttest: 0.2293182\tbestTest: 0.2293182 (69)\ttotal: 6m 38s\tremaining: 2m 50s\n",
      "70: learn: 0.229821\ttest: 0.2290419\tbestTest: 0.2290419 (70)\ttotal: 6m 44s\tremaining: 2m 45s\n",
      "71: learn: 0.2295544\ttest: 0.2287728\tbestTest: 0.2287728 (71)\ttotal: 6m 49s\tremaining: 2m 39s\n",
      "72: learn: 0.2293037\ttest: 0.2285132\tbestTest: 0.2285132 (72)\ttotal: 6m 55s\tremaining: 2m 33s\n",
      "73: learn: 0.229076\ttest: 0.2282829\tbestTest: 0.2282829 (73)\ttotal: 7m\tremaining: 2m 27s\n",
      "74: learn: 0.2288529\ttest: 0.2280579\tbestTest: 0.2280579 (74)\ttotal: 7m 5s\tremaining: 2m 21s\n",
      "75: learn: 0.2286342\ttest: 0.2278374\tbestTest: 0.2278374 (75)\ttotal: 7m 11s\tremaining: 2m 16s\n",
      "76: learn: 0.2284489\ttest: 0.2276495\tbestTest: 0.2276495 (76)\ttotal: 7m 17s\tremaining: 2m 10s\n",
      "77: learn: 0.2282523\ttest: 0.2274504\tbestTest: 0.2274504 (77)\ttotal: 7m 23s\tremaining: 2m 4s\n",
      "78: learn: 0.2280411\ttest: 0.227237\tbestTest: 0.227237 (78)\ttotal: 7m 28s\tremaining: 1m 59s\n",
      "79: learn: 0.2278463\ttest: 0.2270395\tbestTest: 0.2270395 (79)\ttotal: 7m 34s\tremaining: 1m 53s\n",
      "80: learn: 0.2276853\ttest: 0.2268759\tbestTest: 0.2268759 (80)\ttotal: 7m 39s\tremaining: 1m 47s\n",
      "81: learn: 0.2275265\ttest: 0.2267157\tbestTest: 0.2267157 (81)\ttotal: 7m 44s\tremaining: 1m 42s\n",
      "82: learn: 0.227371\ttest: 0.2265593\tbestTest: 0.2265593 (82)\ttotal: 7m 49s\tremaining: 1m 36s\n",
      "83: learn: 0.2272335\ttest: 0.2264201\tbestTest: 0.2264201 (83)\ttotal: 7m 55s\tremaining: 1m 30s\n",
      "84: learn: 0.2271002\ttest: 0.2262867\tbestTest: 0.2262867 (84)\ttotal: 8m\tremaining: 1m 24s\n",
      "85: learn: 0.2269585\ttest: 0.2261445\tbestTest: 0.2261445 (85)\ttotal: 8m 6s\tremaining: 1m 19s\n",
      "86: learn: 0.2267964\ttest: 0.2259834\tbestTest: 0.2259834 (86)\ttotal: 8m 11s\tremaining: 1m 13s\n",
      "87: learn: 0.2266771\ttest: 0.225863\tbestTest: 0.225863 (87)\ttotal: 8m 17s\tremaining: 1m 7s\n",
      "88: learn: 0.2265421\ttest: 0.2257283\tbestTest: 0.2257283 (88)\ttotal: 8m 23s\tremaining: 1m 2s\n",
      "89: learn: 0.2264366\ttest: 0.2256223\tbestTest: 0.2256223 (89)\ttotal: 8m 28s\tremaining: 56.5s\n",
      "90: learn: 0.2263258\ttest: 0.2255106\tbestTest: 0.2255106 (90)\ttotal: 8m 34s\tremaining: 50.9s\n",
      "91: learn: 0.2262238\ttest: 0.2254074\tbestTest: 0.2254074 (91)\ttotal: 8m 40s\tremaining: 45.2s\n",
      "92: learn: 0.2261332\ttest: 0.2253153\tbestTest: 0.2253153 (92)\ttotal: 8m 45s\tremaining: 39.6s\n",
      "93: learn: 0.2260382\ttest: 0.2252208\tbestTest: 0.2252208 (93)\ttotal: 8m 51s\tremaining: 33.9s\n",
      "94: learn: 0.2259453\ttest: 0.2251272\tbestTest: 0.2251272 (94)\ttotal: 8m 57s\tremaining: 28.3s\n",
      "95: learn: 0.225864\ttest: 0.2250444\tbestTest: 0.2250444 (95)\ttotal: 9m 3s\tremaining: 22.6s\n",
      "96: learn: 0.225774\ttest: 0.2249527\tbestTest: 0.2249527 (96)\ttotal: 9m 9s\tremaining: 17s\n",
      "97: learn: 0.225686\ttest: 0.2248641\tbestTest: 0.2248641 (97)\ttotal: 9m 14s\tremaining: 11.3s\n",
      "98: learn: 0.2256048\ttest: 0.224783\tbestTest: 0.224783 (98)\ttotal: 9m 20s\tremaining: 5.66s\n",
      "99: learn: 0.2255423\ttest: 0.2247195\tbestTest: 0.2247195 (99)\ttotal: 9m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.224719511\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_7_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 20:39:50.114025\n",
      "train time given below\n",
      "0:12:46.075126\n",
      "2018-03-14 20:39:50.122752\n",
      "2018-03-14 20:39:50.126281\n",
      "GINI ISIT = 0.460658486368\n",
      "2018-03-14 20:41:23.169059\n",
      "GINI OSIT = 0.461645687457\n",
      "2018-03-14 20:42:02.202967\n",
      "GINI OSOT = 0.41665269241\n",
      "2018-03-14 20:42:14.256906\n",
      "2018-03-14 20:42:14.258822\n",
      "depth = 8\n",
      "2018-03-14 20:42:14.260212\n",
      "model train start\n",
      "2018-03-14 20:42:14.260429\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 6.09s\tremaining: 10m 3s\n",
      "1: learn: 0.6245598\ttest: 0.6245208\tbestTest: 0.6245208 (1)\ttotal: 12.8s\tremaining: 10m 26s\n",
      "2: learn: 0.5945048\ttest: 0.5944628\tbestTest: 0.5944628 (2)\ttotal: 20.1s\tremaining: 10m 50s\n",
      "3: learn: 0.5663661\ttest: 0.5663082\tbestTest: 0.5663082 (3)\ttotal: 26.6s\tremaining: 10m 39s\n",
      "4: learn: 0.5412674\ttest: 0.5411829\tbestTest: 0.5411829 (4)\ttotal: 30.4s\tremaining: 9m 38s\n",
      "5: learn: 0.5167551\ttest: 0.5166423\tbestTest: 0.5166423 (5)\ttotal: 37.1s\tremaining: 9m 40s\n",
      "6: learn: 0.4948621\ttest: 0.4947258\tbestTest: 0.4947258 (6)\ttotal: 43.9s\tremaining: 9m 43s\n",
      "7: learn: 0.474567\ttest: 0.4744045\tbestTest: 0.4744045 (7)\ttotal: 50.4s\tremaining: 9m 39s\n",
      "8: learn: 0.4557439\ttest: 0.4555555\tbestTest: 0.4555555 (8)\ttotal: 56.6s\tremaining: 9m 32s\n",
      "9: learn: 0.4384201\ttest: 0.4381981\tbestTest: 0.4381981 (9)\ttotal: 1m 4s\tremaining: 9m 36s\n",
      "10: learn: 0.4228967\ttest: 0.4226603\tbestTest: 0.4226603 (10)\ttotal: 1m 10s\tremaining: 9m 27s\n",
      "11: learn: 0.4086005\ttest: 0.4083414\tbestTest: 0.4083414 (11)\ttotal: 1m 15s\tremaining: 9m 16s\n",
      "12: learn: 0.3959837\ttest: 0.3957087\tbestTest: 0.3957087 (12)\ttotal: 1m 18s\tremaining: 8m 44s\n",
      "13: learn: 0.3834941\ttest: 0.3832045\tbestTest: 0.3832045 (13)\ttotal: 1m 25s\tremaining: 8m 43s\n",
      "14: learn: 0.3719234\ttest: 0.3716231\tbestTest: 0.3716231 (14)\ttotal: 1m 30s\tremaining: 8m 35s\n",
      "15: learn: 0.3615168\ttest: 0.3612102\tbestTest: 0.3612102 (15)\ttotal: 1m 36s\tremaining: 8m 26s\n",
      "16: learn: 0.352001\ttest: 0.351688\tbestTest: 0.351688 (16)\ttotal: 1m 42s\tremaining: 8m 20s\n",
      "17: learn: 0.3434668\ttest: 0.3431408\tbestTest: 0.3431408 (17)\ttotal: 1m 49s\tremaining: 8m 16s\n",
      "18: learn: 0.3355686\ttest: 0.3352253\tbestTest: 0.3352253 (18)\ttotal: 1m 55s\tremaining: 8m 10s\n",
      "19: learn: 0.3278753\ttest: 0.3275204\tbestTest: 0.3275204 (19)\ttotal: 2m 1s\tremaining: 8m 6s\n",
      "20: learn: 0.3210103\ttest: 0.3206366\tbestTest: 0.3206366 (20)\ttotal: 2m 8s\tremaining: 8m 2s\n",
      "21: learn: 0.3141025\ttest: 0.3137116\tbestTest: 0.3137116 (21)\ttotal: 2m 14s\tremaining: 7m 56s\n",
      "22: learn: 0.3079303\ttest: 0.3075201\tbestTest: 0.3075201 (22)\ttotal: 2m 21s\tremaining: 7m 52s\n",
      "23: learn: 0.3021943\ttest: 0.3017657\tbestTest: 0.3017657 (23)\ttotal: 2m 27s\tremaining: 7m 47s\n",
      "24: learn: 0.2971236\ttest: 0.2966888\tbestTest: 0.2966888 (24)\ttotal: 2m 33s\tremaining: 7m 40s\n",
      "25: learn: 0.2921657\ttest: 0.291715\tbestTest: 0.291715 (25)\ttotal: 2m 40s\tremaining: 7m 35s\n",
      "26: learn: 0.2877844\ttest: 0.2873272\tbestTest: 0.2873272 (26)\ttotal: 2m 46s\tremaining: 7m 29s\n",
      "27: learn: 0.28372\ttest: 0.2832505\tbestTest: 0.2832505 (27)\ttotal: 2m 53s\tremaining: 7m 25s\n",
      "28: learn: 0.2798074\ttest: 0.2793261\tbestTest: 0.2793261 (28)\ttotal: 2m 58s\tremaining: 7m 17s\n",
      "29: learn: 0.276419\ttest: 0.2759234\tbestTest: 0.2759234 (29)\ttotal: 3m 4s\tremaining: 7m 11s\n",
      "30: learn: 0.2730782\ttest: 0.2725687\tbestTest: 0.2725687 (30)\ttotal: 3m 11s\tremaining: 7m 5s\n",
      "31: learn: 0.2700267\ttest: 0.2695052\tbestTest: 0.2695052 (31)\ttotal: 3m 18s\tremaining: 7m\n",
      "32: learn: 0.2672985\ttest: 0.2667667\tbestTest: 0.2667667 (32)\ttotal: 3m 24s\tremaining: 6m 55s\n",
      "33: learn: 0.2645118\ttest: 0.2639761\tbestTest: 0.2639761 (33)\ttotal: 3m 30s\tremaining: 6m 48s\n",
      "34: learn: 0.2621905\ttest: 0.2616443\tbestTest: 0.2616443 (34)\ttotal: 3m 36s\tremaining: 6m 42s\n",
      "35: learn: 0.2598608\ttest: 0.2593053\tbestTest: 0.2593053 (35)\ttotal: 3m 42s\tremaining: 6m 36s\n",
      "36: learn: 0.2577032\ttest: 0.2571369\tbestTest: 0.2571369 (36)\ttotal: 3m 49s\tremaining: 6m 30s\n",
      "37: learn: 0.2556982\ttest: 0.2551238\tbestTest: 0.2551238 (37)\ttotal: 3m 56s\tremaining: 6m 25s\n",
      "38: learn: 0.2537511\ttest: 0.2531651\tbestTest: 0.2531651 (38)\ttotal: 4m 2s\tremaining: 6m 19s\n",
      "39: learn: 0.2519717\ttest: 0.2513746\tbestTest: 0.2513746 (39)\ttotal: 4m 9s\tremaining: 6m 13s\n",
      "40: learn: 0.2502956\ttest: 0.2496891\tbestTest: 0.2496891 (40)\ttotal: 4m 15s\tremaining: 6m 7s\n",
      "41: learn: 0.2487974\ttest: 0.2481828\tbestTest: 0.2481828 (41)\ttotal: 4m 21s\tremaining: 6m 1s\n",
      "42: learn: 0.2473716\ttest: 0.2467506\tbestTest: 0.2467506 (42)\ttotal: 4m 28s\tremaining: 5m 56s\n",
      "43: learn: 0.246121\ttest: 0.2454952\tbestTest: 0.2454952 (43)\ttotal: 4m 34s\tremaining: 5m 49s\n",
      "44: learn: 0.2448435\ttest: 0.2442094\tbestTest: 0.2442094 (44)\ttotal: 4m 41s\tremaining: 5m 44s\n",
      "45: learn: 0.2437861\ttest: 0.2431429\tbestTest: 0.2431429 (45)\ttotal: 4m 47s\tremaining: 5m 37s\n",
      "46: learn: 0.2426203\ttest: 0.2419687\tbestTest: 0.2419687 (46)\ttotal: 4m 53s\tremaining: 5m 31s\n",
      "47: learn: 0.2415711\ttest: 0.2409096\tbestTest: 0.2409096 (47)\ttotal: 4m 59s\tremaining: 5m 24s\n",
      "48: learn: 0.2406081\ttest: 0.2399413\tbestTest: 0.2399413 (48)\ttotal: 5m 5s\tremaining: 5m 18s\n",
      "49: learn: 0.2397818\ttest: 0.2391096\tbestTest: 0.2391096 (49)\ttotal: 5m 11s\tremaining: 5m 11s\n",
      "50: learn: 0.2388892\ttest: 0.2382061\tbestTest: 0.2382061 (50)\ttotal: 5m 18s\tremaining: 5m 5s\n",
      "51: learn: 0.2380483\ttest: 0.2373566\tbestTest: 0.2373566 (51)\ttotal: 5m 24s\tremaining: 4m 59s\n",
      "52: learn: 0.2373377\ttest: 0.2366387\tbestTest: 0.2366387 (52)\ttotal: 5m 31s\tremaining: 4m 53s\n",
      "53: learn: 0.2365769\ttest: 0.2358762\tbestTest: 0.2358762 (53)\ttotal: 5m 37s\tremaining: 4m 47s\n",
      "54: learn: 0.2358837\ttest: 0.2351827\tbestTest: 0.2351827 (54)\ttotal: 5m 43s\tremaining: 4m 40s\n",
      "55: learn: 0.2352108\ttest: 0.234506\tbestTest: 0.234506 (55)\ttotal: 5m 49s\tremaining: 4m 34s\n",
      "56: learn: 0.2346246\ttest: 0.2339158\tbestTest: 0.2339158 (56)\ttotal: 5m 55s\tremaining: 4m 28s\n",
      "57: learn: 0.234039\ttest: 0.2333244\tbestTest: 0.2333244 (57)\ttotal: 6m 1s\tremaining: 4m 21s\n",
      "58: learn: 0.2335504\ttest: 0.2328329\tbestTest: 0.2328329 (58)\ttotal: 6m 7s\tremaining: 4m 15s\n",
      "59: learn: 0.2330546\ttest: 0.2323323\tbestTest: 0.2323323 (59)\ttotal: 6m 13s\tremaining: 4m 9s\n",
      "60: learn: 0.2325887\ttest: 0.2318639\tbestTest: 0.2318639 (60)\ttotal: 6m 20s\tremaining: 4m 2s\n",
      "61: learn: 0.2321735\ttest: 0.2314448\tbestTest: 0.2314448 (61)\ttotal: 6m 26s\tremaining: 3m 56s\n",
      "62: learn: 0.2317586\ttest: 0.2310241\tbestTest: 0.2310241 (62)\ttotal: 6m 32s\tremaining: 3m 50s\n",
      "63: learn: 0.231339\ttest: 0.2306009\tbestTest: 0.2306009 (63)\ttotal: 6m 38s\tremaining: 3m 44s\n",
      "64: learn: 0.2309703\ttest: 0.2302313\tbestTest: 0.2302313 (64)\ttotal: 6m 45s\tremaining: 3m 38s\n",
      "65: learn: 0.2306219\ttest: 0.2298799\tbestTest: 0.2298799 (65)\ttotal: 6m 51s\tremaining: 3m 31s\n",
      "66: learn: 0.2302853\ttest: 0.2295405\tbestTest: 0.2295405 (66)\ttotal: 6m 58s\tremaining: 3m 26s\n",
      "67: learn: 0.2299921\ttest: 0.2292434\tbestTest: 0.2292434 (67)\ttotal: 7m 4s\tremaining: 3m 19s\n",
      "68: learn: 0.2297039\ttest: 0.2289509\tbestTest: 0.2289509 (68)\ttotal: 7m 10s\tremaining: 3m 13s\n",
      "69: learn: 0.2294082\ttest: 0.2286524\tbestTest: 0.2286524 (69)\ttotal: 7m 16s\tremaining: 3m 6s\n",
      "70: learn: 0.2291377\ttest: 0.2283815\tbestTest: 0.2283815 (70)\ttotal: 7m 22s\tremaining: 3m\n",
      "71: learn: 0.228879\ttest: 0.2281198\tbestTest: 0.2281198 (71)\ttotal: 7m 28s\tremaining: 2m 54s\n",
      "72: learn: 0.22865\ttest: 0.2278882\tbestTest: 0.2278882 (72)\ttotal: 7m 34s\tremaining: 2m 48s\n",
      "73: learn: 0.2284188\ttest: 0.2276561\tbestTest: 0.2276561 (73)\ttotal: 7m 41s\tremaining: 2m 42s\n",
      "74: learn: 0.2282203\ttest: 0.2274558\tbestTest: 0.2274558 (74)\ttotal: 7m 48s\tremaining: 2m 36s\n",
      "75: learn: 0.2280024\ttest: 0.2272364\tbestTest: 0.2272364 (75)\ttotal: 7m 54s\tremaining: 2m 29s\n",
      "76: learn: 0.2278063\ttest: 0.2270386\tbestTest: 0.2270386 (76)\ttotal: 8m 1s\tremaining: 2m 23s\n",
      "77: learn: 0.2276089\ttest: 0.2268399\tbestTest: 0.2268399 (77)\ttotal: 8m 7s\tremaining: 2m 17s\n",
      "78: learn: 0.227441\ttest: 0.2266697\tbestTest: 0.2266697 (78)\ttotal: 8m 13s\tremaining: 2m 11s\n",
      "79: learn: 0.2272611\ttest: 0.2264886\tbestTest: 0.2264886 (79)\ttotal: 8m 20s\tremaining: 2m 5s\n",
      "80: learn: 0.2271019\ttest: 0.2263277\tbestTest: 0.2263277 (80)\ttotal: 8m 26s\tremaining: 1m 58s\n",
      "81: learn: 0.2269299\ttest: 0.2261559\tbestTest: 0.2261559 (81)\ttotal: 8m 32s\tremaining: 1m 52s\n",
      "82: learn: 0.2267798\ttest: 0.2260036\tbestTest: 0.2260036 (82)\ttotal: 8m 38s\tremaining: 1m 46s\n",
      "83: learn: 0.2266455\ttest: 0.2258686\tbestTest: 0.2258686 (83)\ttotal: 8m 45s\tremaining: 1m 40s\n",
      "84: learn: 0.2264731\ttest: 0.2256959\tbestTest: 0.2256959 (84)\ttotal: 8m 51s\tremaining: 1m 33s\n",
      "85: learn: 0.2263353\ttest: 0.2255564\tbestTest: 0.2255564 (85)\ttotal: 8m 57s\tremaining: 1m 27s\n",
      "86: learn: 0.2262067\ttest: 0.2254278\tbestTest: 0.2254278 (86)\ttotal: 9m 3s\tremaining: 1m 21s\n",
      "87: learn: 0.2260864\ttest: 0.2253077\tbestTest: 0.2253077 (87)\ttotal: 9m 9s\tremaining: 1m 14s\n",
      "88: learn: 0.2259689\ttest: 0.2251895\tbestTest: 0.2251895 (88)\ttotal: 9m 16s\tremaining: 1m 8s\n",
      "89: learn: 0.2258658\ttest: 0.2250842\tbestTest: 0.2250842 (89)\ttotal: 9m 22s\tremaining: 1m 2s\n",
      "90: learn: 0.2257331\ttest: 0.2249515\tbestTest: 0.2249515 (90)\ttotal: 9m 28s\tremaining: 56.3s\n",
      "91: learn: 0.225625\ttest: 0.2248423\tbestTest: 0.2248423 (91)\ttotal: 9m 34s\tremaining: 50s\n",
      "92: learn: 0.2255266\ttest: 0.2247439\tbestTest: 0.2247439 (92)\ttotal: 9m 40s\tremaining: 43.7s\n",
      "93: learn: 0.2254341\ttest: 0.2246524\tbestTest: 0.2246524 (93)\ttotal: 9m 47s\tremaining: 37.5s\n",
      "94: learn: 0.2253215\ttest: 0.2245407\tbestTest: 0.2245407 (94)\ttotal: 9m 53s\tremaining: 31.2s\n",
      "95: learn: 0.2252292\ttest: 0.2244477\tbestTest: 0.2244477 (95)\ttotal: 9m 58s\tremaining: 25s\n",
      "96: learn: 0.2251421\ttest: 0.22436\tbestTest: 0.22436 (96)\ttotal: 10m 5s\tremaining: 18.7s\n",
      "97: learn: 0.225033\ttest: 0.2242522\tbestTest: 0.2242522 (97)\ttotal: 10m 11s\tremaining: 12.5s\n",
      "98: learn: 0.2249621\ttest: 0.2241812\tbestTest: 0.2241812 (98)\ttotal: 10m 17s\tremaining: 6.23s\n",
      "99: learn: 0.2248814\ttest: 0.2241008\tbestTest: 0.2241008 (99)\ttotal: 10m 23s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2241008025\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_8_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 20:56:00.372982\n",
      "train time given below\n",
      "0:13:46.112553\n",
      "2018-03-14 20:56:00.457966\n",
      "2018-03-14 20:56:00.461707\n",
      "GINI ISIT = 0.465061037229\n",
      "2018-03-14 20:57:32.432568\n",
      "GINI OSIT = 0.465669495464\n",
      "2018-03-14 20:58:12.188398\n",
      "GINI OSOT = 0.417620278521\n",
      "2018-03-14 20:58:24.142329\n",
      "2018-03-14 20:58:24.144497\n",
      "depth = 9\n",
      "2018-03-14 20:58:24.145900\n",
      "model train start\n",
      "2018-03-14 20:58:24.146191\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 6.18s\tremaining: 10m 11s\n",
      "1: learn: 0.6244822\ttest: 0.6244428\tbestTest: 0.6244428 (1)\ttotal: 13.6s\tremaining: 11m 7s\n",
      "2: learn: 0.5934731\ttest: 0.5933933\tbestTest: 0.5933933 (2)\ttotal: 20.8s\tremaining: 11m 12s\n",
      "3: learn: 0.5653188\ttest: 0.5652153\tbestTest: 0.5652153 (3)\ttotal: 28.3s\tremaining: 11m 18s\n",
      "4: learn: 0.5399462\ttest: 0.5398272\tbestTest: 0.5398272 (4)\ttotal: 34.2s\tremaining: 10m 50s\n",
      "5: learn: 0.5156233\ttest: 0.5154826\tbestTest: 0.5154826 (5)\ttotal: 41.9s\tremaining: 10m 55s\n",
      "6: learn: 0.4936347\ttest: 0.4934765\tbestTest: 0.4934765 (6)\ttotal: 49.5s\tremaining: 10m 57s\n",
      "7: learn: 0.4733439\ttest: 0.4731606\tbestTest: 0.4731606 (7)\ttotal: 57s\tremaining: 10m 55s\n",
      "8: learn: 0.4550029\ttest: 0.4548092\tbestTest: 0.4548092 (8)\ttotal: 1m 3s\tremaining: 10m 45s\n",
      "9: learn: 0.4381397\ttest: 0.4379312\tbestTest: 0.4379312 (9)\ttotal: 1m 11s\tremaining: 10m 47s\n",
      "10: learn: 0.423062\ttest: 0.4228274\tbestTest: 0.4228274 (10)\ttotal: 1m 18s\tremaining: 10m 33s\n",
      "11: learn: 0.4088659\ttest: 0.4086199\tbestTest: 0.4086199 (11)\ttotal: 1m 25s\tremaining: 10m 29s\n",
      "12: learn: 0.3954623\ttest: 0.3952007\tbestTest: 0.3952007 (12)\ttotal: 1m 32s\tremaining: 10m 19s\n",
      "13: learn: 0.382817\ttest: 0.3825367\tbestTest: 0.3825367 (13)\ttotal: 1m 39s\tremaining: 10m 13s\n",
      "14: learn: 0.3713312\ttest: 0.371037\tbestTest: 0.371037 (14)\ttotal: 1m 46s\tremaining: 10m 2s\n",
      "15: learn: 0.3609436\ttest: 0.3606414\tbestTest: 0.3606414 (15)\ttotal: 1m 53s\tremaining: 9m 55s\n",
      "16: learn: 0.3519957\ttest: 0.3516765\tbestTest: 0.3516765 (16)\ttotal: 1m 55s\tremaining: 9m 23s\n",
      "17: learn: 0.3430256\ttest: 0.3426908\tbestTest: 0.3426908 (17)\ttotal: 2m 1s\tremaining: 9m 11s\n",
      "18: learn: 0.3351551\ttest: 0.3348061\tbestTest: 0.3348061 (18)\ttotal: 2m 4s\tremaining: 8m 52s\n",
      "19: learn: 0.3282238\ttest: 0.3278607\tbestTest: 0.3278607 (19)\ttotal: 2m 7s\tremaining: 8m 30s\n",
      "20: learn: 0.3210136\ttest: 0.3206296\tbestTest: 0.3206296 (20)\ttotal: 2m 14s\tremaining: 8m 25s\n",
      "21: learn: 0.314323\ttest: 0.3139306\tbestTest: 0.3139306 (21)\ttotal: 2m 21s\tremaining: 8m 21s\n",
      "22: learn: 0.3083837\ttest: 0.307974\tbestTest: 0.307974 (22)\ttotal: 2m 29s\tremaining: 8m 19s\n",
      "23: learn: 0.3026242\ttest: 0.3021974\tbestTest: 0.3021974 (23)\ttotal: 2m 36s\tremaining: 8m 15s\n",
      "24: learn: 0.2975934\ttest: 0.297155\tbestTest: 0.297155 (24)\ttotal: 2m 44s\tremaining: 8m 12s\n",
      "25: learn: 0.2925486\ttest: 0.2920975\tbestTest: 0.2920975 (25)\ttotal: 2m 51s\tremaining: 8m 8s\n",
      "26: learn: 0.2879842\ttest: 0.2875217\tbestTest: 0.2875217 (26)\ttotal: 2m 58s\tremaining: 8m 3s\n",
      "27: learn: 0.2839609\ttest: 0.2834968\tbestTest: 0.2834968 (27)\ttotal: 3m 5s\tremaining: 7m 56s\n",
      "28: learn: 0.2800331\ttest: 0.2795627\tbestTest: 0.2795627 (28)\ttotal: 3m 11s\tremaining: 7m 49s\n",
      "29: learn: 0.2764491\ttest: 0.2759652\tbestTest: 0.2759652 (29)\ttotal: 3m 18s\tremaining: 7m 44s\n",
      "30: learn: 0.2729185\ttest: 0.2724187\tbestTest: 0.2724187 (30)\ttotal: 3m 25s\tremaining: 7m 37s\n",
      "31: learn: 0.2698065\ttest: 0.2692913\tbestTest: 0.2692913 (31)\ttotal: 3m 32s\tremaining: 7m 31s\n",
      "32: learn: 0.2672063\ttest: 0.2666853\tbestTest: 0.2666853 (32)\ttotal: 3m 39s\tremaining: 7m 26s\n",
      "33: learn: 0.2645008\ttest: 0.2639701\tbestTest: 0.2639701 (33)\ttotal: 3m 46s\tremaining: 7m 19s\n",
      "34: learn: 0.2619761\ttest: 0.2614355\tbestTest: 0.2614355 (34)\ttotal: 3m 53s\tremaining: 7m 14s\n",
      "35: learn: 0.2596831\ttest: 0.2591315\tbestTest: 0.2591315 (35)\ttotal: 4m 1s\tremaining: 7m 8s\n",
      "36: learn: 0.2575694\ttest: 0.257012\tbestTest: 0.257012 (36)\ttotal: 4m 7s\tremaining: 7m 2s\n",
      "37: learn: 0.255515\ttest: 0.2549494\tbestTest: 0.2549494 (37)\ttotal: 4m 14s\tremaining: 6m 55s\n",
      "38: learn: 0.2535414\ttest: 0.252966\tbestTest: 0.252966 (38)\ttotal: 4m 21s\tremaining: 6m 49s\n",
      "39: learn: 0.25188\ttest: 0.2512988\tbestTest: 0.2512988 (39)\ttotal: 4m 28s\tremaining: 6m 43s\n",
      "40: learn: 0.2502909\ttest: 0.2497003\tbestTest: 0.2497003 (40)\ttotal: 4m 36s\tremaining: 6m 37s\n",
      "41: learn: 0.2486736\ttest: 0.2480796\tbestTest: 0.2480796 (41)\ttotal: 4m 43s\tremaining: 6m 31s\n",
      "42: learn: 0.2472944\ttest: 0.2466907\tbestTest: 0.2466907 (42)\ttotal: 4m 50s\tremaining: 6m 24s\n",
      "43: learn: 0.245863\ttest: 0.2452542\tbestTest: 0.2452542 (43)\ttotal: 4m 57s\tremaining: 6m 18s\n",
      "44: learn: 0.2447249\ttest: 0.2441116\tbestTest: 0.2441116 (44)\ttotal: 5m 4s\tremaining: 6m 12s\n",
      "45: learn: 0.2434704\ttest: 0.2428487\tbestTest: 0.2428487 (45)\ttotal: 5m 12s\tremaining: 6m 6s\n",
      "46: learn: 0.2423527\ttest: 0.2417256\tbestTest: 0.2417256 (46)\ttotal: 5m 19s\tremaining: 6m\n",
      "47: learn: 0.2413028\ttest: 0.2406704\tbestTest: 0.2406704 (47)\ttotal: 5m 26s\tremaining: 5m 53s\n",
      "48: learn: 0.2402595\ttest: 0.2396233\tbestTest: 0.2396233 (48)\ttotal: 5m 32s\tremaining: 5m 46s\n",
      "49: learn: 0.239351\ttest: 0.2387098\tbestTest: 0.2387098 (49)\ttotal: 5m 39s\tremaining: 5m 39s\n",
      "50: learn: 0.2384523\ttest: 0.237808\tbestTest: 0.237808 (50)\ttotal: 5m 46s\tremaining: 5m 33s\n",
      "51: learn: 0.2376429\ttest: 0.2369947\tbestTest: 0.2369947 (51)\ttotal: 5m 54s\tremaining: 5m 27s\n",
      "52: learn: 0.2369258\ttest: 0.2362723\tbestTest: 0.2362723 (52)\ttotal: 6m 2s\tremaining: 5m 21s\n",
      "53: learn: 0.2363002\ttest: 0.2356422\tbestTest: 0.2356422 (53)\ttotal: 6m 9s\tremaining: 5m 14s\n",
      "54: learn: 0.2355742\ttest: 0.2349143\tbestTest: 0.2349143 (54)\ttotal: 6m 16s\tremaining: 5m 8s\n",
      "55: learn: 0.2349465\ttest: 0.2342802\tbestTest: 0.2342802 (55)\ttotal: 6m 23s\tremaining: 5m 1s\n",
      "56: learn: 0.2343781\ttest: 0.2337084\tbestTest: 0.2337084 (56)\ttotal: 6m 31s\tremaining: 4m 55s\n",
      "57: learn: 0.2338059\ttest: 0.233132\tbestTest: 0.233132 (57)\ttotal: 6m 37s\tremaining: 4m 48s\n",
      "58: learn: 0.2332632\ttest: 0.2325839\tbestTest: 0.2325839 (58)\ttotal: 6m 44s\tremaining: 4m 41s\n",
      "59: learn: 0.2327846\ttest: 0.2321022\tbestTest: 0.2321022 (59)\ttotal: 6m 51s\tremaining: 4m 34s\n",
      "60: learn: 0.2322892\ttest: 0.2316054\tbestTest: 0.2316054 (60)\ttotal: 6m 57s\tremaining: 4m 27s\n",
      "61: learn: 0.2318208\ttest: 0.2311326\tbestTest: 0.2311326 (61)\ttotal: 7m 4s\tremaining: 4m 20s\n",
      "62: learn: 0.2314274\ttest: 0.2307379\tbestTest: 0.2307379 (62)\ttotal: 7m 11s\tremaining: 4m 13s\n",
      "63: learn: 0.2310271\ttest: 0.2303349\tbestTest: 0.2303349 (63)\ttotal: 7m 18s\tremaining: 4m 6s\n",
      "64: learn: 0.230637\ttest: 0.2299412\tbestTest: 0.2299412 (64)\ttotal: 7m 25s\tremaining: 4m\n",
      "65: learn: 0.2302817\ttest: 0.229583\tbestTest: 0.229583 (65)\ttotal: 7m 32s\tremaining: 3m 53s\n",
      "66: learn: 0.2299345\ttest: 0.2292319\tbestTest: 0.2292319 (66)\ttotal: 7m 40s\tremaining: 3m 46s\n",
      "67: learn: 0.2295739\ttest: 0.2288707\tbestTest: 0.2288707 (67)\ttotal: 7m 47s\tremaining: 3m 39s\n",
      "68: learn: 0.2292507\ttest: 0.2285469\tbestTest: 0.2285469 (68)\ttotal: 7m 53s\tremaining: 3m 32s\n",
      "69: learn: 0.228956\ttest: 0.2282515\tbestTest: 0.2282515 (69)\ttotal: 8m\tremaining: 3m 25s\n",
      "70: learn: 0.2286927\ttest: 0.2279853\tbestTest: 0.2279853 (70)\ttotal: 8m 7s\tremaining: 3m 19s\n",
      "71: learn: 0.2284372\ttest: 0.2277268\tbestTest: 0.2277268 (71)\ttotal: 8m 15s\tremaining: 3m 12s\n",
      "72: learn: 0.2281739\ttest: 0.2274603\tbestTest: 0.2274603 (72)\ttotal: 8m 22s\tremaining: 3m 5s\n",
      "73: learn: 0.2279074\ttest: 0.2271939\tbestTest: 0.2271939 (73)\ttotal: 8m 29s\tremaining: 2m 59s\n",
      "74: learn: 0.2277085\ttest: 0.2269935\tbestTest: 0.2269935 (74)\ttotal: 8m 36s\tremaining: 2m 52s\n",
      "75: learn: 0.2275054\ttest: 0.2267897\tbestTest: 0.2267897 (75)\ttotal: 8m 43s\tremaining: 2m 45s\n",
      "76: learn: 0.2272978\ttest: 0.2265817\tbestTest: 0.2265817 (76)\ttotal: 8m 50s\tremaining: 2m 38s\n",
      "77: learn: 0.2271079\ttest: 0.2263919\tbestTest: 0.2263919 (77)\ttotal: 8m 57s\tremaining: 2m 31s\n",
      "78: learn: 0.2269257\ttest: 0.2262106\tbestTest: 0.2262106 (78)\ttotal: 9m 4s\tremaining: 2m 24s\n",
      "79: learn: 0.2267376\ttest: 0.2260228\tbestTest: 0.2260228 (79)\ttotal: 9m 10s\tremaining: 2m 17s\n",
      "80: learn: 0.2265652\ttest: 0.2258504\tbestTest: 0.2258504 (80)\ttotal: 9m 18s\tremaining: 2m 10s\n",
      "81: learn: 0.226389\ttest: 0.2256728\tbestTest: 0.2256728 (81)\ttotal: 9m 24s\tremaining: 2m 3s\n",
      "82: learn: 0.2262336\ttest: 0.2255163\tbestTest: 0.2255163 (82)\ttotal: 9m 31s\tremaining: 1m 57s\n",
      "83: learn: 0.2260793\ttest: 0.2253626\tbestTest: 0.2253626 (83)\ttotal: 9m 38s\tremaining: 1m 50s\n",
      "84: learn: 0.2259504\ttest: 0.2252325\tbestTest: 0.2252325 (84)\ttotal: 9m 45s\tremaining: 1m 43s\n",
      "85: learn: 0.2258072\ttest: 0.2250894\tbestTest: 0.2250894 (85)\ttotal: 9m 52s\tremaining: 1m 36s\n",
      "86: learn: 0.2256743\ttest: 0.2249561\tbestTest: 0.2249561 (86)\ttotal: 9m 59s\tremaining: 1m 29s\n",
      "87: learn: 0.2255473\ttest: 0.2248288\tbestTest: 0.2248288 (87)\ttotal: 10m 6s\tremaining: 1m 22s\n",
      "88: learn: 0.2254378\ttest: 0.2247174\tbestTest: 0.2247174 (88)\ttotal: 10m 14s\tremaining: 1m 15s\n",
      "89: learn: 0.2253242\ttest: 0.2246036\tbestTest: 0.2246036 (89)\ttotal: 10m 20s\tremaining: 1m 8s\n",
      "90: learn: 0.2252201\ttest: 0.2245004\tbestTest: 0.2245004 (90)\ttotal: 10m 27s\tremaining: 1m 2s\n",
      "91: learn: 0.2251197\ttest: 0.224401\tbestTest: 0.224401 (91)\ttotal: 10m 34s\tremaining: 55.2s\n",
      "92: learn: 0.2250227\ttest: 0.2243034\tbestTest: 0.2243034 (92)\ttotal: 10m 41s\tremaining: 48.3s\n",
      "93: learn: 0.2249374\ttest: 0.224218\tbestTest: 0.224218 (93)\ttotal: 10m 49s\tremaining: 41.4s\n",
      "94: learn: 0.2248559\ttest: 0.2241361\tbestTest: 0.2241361 (94)\ttotal: 10m 55s\tremaining: 34.5s\n",
      "95: learn: 0.2247827\ttest: 0.2240632\tbestTest: 0.2240632 (95)\ttotal: 11m 2s\tremaining: 27.6s\n",
      "96: learn: 0.2246992\ttest: 0.2239806\tbestTest: 0.2239806 (96)\ttotal: 11m 9s\tremaining: 20.7s\n",
      "97: learn: 0.2245886\ttest: 0.2238718\tbestTest: 0.2238718 (97)\ttotal: 11m 15s\tremaining: 13.8s\n",
      "98: learn: 0.224494\ttest: 0.2237791\tbestTest: 0.2237791 (98)\ttotal: 11m 22s\tremaining: 6.89s\n",
      "99: learn: 0.2244121\ttest: 0.2236976\tbestTest: 0.2236976 (99)\ttotal: 11m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2236975839\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_9_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 21:13:22.066242\n",
      "train time given below\n",
      "0:14:57.920051\n",
      "2018-03-14 21:13:22.132106\n",
      "2018-03-14 21:13:22.135771\n",
      "GINI ISIT = 0.468305712434\n",
      "2018-03-14 21:14:57.514918\n",
      "GINI OSIT = 0.468324386445\n",
      "2018-03-14 21:15:37.295098\n",
      "GINI OSOT = 0.417121292433\n",
      "2018-03-14 21:15:49.719714\n",
      "2018-03-14 21:15:49.721733\n",
      "depth = 10\n",
      "2018-03-14 21:15:49.723156\n",
      "model train start\n",
      "2018-03-14 21:15:49.723380\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 6.13s\tremaining: 10m 6s\n",
      "1: learn: 0.6243889\ttest: 0.6243559\tbestTest: 0.6243559 (1)\ttotal: 14.7s\tremaining: 12m 2s\n",
      "2: learn: 0.5948854\ttest: 0.5948369\tbestTest: 0.5948369 (2)\ttotal: 18.8s\tremaining: 10m 6s\n",
      "3: learn: 0.566821\ttest: 0.5667426\tbestTest: 0.5667426 (3)\ttotal: 26.9s\tremaining: 10m 45s\n",
      "4: learn: 0.5407037\ttest: 0.5406124\tbestTest: 0.5406124 (4)\ttotal: 35.3s\tremaining: 11m 11s\n",
      "5: learn: 0.5163833\ttest: 0.5162596\tbestTest: 0.5162596 (5)\ttotal: 44s\tremaining: 11m 29s\n",
      "6: learn: 0.4950901\ttest: 0.4949348\tbestTest: 0.4949348 (6)\ttotal: 46.6s\tremaining: 10m 19s\n",
      "7: learn: 0.4744867\ttest: 0.4743141\tbestTest: 0.4743141 (7)\ttotal: 55.5s\tremaining: 10m 38s\n",
      "8: learn: 0.4557634\ttest: 0.4555658\tbestTest: 0.4555658 (8)\ttotal: 1m 1s\tremaining: 10m 19s\n",
      "9: learn: 0.4382239\ttest: 0.4380192\tbestTest: 0.4380192 (9)\ttotal: 1m 10s\tremaining: 10m 30s\n",
      "10: learn: 0.4224004\ttest: 0.4221631\tbestTest: 0.4221631 (10)\ttotal: 1m 18s\tremaining: 10m 36s\n",
      "11: learn: 0.4081616\ttest: 0.4079104\tbestTest: 0.4079104 (11)\ttotal: 1m 24s\tremaining: 10m 21s\n",
      "12: learn: 0.3950533\ttest: 0.3947927\tbestTest: 0.3947927 (12)\ttotal: 1m 33s\tremaining: 10m 24s\n",
      "13: learn: 0.3827336\ttest: 0.3824485\tbestTest: 0.3824485 (13)\ttotal: 1m 41s\tremaining: 10m 25s\n",
      "14: learn: 0.3713146\ttest: 0.3710146\tbestTest: 0.3710146 (14)\ttotal: 1m 49s\tremaining: 10m 21s\n",
      "15: learn: 0.360697\ttest: 0.360383\tbestTest: 0.360383 (15)\ttotal: 1m 57s\tremaining: 10m 19s\n",
      "16: learn: 0.3506589\ttest: 0.3503253\tbestTest: 0.3503253 (16)\ttotal: 2m 5s\tremaining: 10m 13s\n",
      "17: learn: 0.3418275\ttest: 0.3414667\tbestTest: 0.3414667 (17)\ttotal: 2m 13s\tremaining: 10m 9s\n",
      "18: learn: 0.3339514\ttest: 0.3335859\tbestTest: 0.3335859 (18)\ttotal: 2m 21s\tremaining: 10m 4s\n",
      "19: learn: 0.3263053\ttest: 0.3259258\tbestTest: 0.3259258 (19)\ttotal: 2m 29s\tremaining: 9m 59s\n",
      "20: learn: 0.3192944\ttest: 0.3189032\tbestTest: 0.3189032 (20)\ttotal: 2m 38s\tremaining: 9m 54s\n",
      "21: learn: 0.3132016\ttest: 0.3127995\tbestTest: 0.3127995 (21)\ttotal: 2m 47s\tremaining: 9m 52s\n",
      "22: learn: 0.3070842\ttest: 0.3066661\tbestTest: 0.3066661 (22)\ttotal: 2m 55s\tremaining: 9m 48s\n",
      "23: learn: 0.3012812\ttest: 0.3008447\tbestTest: 0.3008447 (23)\ttotal: 3m 3s\tremaining: 9m 39s\n",
      "24: learn: 0.2963313\ttest: 0.2958848\tbestTest: 0.2958848 (24)\ttotal: 3m 11s\tremaining: 9m 33s\n",
      "25: learn: 0.2915392\ttest: 0.291083\tbestTest: 0.291083 (25)\ttotal: 3m 19s\tremaining: 9m 28s\n",
      "26: learn: 0.2870378\ttest: 0.2865712\tbestTest: 0.2865712 (26)\ttotal: 3m 28s\tremaining: 9m 23s\n",
      "27: learn: 0.2827206\ttest: 0.2822421\tbestTest: 0.2822421 (27)\ttotal: 3m 35s\tremaining: 9m 14s\n",
      "28: learn: 0.2789125\ttest: 0.2784207\tbestTest: 0.2784207 (28)\ttotal: 3m 44s\tremaining: 9m 8s\n",
      "29: learn: 0.2754887\ttest: 0.2749906\tbestTest: 0.2749906 (29)\ttotal: 3m 52s\tremaining: 9m 2s\n",
      "30: learn: 0.272221\ttest: 0.2717117\tbestTest: 0.2717117 (30)\ttotal: 4m\tremaining: 8m 56s\n",
      "31: learn: 0.2691781\ttest: 0.2686581\tbestTest: 0.2686581 (31)\ttotal: 4m 9s\tremaining: 8m 49s\n",
      "32: learn: 0.2663065\ttest: 0.2657801\tbestTest: 0.2657801 (32)\ttotal: 4m 17s\tremaining: 8m 41s\n",
      "33: learn: 0.2635659\ttest: 0.2630334\tbestTest: 0.2630334 (33)\ttotal: 4m 24s\tremaining: 8m 33s\n",
      "34: learn: 0.2613232\ttest: 0.2607841\tbestTest: 0.2607841 (34)\ttotal: 4m 32s\tremaining: 8m 26s\n",
      "35: learn: 0.2588712\ttest: 0.2583218\tbestTest: 0.2583218 (35)\ttotal: 4m 41s\tremaining: 8m 19s\n",
      "36: learn: 0.256753\ttest: 0.2561988\tbestTest: 0.2561988 (36)\ttotal: 4m 50s\tremaining: 8m 14s\n",
      "37: learn: 0.2547531\ttest: 0.254191\tbestTest: 0.254191 (37)\ttotal: 4m 58s\tremaining: 8m 7s\n",
      "38: learn: 0.2529197\ttest: 0.2523516\tbestTest: 0.2523516 (38)\ttotal: 5m 6s\tremaining: 7m 59s\n",
      "39: learn: 0.2511384\ttest: 0.2505647\tbestTest: 0.2505647 (39)\ttotal: 5m 14s\tremaining: 7m 52s\n",
      "40: learn: 0.249494\ttest: 0.2489162\tbestTest: 0.2489162 (40)\ttotal: 5m 22s\tremaining: 7m 44s\n",
      "41: learn: 0.2479717\ttest: 0.2473872\tbestTest: 0.2473872 (41)\ttotal: 5m 29s\tremaining: 7m 35s\n",
      "42: learn: 0.246527\ttest: 0.2459378\tbestTest: 0.2459378 (42)\ttotal: 5m 37s\tremaining: 7m 27s\n",
      "43: learn: 0.2451701\ttest: 0.2445766\tbestTest: 0.2445766 (43)\ttotal: 5m 46s\tremaining: 7m 20s\n",
      "44: learn: 0.2438539\ttest: 0.2432608\tbestTest: 0.2432608 (44)\ttotal: 5m 54s\tremaining: 7m 13s\n",
      "45: learn: 0.2426417\ttest: 0.2420449\tbestTest: 0.2420449 (45)\ttotal: 6m 2s\tremaining: 7m 5s\n",
      "46: learn: 0.2415383\ttest: 0.2409387\tbestTest: 0.2409387 (46)\ttotal: 6m 9s\tremaining: 6m 57s\n",
      "47: learn: 0.2404725\ttest: 0.2398691\tbestTest: 0.2398691 (47)\ttotal: 6m 18s\tremaining: 6m 49s\n",
      "48: learn: 0.2394844\ttest: 0.2388796\tbestTest: 0.2388796 (48)\ttotal: 6m 26s\tremaining: 6m 42s\n",
      "49: learn: 0.2386349\ttest: 0.2380307\tbestTest: 0.2380307 (49)\ttotal: 6m 34s\tremaining: 6m 34s\n",
      "50: learn: 0.2377612\ttest: 0.2371506\tbestTest: 0.2371506 (50)\ttotal: 6m 42s\tremaining: 6m 26s\n",
      "51: learn: 0.2370007\ttest: 0.2363881\tbestTest: 0.2363881 (51)\ttotal: 6m 49s\tremaining: 6m 18s\n",
      "52: learn: 0.2362521\ttest: 0.2356336\tbestTest: 0.2356336 (52)\ttotal: 6m 58s\tremaining: 6m 10s\n",
      "53: learn: 0.2355667\ttest: 0.2349479\tbestTest: 0.2349479 (53)\ttotal: 7m 6s\tremaining: 6m 3s\n",
      "54: learn: 0.234903\ttest: 0.2342823\tbestTest: 0.2342823 (54)\ttotal: 7m 14s\tremaining: 5m 55s\n",
      "55: learn: 0.2343147\ttest: 0.2336934\tbestTest: 0.2336934 (55)\ttotal: 7m 22s\tremaining: 5m 47s\n",
      "56: learn: 0.2336905\ttest: 0.2330659\tbestTest: 0.2330659 (56)\ttotal: 7m 30s\tremaining: 5m 39s\n",
      "57: learn: 0.2331059\ttest: 0.2324797\tbestTest: 0.2324797 (57)\ttotal: 7m 37s\tremaining: 5m 31s\n",
      "58: learn: 0.2325831\ttest: 0.2319534\tbestTest: 0.2319534 (58)\ttotal: 7m 45s\tremaining: 5m 23s\n",
      "59: learn: 0.2320878\ttest: 0.231456\tbestTest: 0.231456 (59)\ttotal: 7m 53s\tremaining: 5m 15s\n",
      "60: learn: 0.2316151\ttest: 0.2309783\tbestTest: 0.2309783 (60)\ttotal: 8m 1s\tremaining: 5m 7s\n",
      "61: learn: 0.2311826\ttest: 0.2305449\tbestTest: 0.2305449 (61)\ttotal: 8m 9s\tremaining: 5m\n",
      "62: learn: 0.2308001\ttest: 0.2301621\tbestTest: 0.2301621 (62)\ttotal: 8m 17s\tremaining: 4m 52s\n",
      "63: learn: 0.2304092\ttest: 0.2297706\tbestTest: 0.2297706 (63)\ttotal: 8m 25s\tremaining: 4m 44s\n",
      "64: learn: 0.2300321\ttest: 0.2293935\tbestTest: 0.2293935 (64)\ttotal: 8m 33s\tremaining: 4m 36s\n",
      "65: learn: 0.2296699\ttest: 0.2290321\tbestTest: 0.2290321 (65)\ttotal: 8m 41s\tremaining: 4m 28s\n",
      "66: learn: 0.2293438\ttest: 0.2287031\tbestTest: 0.2287031 (66)\ttotal: 8m 49s\tremaining: 4m 20s\n",
      "67: learn: 0.2289917\ttest: 0.228349\tbestTest: 0.228349 (67)\ttotal: 8m 56s\tremaining: 4m 12s\n",
      "68: learn: 0.2286443\ttest: 0.2280031\tbestTest: 0.2280031 (68)\ttotal: 9m 5s\tremaining: 4m 5s\n",
      "69: learn: 0.2283596\ttest: 0.2277183\tbestTest: 0.2277183 (69)\ttotal: 9m 13s\tremaining: 3m 57s\n",
      "70: learn: 0.2280716\ttest: 0.2274312\tbestTest: 0.2274312 (70)\ttotal: 9m 22s\tremaining: 3m 49s\n",
      "71: learn: 0.2278393\ttest: 0.2271976\tbestTest: 0.2271976 (71)\ttotal: 9m 29s\tremaining: 3m 41s\n",
      "72: learn: 0.2275963\ttest: 0.2269511\tbestTest: 0.2269511 (72)\ttotal: 9m 37s\tremaining: 3m 33s\n",
      "73: learn: 0.2273727\ttest: 0.2267268\tbestTest: 0.2267268 (73)\ttotal: 9m 46s\tremaining: 3m 26s\n",
      "74: learn: 0.2271494\ttest: 0.2265023\tbestTest: 0.2265023 (74)\ttotal: 9m 54s\tremaining: 3m 18s\n",
      "75: learn: 0.2269439\ttest: 0.2262969\tbestTest: 0.2262969 (75)\ttotal: 10m 2s\tremaining: 3m 10s\n",
      "76: learn: 0.2267635\ttest: 0.226116\tbestTest: 0.226116 (76)\ttotal: 10m 11s\tremaining: 3m 2s\n",
      "77: learn: 0.2265529\ttest: 0.2259072\tbestTest: 0.2259072 (77)\ttotal: 10m 19s\tremaining: 2m 54s\n",
      "78: learn: 0.2263594\ttest: 0.2257169\tbestTest: 0.2257169 (78)\ttotal: 10m 27s\tremaining: 2m 46s\n",
      "79: learn: 0.2262102\ttest: 0.2255677\tbestTest: 0.2255677 (79)\ttotal: 10m 36s\tremaining: 2m 39s\n",
      "80: learn: 0.2260202\ttest: 0.2253791\tbestTest: 0.2253791 (80)\ttotal: 10m 43s\tremaining: 2m 31s\n",
      "81: learn: 0.2258522\ttest: 0.2252117\tbestTest: 0.2252117 (81)\ttotal: 10m 51s\tremaining: 2m 22s\n",
      "82: learn: 0.2257123\ttest: 0.2250727\tbestTest: 0.2250727 (82)\ttotal: 10m 59s\tremaining: 2m 15s\n",
      "83: learn: 0.2255683\ttest: 0.2249289\tbestTest: 0.2249289 (83)\ttotal: 11m 7s\tremaining: 2m 7s\n",
      "84: learn: 0.2254281\ttest: 0.22479\tbestTest: 0.22479 (84)\ttotal: 11m 14s\tremaining: 1m 59s\n",
      "85: learn: 0.2252718\ttest: 0.2246377\tbestTest: 0.2246377 (85)\ttotal: 11m 22s\tremaining: 1m 51s\n",
      "86: learn: 0.2251565\ttest: 0.2245217\tbestTest: 0.2245217 (86)\ttotal: 11m 31s\tremaining: 1m 43s\n",
      "87: learn: 0.2250441\ttest: 0.2244087\tbestTest: 0.2244087 (87)\ttotal: 11m 39s\tremaining: 1m 35s\n",
      "88: learn: 0.2249178\ttest: 0.2242846\tbestTest: 0.2242846 (88)\ttotal: 11m 46s\tremaining: 1m 27s\n",
      "89: learn: 0.2248233\ttest: 0.2241901\tbestTest: 0.2241901 (89)\ttotal: 11m 54s\tremaining: 1m 19s\n",
      "90: learn: 0.2247006\ttest: 0.2240683\tbestTest: 0.2240683 (90)\ttotal: 12m 2s\tremaining: 1m 11s\n",
      "91: learn: 0.2245925\ttest: 0.2239624\tbestTest: 0.2239624 (91)\ttotal: 12m 10s\tremaining: 1m 3s\n",
      "92: learn: 0.2244946\ttest: 0.2238668\tbestTest: 0.2238668 (92)\ttotal: 12m 18s\tremaining: 55.6s\n",
      "93: learn: 0.2243992\ttest: 0.2237742\tbestTest: 0.2237742 (93)\ttotal: 12m 26s\tremaining: 47.6s\n",
      "94: learn: 0.2243017\ttest: 0.2236789\tbestTest: 0.2236789 (94)\ttotal: 12m 34s\tremaining: 39.7s\n",
      "95: learn: 0.2242171\ttest: 0.2235946\tbestTest: 0.2235946 (95)\ttotal: 12m 42s\tremaining: 31.8s\n",
      "96: learn: 0.2241361\ttest: 0.2235147\tbestTest: 0.2235147 (96)\ttotal: 12m 49s\tremaining: 23.8s\n",
      "97: learn: 0.2240441\ttest: 0.2234231\tbestTest: 0.2234231 (97)\ttotal: 12m 58s\tremaining: 15.9s\n",
      "98: learn: 0.2239481\ttest: 0.2233313\tbestTest: 0.2233313 (98)\ttotal: 13m 6s\tremaining: 7.94s\n",
      "99: learn: 0.2238754\ttest: 0.2232583\tbestTest: 0.2232583 (99)\ttotal: 13m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2232582649\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 21:32:36.143564\n",
      "train time given below\n",
      "0:16:46.420184\n",
      "2018-03-14 21:32:36.150877\n",
      "2018-03-14 21:32:36.154387\n",
      "GINI ISIT = 0.472580599455\n",
      "2018-03-14 21:34:13.543813\n",
      "GINI OSIT = 0.471884272582\n",
      "2018-03-14 21:34:56.551887\n",
      "GINI OSOT = 0.421360705303\n",
      "2018-03-14 21:35:08.727697\n",
      "2018-03-14 21:35:08.729690\n"
     ]
    }
   ],
   "source": [
    "#optimize depth\n",
    "\n",
    "for dep in dep_pv:\n",
    "    \n",
    "    print('depth = ' + str(dep))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_opt,\n",
    "                           lrn_rt = lrn_rt_def,\n",
    "                           dep = dep,\n",
    "                           l2_reg = l2_reg_opt,\n",
    "                           num_split = num_split_opt,\n",
    "                           cat_split = cat_split_opt,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_opt\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt_def\n",
    "    result_df_temp.loc[0,'depth'] = dep\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_opt\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_opt\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_opt\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451849</td>\n",
       "      <td>0.453623</td>\n",
       "      <td>0.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.45484</td>\n",
       "      <td>0.407005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>0.405824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45513</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454684</td>\n",
       "      <td>0.456024</td>\n",
       "      <td>0.408098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455045</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.40867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45336</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.408261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454922</td>\n",
       "      <td>0.456109</td>\n",
       "      <td>0.410751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456208</td>\n",
       "      <td>0.457545</td>\n",
       "      <td>0.41235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454801</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>0.411622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45617</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.411126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.409276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441066</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>0.396312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.450992</td>\n",
       "      <td>0.404413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460658</td>\n",
       "      <td>0.461646</td>\n",
       "      <td>0.416653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>0.465669</td>\n",
       "      <td>0.41762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468306</td>\n",
       "      <td>0.468324</td>\n",
       "      <td>0.417121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree   rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100     1          0.03     6                 1             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 5             128   \n",
       "0    100     1          0.03     6                10             128   \n",
       "0    100     1          0.03     6                50             128   \n",
       "0    100     1          0.03     6               100             128   \n",
       "0    100     1          0.03     6                 3               5   \n",
       "0    100     1          0.03     6                 3              10   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              32   \n",
       "0    100     1          0.03     6                 3              64   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             255   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100   0.5          0.03     6                 3              16   \n",
       "0    100   0.6          0.03     6                 3              16   \n",
       "0    100   0.7          0.03     6                 3              16   \n",
       "0    100  0.75          0.03     6                 3              16   \n",
       "0    100   0.8          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100   0.9          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     4                 3              16   \n",
       "0    100  0.85          0.03     5                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     7                 3              16   \n",
       "0    100  0.85          0.03     8                 3              16   \n",
       "0    100  0.85          0.03     9                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  \n",
       "0                 5                   1  0.451849  0.453623  0.402904  \n",
       "0                10                   1  0.453604   0.45484  0.407005  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                32                   1  0.453115  0.454388  0.405824  \n",
       "0                64                   1   0.45513  0.456311  0.409631  \n",
       "0               128                   1  0.454684  0.456024  0.408098  \n",
       "0               255                   1  0.455045  0.456244   0.40867  \n",
       "0                16                   1   0.45336  0.454692  0.408261  \n",
       "0                16                   1  0.454922  0.456109  0.410751  \n",
       "0                16                   1  0.456208  0.457545   0.41235  \n",
       "0                16                   1  0.454801  0.456263  0.411622  \n",
       "0                16                   1   0.45617  0.457539  0.411126  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.456422  0.457679  0.409276  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.441066  0.442915  0.396312  \n",
       "0                16                   1  0.449438  0.450992  0.404413  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.460658  0.461646  0.416653  \n",
       "0                16                   1  0.465061  0.465669   0.41762  \n",
       "0                16                   1  0.468306  0.468324  0.417121  \n",
       "0                16                   1  0.472581  0.471884  0.421361  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_opt=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.01\n",
      "2018-03-14 21:42:53.354781\n",
      "model train start\n",
      "2018-03-14 21:42:53.355327\n",
      "0: learn: 0.6809733\ttest: 0.680967\tbestTest: 0.680967 (0)\ttotal: 6.24s\tremaining: 10m 17s\n",
      "1: learn: 0.6692245\ttest: 0.6692138\tbestTest: 0.6692138 (1)\ttotal: 14.8s\tremaining: 12m 4s\n",
      "2: learn: 0.6579237\ttest: 0.6579085\tbestTest: 0.6579085 (2)\ttotal: 23s\tremaining: 12m 23s\n",
      "3: learn: 0.6466216\ttest: 0.6466192\tbestTest: 0.6466192 (3)\ttotal: 32s\tremaining: 12m 47s\n",
      "4: learn: 0.6356272\ttest: 0.6356212\tbestTest: 0.6356212 (4)\ttotal: 40.1s\tremaining: 12m 42s\n",
      "5: learn: 0.6249101\ttest: 0.6248992\tbestTest: 0.6248992 (5)\ttotal: 47.9s\tremaining: 12m 30s\n",
      "6: learn: 0.6143861\ttest: 0.6143667\tbestTest: 0.6143667 (6)\ttotal: 56.4s\tremaining: 12m 29s\n",
      "7: learn: 0.6041749\ttest: 0.6041471\tbestTest: 0.6041471 (7)\ttotal: 1m 5s\tremaining: 12m 35s\n",
      "8: learn: 0.5944685\ttest: 0.5944309\tbestTest: 0.5944309 (8)\ttotal: 1m 14s\tremaining: 12m 31s\n",
      "9: learn: 0.5848424\ttest: 0.5848008\tbestTest: 0.5848008 (9)\ttotal: 1m 21s\tremaining: 12m 13s\n",
      "10: learn: 0.5756198\ttest: 0.5755722\tbestTest: 0.5755722 (10)\ttotal: 1m 29s\tremaining: 12m 2s\n",
      "11: learn: 0.5666644\ttest: 0.5666117\tbestTest: 0.5666117 (11)\ttotal: 1m 35s\tremaining: 11m 38s\n",
      "12: learn: 0.5581487\ttest: 0.5580869\tbestTest: 0.5580869 (12)\ttotal: 1m 38s\tremaining: 10m 57s\n",
      "13: learn: 0.5494925\ttest: 0.5494234\tbestTest: 0.5494234 (13)\ttotal: 1m 46s\tremaining: 10m 52s\n",
      "14: learn: 0.5410882\ttest: 0.541011\tbestTest: 0.541011 (14)\ttotal: 1m 54s\tremaining: 10m 51s\n",
      "15: learn: 0.5328672\ttest: 0.5327848\tbestTest: 0.5327848 (15)\ttotal: 2m 3s\tremaining: 10m 48s\n",
      "16: learn: 0.5248918\ttest: 0.5248048\tbestTest: 0.5248048 (16)\ttotal: 2m 11s\tremaining: 10m 41s\n",
      "17: learn: 0.5171815\ttest: 0.5170836\tbestTest: 0.5170836 (17)\ttotal: 2m 19s\tremaining: 10m 36s\n",
      "18: learn: 0.509694\ttest: 0.5095888\tbestTest: 0.5095888 (18)\ttotal: 2m 27s\tremaining: 10m 30s\n",
      "19: learn: 0.5024042\ttest: 0.5022928\tbestTest: 0.5022928 (19)\ttotal: 2m 35s\tremaining: 10m 20s\n",
      "20: learn: 0.4952931\ttest: 0.495174\tbestTest: 0.495174 (20)\ttotal: 2m 43s\tremaining: 10m 13s\n",
      "21: learn: 0.4882762\ttest: 0.4881517\tbestTest: 0.4881517 (21)\ttotal: 2m 50s\tremaining: 10m 4s\n",
      "22: learn: 0.4815482\ttest: 0.4814156\tbestTest: 0.4814156 (22)\ttotal: 2m 59s\tremaining: 9m 59s\n",
      "23: learn: 0.4750172\ttest: 0.4748805\tbestTest: 0.4748805 (23)\ttotal: 3m 8s\tremaining: 9m 55s\n",
      "24: learn: 0.4688141\ttest: 0.4686712\tbestTest: 0.4686712 (24)\ttotal: 3m 17s\tremaining: 9m 51s\n",
      "25: learn: 0.4625186\ttest: 0.4623701\tbestTest: 0.4623701 (25)\ttotal: 3m 25s\tremaining: 9m 44s\n",
      "26: learn: 0.4567548\ttest: 0.4565991\tbestTest: 0.4565991 (26)\ttotal: 3m 30s\tremaining: 9m 29s\n",
      "27: learn: 0.4508334\ttest: 0.4506733\tbestTest: 0.4506733 (27)\ttotal: 3m 38s\tremaining: 9m 23s\n",
      "28: learn: 0.4451119\ttest: 0.4449465\tbestTest: 0.4449465 (28)\ttotal: 3m 46s\tremaining: 9m 14s\n",
      "29: learn: 0.4395483\ttest: 0.4393776\tbestTest: 0.4393776 (29)\ttotal: 3m 55s\tremaining: 9m 8s\n",
      "30: learn: 0.434144\ttest: 0.4339701\tbestTest: 0.4339701 (30)\ttotal: 4m 3s\tremaining: 9m 1s\n",
      "31: learn: 0.428762\ttest: 0.4285805\tbestTest: 0.4285805 (31)\ttotal: 4m 10s\tremaining: 8m 52s\n",
      "32: learn: 0.4236968\ttest: 0.4235102\tbestTest: 0.4235102 (32)\ttotal: 4m 19s\tremaining: 8m 46s\n",
      "33: learn: 0.4186622\ttest: 0.4184697\tbestTest: 0.4184697 (33)\ttotal: 4m 27s\tremaining: 8m 39s\n",
      "34: learn: 0.4137121\ttest: 0.4135112\tbestTest: 0.4135112 (34)\ttotal: 4m 36s\tremaining: 8m 33s\n",
      "35: learn: 0.4089119\ttest: 0.4087045\tbestTest: 0.4087045 (35)\ttotal: 4m 44s\tremaining: 8m 25s\n",
      "36: learn: 0.4044205\ttest: 0.4042086\tbestTest: 0.4042086 (36)\ttotal: 4m 52s\tremaining: 8m 17s\n",
      "37: learn: 0.399985\ttest: 0.3997678\tbestTest: 0.3997678 (37)\ttotal: 5m\tremaining: 8m 10s\n",
      "38: learn: 0.3958095\ttest: 0.3955889\tbestTest: 0.3955889 (38)\ttotal: 5m 9s\tremaining: 8m 4s\n",
      "39: learn: 0.3915796\ttest: 0.3913519\tbestTest: 0.3913519 (39)\ttotal: 5m 17s\tremaining: 7m 55s\n",
      "40: learn: 0.387433\ttest: 0.3871995\tbestTest: 0.3871995 (40)\ttotal: 5m 24s\tremaining: 7m 47s\n",
      "41: learn: 0.3838345\ttest: 0.3835944\tbestTest: 0.3835944 (41)\ttotal: 5m 26s\tremaining: 7m 30s\n",
      "42: learn: 0.3799816\ttest: 0.3797346\tbestTest: 0.3797346 (42)\ttotal: 5m 35s\tremaining: 7m 24s\n",
      "43: learn: 0.3762478\ttest: 0.3759935\tbestTest: 0.3759935 (43)\ttotal: 5m 43s\tremaining: 7m 17s\n",
      "44: learn: 0.3726557\ttest: 0.3723965\tbestTest: 0.3723965 (44)\ttotal: 5m 51s\tremaining: 7m 9s\n",
      "45: learn: 0.368981\ttest: 0.3687163\tbestTest: 0.3687163 (45)\ttotal: 5m 59s\tremaining: 7m 1s\n",
      "46: learn: 0.3656055\ttest: 0.3653364\tbestTest: 0.3653364 (46)\ttotal: 6m 7s\tremaining: 6m 54s\n",
      "47: learn: 0.3621272\ttest: 0.3618519\tbestTest: 0.3618519 (47)\ttotal: 6m 15s\tremaining: 6m 46s\n",
      "48: learn: 0.3587681\ttest: 0.3584875\tbestTest: 0.3584875 (48)\ttotal: 6m 23s\tremaining: 6m 39s\n",
      "49: learn: 0.3558005\ttest: 0.3555142\tbestTest: 0.3555142 (49)\ttotal: 6m 26s\tremaining: 6m 26s\n",
      "50: learn: 0.3526194\ttest: 0.3523275\tbestTest: 0.3523275 (50)\ttotal: 6m 34s\tremaining: 6m 19s\n",
      "51: learn: 0.3494956\ttest: 0.3491986\tbestTest: 0.3491986 (51)\ttotal: 6m 42s\tremaining: 6m 11s\n",
      "52: learn: 0.3466569\ttest: 0.3463554\tbestTest: 0.3463554 (52)\ttotal: 6m 50s\tremaining: 6m 4s\n",
      "53: learn: 0.3437094\ttest: 0.3434019\tbestTest: 0.3434019 (53)\ttotal: 6m 58s\tremaining: 5m 56s\n",
      "54: learn: 0.3408765\ttest: 0.3405638\tbestTest: 0.3405638 (54)\ttotal: 7m 6s\tremaining: 5m 48s\n",
      "55: learn: 0.3380797\ttest: 0.3377614\tbestTest: 0.3377614 (55)\ttotal: 7m 14s\tremaining: 5m 41s\n",
      "56: learn: 0.335373\ttest: 0.3350481\tbestTest: 0.3350481 (56)\ttotal: 7m 22s\tremaining: 5m 33s\n",
      "57: learn: 0.3327024\ttest: 0.3323742\tbestTest: 0.3323742 (57)\ttotal: 7m 30s\tremaining: 5m 26s\n",
      "58: learn: 0.3301052\ttest: 0.3297728\tbestTest: 0.3297728 (58)\ttotal: 7m 38s\tremaining: 5m 18s\n",
      "59: learn: 0.3278609\ttest: 0.3275229\tbestTest: 0.3275229 (59)\ttotal: 7m 41s\tremaining: 5m 7s\n",
      "60: learn: 0.3255045\ttest: 0.3251615\tbestTest: 0.3251615 (60)\ttotal: 7m 46s\tremaining: 4m 58s\n",
      "61: learn: 0.3232045\ttest: 0.3228574\tbestTest: 0.3228574 (61)\ttotal: 7m 53s\tremaining: 4m 49s\n",
      "62: learn: 0.3208995\ttest: 0.3205484\tbestTest: 0.3205484 (62)\ttotal: 8m\tremaining: 4m 42s\n",
      "63: learn: 0.3187861\ttest: 0.3184314\tbestTest: 0.3184314 (63)\ttotal: 8m 7s\tremaining: 4m 34s\n",
      "64: learn: 0.3166015\ttest: 0.3162428\tbestTest: 0.3162428 (64)\ttotal: 8m 15s\tremaining: 4m 26s\n",
      "65: learn: 0.3144416\ttest: 0.3140795\tbestTest: 0.3140795 (65)\ttotal: 8m 23s\tremaining: 4m 19s\n",
      "66: learn: 0.3123002\ttest: 0.3119316\tbestTest: 0.3119316 (66)\ttotal: 8m 32s\tremaining: 4m 12s\n",
      "67: learn: 0.3103042\ttest: 0.3099331\tbestTest: 0.3099331 (67)\ttotal: 8m 40s\tremaining: 4m 4s\n",
      "68: learn: 0.3083279\ttest: 0.3079512\tbestTest: 0.3079512 (68)\ttotal: 8m 47s\tremaining: 3m 57s\n",
      "69: learn: 0.3064166\ttest: 0.3060352\tbestTest: 0.3060352 (69)\ttotal: 8m 54s\tremaining: 3m 48s\n",
      "70: learn: 0.3045768\ttest: 0.3041925\tbestTest: 0.3041925 (70)\ttotal: 9m 2s\tremaining: 3m 41s\n",
      "71: learn: 0.3029806\ttest: 0.3025915\tbestTest: 0.3025915 (71)\ttotal: 9m 3s\tremaining: 3m 31s\n",
      "72: learn: 0.3012144\ttest: 0.3008216\tbestTest: 0.3008216 (72)\ttotal: 9m 11s\tremaining: 3m 23s\n",
      "73: learn: 0.2994381\ttest: 0.299041\tbestTest: 0.299041 (73)\ttotal: 9m 19s\tremaining: 3m 16s\n",
      "74: learn: 0.2977789\ttest: 0.2973788\tbestTest: 0.2973788 (74)\ttotal: 9m 27s\tremaining: 3m 9s\n",
      "75: learn: 0.2961031\ttest: 0.2956982\tbestTest: 0.2956982 (75)\ttotal: 9m 35s\tremaining: 3m 1s\n",
      "76: learn: 0.29448\ttest: 0.2940678\tbestTest: 0.2940678 (76)\ttotal: 9m 43s\tremaining: 2m 54s\n",
      "77: learn: 0.2928911\ttest: 0.2924758\tbestTest: 0.2924758 (77)\ttotal: 9m 51s\tremaining: 2m 46s\n",
      "78: learn: 0.2913243\ttest: 0.2909056\tbestTest: 0.2909056 (78)\ttotal: 9m 59s\tremaining: 2m 39s\n",
      "79: learn: 0.2897883\ttest: 0.2893647\tbestTest: 0.2893647 (79)\ttotal: 10m 6s\tremaining: 2m 31s\n",
      "80: learn: 0.2884046\ttest: 0.2879775\tbestTest: 0.2879775 (80)\ttotal: 10m 14s\tremaining: 2m 24s\n",
      "81: learn: 0.2869493\ttest: 0.2865187\tbestTest: 0.2865187 (81)\ttotal: 10m 23s\tremaining: 2m 16s\n",
      "82: learn: 0.2854972\ttest: 0.285062\tbestTest: 0.285062 (82)\ttotal: 10m 30s\tremaining: 2m 9s\n",
      "83: learn: 0.2841222\ttest: 0.2836829\tbestTest: 0.2836829 (83)\ttotal: 10m 39s\tremaining: 2m 1s\n",
      "84: learn: 0.2829445\ttest: 0.2825008\tbestTest: 0.2825008 (84)\ttotal: 10m 43s\tremaining: 1m 53s\n",
      "85: learn: 0.2816375\ttest: 0.2811897\tbestTest: 0.2811897 (85)\ttotal: 10m 51s\tremaining: 1m 46s\n",
      "86: learn: 0.2804286\ttest: 0.2799781\tbestTest: 0.2799781 (86)\ttotal: 10m 59s\tremaining: 1m 38s\n",
      "87: learn: 0.279249\ttest: 0.2787951\tbestTest: 0.2787951 (87)\ttotal: 11m 4s\tremaining: 1m 30s\n",
      "88: learn: 0.277997\ttest: 0.2775398\tbestTest: 0.2775398 (88)\ttotal: 11m 11s\tremaining: 1m 23s\n",
      "89: learn: 0.2769295\ttest: 0.276469\tbestTest: 0.276469 (89)\ttotal: 11m 19s\tremaining: 1m 15s\n",
      "90: learn: 0.2757489\ttest: 0.2752843\tbestTest: 0.2752843 (90)\ttotal: 11m 27s\tremaining: 1m 8s\n",
      "91: learn: 0.274625\ttest: 0.2741578\tbestTest: 0.2741578 (91)\ttotal: 11m 35s\tremaining: 1m\n",
      "92: learn: 0.2735057\ttest: 0.273035\tbestTest: 0.273035 (92)\ttotal: 11m 42s\tremaining: 52.9s\n",
      "93: learn: 0.2725525\ttest: 0.272083\tbestTest: 0.272083 (93)\ttotal: 11m 48s\tremaining: 45.2s\n",
      "94: learn: 0.2715234\ttest: 0.2710513\tbestTest: 0.2710513 (94)\ttotal: 11m 56s\tremaining: 37.7s\n",
      "95: learn: 0.2705036\ttest: 0.2700282\tbestTest: 0.2700282 (95)\ttotal: 12m 4s\tremaining: 30.2s\n",
      "96: learn: 0.2694777\ttest: 0.2689993\tbestTest: 0.2689993 (96)\ttotal: 12m 12s\tremaining: 22.7s\n",
      "97: learn: 0.2684781\ttest: 0.2679964\tbestTest: 0.2679964 (97)\ttotal: 12m 20s\tremaining: 15.1s\n",
      "98: learn: 0.2675809\ttest: 0.267096\tbestTest: 0.267096 (98)\ttotal: 12m 29s\tremaining: 7.57s\n",
      "99: learn: 0.2666536\ttest: 0.2661647\tbestTest: 0.2661647 (99)\ttotal: 12m 36s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2661647181\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.01_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 21:59:04.108434\n",
      "train time given below\n",
      "0:16:10.753107\n",
      "2018-03-14 21:59:04.171599\n",
      "2018-03-14 21:59:04.175095\n",
      "GINI ISIT = 0.451027259346\n",
      "2018-03-14 22:00:40.494279\n",
      "GINI OSIT = 0.451404956352\n",
      "2018-03-14 22:01:21.532440\n",
      "GINI OSOT = 0.400854836241\n",
      "2018-03-14 22:01:33.823760\n",
      "2018-03-14 22:01:33.825699\n",
      "loop run time\n",
      "0:18:40.470920\n",
      "learning rate = 0.02\n",
      "2018-03-14 22:01:33.827326\n",
      "model train start\n",
      "2018-03-14 22:01:33.827540\n",
      "0: learn: 0.6690009\ttest: 0.6689882\tbestTest: 0.6689882 (0)\ttotal: 6.15s\tremaining: 10m 9s\n",
      "1: learn: 0.6463135\ttest: 0.6462918\tbestTest: 0.6462918 (1)\ttotal: 14.3s\tremaining: 11m 42s\n",
      "2: learn: 0.6250748\ttest: 0.6250438\tbestTest: 0.6250438 (2)\ttotal: 22.7s\tremaining: 12m 15s\n",
      "3: learn: 0.6043861\ttest: 0.6043771\tbestTest: 0.6043771 (3)\ttotal: 31.8s\tremaining: 12m 44s\n",
      "4: learn: 0.584603\ttest: 0.5845812\tbestTest: 0.5845812 (4)\ttotal: 40.4s\tremaining: 12m 46s\n",
      "5: learn: 0.5662338\ttest: 0.5661921\tbestTest: 0.5661921 (5)\ttotal: 46s\tremaining: 12m\n",
      "6: learn: 0.5484127\ttest: 0.5483664\tbestTest: 0.5483664 (6)\ttotal: 54.2s\tremaining: 12m\n",
      "7: learn: 0.5318625\ttest: 0.5318082\tbestTest: 0.5318082 (7)\ttotal: 1m 1s\tremaining: 11m 51s\n",
      "8: learn: 0.5162578\ttest: 0.5161949\tbestTest: 0.5161949 (8)\ttotal: 1m 10s\tremaining: 11m 49s\n",
      "9: learn: 0.501469\ttest: 0.5013846\tbestTest: 0.5013846 (9)\ttotal: 1m 18s\tremaining: 11m 49s\n",
      "10: learn: 0.4871214\ttest: 0.4870189\tbestTest: 0.4870189 (10)\ttotal: 1m 26s\tremaining: 11m 42s\n",
      "11: learn: 0.4740729\ttest: 0.4739574\tbestTest: 0.4739574 (11)\ttotal: 1m 35s\tremaining: 11m 41s\n",
      "12: learn: 0.4615425\ttest: 0.461417\tbestTest: 0.461417 (12)\ttotal: 1m 43s\tremaining: 11m 34s\n",
      "13: learn: 0.4498959\ttest: 0.4497606\tbestTest: 0.4497606 (13)\ttotal: 1m 50s\tremaining: 11m 17s\n",
      "14: learn: 0.4387679\ttest: 0.438626\tbestTest: 0.438626 (14)\ttotal: 1m 55s\tremaining: 10m 56s\n",
      "15: learn: 0.4282229\ttest: 0.4280634\tbestTest: 0.4280634 (15)\ttotal: 2m 4s\tremaining: 10m 54s\n",
      "16: learn: 0.4183626\ttest: 0.4181891\tbestTest: 0.4181891 (16)\ttotal: 2m 11s\tremaining: 10m 43s\n",
      "17: learn: 0.4093227\ttest: 0.4091347\tbestTest: 0.4091347 (17)\ttotal: 2m 14s\tremaining: 10m 13s\n",
      "18: learn: 0.4002411\ttest: 0.4000397\tbestTest: 0.4000397 (18)\ttotal: 2m 22s\tremaining: 10m 6s\n",
      "19: learn: 0.3920937\ttest: 0.3918817\tbestTest: 0.3918817 (19)\ttotal: 2m 26s\tremaining: 9m 44s\n",
      "20: learn: 0.3839051\ttest: 0.3836766\tbestTest: 0.3836766 (20)\ttotal: 2m 33s\tremaining: 9m 36s\n",
      "21: learn: 0.3761244\ttest: 0.3758989\tbestTest: 0.3758989 (21)\ttotal: 2m 42s\tremaining: 9m 34s\n",
      "22: learn: 0.3687771\ttest: 0.3685356\tbestTest: 0.3685356 (22)\ttotal: 2m 49s\tremaining: 9m 27s\n",
      "23: learn: 0.3618541\ttest: 0.3616009\tbestTest: 0.3616009 (23)\ttotal: 2m 57s\tremaining: 9m 20s\n",
      "24: learn: 0.3552039\ttest: 0.3549299\tbestTest: 0.3549299 (24)\ttotal: 3m 5s\tremaining: 9m 17s\n",
      "25: learn: 0.3490202\ttest: 0.3487305\tbestTest: 0.3487305 (25)\ttotal: 3m 14s\tremaining: 9m 13s\n",
      "26: learn: 0.3430065\ttest: 0.3427096\tbestTest: 0.3427096 (26)\ttotal: 3m 22s\tremaining: 9m 6s\n",
      "27: learn: 0.3376977\ttest: 0.3373943\tbestTest: 0.3373943 (27)\ttotal: 3m 30s\tremaining: 9m 1s\n",
      "28: learn: 0.3324493\ttest: 0.3321323\tbestTest: 0.3321323 (28)\ttotal: 3m 39s\tremaining: 8m 56s\n",
      "29: learn: 0.3275128\ttest: 0.3271847\tbestTest: 0.3271847 (29)\ttotal: 3m 47s\tremaining: 8m 51s\n",
      "30: learn: 0.322965\ttest: 0.3226275\tbestTest: 0.3226275 (30)\ttotal: 3m 54s\tremaining: 8m 42s\n",
      "31: learn: 0.3184206\ttest: 0.3180746\tbestTest: 0.3180746 (31)\ttotal: 4m 1s\tremaining: 8m 34s\n",
      "32: learn: 0.31402\ttest: 0.3136588\tbestTest: 0.3136588 (32)\ttotal: 4m 9s\tremaining: 8m 27s\n",
      "33: learn: 0.3098636\ttest: 0.3094926\tbestTest: 0.3094926 (33)\ttotal: 4m 18s\tremaining: 8m 21s\n",
      "34: learn: 0.3059342\ttest: 0.305554\tbestTest: 0.305554 (34)\ttotal: 4m 27s\tremaining: 8m 16s\n",
      "35: learn: 0.3022912\ttest: 0.3019025\tbestTest: 0.3019025 (35)\ttotal: 4m 35s\tremaining: 8m 9s\n",
      "36: learn: 0.2987968\ttest: 0.2984005\tbestTest: 0.2984005 (36)\ttotal: 4m 43s\tremaining: 8m 3s\n",
      "37: learn: 0.2955248\ttest: 0.2951209\tbestTest: 0.2951209 (37)\ttotal: 4m 52s\tremaining: 7m 56s\n",
      "38: learn: 0.2923632\ttest: 0.291951\tbestTest: 0.291951 (38)\ttotal: 4m 59s\tremaining: 7m 48s\n",
      "39: learn: 0.2892952\ttest: 0.2888759\tbestTest: 0.2888759 (39)\ttotal: 5m 8s\tremaining: 7m 42s\n",
      "40: learn: 0.2863431\ttest: 0.2859131\tbestTest: 0.2859131 (40)\ttotal: 5m 15s\tremaining: 7m 34s\n",
      "41: learn: 0.2840004\ttest: 0.2835617\tbestTest: 0.2835617 (41)\ttotal: 5m 17s\tremaining: 7m 17s\n",
      "42: learn: 0.2813743\ttest: 0.2809297\tbestTest: 0.2809297 (42)\ttotal: 5m 25s\tremaining: 7m 11s\n",
      "43: learn: 0.2790583\ttest: 0.2786058\tbestTest: 0.2786058 (43)\ttotal: 5m 34s\tremaining: 7m 6s\n",
      "44: learn: 0.2767014\ttest: 0.2762425\tbestTest: 0.2762425 (44)\ttotal: 5m 43s\tremaining: 6m 59s\n",
      "45: learn: 0.2743821\ttest: 0.2739154\tbestTest: 0.2739154 (45)\ttotal: 5m 50s\tremaining: 6m 51s\n",
      "46: learn: 0.2722103\ttest: 0.2717348\tbestTest: 0.2717348 (46)\ttotal: 5m 58s\tremaining: 6m 44s\n",
      "47: learn: 0.2701268\ttest: 0.2696465\tbestTest: 0.2696465 (47)\ttotal: 6m 6s\tremaining: 6m 37s\n",
      "48: learn: 0.2680519\ttest: 0.2675634\tbestTest: 0.2675634 (48)\ttotal: 6m 14s\tremaining: 6m 29s\n",
      "49: learn: 0.2662019\ttest: 0.265705\tbestTest: 0.265705 (49)\ttotal: 6m 22s\tremaining: 6m 22s\n",
      "50: learn: 0.2643748\ttest: 0.2638733\tbestTest: 0.2638733 (50)\ttotal: 6m 30s\tremaining: 6m 15s\n",
      "51: learn: 0.2625774\ttest: 0.2620711\tbestTest: 0.2620711 (51)\ttotal: 6m 38s\tremaining: 6m 7s\n",
      "52: learn: 0.2609154\ttest: 0.2604027\tbestTest: 0.2604027 (52)\ttotal: 6m 46s\tremaining: 6m\n",
      "53: learn: 0.2593652\ttest: 0.2588473\tbestTest: 0.2588473 (53)\ttotal: 6m 55s\tremaining: 5m 54s\n",
      "54: learn: 0.2578958\ttest: 0.2573745\tbestTest: 0.2573745 (54)\ttotal: 7m 3s\tremaining: 5m 46s\n",
      "55: learn: 0.2566465\ttest: 0.2561194\tbestTest: 0.2561194 (55)\ttotal: 7m 11s\tremaining: 5m 39s\n",
      "56: learn: 0.2552816\ttest: 0.2547505\tbestTest: 0.2547505 (56)\ttotal: 7m 20s\tremaining: 5m 32s\n",
      "57: learn: 0.2539284\ttest: 0.2533914\tbestTest: 0.2533914 (57)\ttotal: 7m 27s\tremaining: 5m 24s\n",
      "58: learn: 0.2527193\ttest: 0.2521792\tbestTest: 0.2521792 (58)\ttotal: 7m 35s\tremaining: 5m 16s\n",
      "59: learn: 0.2515531\ttest: 0.2510097\tbestTest: 0.2510097 (59)\ttotal: 7m 43s\tremaining: 5m 9s\n",
      "60: learn: 0.2505111\ttest: 0.2499634\tbestTest: 0.2499634 (60)\ttotal: 7m 51s\tremaining: 5m 1s\n",
      "61: learn: 0.2494281\ttest: 0.2488746\tbestTest: 0.2488746 (61)\ttotal: 8m\tremaining: 4m 54s\n",
      "62: learn: 0.2483931\ttest: 0.2478359\tbestTest: 0.2478359 (62)\ttotal: 8m 8s\tremaining: 4m 46s\n",
      "63: learn: 0.2474782\ttest: 0.246918\tbestTest: 0.246918 (63)\ttotal: 8m 16s\tremaining: 4m 39s\n",
      "64: learn: 0.2466093\ttest: 0.246044\tbestTest: 0.246044 (64)\ttotal: 8m 22s\tremaining: 4m 30s\n",
      "65: learn: 0.2457224\ttest: 0.2451549\tbestTest: 0.2451549 (65)\ttotal: 8m 30s\tremaining: 4m 23s\n",
      "66: learn: 0.2448301\ttest: 0.2442575\tbestTest: 0.2442575 (66)\ttotal: 8m 38s\tremaining: 4m 15s\n",
      "67: learn: 0.2439834\ttest: 0.2434074\tbestTest: 0.2434074 (67)\ttotal: 8m 47s\tremaining: 4m 8s\n",
      "68: learn: 0.2431592\ttest: 0.2425781\tbestTest: 0.2425781 (68)\ttotal: 8m 55s\tremaining: 4m\n",
      "69: learn: 0.2423602\ttest: 0.2417745\tbestTest: 0.2417745 (69)\ttotal: 9m 2s\tremaining: 3m 52s\n",
      "70: learn: 0.2418081\ttest: 0.2412178\tbestTest: 0.2412178 (70)\ttotal: 9m 4s\tremaining: 3m 42s\n",
      "71: learn: 0.2410829\ttest: 0.2404883\tbestTest: 0.2404883 (71)\ttotal: 9m 12s\tremaining: 3m 34s\n",
      "72: learn: 0.2404402\ttest: 0.2398415\tbestTest: 0.2398415 (72)\ttotal: 9m 19s\tremaining: 3m 27s\n",
      "73: learn: 0.2397981\ttest: 0.2391981\tbestTest: 0.2391981 (73)\ttotal: 9m 28s\tremaining: 3m 19s\n",
      "74: learn: 0.2391693\ttest: 0.2385664\tbestTest: 0.2385664 (74)\ttotal: 9m 36s\tremaining: 3m 12s\n",
      "75: learn: 0.2385772\ttest: 0.237972\tbestTest: 0.237972 (75)\ttotal: 9m 44s\tremaining: 3m 4s\n",
      "76: learn: 0.2380006\ttest: 0.237394\tbestTest: 0.237394 (76)\ttotal: 9m 51s\tremaining: 2m 56s\n",
      "77: learn: 0.2374659\ttest: 0.2368565\tbestTest: 0.2368565 (77)\ttotal: 9m 59s\tremaining: 2m 48s\n",
      "78: learn: 0.2369319\ttest: 0.2363214\tbestTest: 0.2363214 (78)\ttotal: 10m 6s\tremaining: 2m 41s\n",
      "79: learn: 0.2364128\ttest: 0.2358014\tbestTest: 0.2358014 (79)\ttotal: 10m 14s\tremaining: 2m 33s\n",
      "80: learn: 0.2359405\ttest: 0.2353257\tbestTest: 0.2353257 (80)\ttotal: 10m 22s\tremaining: 2m 26s\n",
      "81: learn: 0.2354712\ttest: 0.2348541\tbestTest: 0.2348541 (81)\ttotal: 10m 30s\tremaining: 2m 18s\n",
      "82: learn: 0.2350223\ttest: 0.2344016\tbestTest: 0.2344016 (82)\ttotal: 10m 37s\tremaining: 2m 10s\n",
      "83: learn: 0.2345926\ttest: 0.2339721\tbestTest: 0.2339721 (83)\ttotal: 10m 45s\tremaining: 2m 2s\n",
      "84: learn: 0.2341887\ttest: 0.2335647\tbestTest: 0.2335647 (84)\ttotal: 10m 53s\tremaining: 1m 55s\n",
      "85: learn: 0.2338213\ttest: 0.2331956\tbestTest: 0.2331956 (85)\ttotal: 11m 1s\tremaining: 1m 47s\n",
      "86: learn: 0.2335496\ttest: 0.2329202\tbestTest: 0.2329202 (86)\ttotal: 11m 4s\tremaining: 1m 39s\n",
      "87: learn: 0.2331824\ttest: 0.2325528\tbestTest: 0.2325528 (87)\ttotal: 11m 12s\tremaining: 1m 31s\n",
      "88: learn: 0.2328437\ttest: 0.2322082\tbestTest: 0.2322082 (88)\ttotal: 11m 20s\tremaining: 1m 24s\n",
      "89: learn: 0.2325089\ttest: 0.2318724\tbestTest: 0.2318724 (89)\ttotal: 11m 29s\tremaining: 1m 16s\n",
      "90: learn: 0.2322056\ttest: 0.2315688\tbestTest: 0.2315688 (90)\ttotal: 11m 37s\tremaining: 1m 8s\n",
      "91: learn: 0.2318766\ttest: 0.2312379\tbestTest: 0.2312379 (91)\ttotal: 11m 45s\tremaining: 1m 1s\n",
      "92: learn: 0.2315448\ttest: 0.2309074\tbestTest: 0.2309074 (92)\ttotal: 11m 52s\tremaining: 53.7s\n",
      "93: learn: 0.2312482\ttest: 0.2306086\tbestTest: 0.2306086 (93)\ttotal: 12m 1s\tremaining: 46s\n",
      "94: learn: 0.2309467\ttest: 0.2303051\tbestTest: 0.2303051 (94)\ttotal: 12m 8s\tremaining: 38.4s\n",
      "95: learn: 0.2306718\ttest: 0.2300288\tbestTest: 0.2300288 (95)\ttotal: 12m 16s\tremaining: 30.7s\n",
      "96: learn: 0.2303992\ttest: 0.2297556\tbestTest: 0.2297556 (96)\ttotal: 12m 24s\tremaining: 23s\n",
      "97: learn: 0.2301339\ttest: 0.229489\tbestTest: 0.229489 (97)\ttotal: 12m 32s\tremaining: 15.4s\n",
      "98: learn: 0.229872\ttest: 0.2292259\tbestTest: 0.2292259 (98)\ttotal: 12m 39s\tremaining: 7.67s\n",
      "99: learn: 0.2296534\ttest: 0.2290062\tbestTest: 0.2290062 (99)\ttotal: 12m 48s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2290061569\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.02_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 22:17:55.720501\n",
      "train time given below\n",
      "0:16:21.892961\n",
      "2018-03-14 22:17:55.893244\n",
      "2018-03-14 22:17:55.897017\n",
      "GINI ISIT = 0.462710335722\n",
      "2018-03-14 22:19:37.401888\n",
      "GINI OSIT = 0.462658234783\n",
      "2018-03-14 22:20:17.322409\n",
      "GINI OSOT = 0.418592383203\n",
      "2018-03-14 22:20:30.035908\n",
      "2018-03-14 22:20:30.038209\n",
      "loop run time\n",
      "0:18:56.210880\n",
      "learning rate = 0.03\n",
      "2018-03-14 22:20:30.039925\n",
      "model train start\n",
      "2018-03-14 22:20:30.040153\n",
      "0: learn: 0.6572298\ttest: 0.6572107\tbestTest: 0.6572107 (0)\ttotal: 6.06s\tremaining: 9m 59s\n",
      "1: learn: 0.6243889\ttest: 0.6243559\tbestTest: 0.6243559 (1)\ttotal: 14.6s\tremaining: 11m 57s\n",
      "2: learn: 0.5948854\ttest: 0.5948369\tbestTest: 0.5948369 (2)\ttotal: 18.6s\tremaining: 10m 2s\n",
      "3: learn: 0.566821\ttest: 0.5667426\tbestTest: 0.5667426 (3)\ttotal: 26.7s\tremaining: 10m 41s\n",
      "4: learn: 0.5407037\ttest: 0.5406124\tbestTest: 0.5406124 (4)\ttotal: 35s\tremaining: 11m 5s\n",
      "5: learn: 0.5163833\ttest: 0.5162596\tbestTest: 0.5162596 (5)\ttotal: 43.5s\tremaining: 11m 21s\n",
      "6: learn: 0.4950901\ttest: 0.4949348\tbestTest: 0.4949348 (6)\ttotal: 46.1s\tremaining: 10m 12s\n",
      "7: learn: 0.4744867\ttest: 0.4743141\tbestTest: 0.4743141 (7)\ttotal: 54.7s\tremaining: 10m 29s\n",
      "8: learn: 0.4557634\ttest: 0.4555658\tbestTest: 0.4555658 (8)\ttotal: 1m\tremaining: 10m 9s\n",
      "9: learn: 0.4382239\ttest: 0.4380192\tbestTest: 0.4380192 (9)\ttotal: 1m 8s\tremaining: 10m 20s\n",
      "10: learn: 0.4224004\ttest: 0.4221631\tbestTest: 0.4221631 (10)\ttotal: 1m 17s\tremaining: 10m 26s\n",
      "11: learn: 0.4081616\ttest: 0.4079104\tbestTest: 0.4079104 (11)\ttotal: 1m 23s\tremaining: 10m 12s\n",
      "12: learn: 0.3950533\ttest: 0.3947927\tbestTest: 0.3947927 (12)\ttotal: 1m 32s\tremaining: 10m 15s\n",
      "13: learn: 0.3827336\ttest: 0.3824485\tbestTest: 0.3824485 (13)\ttotal: 1m 40s\tremaining: 10m 18s\n",
      "14: learn: 0.3713146\ttest: 0.3710146\tbestTest: 0.3710146 (14)\ttotal: 1m 48s\tremaining: 10m 16s\n",
      "15: learn: 0.360697\ttest: 0.360383\tbestTest: 0.360383 (15)\ttotal: 1m 57s\tremaining: 10m 14s\n",
      "16: learn: 0.3506589\ttest: 0.3503253\tbestTest: 0.3503253 (16)\ttotal: 2m 4s\tremaining: 10m 8s\n",
      "17: learn: 0.3418275\ttest: 0.3414667\tbestTest: 0.3414667 (17)\ttotal: 2m 12s\tremaining: 10m 5s\n",
      "18: learn: 0.3339514\ttest: 0.3335859\tbestTest: 0.3335859 (18)\ttotal: 2m 20s\tremaining: 10m\n",
      "19: learn: 0.3263053\ttest: 0.3259258\tbestTest: 0.3259258 (19)\ttotal: 2m 28s\tremaining: 9m 54s\n",
      "20: learn: 0.3192944\ttest: 0.3189032\tbestTest: 0.3189032 (20)\ttotal: 2m 36s\tremaining: 9m 48s\n",
      "21: learn: 0.3132016\ttest: 0.3127995\tbestTest: 0.3127995 (21)\ttotal: 2m 45s\tremaining: 9m 45s\n",
      "22: learn: 0.3070842\ttest: 0.3066661\tbestTest: 0.3066661 (22)\ttotal: 2m 53s\tremaining: 9m 41s\n",
      "23: learn: 0.3012812\ttest: 0.3008447\tbestTest: 0.3008447 (23)\ttotal: 3m\tremaining: 9m 32s\n",
      "24: learn: 0.2963313\ttest: 0.2958848\tbestTest: 0.2958848 (24)\ttotal: 3m 8s\tremaining: 9m 26s\n",
      "25: learn: 0.2915392\ttest: 0.291083\tbestTest: 0.291083 (25)\ttotal: 3m 17s\tremaining: 9m 21s\n",
      "26: learn: 0.2870378\ttest: 0.2865712\tbestTest: 0.2865712 (26)\ttotal: 3m 25s\tremaining: 9m 16s\n",
      "27: learn: 0.2827206\ttest: 0.2822421\tbestTest: 0.2822421 (27)\ttotal: 3m 33s\tremaining: 9m 7s\n",
      "28: learn: 0.2789125\ttest: 0.2784207\tbestTest: 0.2784207 (28)\ttotal: 3m 41s\tremaining: 9m 1s\n",
      "29: learn: 0.2754887\ttest: 0.2749906\tbestTest: 0.2749906 (29)\ttotal: 3m 49s\tremaining: 8m 55s\n",
      "30: learn: 0.272221\ttest: 0.2717117\tbestTest: 0.2717117 (30)\ttotal: 3m 57s\tremaining: 8m 49s\n",
      "31: learn: 0.2691781\ttest: 0.2686581\tbestTest: 0.2686581 (31)\ttotal: 4m 5s\tremaining: 8m 42s\n",
      "32: learn: 0.2663065\ttest: 0.2657801\tbestTest: 0.2657801 (32)\ttotal: 4m 13s\tremaining: 8m 35s\n",
      "33: learn: 0.2635659\ttest: 0.2630334\tbestTest: 0.2630334 (33)\ttotal: 4m 21s\tremaining: 8m 27s\n",
      "34: learn: 0.2613232\ttest: 0.2607841\tbestTest: 0.2607841 (34)\ttotal: 4m 29s\tremaining: 8m 21s\n",
      "35: learn: 0.2588712\ttest: 0.2583218\tbestTest: 0.2583218 (35)\ttotal: 4m 38s\tremaining: 8m 14s\n",
      "36: learn: 0.256753\ttest: 0.2561988\tbestTest: 0.2561988 (36)\ttotal: 4m 47s\tremaining: 8m 9s\n",
      "37: learn: 0.2547531\ttest: 0.254191\tbestTest: 0.254191 (37)\ttotal: 4m 55s\tremaining: 8m 1s\n",
      "38: learn: 0.2529197\ttest: 0.2523516\tbestTest: 0.2523516 (38)\ttotal: 5m 2s\tremaining: 7m 53s\n",
      "39: learn: 0.2511384\ttest: 0.2505647\tbestTest: 0.2505647 (39)\ttotal: 5m 11s\tremaining: 7m 46s\n",
      "40: learn: 0.249494\ttest: 0.2489162\tbestTest: 0.2489162 (40)\ttotal: 5m 19s\tremaining: 7m 39s\n",
      "41: learn: 0.2479717\ttest: 0.2473872\tbestTest: 0.2473872 (41)\ttotal: 5m 26s\tremaining: 7m 30s\n",
      "42: learn: 0.246527\ttest: 0.2459378\tbestTest: 0.2459378 (42)\ttotal: 5m 33s\tremaining: 7m 22s\n",
      "43: learn: 0.2451701\ttest: 0.2445766\tbestTest: 0.2445766 (43)\ttotal: 5m 42s\tremaining: 7m 15s\n",
      "44: learn: 0.2438539\ttest: 0.2432608\tbestTest: 0.2432608 (44)\ttotal: 5m 50s\tremaining: 7m 8s\n",
      "45: learn: 0.2426417\ttest: 0.2420449\tbestTest: 0.2420449 (45)\ttotal: 5m 57s\tremaining: 6m 59s\n",
      "46: learn: 0.2415383\ttest: 0.2409387\tbestTest: 0.2409387 (46)\ttotal: 6m 4s\tremaining: 6m 51s\n",
      "47: learn: 0.2404725\ttest: 0.2398691\tbestTest: 0.2398691 (47)\ttotal: 6m 13s\tremaining: 6m 44s\n",
      "48: learn: 0.2394844\ttest: 0.2388796\tbestTest: 0.2388796 (48)\ttotal: 6m 21s\tremaining: 6m 37s\n",
      "49: learn: 0.2386349\ttest: 0.2380307\tbestTest: 0.2380307 (49)\ttotal: 6m 29s\tremaining: 6m 29s\n",
      "50: learn: 0.2377612\ttest: 0.2371506\tbestTest: 0.2371506 (50)\ttotal: 6m 36s\tremaining: 6m 20s\n",
      "51: learn: 0.2370007\ttest: 0.2363881\tbestTest: 0.2363881 (51)\ttotal: 6m 44s\tremaining: 6m 13s\n",
      "52: learn: 0.2362521\ttest: 0.2356336\tbestTest: 0.2356336 (52)\ttotal: 6m 52s\tremaining: 6m 5s\n",
      "53: learn: 0.2355667\ttest: 0.2349479\tbestTest: 0.2349479 (53)\ttotal: 7m\tremaining: 5m 57s\n",
      "54: learn: 0.234903\ttest: 0.2342823\tbestTest: 0.2342823 (54)\ttotal: 7m 7s\tremaining: 5m 50s\n",
      "55: learn: 0.2343147\ttest: 0.2336934\tbestTest: 0.2336934 (55)\ttotal: 7m 15s\tremaining: 5m 42s\n",
      "56: learn: 0.2336905\ttest: 0.2330659\tbestTest: 0.2330659 (56)\ttotal: 7m 23s\tremaining: 5m 34s\n",
      "57: learn: 0.2331059\ttest: 0.2324797\tbestTest: 0.2324797 (57)\ttotal: 7m 30s\tremaining: 5m 26s\n",
      "58: learn: 0.2325831\ttest: 0.2319534\tbestTest: 0.2319534 (58)\ttotal: 7m 38s\tremaining: 5m 18s\n",
      "59: learn: 0.2320878\ttest: 0.231456\tbestTest: 0.231456 (59)\ttotal: 7m 45s\tremaining: 5m 10s\n",
      "60: learn: 0.2316151\ttest: 0.2309783\tbestTest: 0.2309783 (60)\ttotal: 7m 54s\tremaining: 5m 3s\n",
      "61: learn: 0.2311826\ttest: 0.2305449\tbestTest: 0.2305449 (61)\ttotal: 8m 1s\tremaining: 4m 55s\n",
      "62: learn: 0.2308001\ttest: 0.2301621\tbestTest: 0.2301621 (62)\ttotal: 8m 9s\tremaining: 4m 47s\n",
      "63: learn: 0.2304092\ttest: 0.2297706\tbestTest: 0.2297706 (63)\ttotal: 8m 16s\tremaining: 4m 39s\n",
      "64: learn: 0.2300321\ttest: 0.2293935\tbestTest: 0.2293935 (64)\ttotal: 8m 24s\tremaining: 4m 31s\n",
      "65: learn: 0.2296699\ttest: 0.2290321\tbestTest: 0.2290321 (65)\ttotal: 8m 32s\tremaining: 4m 24s\n",
      "66: learn: 0.2293438\ttest: 0.2287031\tbestTest: 0.2287031 (66)\ttotal: 8m 40s\tremaining: 4m 16s\n",
      "67: learn: 0.2289917\ttest: 0.228349\tbestTest: 0.228349 (67)\ttotal: 8m 47s\tremaining: 4m 8s\n",
      "68: learn: 0.2286443\ttest: 0.2280031\tbestTest: 0.2280031 (68)\ttotal: 8m 56s\tremaining: 4m\n",
      "69: learn: 0.2283596\ttest: 0.2277183\tbestTest: 0.2277183 (69)\ttotal: 9m 3s\tremaining: 3m 53s\n",
      "70: learn: 0.2280716\ttest: 0.2274312\tbestTest: 0.2274312 (70)\ttotal: 9m 12s\tremaining: 3m 45s\n",
      "71: learn: 0.2278393\ttest: 0.2271976\tbestTest: 0.2271976 (71)\ttotal: 9m 19s\tremaining: 3m 37s\n",
      "72: learn: 0.2275963\ttest: 0.2269511\tbestTest: 0.2269511 (72)\ttotal: 9m 27s\tremaining: 3m 29s\n",
      "73: learn: 0.2273727\ttest: 0.2267268\tbestTest: 0.2267268 (73)\ttotal: 9m 36s\tremaining: 3m 22s\n",
      "74: learn: 0.2271494\ttest: 0.2265023\tbestTest: 0.2265023 (74)\ttotal: 9m 43s\tremaining: 3m 14s\n",
      "75: learn: 0.2269439\ttest: 0.2262969\tbestTest: 0.2262969 (75)\ttotal: 9m 51s\tremaining: 3m 6s\n",
      "76: learn: 0.2267635\ttest: 0.226116\tbestTest: 0.226116 (76)\ttotal: 10m\tremaining: 2m 59s\n",
      "77: learn: 0.2265529\ttest: 0.2259072\tbestTest: 0.2259072 (77)\ttotal: 10m 8s\tremaining: 2m 51s\n",
      "78: learn: 0.2263594\ttest: 0.2257169\tbestTest: 0.2257169 (78)\ttotal: 10m 15s\tremaining: 2m 43s\n",
      "79: learn: 0.2262102\ttest: 0.2255677\tbestTest: 0.2255677 (79)\ttotal: 10m 24s\tremaining: 2m 36s\n",
      "80: learn: 0.2260202\ttest: 0.2253791\tbestTest: 0.2253791 (80)\ttotal: 10m 31s\tremaining: 2m 28s\n",
      "81: learn: 0.2258522\ttest: 0.2252117\tbestTest: 0.2252117 (81)\ttotal: 10m 39s\tremaining: 2m 20s\n",
      "82: learn: 0.2257123\ttest: 0.2250727\tbestTest: 0.2250727 (82)\ttotal: 10m 47s\tremaining: 2m 12s\n",
      "83: learn: 0.2255683\ttest: 0.2249289\tbestTest: 0.2249289 (83)\ttotal: 10m 54s\tremaining: 2m 4s\n",
      "84: learn: 0.2254281\ttest: 0.22479\tbestTest: 0.22479 (84)\ttotal: 11m 1s\tremaining: 1m 56s\n",
      "85: learn: 0.2252718\ttest: 0.2246377\tbestTest: 0.2246377 (85)\ttotal: 11m 9s\tremaining: 1m 48s\n",
      "86: learn: 0.2251565\ttest: 0.2245217\tbestTest: 0.2245217 (86)\ttotal: 11m 17s\tremaining: 1m 41s\n",
      "87: learn: 0.2250441\ttest: 0.2244087\tbestTest: 0.2244087 (87)\ttotal: 11m 25s\tremaining: 1m 33s\n",
      "88: learn: 0.2249178\ttest: 0.2242846\tbestTest: 0.2242846 (88)\ttotal: 11m 33s\tremaining: 1m 25s\n",
      "89: learn: 0.2248233\ttest: 0.2241901\tbestTest: 0.2241901 (89)\ttotal: 11m 41s\tremaining: 1m 17s\n",
      "90: learn: 0.2247006\ttest: 0.2240683\tbestTest: 0.2240683 (90)\ttotal: 11m 49s\tremaining: 1m 10s\n",
      "91: learn: 0.2245925\ttest: 0.2239624\tbestTest: 0.2239624 (91)\ttotal: 11m 56s\tremaining: 1m 2s\n",
      "92: learn: 0.2244946\ttest: 0.2238668\tbestTest: 0.2238668 (92)\ttotal: 12m 5s\tremaining: 54.6s\n",
      "93: learn: 0.2243992\ttest: 0.2237742\tbestTest: 0.2237742 (93)\ttotal: 12m 12s\tremaining: 46.8s\n",
      "94: learn: 0.2243017\ttest: 0.2236789\tbestTest: 0.2236789 (94)\ttotal: 12m 21s\tremaining: 39s\n",
      "95: learn: 0.2242171\ttest: 0.2235946\tbestTest: 0.2235946 (95)\ttotal: 12m 28s\tremaining: 31.2s\n",
      "96: learn: 0.2241361\ttest: 0.2235147\tbestTest: 0.2235147 (96)\ttotal: 12m 36s\tremaining: 23.4s\n",
      "97: learn: 0.2240441\ttest: 0.2234231\tbestTest: 0.2234231 (97)\ttotal: 12m 44s\tremaining: 15.6s\n",
      "98: learn: 0.2239481\ttest: 0.2233313\tbestTest: 0.2233313 (98)\ttotal: 12m 52s\tremaining: 7.8s\n",
      "99: learn: 0.2238754\ttest: 0.2232583\tbestTest: 0.2232583 (99)\ttotal: 13m\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2232582649\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.03_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 22:37:02.031528\n",
      "train time given below\n",
      "0:16:31.991375\n",
      "2018-03-14 22:37:02.090179\n",
      "2018-03-14 22:37:02.094017\n",
      "GINI ISIT = 0.472580599455\n",
      "2018-03-14 22:38:35.897664\n",
      "GINI OSIT = 0.471884272582\n",
      "2018-03-14 22:39:15.515548\n",
      "GINI OSOT = 0.421360705303\n",
      "2018-03-14 22:39:27.860423\n",
      "2018-03-14 22:39:27.862525\n",
      "loop run time\n",
      "0:18:57.822597\n",
      "learning rate = 0.05\n",
      "2018-03-14 22:39:27.864172\n",
      "model train start\n",
      "2018-03-14 22:39:27.864387\n",
      "0: learn: 0.6342908\ttest: 0.6342585\tbestTest: 0.6342585 (0)\ttotal: 6.16s\tremaining: 10m 9s\n",
      "1: learn: 0.5833933\ttest: 0.5833369\tbestTest: 0.5833369 (1)\ttotal: 14.5s\tremaining: 11m 51s\n",
      "2: learn: 0.5399227\ttest: 0.5398259\tbestTest: 0.5398259 (2)\ttotal: 18.5s\tremaining: 9m 59s\n",
      "3: learn: 0.5010276\ttest: 0.5008902\tbestTest: 0.5008902 (3)\ttotal: 24.6s\tremaining: 9m 51s\n",
      "4: learn: 0.4662307\ttest: 0.4660693\tbestTest: 0.4660693 (4)\ttotal: 32.6s\tremaining: 10m 19s\n",
      "5: learn: 0.4363761\ttest: 0.4361715\tbestTest: 0.4361715 (5)\ttotal: 41.1s\tremaining: 10m 43s\n",
      "6: learn: 0.4103483\ttest: 0.4101041\tbestTest: 0.4101041 (6)\ttotal: 50.2s\tremaining: 11m 7s\n",
      "7: learn: 0.3880164\ttest: 0.3877482\tbestTest: 0.3877482 (7)\ttotal: 59.4s\tremaining: 11m 23s\n",
      "8: learn: 0.3693182\ttest: 0.3690361\tbestTest: 0.3690361 (8)\ttotal: 1m 5s\tremaining: 11m 7s\n",
      "9: learn: 0.3533893\ttest: 0.3530865\tbestTest: 0.3530865 (9)\ttotal: 1m 11s\tremaining: 10m 39s\n",
      "10: learn: 0.3384294\ttest: 0.3380992\tbestTest: 0.3380992 (10)\ttotal: 1m 19s\tremaining: 10m 41s\n",
      "11: learn: 0.325856\ttest: 0.3254933\tbestTest: 0.3254933 (11)\ttotal: 1m 28s\tremaining: 10m 45s\n",
      "12: learn: 0.3146236\ttest: 0.3142361\tbestTest: 0.3142361 (12)\ttotal: 1m 36s\tremaining: 10m 45s\n",
      "13: learn: 0.3043828\ttest: 0.3039693\tbestTest: 0.3039693 (13)\ttotal: 1m 44s\tremaining: 10m 40s\n",
      "14: learn: 0.2953768\ttest: 0.2949464\tbestTest: 0.2949464 (14)\ttotal: 1m 51s\tremaining: 10m 33s\n",
      "15: learn: 0.2883767\ttest: 0.2879234\tbestTest: 0.2879234 (15)\ttotal: 1m 54s\tremaining: 10m\n",
      "16: learn: 0.2811553\ttest: 0.2806917\tbestTest: 0.2806917 (16)\ttotal: 2m 2s\tremaining: 9m 56s\n",
      "17: learn: 0.2750541\ttest: 0.2745687\tbestTest: 0.2745687 (17)\ttotal: 2m 10s\tremaining: 9m 52s\n",
      "18: learn: 0.2695628\ttest: 0.2690629\tbestTest: 0.2690629 (18)\ttotal: 2m 18s\tremaining: 9m 48s\n",
      "19: learn: 0.2646008\ttest: 0.2640801\tbestTest: 0.2640801 (19)\ttotal: 2m 27s\tremaining: 9m 48s\n",
      "20: learn: 0.2604774\ttest: 0.2599462\tbestTest: 0.2599462 (20)\ttotal: 2m 35s\tremaining: 9m 44s\n",
      "21: learn: 0.2566097\ttest: 0.2560622\tbestTest: 0.2560622 (21)\ttotal: 2m 42s\tremaining: 9m 37s\n",
      "22: learn: 0.2531703\ttest: 0.2526155\tbestTest: 0.2526155 (22)\ttotal: 2m 50s\tremaining: 9m 30s\n",
      "23: learn: 0.2503454\ttest: 0.2497824\tbestTest: 0.2497824 (23)\ttotal: 2m 59s\tremaining: 9m 27s\n",
      "24: learn: 0.2477626\ttest: 0.2471863\tbestTest: 0.2471863 (24)\ttotal: 3m 8s\tremaining: 9m 25s\n",
      "25: learn: 0.2453579\ttest: 0.2447722\tbestTest: 0.2447722 (25)\ttotal: 3m 17s\tremaining: 9m 21s\n",
      "26: learn: 0.2432117\ttest: 0.242621\tbestTest: 0.242621 (26)\ttotal: 3m 24s\tremaining: 9m 14s\n",
      "27: learn: 0.241306\ttest: 0.2407045\tbestTest: 0.2407045 (27)\ttotal: 3m 32s\tremaining: 9m 6s\n",
      "28: learn: 0.2395612\ttest: 0.2389492\tbestTest: 0.2389492 (28)\ttotal: 3m 40s\tremaining: 8m 58s\n",
      "29: learn: 0.2382322\ttest: 0.2376124\tbestTest: 0.2376124 (29)\ttotal: 3m 48s\tremaining: 8m 53s\n",
      "30: learn: 0.2370012\ttest: 0.2363774\tbestTest: 0.2363774 (30)\ttotal: 3m 56s\tremaining: 8m 45s\n",
      "31: learn: 0.2357161\ttest: 0.2350872\tbestTest: 0.2350872 (31)\ttotal: 4m 4s\tremaining: 8m 39s\n",
      "32: learn: 0.2346218\ttest: 0.2339912\tbestTest: 0.2339912 (32)\ttotal: 4m 11s\tremaining: 8m 31s\n",
      "33: learn: 0.2336457\ttest: 0.2330139\tbestTest: 0.2330139 (33)\ttotal: 4m 19s\tremaining: 8m 23s\n",
      "34: learn: 0.2326884\ttest: 0.2320549\tbestTest: 0.2320549 (34)\ttotal: 4m 27s\tremaining: 8m 16s\n",
      "35: learn: 0.2318318\ttest: 0.2311963\tbestTest: 0.2311963 (35)\ttotal: 4m 35s\tremaining: 8m 10s\n",
      "36: learn: 0.2311518\ttest: 0.2305155\tbestTest: 0.2305155 (36)\ttotal: 4m 44s\tremaining: 8m 4s\n",
      "37: learn: 0.2304913\ttest: 0.2298489\tbestTest: 0.2298489 (37)\ttotal: 4m 52s\tremaining: 7m 57s\n",
      "38: learn: 0.2298632\ttest: 0.2292225\tbestTest: 0.2292225 (38)\ttotal: 5m\tremaining: 7m 49s\n",
      "39: learn: 0.2292838\ttest: 0.2286402\tbestTest: 0.2286402 (39)\ttotal: 5m 8s\tremaining: 7m 42s\n",
      "40: learn: 0.2287603\ttest: 0.2281177\tbestTest: 0.2281177 (40)\ttotal: 5m 15s\tremaining: 7m 34s\n",
      "41: learn: 0.2282947\ttest: 0.2276485\tbestTest: 0.2276485 (41)\ttotal: 5m 24s\tremaining: 7m 27s\n",
      "42: learn: 0.2278818\ttest: 0.2272315\tbestTest: 0.2272315 (42)\ttotal: 5m 31s\tremaining: 7m 19s\n",
      "43: learn: 0.2274655\ttest: 0.2268156\tbestTest: 0.2268156 (43)\ttotal: 5m 39s\tremaining: 7m 11s\n",
      "44: learn: 0.2271108\ttest: 0.2264614\tbestTest: 0.2264614 (44)\ttotal: 5m 46s\tremaining: 7m 3s\n",
      "45: learn: 0.2268072\ttest: 0.2261554\tbestTest: 0.2261554 (45)\ttotal: 5m 54s\tremaining: 6m 56s\n",
      "46: learn: 0.2264771\ttest: 0.2258271\tbestTest: 0.2258271 (46)\ttotal: 6m 2s\tremaining: 6m 48s\n",
      "47: learn: 0.2261943\ttest: 0.2255487\tbestTest: 0.2255487 (47)\ttotal: 6m 10s\tremaining: 6m 41s\n",
      "48: learn: 0.2258614\ttest: 0.2252196\tbestTest: 0.2252196 (48)\ttotal: 6m 17s\tremaining: 6m 33s\n",
      "49: learn: 0.2256315\ttest: 0.2249959\tbestTest: 0.2249959 (49)\ttotal: 6m 25s\tremaining: 6m 25s\n",
      "50: learn: 0.2253824\ttest: 0.2247542\tbestTest: 0.2247542 (50)\ttotal: 6m 33s\tremaining: 6m 17s\n",
      "51: learn: 0.2251611\ttest: 0.2245364\tbestTest: 0.2245364 (51)\ttotal: 6m 40s\tremaining: 6m 9s\n",
      "52: learn: 0.2249653\ttest: 0.2243412\tbestTest: 0.2243412 (52)\ttotal: 6m 48s\tremaining: 6m 2s\n",
      "53: learn: 0.2247477\ttest: 0.2241256\tbestTest: 0.2241256 (53)\ttotal: 6m 55s\tremaining: 5m 54s\n",
      "54: learn: 0.224573\ttest: 0.2239529\tbestTest: 0.2239529 (54)\ttotal: 7m 4s\tremaining: 5m 46s\n",
      "55: learn: 0.2244226\ttest: 0.2238014\tbestTest: 0.2238014 (55)\ttotal: 7m 11s\tremaining: 5m 39s\n",
      "56: learn: 0.224277\ttest: 0.2236603\tbestTest: 0.2236603 (56)\ttotal: 7m 19s\tremaining: 5m 31s\n",
      "57: learn: 0.224117\ttest: 0.2234997\tbestTest: 0.2234997 (57)\ttotal: 7m 28s\tremaining: 5m 24s\n",
      "58: learn: 0.2239886\ttest: 0.2233717\tbestTest: 0.2233717 (58)\ttotal: 7m 36s\tremaining: 5m 17s\n",
      "59: learn: 0.223866\ttest: 0.2232514\tbestTest: 0.2232514 (59)\ttotal: 7m 44s\tremaining: 5m 9s\n",
      "60: learn: 0.2237362\ttest: 0.2231262\tbestTest: 0.2231262 (60)\ttotal: 7m 52s\tremaining: 5m 1s\n",
      "61: learn: 0.223638\ttest: 0.2230282\tbestTest: 0.2230282 (61)\ttotal: 7m 59s\tremaining: 4m 54s\n",
      "62: learn: 0.2235376\ttest: 0.2229316\tbestTest: 0.2229316 (62)\ttotal: 8m 8s\tremaining: 4m 46s\n",
      "63: learn: 0.2234348\ttest: 0.222831\tbestTest: 0.222831 (63)\ttotal: 8m 16s\tremaining: 4m 39s\n",
      "64: learn: 0.2233517\ttest: 0.2227484\tbestTest: 0.2227484 (64)\ttotal: 8m 23s\tremaining: 4m 31s\n",
      "65: learn: 0.2232626\ttest: 0.2226618\tbestTest: 0.2226618 (65)\ttotal: 8m 31s\tremaining: 4m 23s\n",
      "66: learn: 0.2231777\ttest: 0.222581\tbestTest: 0.222581 (66)\ttotal: 8m 39s\tremaining: 4m 16s\n",
      "67: learn: 0.223054\ttest: 0.2224622\tbestTest: 0.2224622 (67)\ttotal: 8m 47s\tremaining: 4m 8s\n",
      "68: learn: 0.2229765\ttest: 0.222386\tbestTest: 0.222386 (68)\ttotal: 8m 56s\tremaining: 4m 1s\n",
      "69: learn: 0.2228965\ttest: 0.2223074\tbestTest: 0.2223074 (69)\ttotal: 9m 5s\tremaining: 3m 53s\n",
      "70: learn: 0.2228029\ttest: 0.2222171\tbestTest: 0.2222171 (70)\ttotal: 9m 13s\tremaining: 3m 46s\n",
      "71: learn: 0.2227362\ttest: 0.2221557\tbestTest: 0.2221557 (71)\ttotal: 9m 21s\tremaining: 3m 38s\n",
      "72: learn: 0.2226592\ttest: 0.2220863\tbestTest: 0.2220863 (72)\ttotal: 9m 28s\tremaining: 3m 30s\n",
      "73: learn: 0.222586\ttest: 0.222022\tbestTest: 0.222022 (73)\ttotal: 9m 37s\tremaining: 3m 22s\n",
      "74: learn: 0.2225137\ttest: 0.2219559\tbestTest: 0.2219559 (74)\ttotal: 9m 44s\tremaining: 3m 14s\n",
      "75: learn: 0.2224623\ttest: 0.2219092\tbestTest: 0.2219092 (75)\ttotal: 9m 51s\tremaining: 3m 6s\n",
      "76: learn: 0.2223971\ttest: 0.2218492\tbestTest: 0.2218492 (76)\ttotal: 10m\tremaining: 2m 59s\n",
      "77: learn: 0.222326\ttest: 0.221786\tbestTest: 0.221786 (77)\ttotal: 10m 8s\tremaining: 2m 51s\n",
      "78: learn: 0.2222647\ttest: 0.2217274\tbestTest: 0.2217274 (78)\ttotal: 10m 16s\tremaining: 2m 43s\n",
      "79: learn: 0.2221939\ttest: 0.2216644\tbestTest: 0.2216644 (79)\ttotal: 10m 24s\tremaining: 2m 36s\n",
      "80: learn: 0.222146\ttest: 0.2216213\tbestTest: 0.2216213 (80)\ttotal: 10m 32s\tremaining: 2m 28s\n",
      "81: learn: 0.2221168\ttest: 0.2215922\tbestTest: 0.2215922 (81)\ttotal: 10m 38s\tremaining: 2m 20s\n",
      "82: learn: 0.2220425\ttest: 0.2215214\tbestTest: 0.2215214 (82)\ttotal: 10m 46s\tremaining: 2m 12s\n",
      "83: learn: 0.2219918\ttest: 0.2214763\tbestTest: 0.2214763 (83)\ttotal: 10m 54s\tremaining: 2m 4s\n",
      "84: learn: 0.2219574\ttest: 0.2214442\tbestTest: 0.2214442 (84)\ttotal: 11m 2s\tremaining: 1m 56s\n",
      "85: learn: 0.221903\ttest: 0.2213972\tbestTest: 0.2213972 (85)\ttotal: 11m 9s\tremaining: 1m 49s\n",
      "86: learn: 0.2218729\ttest: 0.2213692\tbestTest: 0.2213692 (86)\ttotal: 11m 17s\tremaining: 1m 41s\n",
      "87: learn: 0.2218182\ttest: 0.2213196\tbestTest: 0.2213196 (87)\ttotal: 11m 25s\tremaining: 1m 33s\n",
      "88: learn: 0.2217712\ttest: 0.2212816\tbestTest: 0.2212816 (88)\ttotal: 11m 33s\tremaining: 1m 25s\n",
      "89: learn: 0.2217003\ttest: 0.2212227\tbestTest: 0.2212227 (89)\ttotal: 11m 40s\tremaining: 1m 17s\n",
      "90: learn: 0.2216555\ttest: 0.221185\tbestTest: 0.221185 (90)\ttotal: 11m 48s\tremaining: 1m 10s\n",
      "91: learn: 0.2216322\ttest: 0.2211633\tbestTest: 0.2211633 (91)\ttotal: 11m 56s\tremaining: 1m 2s\n",
      "92: learn: 0.2216055\ttest: 0.2211392\tbestTest: 0.2211392 (92)\ttotal: 12m 5s\tremaining: 54.6s\n",
      "93: learn: 0.2215736\ttest: 0.2211118\tbestTest: 0.2211118 (93)\ttotal: 12m 12s\tremaining: 46.8s\n",
      "94: learn: 0.2215297\ttest: 0.2210759\tbestTest: 0.2210759 (94)\ttotal: 12m 20s\tremaining: 39s\n",
      "95: learn: 0.2214872\ttest: 0.2210414\tbestTest: 0.2210414 (95)\ttotal: 12m 28s\tremaining: 31.2s\n",
      "96: learn: 0.2214404\ttest: 0.2210026\tbestTest: 0.2210026 (96)\ttotal: 12m 36s\tremaining: 23.4s\n",
      "97: learn: 0.2213921\ttest: 0.2209568\tbestTest: 0.2209568 (97)\ttotal: 12m 44s\tremaining: 15.6s\n",
      "98: learn: 0.2213394\ttest: 0.2209147\tbestTest: 0.2209147 (98)\ttotal: 12m 52s\tremaining: 7.8s\n",
      "99: learn: 0.2213109\ttest: 0.2208894\tbestTest: 0.2208894 (99)\ttotal: 13m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2208894411\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.05_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 22:55:56.595295\n",
      "train time given below\n",
      "0:16:28.730908\n",
      "2018-03-14 22:55:56.643343\n",
      "2018-03-14 22:55:56.646908\n",
      "GINI ISIT = 0.484077987197\n",
      "2018-03-14 22:57:29.135959\n",
      "GINI OSIT = 0.481967005769\n",
      "2018-03-14 22:58:07.989304\n",
      "GINI OSOT = 0.434896936487\n",
      "2018-03-14 22:58:19.951425\n",
      "2018-03-14 22:58:19.953444\n",
      "loop run time\n",
      "0:18:52.089272\n",
      "learning rate = 0.075\n",
      "2018-03-14 22:58:19.955104\n",
      "model train start\n",
      "2018-03-14 22:58:19.955288\n",
      "0: learn: 0.6067438\ttest: 0.6066943\tbestTest: 0.6066943 (0)\ttotal: 6.15s\tremaining: 10m 8s\n",
      "1: learn: 0.5359143\ttest: 0.5357794\tbestTest: 0.5357794 (1)\ttotal: 14.7s\tremaining: 11m 59s\n",
      "2: learn: 0.4805551\ttest: 0.4803735\tbestTest: 0.4803735 (2)\ttotal: 19.2s\tremaining: 10m 20s\n",
      "3: learn: 0.4335261\ttest: 0.4332844\tbestTest: 0.4332844 (3)\ttotal: 27.3s\tremaining: 10m 54s\n",
      "4: learn: 0.396553\ttest: 0.3962939\tbestTest: 0.3962939 (4)\ttotal: 35.8s\tremaining: 11m 20s\n",
      "5: learn: 0.3672449\ttest: 0.3669819\tbestTest: 0.3669819 (5)\ttotal: 44.7s\tremaining: 11m 39s\n",
      "6: learn: 0.3427831\ttest: 0.3424799\tbestTest: 0.3424799 (6)\ttotal: 52.6s\tremaining: 11m 38s\n",
      "7: learn: 0.3227354\ttest: 0.322389\tbestTest: 0.322389 (7)\ttotal: 1m\tremaining: 11m 31s\n",
      "8: learn: 0.3068248\ttest: 0.3064433\tbestTest: 0.3064433 (8)\ttotal: 1m 8s\tremaining: 11m 36s\n",
      "9: learn: 0.2934058\ttest: 0.2929961\tbestTest: 0.2929961 (9)\ttotal: 1m 16s\tremaining: 11m 31s\n",
      "10: learn: 0.2824028\ttest: 0.2819592\tbestTest: 0.2819592 (10)\ttotal: 1m 25s\tremaining: 11m 32s\n",
      "11: learn: 0.2728922\ttest: 0.2724148\tbestTest: 0.2724148 (11)\ttotal: 1m 33s\tremaining: 11m 23s\n",
      "12: learn: 0.2659805\ttest: 0.2654764\tbestTest: 0.2654764 (12)\ttotal: 1m 39s\tremaining: 11m 4s\n",
      "13: learn: 0.2595209\ttest: 0.2589906\tbestTest: 0.2589906 (13)\ttotal: 1m 48s\tremaining: 11m 4s\n",
      "14: learn: 0.2541142\ttest: 0.2535802\tbestTest: 0.2535802 (14)\ttotal: 1m 55s\tremaining: 10m 57s\n",
      "15: learn: 0.2495966\ttest: 0.2490415\tbestTest: 0.2490415 (15)\ttotal: 2m 4s\tremaining: 10m 52s\n",
      "16: learn: 0.245974\ttest: 0.2453996\tbestTest: 0.2453996 (16)\ttotal: 2m 12s\tremaining: 10m 47s\n",
      "17: learn: 0.2426973\ttest: 0.2421077\tbestTest: 0.2421077 (17)\ttotal: 2m 20s\tremaining: 10m 41s\n",
      "18: learn: 0.2399979\ttest: 0.2394067\tbestTest: 0.2394067 (18)\ttotal: 2m 28s\tremaining: 10m 32s\n",
      "19: learn: 0.2375672\ttest: 0.2369694\tbestTest: 0.2369694 (19)\ttotal: 2m 35s\tremaining: 10m 22s\n",
      "20: learn: 0.2357912\ttest: 0.2351825\tbestTest: 0.2351825 (20)\ttotal: 2m 43s\tremaining: 10m 14s\n",
      "21: learn: 0.2340412\ttest: 0.2334193\tbestTest: 0.2334193 (21)\ttotal: 2m 51s\tremaining: 10m 7s\n",
      "22: learn: 0.2326026\ttest: 0.2319829\tbestTest: 0.2319829 (22)\ttotal: 2m 58s\tremaining: 9m 58s\n",
      "23: learn: 0.2314063\ttest: 0.2307792\tbestTest: 0.2307792 (23)\ttotal: 3m 8s\tremaining: 9m 55s\n",
      "24: learn: 0.2303125\ttest: 0.2296825\tbestTest: 0.2296825 (24)\ttotal: 3m 15s\tremaining: 9m 47s\n",
      "25: learn: 0.2294166\ttest: 0.2287881\tbestTest: 0.2287881 (25)\ttotal: 3m 23s\tremaining: 9m 38s\n",
      "26: learn: 0.2286963\ttest: 0.2280618\tbestTest: 0.2280618 (26)\ttotal: 3m 31s\tremaining: 9m 32s\n",
      "27: learn: 0.2279603\ttest: 0.2273237\tbestTest: 0.2273237 (27)\ttotal: 3m 40s\tremaining: 9m 26s\n",
      "28: learn: 0.2273555\ttest: 0.2267223\tbestTest: 0.2267223 (28)\ttotal: 3m 47s\tremaining: 9m 17s\n",
      "29: learn: 0.2267911\ttest: 0.2261648\tbestTest: 0.2261648 (29)\ttotal: 3m 55s\tremaining: 9m 10s\n",
      "30: learn: 0.2262811\ttest: 0.2256514\tbestTest: 0.2256514 (30)\ttotal: 4m 2s\tremaining: 9m\n",
      "31: learn: 0.2258737\ttest: 0.2252445\tbestTest: 0.2252445 (31)\ttotal: 4m 10s\tremaining: 8m 51s\n",
      "32: learn: 0.2255453\ttest: 0.2249209\tbestTest: 0.2249209 (32)\ttotal: 4m 18s\tremaining: 8m 45s\n",
      "33: learn: 0.2251542\ttest: 0.2245332\tbestTest: 0.2245332 (33)\ttotal: 4m 26s\tremaining: 8m 36s\n",
      "34: learn: 0.2248303\ttest: 0.2242203\tbestTest: 0.2242203 (34)\ttotal: 4m 33s\tremaining: 8m 27s\n",
      "35: learn: 0.2245555\ttest: 0.2239494\tbestTest: 0.2239494 (35)\ttotal: 4m 41s\tremaining: 8m 19s\n",
      "36: learn: 0.2242919\ttest: 0.2236908\tbestTest: 0.2236908 (36)\ttotal: 4m 48s\tremaining: 8m 11s\n",
      "37: learn: 0.2240065\ttest: 0.2234207\tbestTest: 0.2234207 (37)\ttotal: 4m 57s\tremaining: 8m 4s\n",
      "38: learn: 0.2237977\ttest: 0.2232162\tbestTest: 0.2232162 (38)\ttotal: 5m 4s\tremaining: 7m 56s\n",
      "39: learn: 0.2236515\ttest: 0.2230737\tbestTest: 0.2230737 (39)\ttotal: 5m 12s\tremaining: 7m 48s\n",
      "40: learn: 0.2234974\ttest: 0.2229198\tbestTest: 0.2229198 (40)\ttotal: 5m 20s\tremaining: 7m 41s\n",
      "41: learn: 0.2233342\ttest: 0.2227649\tbestTest: 0.2227649 (41)\ttotal: 5m 27s\tremaining: 7m 32s\n",
      "42: learn: 0.2231726\ttest: 0.2226185\tbestTest: 0.2226185 (42)\ttotal: 5m 35s\tremaining: 7m 24s\n",
      "43: learn: 0.2230675\ttest: 0.2225156\tbestTest: 0.2225156 (43)\ttotal: 5m 43s\tremaining: 7m 17s\n",
      "44: learn: 0.2229234\ttest: 0.2223823\tbestTest: 0.2223823 (44)\ttotal: 5m 50s\tremaining: 7m 8s\n",
      "45: learn: 0.2227782\ttest: 0.2222404\tbestTest: 0.2222404 (45)\ttotal: 5m 58s\tremaining: 7m 1s\n",
      "46: learn: 0.2226588\ttest: 0.2221304\tbestTest: 0.2221304 (46)\ttotal: 6m 6s\tremaining: 6m 53s\n",
      "47: learn: 0.2225366\ttest: 0.222013\tbestTest: 0.222013 (47)\ttotal: 6m 14s\tremaining: 6m 45s\n",
      "48: learn: 0.222438\ttest: 0.2219229\tbestTest: 0.2219229 (48)\ttotal: 6m 21s\tremaining: 6m 37s\n",
      "49: learn: 0.2223385\ttest: 0.2218388\tbestTest: 0.2218388 (49)\ttotal: 6m 29s\tremaining: 6m 29s\n",
      "50: learn: 0.2222789\ttest: 0.2217794\tbestTest: 0.2217794 (50)\ttotal: 6m 37s\tremaining: 6m 21s\n",
      "51: learn: 0.2221952\ttest: 0.2217049\tbestTest: 0.2217049 (51)\ttotal: 6m 44s\tremaining: 6m 13s\n",
      "52: learn: 0.2221061\ttest: 0.2216192\tbestTest: 0.2216192 (52)\ttotal: 6m 51s\tremaining: 6m 5s\n",
      "53: learn: 0.2220326\ttest: 0.2215528\tbestTest: 0.2215528 (53)\ttotal: 6m 59s\tremaining: 5m 57s\n",
      "54: learn: 0.2219702\ttest: 0.2214933\tbestTest: 0.2214933 (54)\ttotal: 7m 7s\tremaining: 5m 49s\n",
      "55: learn: 0.221917\ttest: 0.2214423\tbestTest: 0.2214423 (55)\ttotal: 7m 15s\tremaining: 5m 41s\n",
      "56: learn: 0.2218308\ttest: 0.2213624\tbestTest: 0.2213624 (56)\ttotal: 7m 23s\tremaining: 5m 34s\n",
      "57: learn: 0.2217844\ttest: 0.2213213\tbestTest: 0.2213213 (57)\ttotal: 7m 31s\tremaining: 5m 27s\n",
      "58: learn: 0.221715\ttest: 0.2212558\tbestTest: 0.2212558 (58)\ttotal: 7m 39s\tremaining: 5m 19s\n",
      "59: learn: 0.2216414\ttest: 0.2211871\tbestTest: 0.2211871 (59)\ttotal: 7m 47s\tremaining: 5m 11s\n",
      "60: learn: 0.2215863\ttest: 0.221138\tbestTest: 0.221138 (60)\ttotal: 7m 55s\tremaining: 5m 4s\n",
      "61: learn: 0.2214992\ttest: 0.2210674\tbestTest: 0.2210674 (61)\ttotal: 8m 4s\tremaining: 4m 56s\n",
      "62: learn: 0.2214532\ttest: 0.2210302\tbestTest: 0.2210302 (62)\ttotal: 8m 12s\tremaining: 4m 49s\n",
      "63: learn: 0.2214032\ttest: 0.2209896\tbestTest: 0.2209896 (63)\ttotal: 8m 21s\tremaining: 4m 41s\n",
      "64: learn: 0.2213462\ttest: 0.2209479\tbestTest: 0.2209479 (64)\ttotal: 8m 28s\tremaining: 4m 33s\n",
      "65: learn: 0.2212906\ttest: 0.2208983\tbestTest: 0.2208983 (65)\ttotal: 8m 36s\tremaining: 4m 26s\n",
      "66: learn: 0.2212477\ttest: 0.2208643\tbestTest: 0.2208643 (66)\ttotal: 8m 44s\tremaining: 4m 18s\n",
      "67: learn: 0.221194\ttest: 0.2208195\tbestTest: 0.2208195 (67)\ttotal: 8m 52s\tremaining: 4m 10s\n",
      "68: learn: 0.221154\ttest: 0.2207855\tbestTest: 0.2207855 (68)\ttotal: 9m\tremaining: 4m 2s\n",
      "69: learn: 0.2211147\ttest: 0.2207511\tbestTest: 0.2207511 (69)\ttotal: 9m 7s\tremaining: 3m 54s\n",
      "70: learn: 0.2210511\ttest: 0.2207006\tbestTest: 0.2207006 (70)\ttotal: 9m 15s\tremaining: 3m 46s\n",
      "71: learn: 0.2210192\ttest: 0.2206714\tbestTest: 0.2206714 (71)\ttotal: 9m 24s\tremaining: 3m 39s\n",
      "72: learn: 0.2209602\ttest: 0.2206174\tbestTest: 0.2206174 (72)\ttotal: 9m 33s\tremaining: 3m 31s\n",
      "73: learn: 0.2209008\ttest: 0.2205726\tbestTest: 0.2205726 (73)\ttotal: 9m 40s\tremaining: 3m 24s\n",
      "74: learn: 0.2208442\ttest: 0.2205284\tbestTest: 0.2205284 (74)\ttotal: 9m 48s\tremaining: 3m 16s\n",
      "75: learn: 0.2208083\ttest: 0.2204993\tbestTest: 0.2204993 (75)\ttotal: 9m 56s\tremaining: 3m 8s\n",
      "76: learn: 0.2207588\ttest: 0.2204643\tbestTest: 0.2204643 (76)\ttotal: 10m 3s\tremaining: 3m\n",
      "77: learn: 0.2207302\ttest: 0.2204449\tbestTest: 0.2204449 (77)\ttotal: 10m 12s\tremaining: 2m 52s\n",
      "78: learn: 0.2206891\ttest: 0.2204088\tbestTest: 0.2204088 (78)\ttotal: 10m 20s\tremaining: 2m 44s\n",
      "79: learn: 0.2206462\ttest: 0.2203776\tbestTest: 0.2203776 (79)\ttotal: 10m 27s\tremaining: 2m 36s\n",
      "80: learn: 0.2206166\ttest: 0.2203518\tbestTest: 0.2203518 (80)\ttotal: 10m 35s\tremaining: 2m 29s\n",
      "81: learn: 0.2205835\ttest: 0.2203294\tbestTest: 0.2203294 (81)\ttotal: 10m 44s\tremaining: 2m 21s\n",
      "82: learn: 0.2205434\ttest: 0.220299\tbestTest: 0.220299 (82)\ttotal: 10m 52s\tremaining: 2m 13s\n",
      "83: learn: 0.2205229\ttest: 0.2202819\tbestTest: 0.2202819 (83)\ttotal: 11m 1s\tremaining: 2m 5s\n",
      "84: learn: 0.2204831\ttest: 0.2202499\tbestTest: 0.2202499 (84)\ttotal: 11m 9s\tremaining: 1m 58s\n",
      "85: learn: 0.2204502\ttest: 0.2202228\tbestTest: 0.2202228 (85)\ttotal: 11m 16s\tremaining: 1m 50s\n",
      "86: learn: 0.22041\ttest: 0.2201961\tbestTest: 0.2201961 (86)\ttotal: 11m 24s\tremaining: 1m 42s\n",
      "87: learn: 0.2203756\ttest: 0.22017\tbestTest: 0.22017 (87)\ttotal: 11m 32s\tremaining: 1m 34s\n",
      "88: learn: 0.2203338\ttest: 0.2201378\tbestTest: 0.2201378 (88)\ttotal: 11m 40s\tremaining: 1m 26s\n",
      "89: learn: 0.2202995\ttest: 0.2201153\tbestTest: 0.2201153 (89)\ttotal: 11m 48s\tremaining: 1m 18s\n",
      "90: learn: 0.2202668\ttest: 0.2200858\tbestTest: 0.2200858 (90)\ttotal: 11m 56s\tremaining: 1m 10s\n",
      "91: learn: 0.220244\ttest: 0.220068\tbestTest: 0.220068 (91)\ttotal: 12m 4s\tremaining: 1m 2s\n",
      "92: learn: 0.2202173\ttest: 0.2200448\tbestTest: 0.2200448 (92)\ttotal: 12m 12s\tremaining: 55.1s\n",
      "93: learn: 0.2201963\ttest: 0.2200287\tbestTest: 0.2200287 (93)\ttotal: 12m 20s\tremaining: 47.3s\n",
      "94: learn: 0.2201663\ttest: 0.2200107\tbestTest: 0.2200107 (94)\ttotal: 12m 28s\tremaining: 39.4s\n",
      "95: learn: 0.2201315\ttest: 0.2199823\tbestTest: 0.2199823 (95)\ttotal: 12m 37s\tremaining: 31.5s\n",
      "96: learn: 0.2200948\ttest: 0.2199526\tbestTest: 0.2199526 (96)\ttotal: 12m 44s\tremaining: 23.6s\n",
      "97: learn: 0.2200742\ttest: 0.2199368\tbestTest: 0.2199368 (97)\ttotal: 12m 52s\tremaining: 15.8s\n",
      "98: learn: 0.220051\ttest: 0.2199231\tbestTest: 0.2199231 (98)\ttotal: 13m 1s\tremaining: 7.89s\n",
      "99: learn: 0.2200104\ttest: 0.2198982\tbestTest: 0.2198982 (99)\ttotal: 13m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2198981654\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.075_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 23:14:56.295264\n",
      "train time given below\n",
      "0:16:36.339976\n",
      "2018-03-14 23:14:56.322394\n",
      "2018-03-14 23:14:56.326249\n",
      "GINI ISIT = 0.493039269378\n",
      "2018-03-14 23:16:37.652225\n",
      "GINI OSIT = 0.488948647604\n",
      "2018-03-14 23:17:18.977590\n",
      "GINI OSOT = 0.44538480157\n",
      "2018-03-14 23:17:31.712478\n",
      "2018-03-14 23:17:31.714831\n",
      "loop run time\n",
      "0:19:11.759721\n",
      "learning rate = 0.1\n",
      "2018-03-14 23:17:31.716993\n",
      "model train start\n",
      "2018-03-14 23:17:31.717359\n",
      "0: learn: 0.5804401\ttest: 0.580373\tbestTest: 0.580373 (0)\ttotal: 6.13s\tremaining: 10m 6s\n",
      "1: learn: 0.4949501\ttest: 0.4948206\tbestTest: 0.4948206 (1)\ttotal: 13.6s\tremaining: 11m 6s\n",
      "2: learn: 0.4321216\ttest: 0.4319223\tbestTest: 0.4319223 (2)\ttotal: 22.1s\tremaining: 11m 54s\n",
      "3: learn: 0.3861797\ttest: 0.3859351\tbestTest: 0.3859351 (3)\ttotal: 27.7s\tremaining: 11m 4s\n",
      "4: learn: 0.3502169\ttest: 0.3499115\tbestTest: 0.3499115 (4)\ttotal: 36.9s\tremaining: 11m 41s\n",
      "5: learn: 0.322177\ttest: 0.3218293\tbestTest: 0.3218293 (5)\ttotal: 45.2s\tremaining: 11m 47s\n",
      "6: learn: 0.3001264\ttest: 0.2997263\tbestTest: 0.2997263 (6)\ttotal: 53.3s\tremaining: 11m 48s\n",
      "7: learn: 0.2845558\ttest: 0.284134\tbestTest: 0.284134 (7)\ttotal: 1m 1s\tremaining: 11m 41s\n",
      "8: learn: 0.271976\ttest: 0.2715071\tbestTest: 0.2715071 (8)\ttotal: 1m 9s\tremaining: 11m 40s\n",
      "9: learn: 0.2618779\ttest: 0.2613735\tbestTest: 0.2613735 (9)\ttotal: 1m 16s\tremaining: 11m 29s\n",
      "10: learn: 0.2543376\ttest: 0.2538048\tbestTest: 0.2538048 (10)\ttotal: 1m 24s\tremaining: 11m 20s\n",
      "11: learn: 0.248842\ttest: 0.2482904\tbestTest: 0.2482904 (11)\ttotal: 1m 32s\tremaining: 11m 21s\n",
      "12: learn: 0.2439908\ttest: 0.2434302\tbestTest: 0.2434302 (12)\ttotal: 1m 40s\tremaining: 11m 11s\n",
      "13: learn: 0.2408985\ttest: 0.2403101\tbestTest: 0.2403101 (13)\ttotal: 1m 44s\tremaining: 10m 44s\n",
      "14: learn: 0.2377793\ttest: 0.2371805\tbestTest: 0.2371805 (14)\ttotal: 1m 52s\tremaining: 10m 34s\n",
      "15: learn: 0.2351176\ttest: 0.2345103\tbestTest: 0.2345103 (15)\ttotal: 1m 59s\tremaining: 10m 29s\n",
      "16: learn: 0.2331435\ttest: 0.2325226\tbestTest: 0.2325226 (16)\ttotal: 2m 7s\tremaining: 10m 21s\n",
      "17: learn: 0.231491\ttest: 0.2308612\tbestTest: 0.2308612 (17)\ttotal: 2m 15s\tremaining: 10m 17s\n",
      "18: learn: 0.2300637\ttest: 0.229421\tbestTest: 0.229421 (18)\ttotal: 2m 23s\tremaining: 10m 13s\n",
      "19: learn: 0.2289483\ttest: 0.2283115\tbestTest: 0.2283115 (19)\ttotal: 2m 31s\tremaining: 10m 5s\n",
      "20: learn: 0.2279308\ttest: 0.2273041\tbestTest: 0.2273041 (20)\ttotal: 2m 39s\tremaining: 9m 59s\n",
      "21: learn: 0.227186\ttest: 0.2265557\tbestTest: 0.2265557 (21)\ttotal: 2m 46s\tremaining: 9m 51s\n",
      "22: learn: 0.22653\ttest: 0.2258937\tbestTest: 0.2258937 (22)\ttotal: 2m 54s\tremaining: 9m 43s\n",
      "23: learn: 0.2259492\ttest: 0.2253183\tbestTest: 0.2253183 (23)\ttotal: 3m 2s\tremaining: 9m 38s\n",
      "24: learn: 0.2254064\ttest: 0.224784\tbestTest: 0.224784 (24)\ttotal: 3m 10s\tremaining: 9m 31s\n",
      "25: learn: 0.2250103\ttest: 0.2243882\tbestTest: 0.2243882 (25)\ttotal: 3m 18s\tremaining: 9m 25s\n",
      "26: learn: 0.2246924\ttest: 0.2240743\tbestTest: 0.2240743 (26)\ttotal: 3m 27s\tremaining: 9m 22s\n",
      "27: learn: 0.2244197\ttest: 0.2238029\tbestTest: 0.2238029 (27)\ttotal: 3m 36s\tremaining: 9m 17s\n",
      "28: learn: 0.2240443\ttest: 0.2234434\tbestTest: 0.2234434 (28)\ttotal: 3m 43s\tremaining: 9m 8s\n",
      "29: learn: 0.2237452\ttest: 0.2231532\tbestTest: 0.2231532 (29)\ttotal: 3m 51s\tremaining: 9m\n",
      "30: learn: 0.2234878\ttest: 0.2229083\tbestTest: 0.2229083 (30)\ttotal: 3m 59s\tremaining: 8m 52s\n",
      "31: learn: 0.223313\ttest: 0.2227366\tbestTest: 0.2227366 (31)\ttotal: 4m 7s\tremaining: 8m 46s\n",
      "32: learn: 0.2231101\ttest: 0.2225465\tbestTest: 0.2225465 (32)\ttotal: 4m 15s\tremaining: 8m 38s\n",
      "33: learn: 0.2229717\ttest: 0.2224156\tbestTest: 0.2224156 (33)\ttotal: 4m 23s\tremaining: 8m 30s\n",
      "34: learn: 0.2227796\ttest: 0.2222369\tbestTest: 0.2222369 (34)\ttotal: 4m 30s\tremaining: 8m 22s\n",
      "35: learn: 0.2226215\ttest: 0.222089\tbestTest: 0.222089 (35)\ttotal: 4m 38s\tremaining: 8m 14s\n",
      "36: learn: 0.2225143\ttest: 0.2219907\tbestTest: 0.2219907 (36)\ttotal: 4m 46s\tremaining: 8m 7s\n",
      "37: learn: 0.2223819\ttest: 0.2218692\tbestTest: 0.2218692 (37)\ttotal: 4m 54s\tremaining: 8m\n",
      "38: learn: 0.2222728\ttest: 0.2217711\tbestTest: 0.2217711 (38)\ttotal: 5m 2s\tremaining: 7m 53s\n",
      "39: learn: 0.2221533\ttest: 0.221659\tbestTest: 0.221659 (39)\ttotal: 5m 11s\tremaining: 7m 46s\n",
      "40: learn: 0.2220368\ttest: 0.2215623\tbestTest: 0.2215623 (40)\ttotal: 5m 19s\tremaining: 7m 39s\n",
      "41: learn: 0.2219368\ttest: 0.2214756\tbestTest: 0.2214756 (41)\ttotal: 5m 26s\tremaining: 7m 31s\n",
      "42: learn: 0.2218582\ttest: 0.2214029\tbestTest: 0.2214029 (42)\ttotal: 5m 35s\tremaining: 7m 24s\n",
      "43: learn: 0.2217914\ttest: 0.2213438\tbestTest: 0.2213438 (43)\ttotal: 5m 43s\tremaining: 7m 17s\n",
      "44: learn: 0.2216703\ttest: 0.2212313\tbestTest: 0.2212313 (44)\ttotal: 5m 51s\tremaining: 7m 9s\n",
      "45: learn: 0.221607\ttest: 0.2211759\tbestTest: 0.2211759 (45)\ttotal: 5m 59s\tremaining: 7m 1s\n",
      "46: learn: 0.2215562\ttest: 0.2211281\tbestTest: 0.2211281 (46)\ttotal: 6m 6s\tremaining: 6m 52s\n",
      "47: learn: 0.2215001\ttest: 0.2210832\tbestTest: 0.2210832 (47)\ttotal: 6m 13s\tremaining: 6m 44s\n",
      "48: learn: 0.2214123\ttest: 0.2210089\tbestTest: 0.2210089 (48)\ttotal: 6m 21s\tremaining: 6m 36s\n",
      "49: learn: 0.221337\ttest: 0.2209489\tbestTest: 0.2209489 (49)\ttotal: 6m 29s\tremaining: 6m 29s\n",
      "50: learn: 0.2212899\ttest: 0.2209052\tbestTest: 0.2209052 (50)\ttotal: 6m 37s\tremaining: 6m 21s\n",
      "51: learn: 0.2212137\ttest: 0.2208382\tbestTest: 0.2208382 (51)\ttotal: 6m 44s\tremaining: 6m 13s\n",
      "52: learn: 0.2211514\ttest: 0.2207858\tbestTest: 0.2207858 (52)\ttotal: 6m 52s\tremaining: 6m 5s\n",
      "53: learn: 0.221088\ttest: 0.2207269\tbestTest: 0.2207269 (53)\ttotal: 7m\tremaining: 5m 58s\n",
      "54: learn: 0.2210233\ttest: 0.2206743\tbestTest: 0.2206743 (54)\ttotal: 7m 8s\tremaining: 5m 50s\n",
      "55: learn: 0.2209532\ttest: 0.2206124\tbestTest: 0.2206124 (55)\ttotal: 7m 16s\tremaining: 5m 42s\n",
      "56: learn: 0.2209162\ttest: 0.2205795\tbestTest: 0.2205795 (56)\ttotal: 7m 24s\tremaining: 5m 35s\n",
      "57: learn: 0.2208559\ttest: 0.2205308\tbestTest: 0.2205308 (57)\ttotal: 7m 32s\tremaining: 5m 28s\n",
      "58: learn: 0.2208131\ttest: 0.2204973\tbestTest: 0.2204973 (58)\ttotal: 7m 41s\tremaining: 5m 20s\n",
      "59: learn: 0.2207726\ttest: 0.2204641\tbestTest: 0.2204641 (59)\ttotal: 7m 50s\tremaining: 5m 13s\n",
      "60: learn: 0.2207259\ttest: 0.2204299\tbestTest: 0.2204299 (60)\ttotal: 7m 57s\tremaining: 5m 5s\n",
      "61: learn: 0.220677\ttest: 0.2203901\tbestTest: 0.2203901 (61)\ttotal: 8m 5s\tremaining: 4m 57s\n",
      "62: learn: 0.2206245\ttest: 0.2203475\tbestTest: 0.2203475 (62)\ttotal: 8m 13s\tremaining: 4m 49s\n",
      "63: learn: 0.2205793\ttest: 0.2203126\tbestTest: 0.2203126 (63)\ttotal: 8m 21s\tremaining: 4m 42s\n",
      "64: learn: 0.2205098\ttest: 0.2202535\tbestTest: 0.2202535 (64)\ttotal: 8m 29s\tremaining: 4m 34s\n",
      "65: learn: 0.2204518\ttest: 0.2202094\tbestTest: 0.2202094 (65)\ttotal: 8m 37s\tremaining: 4m 26s\n",
      "66: learn: 0.2203913\ttest: 0.2201637\tbestTest: 0.2201637 (66)\ttotal: 8m 44s\tremaining: 4m 18s\n",
      "67: learn: 0.220352\ttest: 0.2201338\tbestTest: 0.2201338 (67)\ttotal: 8m 52s\tremaining: 4m 10s\n",
      "68: learn: 0.2202942\ttest: 0.2200933\tbestTest: 0.2200933 (68)\ttotal: 9m\tremaining: 4m 2s\n",
      "69: learn: 0.2202288\ttest: 0.2200417\tbestTest: 0.2200417 (69)\ttotal: 9m 8s\tremaining: 3m 55s\n",
      "70: learn: 0.2202036\ttest: 0.2200226\tbestTest: 0.2200226 (70)\ttotal: 9m 17s\tremaining: 3m 47s\n",
      "71: learn: 0.2201756\ttest: 0.2200011\tbestTest: 0.2200011 (71)\ttotal: 9m 24s\tremaining: 3m 39s\n",
      "72: learn: 0.2201455\ttest: 0.2199778\tbestTest: 0.2199778 (72)\ttotal: 9m 32s\tremaining: 3m 31s\n",
      "73: learn: 0.2200995\ttest: 0.2199476\tbestTest: 0.2199476 (73)\ttotal: 9m 41s\tremaining: 3m 24s\n",
      "74: learn: 0.2200681\ttest: 0.2199222\tbestTest: 0.2199222 (74)\ttotal: 9m 49s\tremaining: 3m 16s\n",
      "75: learn: 0.220045\ttest: 0.2199046\tbestTest: 0.2199046 (75)\ttotal: 9m 58s\tremaining: 3m 9s\n",
      "76: learn: 0.2199925\ttest: 0.2198665\tbestTest: 0.2198665 (76)\ttotal: 10m 5s\tremaining: 3m\n",
      "77: learn: 0.2199819\ttest: 0.219856\tbestTest: 0.219856 (77)\ttotal: 10m 9s\tremaining: 2m 52s\n",
      "78: learn: 0.2199322\ttest: 0.2198269\tbestTest: 0.2198269 (78)\ttotal: 10m 17s\tremaining: 2m 44s\n",
      "79: learn: 0.2198853\ttest: 0.2197876\tbestTest: 0.2197876 (79)\ttotal: 10m 26s\tremaining: 2m 36s\n",
      "80: learn: 0.2198613\ttest: 0.2197721\tbestTest: 0.2197721 (80)\ttotal: 10m 34s\tremaining: 2m 28s\n",
      "81: learn: 0.2198161\ttest: 0.2197389\tbestTest: 0.2197389 (81)\ttotal: 10m 42s\tremaining: 2m 20s\n",
      "82: learn: 0.2197683\ttest: 0.2197067\tbestTest: 0.2197067 (82)\ttotal: 10m 49s\tremaining: 2m 13s\n",
      "83: learn: 0.219734\ttest: 0.2196807\tbestTest: 0.2196807 (83)\ttotal: 10m 58s\tremaining: 2m 5s\n",
      "84: learn: 0.2197118\ttest: 0.2196676\tbestTest: 0.2196676 (84)\ttotal: 11m 6s\tremaining: 1m 57s\n",
      "85: learn: 0.2196722\ttest: 0.2196427\tbestTest: 0.2196427 (85)\ttotal: 11m 15s\tremaining: 1m 49s\n",
      "86: learn: 0.2196532\ttest: 0.2196299\tbestTest: 0.2196299 (86)\ttotal: 11m 23s\tremaining: 1m 42s\n",
      "87: learn: 0.219622\ttest: 0.2196088\tbestTest: 0.2196088 (87)\ttotal: 11m 30s\tremaining: 1m 34s\n",
      "88: learn: 0.2195908\ttest: 0.2195857\tbestTest: 0.2195857 (88)\ttotal: 11m 38s\tremaining: 1m 26s\n",
      "89: learn: 0.2195582\ttest: 0.2195575\tbestTest: 0.2195575 (89)\ttotal: 11m 47s\tremaining: 1m 18s\n",
      "90: learn: 0.2195424\ttest: 0.2195467\tbestTest: 0.2195467 (90)\ttotal: 11m 55s\tremaining: 1m 10s\n",
      "91: learn: 0.2194814\ttest: 0.2195075\tbestTest: 0.2195075 (91)\ttotal: 12m 3s\tremaining: 1m 2s\n",
      "92: learn: 0.2194622\ttest: 0.2194939\tbestTest: 0.2194939 (92)\ttotal: 12m 12s\tremaining: 55.1s\n",
      "93: learn: 0.2194175\ttest: 0.219469\tbestTest: 0.219469 (93)\ttotal: 12m 20s\tremaining: 47.3s\n",
      "94: learn: 0.2194077\ttest: 0.2194601\tbestTest: 0.2194601 (94)\ttotal: 12m 27s\tremaining: 39.4s\n",
      "95: learn: 0.2193647\ttest: 0.2194328\tbestTest: 0.2194328 (95)\ttotal: 12m 35s\tremaining: 31.5s\n",
      "96: learn: 0.2193354\ttest: 0.2194167\tbestTest: 0.2194167 (96)\ttotal: 12m 44s\tremaining: 23.6s\n",
      "97: learn: 0.2193247\ttest: 0.2194083\tbestTest: 0.2194083 (97)\ttotal: 12m 49s\tremaining: 15.7s\n",
      "98: learn: 0.2192942\ttest: 0.2193839\tbestTest: 0.2193839 (98)\ttotal: 12m 56s\tremaining: 7.85s\n",
      "99: learn: 0.2192657\ttest: 0.2193633\tbestTest: 0.2193633 (99)\ttotal: 13m 4s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2193633163\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.1_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 23:34:11.709282\n",
      "train time given below\n",
      "0:16:39.991923\n",
      "2018-03-14 23:34:12.067420\n",
      "2018-03-14 23:34:12.071696\n",
      "GINI ISIT = 0.498417282022\n",
      "2018-03-14 23:35:48.196958\n",
      "GINI OSIT = 0.49269236584\n",
      "2018-03-14 23:36:28.776811\n",
      "GINI OSOT = 0.431242030536\n",
      "2018-03-14 23:36:41.303305\n",
      "2018-03-14 23:36:41.305259\n",
      "loop run time\n",
      "0:19:09.588265\n",
      "learning rate = 0.125\n",
      "2018-03-14 23:36:41.306983\n",
      "model train start\n",
      "2018-03-14 23:36:41.307199\n",
      "0: learn: 0.5553676\ttest: 0.5552822\tbestTest: 0.5552822 (0)\ttotal: 6.28s\tremaining: 10m 21s\n",
      "1: learn: 0.4580859\ttest: 0.4579144\tbestTest: 0.4579144 (1)\ttotal: 14.2s\tremaining: 11m 35s\n",
      "2: learn: 0.3923879\ttest: 0.3921301\tbestTest: 0.3921301 (2)\ttotal: 22.8s\tremaining: 12m 16s\n",
      "3: learn: 0.3469007\ttest: 0.3465829\tbestTest: 0.3465829 (3)\ttotal: 32.1s\tremaining: 12m 49s\n",
      "4: learn: 0.3131349\ttest: 0.3127569\tbestTest: 0.3127569 (4)\ttotal: 40.8s\tremaining: 12m 55s\n",
      "5: learn: 0.2893866\ttest: 0.2889603\tbestTest: 0.2889603 (5)\ttotal: 48.7s\tremaining: 12m 43s\n",
      "6: learn: 0.2733937\ttest: 0.2728993\tbestTest: 0.2728993 (6)\ttotal: 56.9s\tremaining: 12m 36s\n",
      "7: learn: 0.2611568\ttest: 0.2606215\tbestTest: 0.2606215 (7)\ttotal: 1m 4s\tremaining: 12m 25s\n",
      "8: learn: 0.2524784\ttest: 0.2519088\tbestTest: 0.2519088 (8)\ttotal: 1m 12s\tremaining: 12m 15s\n",
      "9: learn: 0.2456856\ttest: 0.2451101\tbestTest: 0.2451101 (9)\ttotal: 1m 20s\tremaining: 12m 2s\n",
      "10: learn: 0.2409662\ttest: 0.2403574\tbestTest: 0.2403574 (10)\ttotal: 1m 28s\tremaining: 11m 55s\n",
      "11: learn: 0.2370314\ttest: 0.2364005\tbestTest: 0.2364005 (11)\ttotal: 1m 35s\tremaining: 11m 43s\n",
      "12: learn: 0.2341276\ttest: 0.2334846\tbestTest: 0.2334846 (12)\ttotal: 1m 44s\tremaining: 11m 39s\n",
      "13: learn: 0.2318181\ttest: 0.2311735\tbestTest: 0.2311735 (13)\ttotal: 1m 52s\tremaining: 11m 29s\n",
      "14: learn: 0.2300865\ttest: 0.2294317\tbestTest: 0.2294317 (14)\ttotal: 2m\tremaining: 11m 21s\n",
      "15: learn: 0.2285991\ttest: 0.2279411\tbestTest: 0.2279411 (15)\ttotal: 2m 8s\tremaining: 11m 12s\n",
      "16: learn: 0.2275624\ttest: 0.2268947\tbestTest: 0.2268947 (16)\ttotal: 2m 16s\tremaining: 11m 6s\n",
      "17: learn: 0.2265295\ttest: 0.22588\tbestTest: 0.22588 (17)\ttotal: 2m 24s\tremaining: 10m 58s\n",
      "18: learn: 0.2258161\ttest: 0.2251771\tbestTest: 0.2251771 (18)\ttotal: 2m 33s\tremaining: 10m 55s\n",
      "19: learn: 0.2252361\ttest: 0.2246111\tbestTest: 0.2246111 (19)\ttotal: 2m 41s\tremaining: 10m 44s\n",
      "20: learn: 0.2248075\ttest: 0.2241799\tbestTest: 0.2241799 (20)\ttotal: 2m 49s\tremaining: 10m 36s\n",
      "21: learn: 0.2243444\ttest: 0.2237312\tbestTest: 0.2237312 (21)\ttotal: 2m 57s\tremaining: 10m 31s\n",
      "22: learn: 0.2239775\ttest: 0.223369\tbestTest: 0.223369 (22)\ttotal: 3m 5s\tremaining: 10m 19s\n",
      "23: learn: 0.2236128\ttest: 0.2230362\tbestTest: 0.2230362 (23)\ttotal: 3m 13s\tremaining: 10m 12s\n",
      "24: learn: 0.2233521\ttest: 0.222777\tbestTest: 0.222777 (24)\ttotal: 3m 20s\tremaining: 10m 2s\n",
      "25: learn: 0.2231513\ttest: 0.2225771\tbestTest: 0.2225771 (25)\ttotal: 3m 29s\tremaining: 9m 56s\n",
      "26: learn: 0.2229001\ttest: 0.2223306\tbestTest: 0.2223306 (26)\ttotal: 3m 37s\tremaining: 9m 48s\n",
      "27: learn: 0.2227296\ttest: 0.2221674\tbestTest: 0.2221674 (27)\ttotal: 3m 46s\tremaining: 9m 43s\n",
      "28: learn: 0.2225867\ttest: 0.2220282\tbestTest: 0.2220282 (28)\ttotal: 3m 54s\tremaining: 9m 34s\n",
      "29: learn: 0.2223365\ttest: 0.2218051\tbestTest: 0.2218051 (29)\ttotal: 4m 2s\tremaining: 9m 26s\n",
      "30: learn: 0.222169\ttest: 0.2216586\tbestTest: 0.2216586 (30)\ttotal: 4m 10s\tremaining: 9m 17s\n",
      "31: learn: 0.2220281\ttest: 0.2215336\tbestTest: 0.2215336 (31)\ttotal: 4m 18s\tremaining: 9m 8s\n",
      "32: learn: 0.2219195\ttest: 0.2214374\tbestTest: 0.2214374 (32)\ttotal: 4m 26s\tremaining: 9m 1s\n",
      "33: learn: 0.2217968\ttest: 0.221325\tbestTest: 0.221325 (33)\ttotal: 4m 34s\tremaining: 8m 53s\n",
      "34: learn: 0.2217185\ttest: 0.2212523\tbestTest: 0.2212523 (34)\ttotal: 4m 42s\tremaining: 8m 45s\n",
      "35: learn: 0.2216636\ttest: 0.2211991\tbestTest: 0.2211991 (35)\ttotal: 4m 51s\tremaining: 8m 37s\n",
      "36: learn: 0.2215494\ttest: 0.2211023\tbestTest: 0.2211023 (36)\ttotal: 4m 59s\tremaining: 8m 29s\n",
      "37: learn: 0.2214796\ttest: 0.2210408\tbestTest: 0.2210408 (37)\ttotal: 5m 7s\tremaining: 8m 21s\n",
      "38: learn: 0.22138\ttest: 0.2209666\tbestTest: 0.2209666 (38)\ttotal: 5m 14s\tremaining: 8m 12s\n",
      "39: learn: 0.221284\ttest: 0.2208873\tbestTest: 0.2208873 (39)\ttotal: 5m 22s\tremaining: 8m 4s\n",
      "40: learn: 0.2212206\ttest: 0.2208328\tbestTest: 0.2208328 (40)\ttotal: 5m 30s\tremaining: 7m 55s\n",
      "41: learn: 0.2211489\ttest: 0.2207747\tbestTest: 0.2207747 (41)\ttotal: 5m 39s\tremaining: 7m 49s\n",
      "42: learn: 0.2210907\ttest: 0.220723\tbestTest: 0.220723 (42)\ttotal: 5m 48s\tremaining: 7m 41s\n",
      "43: learn: 0.2209892\ttest: 0.2206323\tbestTest: 0.2206323 (43)\ttotal: 5m 56s\tremaining: 7m 33s\n",
      "44: learn: 0.2208973\ttest: 0.2205629\tbestTest: 0.2205629 (44)\ttotal: 6m 4s\tremaining: 7m 25s\n",
      "45: learn: 0.2208102\ttest: 0.2204917\tbestTest: 0.2204917 (45)\ttotal: 6m 12s\tremaining: 7m 17s\n",
      "46: learn: 0.2207227\ttest: 0.2204188\tbestTest: 0.2204188 (46)\ttotal: 6m 21s\tremaining: 7m 10s\n",
      "47: learn: 0.2206731\ttest: 0.22038\tbestTest: 0.22038 (47)\ttotal: 6m 29s\tremaining: 7m 1s\n",
      "48: learn: 0.2205749\ttest: 0.2203008\tbestTest: 0.2203008 (48)\ttotal: 6m 37s\tremaining: 6m 53s\n",
      "49: learn: 0.2205279\ttest: 0.2202623\tbestTest: 0.2202623 (49)\ttotal: 6m 45s\tremaining: 6m 45s\n",
      "50: learn: 0.2204799\ttest: 0.2202204\tbestTest: 0.2202204 (50)\ttotal: 6m 54s\tremaining: 6m 38s\n",
      "51: learn: 0.2203896\ttest: 0.2201496\tbestTest: 0.2201496 (51)\ttotal: 7m 1s\tremaining: 6m 29s\n",
      "52: learn: 0.2203264\ttest: 0.2200999\tbestTest: 0.2200999 (52)\ttotal: 7m 9s\tremaining: 6m 21s\n",
      "53: learn: 0.2202436\ttest: 0.2200338\tbestTest: 0.2200338 (53)\ttotal: 7m 17s\tremaining: 6m 13s\n",
      "54: learn: 0.2201956\ttest: 0.2199952\tbestTest: 0.2199952 (54)\ttotal: 7m 25s\tremaining: 6m 4s\n",
      "55: learn: 0.2201513\ttest: 0.2199572\tbestTest: 0.2199572 (55)\ttotal: 7m 34s\tremaining: 5m 57s\n",
      "56: learn: 0.220095\ttest: 0.2199119\tbestTest: 0.2199119 (56)\ttotal: 7m 42s\tremaining: 5m 48s\n",
      "57: learn: 0.2200486\ttest: 0.219881\tbestTest: 0.219881 (57)\ttotal: 7m 49s\tremaining: 5m 40s\n",
      "58: learn: 0.2199968\ttest: 0.2198393\tbestTest: 0.2198393 (58)\ttotal: 7m 57s\tremaining: 5m 32s\n",
      "59: learn: 0.2199432\ttest: 0.2197936\tbestTest: 0.2197936 (59)\ttotal: 8m 6s\tremaining: 5m 24s\n",
      "60: learn: 0.219906\ttest: 0.2197664\tbestTest: 0.2197664 (60)\ttotal: 8m 14s\tremaining: 5m 16s\n",
      "61: learn: 0.2198818\ttest: 0.2197469\tbestTest: 0.2197469 (61)\ttotal: 8m 23s\tremaining: 5m 8s\n",
      "62: learn: 0.2198249\ttest: 0.2197054\tbestTest: 0.2197054 (62)\ttotal: 8m 30s\tremaining: 4m 59s\n",
      "63: learn: 0.2197928\ttest: 0.219683\tbestTest: 0.219683 (63)\ttotal: 8m 39s\tremaining: 4m 52s\n",
      "64: learn: 0.2197615\ttest: 0.2196584\tbestTest: 0.2196584 (64)\ttotal: 8m 47s\tremaining: 4m 44s\n",
      "65: learn: 0.2197126\ttest: 0.2196236\tbestTest: 0.2196236 (65)\ttotal: 8m 55s\tremaining: 4m 35s\n",
      "66: learn: 0.2196787\ttest: 0.2195956\tbestTest: 0.2195956 (66)\ttotal: 9m 4s\tremaining: 4m 28s\n",
      "67: learn: 0.2196585\ttest: 0.2195834\tbestTest: 0.2195834 (67)\ttotal: 9m 12s\tremaining: 4m 20s\n",
      "68: learn: 0.2196033\ttest: 0.2195454\tbestTest: 0.2195454 (68)\ttotal: 9m 20s\tremaining: 4m 11s\n",
      "69: learn: 0.2195681\ttest: 0.2195275\tbestTest: 0.2195275 (69)\ttotal: 9m 28s\tremaining: 4m 3s\n",
      "70: learn: 0.2195274\ttest: 0.2195078\tbestTest: 0.2195078 (70)\ttotal: 9m 36s\tremaining: 3m 55s\n",
      "71: learn: 0.2194802\ttest: 0.2194684\tbestTest: 0.2194684 (71)\ttotal: 9m 44s\tremaining: 3m 47s\n",
      "72: learn: 0.219438\ttest: 0.2194454\tbestTest: 0.2194454 (72)\ttotal: 9m 51s\tremaining: 3m 38s\n",
      "73: learn: 0.2194001\ttest: 0.219417\tbestTest: 0.219417 (73)\ttotal: 10m\tremaining: 3m 30s\n",
      "74: learn: 0.2193663\ttest: 0.2193894\tbestTest: 0.2193894 (74)\ttotal: 10m 8s\tremaining: 3m 22s\n",
      "75: learn: 0.2193264\ttest: 0.2193613\tbestTest: 0.2193613 (75)\ttotal: 10m 16s\tremaining: 3m 14s\n",
      "76: learn: 0.2192968\ttest: 0.2193405\tbestTest: 0.2193405 (76)\ttotal: 10m 25s\tremaining: 3m 6s\n",
      "77: learn: 0.2192617\ttest: 0.2193129\tbestTest: 0.2193129 (77)\ttotal: 10m 33s\tremaining: 2m 58s\n",
      "78: learn: 0.2192218\ttest: 0.2192941\tbestTest: 0.2192941 (78)\ttotal: 10m 41s\tremaining: 2m 50s\n",
      "79: learn: 0.2191982\ttest: 0.21928\tbestTest: 0.21928 (79)\ttotal: 10m 49s\tremaining: 2m 42s\n",
      "80: learn: 0.2191885\ttest: 0.2192728\tbestTest: 0.2192728 (80)\ttotal: 10m 56s\tremaining: 2m 34s\n",
      "81: learn: 0.2191511\ttest: 0.2192539\tbestTest: 0.2192539 (81)\ttotal: 11m 5s\tremaining: 2m 25s\n",
      "82: learn: 0.2191234\ttest: 0.2192371\tbestTest: 0.2192371 (82)\ttotal: 11m 14s\tremaining: 2m 18s\n",
      "83: learn: 0.2191007\ttest: 0.219219\tbestTest: 0.219219 (83)\ttotal: 11m 23s\tremaining: 2m 10s\n",
      "84: learn: 0.2190658\ttest: 0.2191923\tbestTest: 0.2191923 (84)\ttotal: 11m 31s\tremaining: 2m 1s\n",
      "85: learn: 0.2190266\ttest: 0.2191721\tbestTest: 0.2191721 (85)\ttotal: 11m 39s\tremaining: 1m 53s\n",
      "86: learn: 0.2189881\ttest: 0.2191484\tbestTest: 0.2191484 (86)\ttotal: 11m 48s\tremaining: 1m 45s\n",
      "87: learn: 0.2189542\ttest: 0.2191312\tbestTest: 0.2191312 (87)\ttotal: 11m 56s\tremaining: 1m 37s\n",
      "88: learn: 0.2189304\ttest: 0.219121\tbestTest: 0.219121 (88)\ttotal: 12m 3s\tremaining: 1m 29s\n",
      "89: learn: 0.2188967\ttest: 0.2191083\tbestTest: 0.2191083 (89)\ttotal: 12m 11s\tremaining: 1m 21s\n",
      "90: learn: 0.2188698\ttest: 0.2190919\tbestTest: 0.2190919 (90)\ttotal: 12m 19s\tremaining: 1m 13s\n",
      "91: learn: 0.2188445\ttest: 0.2190839\tbestTest: 0.2190839 (91)\ttotal: 12m 27s\tremaining: 1m 5s\n",
      "92: learn: 0.2188204\ttest: 0.2190743\tbestTest: 0.2190743 (92)\ttotal: 12m 36s\tremaining: 57s\n",
      "93: learn: 0.2187981\ttest: 0.2190613\tbestTest: 0.2190613 (93)\ttotal: 12m 45s\tremaining: 48.8s\n",
      "94: learn: 0.2187731\ttest: 0.2190456\tbestTest: 0.2190456 (94)\ttotal: 12m 53s\tremaining: 40.7s\n",
      "95: learn: 0.2187318\ttest: 0.219027\tbestTest: 0.219027 (95)\ttotal: 13m\tremaining: 32.5s\n",
      "96: learn: 0.2187112\ttest: 0.219009\tbestTest: 0.219009 (96)\ttotal: 13m 7s\tremaining: 24.4s\n",
      "97: learn: 0.2186763\ttest: 0.2189933\tbestTest: 0.2189933 (97)\ttotal: 13m 15s\tremaining: 16.2s\n",
      "98: learn: 0.2186558\ttest: 0.2189781\tbestTest: 0.2189781 (98)\ttotal: 13m 23s\tremaining: 8.12s\n",
      "99: learn: 0.2186422\ttest: 0.2189699\tbestTest: 0.2189699 (99)\ttotal: 13m 32s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2189698908\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.125_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-14 23:53:48.443545\n",
      "train time given below\n",
      "0:17:07.136346\n",
      "2018-03-14 23:53:48.466772\n",
      "2018-03-14 23:53:48.470256\n",
      "GINI ISIT = 0.503327874204\n",
      "2018-03-14 23:55:23.115836\n",
      "GINI OSIT = 0.496472963025\n",
      "2018-03-14 23:56:03.430086\n",
      "GINI OSOT = 0.442770464504\n",
      "2018-03-14 23:56:15.964871\n",
      "2018-03-14 23:56:15.967101\n",
      "loop run time\n",
      "0:19:34.660118\n",
      "learning rate = 0.15\n",
      "2018-03-14 23:56:15.968722\n",
      "model train start\n",
      "2018-03-14 23:56:15.968937\n",
      "0: learn: 0.5315107\ttest: 0.5314065\tbestTest: 0.5314065 (0)\ttotal: 6.16s\tremaining: 10m 9s\n",
      "1: learn: 0.4260721\ttest: 0.4258641\tbestTest: 0.4258641 (1)\ttotal: 13.6s\tremaining: 11m 4s\n",
      "2: learn: 0.3608552\ttest: 0.3605424\tbestTest: 0.3605424 (2)\ttotal: 22s\tremaining: 11m 52s\n",
      "3: learn: 0.3180691\ttest: 0.317677\tbestTest: 0.317677 (3)\ttotal: 30.9s\tremaining: 12m 22s\n",
      "4: learn: 0.2886252\ttest: 0.2882071\tbestTest: 0.2882071 (4)\ttotal: 39.1s\tremaining: 12m 22s\n",
      "5: learn: 0.2703954\ttest: 0.2699034\tbestTest: 0.2699034 (5)\ttotal: 47.7s\tremaining: 12m 26s\n",
      "6: learn: 0.256434\ttest: 0.2558859\tbestTest: 0.2558859 (6)\ttotal: 55.4s\tremaining: 12m 16s\n",
      "7: learn: 0.2473454\ttest: 0.2467765\tbestTest: 0.2467765 (7)\ttotal: 1m 3s\tremaining: 12m 9s\n",
      "8: learn: 0.2411337\ttest: 0.2405316\tbestTest: 0.2405316 (8)\ttotal: 1m 11s\tremaining: 12m 6s\n",
      "9: learn: 0.2363545\ttest: 0.2357266\tbestTest: 0.2357266 (9)\ttotal: 1m 19s\tremaining: 11m 57s\n",
      "10: learn: 0.2331825\ttest: 0.2325502\tbestTest: 0.2325502 (10)\ttotal: 1m 28s\tremaining: 11m 55s\n",
      "11: learn: 0.2306493\ttest: 0.2300172\tbestTest: 0.2300172 (11)\ttotal: 1m 36s\tremaining: 11m 49s\n",
      "12: learn: 0.2289176\ttest: 0.2282687\tbestTest: 0.2282687 (12)\ttotal: 1m 45s\tremaining: 11m 44s\n",
      "13: learn: 0.2275393\ttest: 0.2268831\tbestTest: 0.2268831 (13)\ttotal: 1m 53s\tremaining: 11m 34s\n",
      "14: learn: 0.2265222\ttest: 0.2258728\tbestTest: 0.2258728 (14)\ttotal: 2m 1s\tremaining: 11m 29s\n",
      "15: learn: 0.2255841\ttest: 0.2249551\tbestTest: 0.2249551 (15)\ttotal: 2m 10s\tremaining: 11m 23s\n",
      "16: learn: 0.2249588\ttest: 0.2243289\tbestTest: 0.2243289 (16)\ttotal: 2m 17s\tremaining: 11m 12s\n",
      "17: learn: 0.2245048\ttest: 0.223868\tbestTest: 0.223868 (17)\ttotal: 2m 26s\tremaining: 11m 8s\n",
      "18: learn: 0.2240512\ttest: 0.2234333\tbestTest: 0.2234333 (18)\ttotal: 2m 34s\tremaining: 11m\n",
      "19: learn: 0.2237268\ttest: 0.2231256\tbestTest: 0.2231256 (19)\ttotal: 2m 43s\tremaining: 10m 54s\n",
      "20: learn: 0.2233303\ttest: 0.2227365\tbestTest: 0.2227365 (20)\ttotal: 2m 51s\tremaining: 10m 45s\n",
      "21: learn: 0.2230691\ttest: 0.2224893\tbestTest: 0.2224893 (21)\ttotal: 2m 59s\tremaining: 10m 37s\n",
      "22: learn: 0.2228801\ttest: 0.2223027\tbestTest: 0.2223027 (22)\ttotal: 3m 7s\tremaining: 10m 29s\n",
      "23: learn: 0.2225791\ttest: 0.2220207\tbestTest: 0.2220207 (23)\ttotal: 3m 20s\tremaining: 10m 36s\n",
      "24: learn: 0.2224094\ttest: 0.2218588\tbestTest: 0.2218588 (24)\ttotal: 3m 34s\tremaining: 10m 44s\n",
      "25: learn: 0.2222429\ttest: 0.2217135\tbestTest: 0.2217135 (25)\ttotal: 3m 49s\tremaining: 10m 53s\n",
      "26: learn: 0.222107\ttest: 0.2215913\tbestTest: 0.2215913 (26)\ttotal: 4m 3s\tremaining: 10m 59s\n",
      "27: learn: 0.2218833\ttest: 0.2213956\tbestTest: 0.2213956 (27)\ttotal: 4m 18s\tremaining: 11m 5s\n",
      "28: learn: 0.2217286\ttest: 0.221256\tbestTest: 0.221256 (28)\ttotal: 4m 33s\tremaining: 11m 9s\n",
      "29: learn: 0.2216082\ttest: 0.2211585\tbestTest: 0.2211585 (29)\ttotal: 4m 48s\tremaining: 11m 14s\n",
      "30: learn: 0.2215023\ttest: 0.2210674\tbestTest: 0.2210674 (30)\ttotal: 5m 4s\tremaining: 11m 16s\n",
      "31: learn: 0.2213604\ttest: 0.2209521\tbestTest: 0.2209521 (31)\ttotal: 5m 19s\tremaining: 11m 18s\n",
      "32: learn: 0.221298\ttest: 0.2208994\tbestTest: 0.2208994 (32)\ttotal: 5m 36s\tremaining: 11m 23s\n",
      "33: learn: 0.2211918\ttest: 0.2208185\tbestTest: 0.2208185 (33)\ttotal: 5m 51s\tremaining: 11m 22s\n",
      "34: learn: 0.2210898\ttest: 0.2207292\tbestTest: 0.2207292 (34)\ttotal: 6m 8s\tremaining: 11m 23s\n",
      "35: learn: 0.2209856\ttest: 0.2206457\tbestTest: 0.2206457 (35)\ttotal: 6m 23s\tremaining: 11m 20s\n",
      "36: learn: 0.2208929\ttest: 0.2205715\tbestTest: 0.2205715 (36)\ttotal: 6m 38s\tremaining: 11m 19s\n",
      "37: learn: 0.2208051\ttest: 0.2205011\tbestTest: 0.2205011 (37)\ttotal: 6m 53s\tremaining: 11m 14s\n",
      "38: learn: 0.2207354\ttest: 0.2204515\tbestTest: 0.2204515 (38)\ttotal: 7m 11s\tremaining: 11m 14s\n",
      "39: learn: 0.2206454\ttest: 0.2203801\tbestTest: 0.2203801 (39)\ttotal: 7m 26s\tremaining: 11m 10s\n",
      "40: learn: 0.2205694\ttest: 0.22032\tbestTest: 0.22032 (40)\ttotal: 7m 43s\tremaining: 11m 7s\n",
      "41: learn: 0.2205029\ttest: 0.2202756\tbestTest: 0.2202756 (41)\ttotal: 7m 58s\tremaining: 11m\n",
      "42: learn: 0.2204438\ttest: 0.2202263\tbestTest: 0.2202263 (42)\ttotal: 8m 14s\tremaining: 10m 55s\n",
      "43: learn: 0.2203728\ttest: 0.2201687\tbestTest: 0.2201687 (43)\ttotal: 8m 30s\tremaining: 10m 49s\n",
      "44: learn: 0.2203209\ttest: 0.2201283\tbestTest: 0.2201283 (44)\ttotal: 8m 46s\tremaining: 10m 43s\n",
      "45: learn: 0.2202616\ttest: 0.2200865\tbestTest: 0.2200865 (45)\ttotal: 9m 3s\tremaining: 10m 37s\n",
      "46: learn: 0.2201948\ttest: 0.220047\tbestTest: 0.220047 (46)\ttotal: 9m 18s\tremaining: 10m 29s\n",
      "47: learn: 0.2201053\ttest: 0.2199767\tbestTest: 0.2199767 (47)\ttotal: 9m 32s\tremaining: 10m 19s\n",
      "48: learn: 0.220057\ttest: 0.2199508\tbestTest: 0.2199508 (48)\ttotal: 9m 46s\tremaining: 10m 10s\n",
      "49: learn: 0.2199801\ttest: 0.2199053\tbestTest: 0.2199053 (49)\ttotal: 10m 2s\tremaining: 10m 2s\n",
      "50: learn: 0.2199345\ttest: 0.2198706\tbestTest: 0.2198706 (50)\ttotal: 10m 19s\tremaining: 9m 54s\n",
      "51: learn: 0.2198987\ttest: 0.2198386\tbestTest: 0.2198386 (51)\ttotal: 10m 36s\tremaining: 9m 47s\n",
      "52: learn: 0.219835\ttest: 0.2198005\tbestTest: 0.2198005 (52)\ttotal: 10m 52s\tremaining: 9m 38s\n",
      "53: learn: 0.2197701\ttest: 0.2197466\tbestTest: 0.2197466 (53)\ttotal: 11m 8s\tremaining: 9m 29s\n",
      "54: learn: 0.2197475\ttest: 0.2197252\tbestTest: 0.2197252 (54)\ttotal: 11m 21s\tremaining: 9m 17s\n",
      "55: learn: 0.2197006\ttest: 0.2196919\tbestTest: 0.2196919 (55)\ttotal: 11m 38s\tremaining: 9m 8s\n",
      "56: learn: 0.2196566\ttest: 0.2196635\tbestTest: 0.2196635 (56)\ttotal: 11m 51s\tremaining: 8m 56s\n",
      "57: learn: 0.2196082\ttest: 0.2196271\tbestTest: 0.2196271 (57)\ttotal: 12m 6s\tremaining: 8m 46s\n",
      "58: learn: 0.2195845\ttest: 0.219606\tbestTest: 0.219606 (58)\ttotal: 12m 20s\tremaining: 8m 34s\n",
      "59: learn: 0.2195472\ttest: 0.2195824\tbestTest: 0.2195824 (59)\ttotal: 12m 36s\tremaining: 8m 24s\n",
      "60: learn: 0.2194703\ttest: 0.2195205\tbestTest: 0.2195205 (60)\ttotal: 12m 52s\tremaining: 8m 13s\n",
      "61: learn: 0.2194381\ttest: 0.2194946\tbestTest: 0.2194946 (61)\ttotal: 13m 7s\tremaining: 8m 2s\n",
      "62: learn: 0.2193549\ttest: 0.2194502\tbestTest: 0.2194502 (62)\ttotal: 13m 23s\tremaining: 7m 51s\n",
      "63: learn: 0.2193149\ttest: 0.2194237\tbestTest: 0.2194237 (63)\ttotal: 13m 37s\tremaining: 7m 39s\n",
      "64: learn: 0.2192859\ttest: 0.2194075\tbestTest: 0.2194075 (64)\ttotal: 13m 53s\tremaining: 7m 29s\n",
      "65: learn: 0.2192479\ttest: 0.2193837\tbestTest: 0.2193837 (65)\ttotal: 14m 8s\tremaining: 7m 16s\n",
      "66: learn: 0.2192158\ttest: 0.2193671\tbestTest: 0.2193671 (66)\ttotal: 14m 21s\tremaining: 7m 4s\n",
      "67: learn: 0.2191574\ttest: 0.2193278\tbestTest: 0.2193278 (67)\ttotal: 14m 36s\tremaining: 6m 52s\n",
      "68: learn: 0.2191302\ttest: 0.21931\tbestTest: 0.21931 (68)\ttotal: 14m 51s\tremaining: 6m 40s\n",
      "69: learn: 0.2190971\ttest: 0.2192857\tbestTest: 0.2192857 (69)\ttotal: 15m 8s\tremaining: 6m 29s\n",
      "70: learn: 0.2190598\ttest: 0.2192666\tbestTest: 0.2192666 (70)\ttotal: 15m 24s\tremaining: 6m 17s\n",
      "71: learn: 0.2190429\ttest: 0.2192522\tbestTest: 0.2192522 (71)\ttotal: 15m 40s\tremaining: 6m 5s\n",
      "72: learn: 0.2190296\ttest: 0.2192417\tbestTest: 0.2192417 (72)\ttotal: 15m 50s\tremaining: 5m 51s\n",
      "73: learn: 0.2189957\ttest: 0.2192278\tbestTest: 0.2192278 (73)\ttotal: 16m 5s\tremaining: 5m 39s\n",
      "74: learn: 0.2189196\ttest: 0.2191755\tbestTest: 0.2191755 (74)\ttotal: 16m 19s\tremaining: 5m 26s\n",
      "75: learn: 0.2188843\ttest: 0.2191531\tbestTest: 0.2191531 (75)\ttotal: 16m 34s\tremaining: 5m 14s\n",
      "76: learn: 0.2188612\ttest: 0.2191382\tbestTest: 0.2191382 (76)\ttotal: 16m 49s\tremaining: 5m 1s\n",
      "77: learn: 0.2188318\ttest: 0.2191197\tbestTest: 0.2191197 (77)\ttotal: 17m 5s\tremaining: 4m 49s\n",
      "78: learn: 0.2187886\ttest: 0.2191014\tbestTest: 0.2191014 (78)\ttotal: 17m 19s\tremaining: 4m 36s\n",
      "79: learn: 0.218734\ttest: 0.2190732\tbestTest: 0.2190732 (79)\ttotal: 17m 33s\tremaining: 4m 23s\n",
      "80: learn: 0.2187039\ttest: 0.2190585\tbestTest: 0.2190585 (80)\ttotal: 17m 49s\tremaining: 4m 10s\n",
      "81: learn: 0.2186764\ttest: 0.2190457\tbestTest: 0.2190457 (81)\ttotal: 18m 2s\tremaining: 3m 57s\n",
      "82: learn: 0.2186424\ttest: 0.2190245\tbestTest: 0.2190245 (82)\ttotal: 18m 17s\tremaining: 3m 44s\n",
      "83: learn: 0.2186246\ttest: 0.2190136\tbestTest: 0.2190136 (83)\ttotal: 18m 33s\tremaining: 3m 32s\n",
      "84: learn: 0.2185851\ttest: 0.2189959\tbestTest: 0.2189959 (84)\ttotal: 18m 47s\tremaining: 3m 19s\n",
      "85: learn: 0.218563\ttest: 0.2189836\tbestTest: 0.2189836 (85)\ttotal: 19m 3s\tremaining: 3m 6s\n",
      "86: learn: 0.2185117\ttest: 0.2189535\tbestTest: 0.2189535 (86)\ttotal: 19m 18s\tremaining: 2m 53s\n",
      "87: learn: 0.2184843\ttest: 0.2189403\tbestTest: 0.2189403 (87)\ttotal: 19m 33s\tremaining: 2m 39s\n",
      "88: learn: 0.2184461\ttest: 0.2189192\tbestTest: 0.2189192 (88)\ttotal: 19m 47s\tremaining: 2m 26s\n",
      "89: learn: 0.2184052\ttest: 0.2189021\tbestTest: 0.2189021 (89)\ttotal: 20m 2s\tremaining: 2m 13s\n",
      "90: learn: 0.2183978\ttest: 0.2188973\tbestTest: 0.2188973 (90)\ttotal: 20m 15s\tremaining: 2m\n",
      "91: learn: 0.2183781\ttest: 0.2188873\tbestTest: 0.2188873 (91)\ttotal: 20m 31s\tremaining: 1m 47s\n",
      "92: learn: 0.218347\ttest: 0.2188726\tbestTest: 0.2188726 (92)\ttotal: 20m 46s\tremaining: 1m 33s\n",
      "93: learn: 0.2183184\ttest: 0.2188621\tbestTest: 0.2188621 (93)\ttotal: 21m 1s\tremaining: 1m 20s\n",
      "94: learn: 0.2182715\ttest: 0.2188363\tbestTest: 0.2188363 (94)\ttotal: 21m 16s\tremaining: 1m 7s\n",
      "95: learn: 0.2182449\ttest: 0.2188153\tbestTest: 0.2188153 (95)\ttotal: 21m 32s\tremaining: 53.9s\n",
      "96: learn: 0.2182205\ttest: 0.2188014\tbestTest: 0.2188014 (96)\ttotal: 21m 47s\tremaining: 40.4s\n",
      "97: learn: 0.2181914\ttest: 0.2187936\tbestTest: 0.2187936 (97)\ttotal: 22m 1s\tremaining: 27s\n",
      "98: learn: 0.2181644\ttest: 0.218782\tbestTest: 0.218782 (98)\ttotal: 22m 15s\tremaining: 13.5s\n",
      "99: learn: 0.2181127\ttest: 0.2187529\tbestTest: 0.2187529 (99)\ttotal: 22m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2187528974\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.15_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 00:22:57.908320\n",
      "train time given below\n",
      "0:26:41.939383\n",
      "2018-03-15 00:22:57.995148\n",
      "2018-03-15 00:22:58.001927\n",
      "GINI ISIT = 0.506916435364\n",
      "2018-03-15 00:26:03.458066\n",
      "GINI OSIT = 0.497735638859\n",
      "2018-03-15 00:27:21.367669\n",
      "GINI OSOT = 0.422210115567\n",
      "2018-03-15 00:27:44.925979\n",
      "2018-03-15 00:27:44.929259\n",
      "loop run time\n",
      "0:31:28.960512\n"
     ]
    }
   ],
   "source": [
    "#optimize learning rate\n",
    "\n",
    "for lrn_rt in lrn_rt_pv:\n",
    "    \n",
    "    print('learning rate = ' + str(lrn_rt))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_opt,\n",
    "                           lrn_rt = lrn_rt,\n",
    "                           dep = dep_opt,\n",
    "                           l2_reg = l2_reg_opt,\n",
    "                           num_split = num_split_opt,\n",
    "                           cat_split = cat_split_opt,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_opt\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt\n",
    "    result_df_temp.loc[0,'depth'] = dep_opt\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_opt\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_opt\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_opt\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    t2 = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"loop run time\")\n",
    "    print(t2-t1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451849</td>\n",
       "      <td>0.453623</td>\n",
       "      <td>0.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.45484</td>\n",
       "      <td>0.407005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>0.405824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45513</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454684</td>\n",
       "      <td>0.456024</td>\n",
       "      <td>0.408098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455045</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.40867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45336</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.408261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454922</td>\n",
       "      <td>0.456109</td>\n",
       "      <td>0.410751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456208</td>\n",
       "      <td>0.457545</td>\n",
       "      <td>0.41235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454801</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>0.411622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45617</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.411126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.409276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441066</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>0.396312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.450992</td>\n",
       "      <td>0.404413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460658</td>\n",
       "      <td>0.461646</td>\n",
       "      <td>0.416653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>0.465669</td>\n",
       "      <td>0.41762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468306</td>\n",
       "      <td>0.468324</td>\n",
       "      <td>0.417121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.451405</td>\n",
       "      <td>0.400855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46271</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>0.418592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484078</td>\n",
       "      <td>0.481967</td>\n",
       "      <td>0.434897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.075</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493039</td>\n",
       "      <td>0.488949</td>\n",
       "      <td>0.445385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498417</td>\n",
       "      <td>0.492692</td>\n",
       "      <td>0.431242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.125</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503328</td>\n",
       "      <td>0.496473</td>\n",
       "      <td>0.44277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506916</td>\n",
       "      <td>0.497736</td>\n",
       "      <td>0.42221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree   rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100     1          0.03     6                 1             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 5             128   \n",
       "0    100     1          0.03     6                10             128   \n",
       "0    100     1          0.03     6                50             128   \n",
       "0    100     1          0.03     6               100             128   \n",
       "0    100     1          0.03     6                 3               5   \n",
       "0    100     1          0.03     6                 3              10   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              32   \n",
       "0    100     1          0.03     6                 3              64   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             255   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100   0.5          0.03     6                 3              16   \n",
       "0    100   0.6          0.03     6                 3              16   \n",
       "0    100   0.7          0.03     6                 3              16   \n",
       "0    100  0.75          0.03     6                 3              16   \n",
       "0    100   0.8          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100   0.9          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     4                 3              16   \n",
       "0    100  0.85          0.03     5                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     7                 3              16   \n",
       "0    100  0.85          0.03     8                 3              16   \n",
       "0    100  0.85          0.03     9                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "0    100  0.85          0.01    10                 3              16   \n",
       "0    100  0.85          0.02    10                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "0    100  0.85          0.05    10                 3              16   \n",
       "0    100  0.85         0.075    10                 3              16   \n",
       "0    100  0.85           0.1    10                 3              16   \n",
       "0    100  0.85         0.125    10                 3              16   \n",
       "0    100  0.85          0.15    10                 3              16   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  \n",
       "0                 5                   1  0.451849  0.453623  0.402904  \n",
       "0                10                   1  0.453604   0.45484  0.407005  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                32                   1  0.453115  0.454388  0.405824  \n",
       "0                64                   1   0.45513  0.456311  0.409631  \n",
       "0               128                   1  0.454684  0.456024  0.408098  \n",
       "0               255                   1  0.455045  0.456244   0.40867  \n",
       "0                16                   1   0.45336  0.454692  0.408261  \n",
       "0                16                   1  0.454922  0.456109  0.410751  \n",
       "0                16                   1  0.456208  0.457545   0.41235  \n",
       "0                16                   1  0.454801  0.456263  0.411622  \n",
       "0                16                   1   0.45617  0.457539  0.411126  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.456422  0.457679  0.409276  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.441066  0.442915  0.396312  \n",
       "0                16                   1  0.449438  0.450992  0.404413  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.460658  0.461646  0.416653  \n",
       "0                16                   1  0.465061  0.465669   0.41762  \n",
       "0                16                   1  0.468306  0.468324  0.417121  \n",
       "0                16                   1  0.472581  0.471884  0.421361  \n",
       "0                16                   1  0.451027  0.451405  0.400855  \n",
       "0                16                   1   0.46271  0.462658  0.418592  \n",
       "0                16                   1  0.472581  0.471884  0.421361  \n",
       "0                16                   1  0.484078  0.481967  0.434897  \n",
       "0                16                   1  0.493039  0.488949  0.445385  \n",
       "0                16                   1  0.498417  0.492692  0.431242  \n",
       "0                16                   1  0.503328  0.496473   0.44277  \n",
       "0                16                   1  0.506916  0.497736   0.42221  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.3\n",
      "2018-03-15 00:38:13.801742\n",
      "model train start\n",
      "2018-03-15 00:38:13.802139\n",
      "0: learn: 0.4126743\ttest: 0.4124469\tbestTest: 0.4124469 (0)\ttotal: 6.15s\tremaining: 10m 8s\n",
      "1: learn: 0.3024897\ttest: 0.3021123\tbestTest: 0.3021123 (1)\ttotal: 13.6s\tremaining: 11m 5s\n",
      "2: learn: 0.2605809\ttest: 0.2600461\tbestTest: 0.2600461 (2)\ttotal: 21.9s\tremaining: 11m 49s\n",
      "3: learn: 0.241641\ttest: 0.2410223\tbestTest: 0.2410223 (3)\ttotal: 29s\tremaining: 11m 37s\n",
      "4: learn: 0.2332284\ttest: 0.2325811\tbestTest: 0.2325811 (4)\ttotal: 38.1s\tremaining: 12m 4s\n",
      "5: learn: 0.2288889\ttest: 0.228194\tbestTest: 0.228194 (5)\ttotal: 47.1s\tremaining: 12m 17s\n",
      "6: learn: 0.2264316\ttest: 0.2257552\tbestTest: 0.2257552 (6)\ttotal: 55.7s\tremaining: 12m 20s\n",
      "7: learn: 0.2249431\ttest: 0.2242616\tbestTest: 0.2242616 (7)\ttotal: 1m 3s\tremaining: 12m 10s\n",
      "8: learn: 0.2239689\ttest: 0.2233148\tbestTest: 0.2233148 (8)\ttotal: 1m 11s\tremaining: 11m 59s\n",
      "9: learn: 0.2234166\ttest: 0.2227748\tbestTest: 0.2227748 (9)\ttotal: 1m 19s\tremaining: 11m 51s\n",
      "10: learn: 0.2229457\ttest: 0.2223465\tbestTest: 0.2223465 (10)\ttotal: 1m 27s\tremaining: 11m 49s\n",
      "11: learn: 0.2225577\ttest: 0.221989\tbestTest: 0.221989 (11)\ttotal: 1m 35s\tremaining: 11m 42s\n",
      "12: learn: 0.2221995\ttest: 0.2216708\tbestTest: 0.2216708 (12)\ttotal: 1m 43s\tremaining: 11m 35s\n",
      "13: learn: 0.2218089\ttest: 0.2213272\tbestTest: 0.2213272 (13)\ttotal: 1m 51s\tremaining: 11m 26s\n",
      "14: learn: 0.2215306\ttest: 0.2211088\tbestTest: 0.2211088 (14)\ttotal: 1m 59s\tremaining: 11m 18s\n",
      "15: learn: 0.2213527\ttest: 0.2209414\tbestTest: 0.2209414 (15)\ttotal: 2m 7s\tremaining: 11m 8s\n",
      "16: learn: 0.2212163\ttest: 0.2208199\tbestTest: 0.2208199 (16)\ttotal: 2m 15s\tremaining: 11m 2s\n",
      "17: learn: 0.2210791\ttest: 0.2207036\tbestTest: 0.2207036 (17)\ttotal: 2m 24s\tremaining: 10m 59s\n",
      "18: learn: 0.2208972\ttest: 0.2205724\tbestTest: 0.2205724 (18)\ttotal: 2m 33s\tremaining: 10m 54s\n",
      "19: learn: 0.220764\ttest: 0.2204771\tbestTest: 0.2204771 (19)\ttotal: 2m 41s\tremaining: 10m 45s\n",
      "20: learn: 0.2206623\ttest: 0.2204004\tbestTest: 0.2204004 (20)\ttotal: 2m 49s\tremaining: 10m 37s\n",
      "21: learn: 0.2205627\ttest: 0.2203258\tbestTest: 0.2203258 (21)\ttotal: 2m 58s\tremaining: 10m 32s\n",
      "22: learn: 0.2204942\ttest: 0.2202713\tbestTest: 0.2202713 (22)\ttotal: 3m 4s\tremaining: 10m 18s\n",
      "23: learn: 0.2203778\ttest: 0.2201893\tbestTest: 0.2201893 (23)\ttotal: 3m 13s\tremaining: 10m 11s\n",
      "24: learn: 0.2202029\ttest: 0.2200488\tbestTest: 0.2200488 (24)\ttotal: 3m 21s\tremaining: 10m 3s\n",
      "25: learn: 0.2201203\ttest: 0.2199869\tbestTest: 0.2199869 (25)\ttotal: 3m 28s\tremaining: 9m 53s\n",
      "26: learn: 0.2200525\ttest: 0.2199308\tbestTest: 0.2199308 (26)\ttotal: 3m 36s\tremaining: 9m 46s\n",
      "27: learn: 0.2200153\ttest: 0.2198986\tbestTest: 0.2198986 (27)\ttotal: 3m 42s\tremaining: 9m 31s\n",
      "28: learn: 0.219879\ttest: 0.2197956\tbestTest: 0.2197956 (28)\ttotal: 3m 50s\tremaining: 9m 24s\n",
      "29: learn: 0.2197394\ttest: 0.2197129\tbestTest: 0.2197129 (29)\ttotal: 3m 58s\tremaining: 9m 15s\n",
      "30: learn: 0.2196849\ttest: 0.219676\tbestTest: 0.219676 (30)\ttotal: 4m 6s\tremaining: 9m 7s\n",
      "31: learn: 0.2195991\ttest: 0.2196128\tbestTest: 0.2196128 (31)\ttotal: 4m 14s\tremaining: 9m 1s\n",
      "32: learn: 0.2195439\ttest: 0.2195765\tbestTest: 0.2195765 (32)\ttotal: 4m 22s\tremaining: 8m 53s\n",
      "33: learn: 0.2194865\ttest: 0.2195509\tbestTest: 0.2195509 (33)\ttotal: 4m 30s\tremaining: 8m 45s\n",
      "34: learn: 0.2194101\ttest: 0.2194912\tbestTest: 0.2194912 (34)\ttotal: 4m 38s\tremaining: 8m 38s\n",
      "35: learn: 0.2193451\ttest: 0.2194609\tbestTest: 0.2194609 (35)\ttotal: 4m 46s\tremaining: 8m 29s\n",
      "36: learn: 0.219284\ttest: 0.2194381\tbestTest: 0.2194381 (36)\ttotal: 4m 54s\tremaining: 8m 22s\n",
      "37: learn: 0.2192154\ttest: 0.2193811\tbestTest: 0.2193811 (37)\ttotal: 5m 3s\tremaining: 8m 14s\n",
      "38: learn: 0.2191824\ttest: 0.2193636\tbestTest: 0.2193636 (38)\ttotal: 5m 11s\tremaining: 8m 7s\n",
      "39: learn: 0.2191301\ttest: 0.2193297\tbestTest: 0.2193297 (39)\ttotal: 5m 19s\tremaining: 7m 59s\n",
      "40: learn: 0.219083\ttest: 0.2193104\tbestTest: 0.2193104 (40)\ttotal: 5m 28s\tremaining: 7m 53s\n",
      "41: learn: 0.2190201\ttest: 0.2192594\tbestTest: 0.2192594 (41)\ttotal: 5m 37s\tremaining: 7m 46s\n",
      "42: learn: 0.2189492\ttest: 0.2192169\tbestTest: 0.2192169 (42)\ttotal: 5m 45s\tremaining: 7m 37s\n",
      "43: learn: 0.218929\ttest: 0.2192011\tbestTest: 0.2192011 (43)\ttotal: 5m 51s\tremaining: 7m 26s\n",
      "44: learn: 0.2188718\ttest: 0.2191701\tbestTest: 0.2191701 (44)\ttotal: 6m\tremaining: 7m 20s\n",
      "45: learn: 0.2187982\ttest: 0.2191119\tbestTest: 0.2191119 (45)\ttotal: 6m 7s\tremaining: 7m 11s\n",
      "46: learn: 0.2187179\ttest: 0.2190687\tbestTest: 0.2190687 (46)\ttotal: 6m 15s\tremaining: 7m 3s\n",
      "47: learn: 0.218651\ttest: 0.2190484\tbestTest: 0.2190484 (47)\ttotal: 6m 23s\tremaining: 6m 55s\n",
      "48: learn: 0.218592\ttest: 0.2190183\tbestTest: 0.2190183 (48)\ttotal: 6m 32s\tremaining: 6m 48s\n",
      "49: learn: 0.2185039\ttest: 0.2189979\tbestTest: 0.2189979 (49)\ttotal: 6m 40s\tremaining: 6m 40s\n",
      "50: learn: 0.2184629\ttest: 0.2189772\tbestTest: 0.2189772 (50)\ttotal: 6m 47s\tremaining: 6m 31s\n",
      "51: learn: 0.2184074\ttest: 0.2189594\tbestTest: 0.2189594 (51)\ttotal: 6m 55s\tremaining: 6m 23s\n",
      "52: learn: 0.2183818\ttest: 0.2189498\tbestTest: 0.2189498 (52)\ttotal: 7m 4s\tremaining: 6m 16s\n",
      "53: learn: 0.2182989\ttest: 0.2188998\tbestTest: 0.2188998 (53)\ttotal: 7m 11s\tremaining: 6m 7s\n",
      "54: learn: 0.2182207\ttest: 0.2188578\tbestTest: 0.2188578 (54)\ttotal: 7m 20s\tremaining: 6m\n",
      "55: learn: 0.2181698\ttest: 0.2188431\tbestTest: 0.2188431 (55)\ttotal: 7m 28s\tremaining: 5m 52s\n",
      "56: learn: 0.2181172\ttest: 0.2188219\tbestTest: 0.2188219 (56)\ttotal: 7m 35s\tremaining: 5m 43s\n",
      "57: learn: 0.2180862\ttest: 0.2188105\tbestTest: 0.2188105 (57)\ttotal: 7m 44s\tremaining: 5m 36s\n",
      "58: learn: 0.2180416\ttest: 0.2187801\tbestTest: 0.2187801 (58)\ttotal: 7m 52s\tremaining: 5m 28s\n",
      "59: learn: 0.2179786\ttest: 0.2187409\tbestTest: 0.2187409 (59)\ttotal: 8m\tremaining: 5m 20s\n",
      "60: learn: 0.2179017\ttest: 0.2187241\tbestTest: 0.2187241 (60)\ttotal: 8m 8s\tremaining: 5m 12s\n",
      "61: learn: 0.2178468\ttest: 0.218699\tbestTest: 0.218699 (61)\ttotal: 8m 15s\tremaining: 5m 3s\n",
      "62: learn: 0.2178155\ttest: 0.2186784\tbestTest: 0.2186784 (62)\ttotal: 8m 23s\tremaining: 4m 55s\n",
      "63: learn: 0.2177778\ttest: 0.2186624\tbestTest: 0.2186624 (63)\ttotal: 8m 31s\tremaining: 4m 47s\n",
      "64: learn: 0.2177191\ttest: 0.2186467\tbestTest: 0.2186467 (64)\ttotal: 8m 38s\tremaining: 4m 39s\n",
      "65: learn: 0.2177035\ttest: 0.2186434\tbestTest: 0.2186434 (65)\ttotal: 8m 47s\tremaining: 4m 31s\n",
      "66: learn: 0.2176875\ttest: 0.2186374\tbestTest: 0.2186374 (66)\ttotal: 8m 55s\tremaining: 4m 23s\n",
      "67: learn: 0.2176352\ttest: 0.2186265\tbestTest: 0.2186265 (67)\ttotal: 9m 3s\tremaining: 4m 15s\n",
      "68: learn: 0.2176049\ttest: 0.2186229\tbestTest: 0.2186229 (68)\ttotal: 9m 11s\tremaining: 4m 7s\n",
      "69: learn: 0.2175645\ttest: 0.218607\tbestTest: 0.218607 (69)\ttotal: 9m 19s\tremaining: 3m 59s\n",
      "70: learn: 0.2175325\ttest: 0.2185974\tbestTest: 0.2185974 (70)\ttotal: 9m 27s\tremaining: 3m 51s\n",
      "71: learn: 0.2174949\ttest: 0.2185888\tbestTest: 0.2185888 (71)\ttotal: 9m 34s\tremaining: 3m 43s\n",
      "72: learn: 0.2174494\ttest: 0.2185585\tbestTest: 0.2185585 (72)\ttotal: 9m 43s\tremaining: 3m 35s\n",
      "73: learn: 0.2174286\ttest: 0.2185479\tbestTest: 0.2185479 (73)\ttotal: 9m 52s\tremaining: 3m 28s\n",
      "74: learn: 0.2173795\ttest: 0.2185444\tbestTest: 0.2185444 (74)\ttotal: 10m 1s\tremaining: 3m 20s\n",
      "75: learn: 0.2173229\ttest: 0.2185457\tbestTest: 0.2185444 (74)\ttotal: 10m 9s\tremaining: 3m 12s\n",
      "76: learn: 0.2172999\ttest: 0.2185372\tbestTest: 0.2185372 (76)\ttotal: 10m 17s\tremaining: 3m 4s\n",
      "77: learn: 0.2172829\ttest: 0.218533\tbestTest: 0.218533 (77)\ttotal: 10m 25s\tremaining: 2m 56s\n",
      "78: learn: 0.2172243\ttest: 0.2185343\tbestTest: 0.218533 (77)\ttotal: 10m 34s\tremaining: 2m 48s\n",
      "79: learn: 0.2171841\ttest: 0.2185261\tbestTest: 0.2185261 (79)\ttotal: 10m 42s\tremaining: 2m 40s\n",
      "80: learn: 0.2171737\ttest: 0.2185234\tbestTest: 0.2185234 (80)\ttotal: 10m 51s\tremaining: 2m 32s\n",
      "81: learn: 0.2171403\ttest: 0.218525\tbestTest: 0.2185234 (80)\ttotal: 10m 59s\tremaining: 2m 24s\n",
      "82: learn: 0.2171394\ttest: 0.2185248\tbestTest: 0.2185234 (80)\ttotal: 11m 9s\tremaining: 2m 17s\n",
      "83: learn: 0.2170922\ttest: 0.218524\tbestTest: 0.2185234 (80)\ttotal: 11m 18s\tremaining: 2m 9s\n",
      "84: learn: 0.2170648\ttest: 0.2185123\tbestTest: 0.2185123 (84)\ttotal: 11m 27s\tremaining: 2m 1s\n",
      "85: learn: 0.2170347\ttest: 0.2185088\tbestTest: 0.2185088 (85)\ttotal: 11m 35s\tremaining: 1m 53s\n",
      "86: learn: 0.2170079\ttest: 0.2185083\tbestTest: 0.2185083 (86)\ttotal: 11m 43s\tremaining: 1m 45s\n",
      "87: learn: 0.2169467\ttest: 0.2185076\tbestTest: 0.2185076 (87)\ttotal: 11m 50s\tremaining: 1m 36s\n",
      "88: learn: 0.216918\ttest: 0.218509\tbestTest: 0.2185076 (87)\ttotal: 11m 58s\tremaining: 1m 28s\n",
      "89: learn: 0.2168329\ttest: 0.2185045\tbestTest: 0.2185045 (89)\ttotal: 12m 5s\tremaining: 1m 20s\n",
      "90: learn: 0.2167967\ttest: 0.2185031\tbestTest: 0.2185031 (90)\ttotal: 12m 13s\tremaining: 1m 12s\n",
      "91: learn: 0.2167427\ttest: 0.21849\tbestTest: 0.21849 (91)\ttotal: 12m 21s\tremaining: 1m 4s\n",
      "92: learn: 0.2166951\ttest: 0.2184872\tbestTest: 0.2184872 (92)\ttotal: 12m 28s\tremaining: 56.4s\n",
      "93: learn: 0.216652\ttest: 0.2184915\tbestTest: 0.2184872 (92)\ttotal: 12m 36s\tremaining: 48.3s\n",
      "94: learn: 0.2166129\ttest: 0.218481\tbestTest: 0.218481 (94)\ttotal: 12m 44s\tremaining: 40.2s\n",
      "95: learn: 0.2165625\ttest: 0.2184758\tbestTest: 0.2184758 (95)\ttotal: 12m 52s\tremaining: 32.2s\n",
      "96: learn: 0.2165178\ttest: 0.2184682\tbestTest: 0.2184682 (96)\ttotal: 13m 1s\tremaining: 24.2s\n",
      "97: learn: 0.2164721\ttest: 0.2184599\tbestTest: 0.2184599 (97)\ttotal: 13m 8s\tremaining: 16.1s\n",
      "98: learn: 0.2164438\ttest: 0.2184499\tbestTest: 0.2184499 (98)\ttotal: 13m 16s\tremaining: 8.04s\n",
      "99: learn: 0.2163877\ttest: 0.2184478\tbestTest: 0.2184478 (99)\ttotal: 13m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2184477764\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 00:57:18.173177\n",
      "train time given below\n",
      "0:19:04.371038\n",
      "2018-03-15 00:57:18.192542\n",
      "2018-03-15 00:57:18.196055\n",
      "GINI ISIT = 0.516769885861\n",
      "2018-03-15 00:58:54.249825\n",
      "GINI OSIT = 0.500367852\n",
      "2018-03-15 00:59:33.300762\n",
      "GINI OSOT = 0.429061950528\n",
      "2018-03-15 00:59:45.519454\n",
      "2018-03-15 00:59:45.521473\n",
      "loop run time\n",
      "0:21:31.719753\n",
      "learning rate = 0.5\n",
      "2018-03-15 00:59:45.523137\n",
      "model train start\n",
      "2018-03-15 00:59:45.523362\n",
      "0: learn: 0.31071\ttest: 0.3102978\tbestTest: 0.3102978 (0)\ttotal: 6.15s\tremaining: 10m 9s\n",
      "1: learn: 0.2447754\ttest: 0.2441377\tbestTest: 0.2441377 (1)\ttotal: 13.9s\tremaining: 11m 22s\n",
      "2: learn: 0.2308358\ttest: 0.2301217\tbestTest: 0.2301217 (2)\ttotal: 22.6s\tremaining: 12m 11s\n",
      "3: learn: 0.226278\ttest: 0.225584\tbestTest: 0.225584 (3)\ttotal: 31s\tremaining: 12m 24s\n",
      "4: learn: 0.224637\ttest: 0.2239131\tbestTest: 0.2239131 (4)\ttotal: 38.7s\tremaining: 12m 16s\n",
      "5: learn: 0.2237613\ttest: 0.2231299\tbestTest: 0.2231299 (5)\ttotal: 47.2s\tremaining: 12m 19s\n",
      "6: learn: 0.2228193\ttest: 0.2222936\tbestTest: 0.2222936 (6)\ttotal: 55.3s\tremaining: 12m 15s\n",
      "7: learn: 0.2223478\ttest: 0.2218628\tbestTest: 0.2218628 (7)\ttotal: 1m 3s\tremaining: 12m 11s\n",
      "8: learn: 0.222115\ttest: 0.2216525\tbestTest: 0.2216525 (8)\ttotal: 1m 11s\tremaining: 12m 7s\n",
      "9: learn: 0.2216726\ttest: 0.2213013\tbestTest: 0.2213013 (9)\ttotal: 1m 19s\tremaining: 11m 58s\n",
      "10: learn: 0.2213336\ttest: 0.2210619\tbestTest: 0.2210619 (10)\ttotal: 1m 27s\tremaining: 11m 45s\n",
      "11: learn: 0.2212141\ttest: 0.2209615\tbestTest: 0.2209615 (11)\ttotal: 1m 35s\tremaining: 11m 38s\n",
      "12: learn: 0.2209239\ttest: 0.2207163\tbestTest: 0.2207163 (12)\ttotal: 1m 43s\tremaining: 11m 35s\n",
      "13: learn: 0.2208135\ttest: 0.2206331\tbestTest: 0.2206331 (13)\ttotal: 1m 52s\tremaining: 11m 31s\n",
      "14: learn: 0.2206858\ttest: 0.2205346\tbestTest: 0.2205346 (14)\ttotal: 2m 1s\tremaining: 11m 30s\n",
      "15: learn: 0.2205401\ttest: 0.2204303\tbestTest: 0.2204303 (15)\ttotal: 2m 10s\tremaining: 11m 22s\n",
      "16: learn: 0.2203414\ttest: 0.2202692\tbestTest: 0.2202692 (16)\ttotal: 2m 18s\tremaining: 11m 17s\n",
      "17: learn: 0.2202303\ttest: 0.2201838\tbestTest: 0.2201838 (17)\ttotal: 2m 27s\tremaining: 11m 12s\n",
      "18: learn: 0.2201287\ttest: 0.2201211\tbestTest: 0.2201211 (18)\ttotal: 2m 35s\tremaining: 11m 4s\n",
      "19: learn: 0.2200248\ttest: 0.2200401\tbestTest: 0.2200401 (19)\ttotal: 2m 43s\tremaining: 10m 55s\n",
      "20: learn: 0.2199234\ttest: 0.2199608\tbestTest: 0.2199608 (20)\ttotal: 2m 51s\tremaining: 10m 45s\n",
      "21: learn: 0.2198312\ttest: 0.2199085\tbestTest: 0.2199085 (21)\ttotal: 3m\tremaining: 10m 38s\n",
      "22: learn: 0.2197294\ttest: 0.2198522\tbestTest: 0.2198522 (22)\ttotal: 3m 8s\tremaining: 10m 32s\n",
      "23: learn: 0.2196628\ttest: 0.2198079\tbestTest: 0.2198079 (23)\ttotal: 3m 16s\tremaining: 10m 20s\n",
      "24: learn: 0.2195812\ttest: 0.2197697\tbestTest: 0.2197697 (24)\ttotal: 3m 25s\tremaining: 10m 15s\n",
      "25: learn: 0.2195116\ttest: 0.2197252\tbestTest: 0.2197252 (25)\ttotal: 3m 33s\tremaining: 10m 7s\n",
      "26: learn: 0.2194346\ttest: 0.219689\tbestTest: 0.219689 (26)\ttotal: 3m 41s\tremaining: 9m 58s\n",
      "27: learn: 0.219335\ttest: 0.219649\tbestTest: 0.219649 (27)\ttotal: 3m 49s\tremaining: 9m 51s\n",
      "28: learn: 0.2192172\ttest: 0.2195643\tbestTest: 0.2195643 (28)\ttotal: 3m 57s\tremaining: 9m 42s\n",
      "29: learn: 0.2191298\ttest: 0.2195534\tbestTest: 0.2195534 (29)\ttotal: 4m 5s\tremaining: 9m 32s\n",
      "30: learn: 0.2190661\ttest: 0.2195285\tbestTest: 0.2195285 (30)\ttotal: 4m 12s\tremaining: 9m 22s\n",
      "31: learn: 0.2189426\ttest: 0.2194644\tbestTest: 0.2194644 (31)\ttotal: 4m 20s\tremaining: 9m 13s\n",
      "32: learn: 0.2188056\ttest: 0.2194496\tbestTest: 0.2194496 (32)\ttotal: 4m 28s\tremaining: 9m 4s\n",
      "33: learn: 0.218694\ttest: 0.2194289\tbestTest: 0.2194289 (33)\ttotal: 4m 36s\tremaining: 8m 55s\n",
      "34: learn: 0.2186328\ttest: 0.219405\tbestTest: 0.219405 (34)\ttotal: 4m 44s\tremaining: 8m 48s\n",
      "35: learn: 0.2185139\ttest: 0.2193439\tbestTest: 0.2193439 (35)\ttotal: 4m 52s\tremaining: 8m 40s\n",
      "36: learn: 0.2183323\ttest: 0.2192943\tbestTest: 0.2192943 (36)\ttotal: 5m\tremaining: 8m 30s\n",
      "37: learn: 0.2182713\ttest: 0.2192926\tbestTest: 0.2192926 (37)\ttotal: 5m 8s\tremaining: 8m 22s\n",
      "38: learn: 0.2181388\ttest: 0.2192306\tbestTest: 0.2192306 (38)\ttotal: 5m 16s\tremaining: 8m 14s\n",
      "39: learn: 0.2181221\ttest: 0.2192286\tbestTest: 0.2192286 (39)\ttotal: 5m 24s\tremaining: 8m 7s\n",
      "40: learn: 0.2180648\ttest: 0.2192238\tbestTest: 0.2192238 (40)\ttotal: 5m 32s\tremaining: 7m 58s\n",
      "41: learn: 0.2179846\ttest: 0.2192238\tbestTest: 0.2192238 (41)\ttotal: 5m 40s\tremaining: 7m 49s\n",
      "42: learn: 0.2179538\ttest: 0.2192133\tbestTest: 0.2192133 (42)\ttotal: 5m 48s\tremaining: 7m 42s\n",
      "43: learn: 0.2178034\ttest: 0.2191898\tbestTest: 0.2191898 (43)\ttotal: 5m 56s\tremaining: 7m 33s\n",
      "44: learn: 0.21775\ttest: 0.2191748\tbestTest: 0.2191748 (44)\ttotal: 6m 4s\tremaining: 7m 25s\n",
      "45: learn: 0.2176452\ttest: 0.2191267\tbestTest: 0.2191267 (45)\ttotal: 6m 11s\tremaining: 7m 16s\n",
      "46: learn: 0.2175855\ttest: 0.219121\tbestTest: 0.219121 (46)\ttotal: 6m 20s\tremaining: 7m 8s\n",
      "47: learn: 0.2174835\ttest: 0.2191015\tbestTest: 0.2191015 (47)\ttotal: 6m 28s\tremaining: 7m\n",
      "48: learn: 0.2174322\ttest: 0.2190826\tbestTest: 0.2190826 (48)\ttotal: 6m 36s\tremaining: 6m 53s\n",
      "49: learn: 0.2173498\ttest: 0.2190813\tbestTest: 0.2190813 (49)\ttotal: 6m 44s\tremaining: 6m 44s\n",
      "50: learn: 0.2173108\ttest: 0.2190733\tbestTest: 0.2190733 (50)\ttotal: 6m 52s\tremaining: 6m 36s\n",
      "51: learn: 0.2172173\ttest: 0.2190536\tbestTest: 0.2190536 (51)\ttotal: 7m\tremaining: 6m 28s\n",
      "52: learn: 0.217151\ttest: 0.2190371\tbestTest: 0.2190371 (52)\ttotal: 7m 8s\tremaining: 6m 19s\n",
      "53: learn: 0.2170699\ttest: 0.2189797\tbestTest: 0.2189797 (53)\ttotal: 7m 15s\tremaining: 6m 11s\n",
      "54: learn: 0.217041\ttest: 0.2189861\tbestTest: 0.2189797 (53)\ttotal: 7m 23s\tremaining: 6m 3s\n",
      "55: learn: 0.2170069\ttest: 0.2189824\tbestTest: 0.2189797 (53)\ttotal: 7m 32s\tremaining: 5m 55s\n",
      "56: learn: 0.2169342\ttest: 0.21898\tbestTest: 0.2189797 (53)\ttotal: 7m 40s\tremaining: 5m 47s\n",
      "57: learn: 0.2169307\ttest: 0.2189815\tbestTest: 0.2189797 (53)\ttotal: 7m 49s\tremaining: 5m 39s\n",
      "58: learn: 0.2168335\ttest: 0.2189734\tbestTest: 0.2189734 (58)\ttotal: 7m 57s\tremaining: 5m 31s\n",
      "59: learn: 0.216801\ttest: 0.2189674\tbestTest: 0.2189674 (59)\ttotal: 8m 6s\tremaining: 5m 24s\n",
      "60: learn: 0.2166891\ttest: 0.2189555\tbestTest: 0.2189555 (60)\ttotal: 8m 13s\tremaining: 5m 15s\n",
      "61: learn: 0.2166389\ttest: 0.2189521\tbestTest: 0.2189521 (61)\ttotal: 8m 22s\tremaining: 5m 7s\n",
      "62: learn: 0.2165792\ttest: 0.2189456\tbestTest: 0.2189456 (62)\ttotal: 8m 30s\tremaining: 4m 59s\n",
      "63: learn: 0.2165611\ttest: 0.2189457\tbestTest: 0.2189456 (62)\ttotal: 8m 39s\tremaining: 4m 52s\n",
      "64: learn: 0.2164509\ttest: 0.2189653\tbestTest: 0.2189456 (62)\ttotal: 8m 47s\tremaining: 4m 44s\n",
      "65: learn: 0.2164156\ttest: 0.2189628\tbestTest: 0.2189456 (62)\ttotal: 8m 55s\tremaining: 4m 36s\n",
      "66: learn: 0.2163594\ttest: 0.2189641\tbestTest: 0.2189456 (62)\ttotal: 9m 4s\tremaining: 4m 28s\n",
      "67: learn: 0.2162931\ttest: 0.218975\tbestTest: 0.2189456 (62)\ttotal: 9m 13s\tremaining: 4m 20s\n",
      "68: learn: 0.2162476\ttest: 0.2189815\tbestTest: 0.2189456 (62)\ttotal: 9m 21s\tremaining: 4m 12s\n",
      "69: learn: 0.216216\ttest: 0.2189823\tbestTest: 0.2189456 (62)\ttotal: 9m 30s\tremaining: 4m 4s\n",
      "70: learn: 0.2161462\ttest: 0.2190025\tbestTest: 0.2189456 (62)\ttotal: 9m 39s\tremaining: 3m 56s\n",
      "71: learn: 0.2160936\ttest: 0.218998\tbestTest: 0.2189456 (62)\ttotal: 9m 46s\tremaining: 3m 48s\n",
      "72: learn: 0.2160812\ttest: 0.2189967\tbestTest: 0.2189456 (62)\ttotal: 9m 56s\tremaining: 3m 40s\n",
      "73: learn: 0.2160495\ttest: 0.2189961\tbestTest: 0.2189456 (62)\ttotal: 10m 5s\tremaining: 3m 32s\n",
      "74: learn: 0.2159665\ttest: 0.2189909\tbestTest: 0.2189456 (62)\ttotal: 10m 13s\tremaining: 3m 24s\n",
      "75: learn: 0.2159091\ttest: 0.2190017\tbestTest: 0.2189456 (62)\ttotal: 10m 21s\tremaining: 3m 16s\n",
      "76: learn: 0.2158505\ttest: 0.2189942\tbestTest: 0.2189456 (62)\ttotal: 10m 30s\tremaining: 3m 8s\n",
      "77: learn: 0.2157746\ttest: 0.2190083\tbestTest: 0.2189456 (62)\ttotal: 10m 37s\tremaining: 2m 59s\n",
      "78: learn: 0.2157303\ttest: 0.2190104\tbestTest: 0.2189456 (62)\ttotal: 10m 46s\tremaining: 2m 51s\n",
      "79: learn: 0.215699\ttest: 0.2190089\tbestTest: 0.2189456 (62)\ttotal: 10m 53s\tremaining: 2m 43s\n",
      "80: learn: 0.2156487\ttest: 0.2190177\tbestTest: 0.2189456 (62)\ttotal: 11m 2s\tremaining: 2m 35s\n",
      "81: learn: 0.2156055\ttest: 0.2190307\tbestTest: 0.2189456 (62)\ttotal: 11m 10s\tremaining: 2m 27s\n",
      "82: learn: 0.2155618\ttest: 0.2190402\tbestTest: 0.2189456 (62)\ttotal: 11m 18s\tremaining: 2m 19s\n",
      "83: learn: 0.2154902\ttest: 0.2190531\tbestTest: 0.2189456 (62)\ttotal: 11m 26s\tremaining: 2m 10s\n",
      "84: learn: 0.2154432\ttest: 0.2190577\tbestTest: 0.2189456 (62)\ttotal: 11m 34s\tremaining: 2m 2s\n",
      "85: learn: 0.215435\ttest: 0.2190586\tbestTest: 0.2189456 (62)\ttotal: 11m 44s\tremaining: 1m 54s\n",
      "86: learn: 0.2154343\ttest: 0.2190586\tbestTest: 0.2189456 (62)\ttotal: 11m 54s\tremaining: 1m 46s\n",
      "87: learn: 0.2154333\ttest: 0.2190589\tbestTest: 0.2189456 (62)\ttotal: 12m 4s\tremaining: 1m 38s\n",
      "88: learn: 0.21533\ttest: 0.2190879\tbestTest: 0.2189456 (62)\ttotal: 12m 12s\tremaining: 1m 30s\n",
      "89: learn: 0.2152774\ttest: 0.21908\tbestTest: 0.2189456 (62)\ttotal: 12m 19s\tremaining: 1m 22s\n",
      "90: learn: 0.2152355\ttest: 0.2190612\tbestTest: 0.2189456 (62)\ttotal: 12m 27s\tremaining: 1m 13s\n",
      "91: learn: 0.215235\ttest: 0.2190615\tbestTest: 0.2189456 (62)\ttotal: 12m 36s\tremaining: 1m 5s\n",
      "92: learn: 0.2151719\ttest: 0.219068\tbestTest: 0.2189456 (62)\ttotal: 12m 45s\tremaining: 57.6s\n",
      "93: learn: 0.2151546\ttest: 0.2190609\tbestTest: 0.2189456 (62)\ttotal: 12m 53s\tremaining: 49.4s\n",
      "94: learn: 0.2151468\ttest: 0.2190567\tbestTest: 0.2189456 (62)\ttotal: 13m 3s\tremaining: 41.2s\n",
      "95: learn: 0.2151441\ttest: 0.2190562\tbestTest: 0.2189456 (62)\ttotal: 13m 12s\tremaining: 33s\n",
      "96: learn: 0.2151214\ttest: 0.2190425\tbestTest: 0.2189456 (62)\ttotal: 13m 22s\tremaining: 24.8s\n",
      "97: learn: 0.2150794\ttest: 0.219053\tbestTest: 0.2189456 (62)\ttotal: 13m 29s\tremaining: 16.5s\n",
      "98: learn: 0.2150183\ttest: 0.2190613\tbestTest: 0.2189456 (62)\ttotal: 13m 37s\tremaining: 8.26s\n",
      "99: learn: 0.2150165\ttest: 0.2190617\tbestTest: 0.2189456 (62)\ttotal: 13m 47s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2189456197\n",
      "bestIteration = 62\n",
      "\n",
      "Shrink model to first 63 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.5_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 01:16:52.757185\n",
      "train time given below\n",
      "0:17:07.233823\n",
      "2018-03-15 01:16:52.781513\n",
      "2018-03-15 01:16:52.785090\n",
      "GINI ISIT = 0.515281829722\n",
      "2018-03-15 01:18:28.586234\n",
      "GINI OSIT = 0.497004326474\n",
      "2018-03-15 01:19:07.521276\n",
      "GINI OSOT = 0.413381450955\n",
      "2018-03-15 01:19:19.685367\n",
      "2018-03-15 01:19:19.687389\n",
      "loop run time\n",
      "0:19:34.164249\n",
      "learning rate = 0.75\n",
      "2018-03-15 01:19:19.689083\n",
      "model train start\n",
      "2018-03-15 01:19:19.689302\n",
      "0: learn: 0.2495658\ttest: 0.2489044\tbestTest: 0.2489044 (0)\ttotal: 6.06s\tremaining: 10m\n",
      "1: learn: 0.2286009\ttest: 0.2278475\tbestTest: 0.2278475 (1)\ttotal: 13.5s\tremaining: 11m 1s\n",
      "2: learn: 0.2255542\ttest: 0.2248681\tbestTest: 0.2248681 (2)\ttotal: 20.8s\tremaining: 11m 13s\n",
      "3: learn: 0.2241082\ttest: 0.2235051\tbestTest: 0.2235051 (3)\ttotal: 28.9s\tremaining: 11m 33s\n",
      "4: learn: 0.2234388\ttest: 0.2229462\tbestTest: 0.2229462 (4)\ttotal: 37.1s\tremaining: 11m 44s\n",
      "5: learn: 0.2229328\ttest: 0.2224864\tbestTest: 0.2224864 (5)\ttotal: 44.1s\tremaining: 11m 30s\n",
      "6: learn: 0.2223468\ttest: 0.2220443\tbestTest: 0.2220443 (6)\ttotal: 52.1s\tremaining: 11m 32s\n",
      "7: learn: 0.2217936\ttest: 0.2215827\tbestTest: 0.2215827 (7)\ttotal: 1m\tremaining: 11m 32s\n",
      "8: learn: 0.2214259\ttest: 0.2212396\tbestTest: 0.2212396 (8)\ttotal: 1m 7s\tremaining: 11m 25s\n",
      "9: learn: 0.2211151\ttest: 0.2209684\tbestTest: 0.2209684 (9)\ttotal: 1m 16s\tremaining: 11m 24s\n",
      "10: learn: 0.2209269\ttest: 0.2208169\tbestTest: 0.2208169 (10)\ttotal: 1m 24s\tremaining: 11m 19s\n",
      "11: learn: 0.2207807\ttest: 0.2207199\tbestTest: 0.2207199 (11)\ttotal: 1m 33s\tremaining: 11m 22s\n",
      "12: learn: 0.2207128\ttest: 0.22066\tbestTest: 0.22066 (12)\ttotal: 1m 37s\tremaining: 10m 50s\n",
      "13: learn: 0.2205828\ttest: 0.2205817\tbestTest: 0.2205817 (13)\ttotal: 1m 45s\tremaining: 10m 48s\n",
      "14: learn: 0.2203144\ttest: 0.2204117\tbestTest: 0.2204117 (14)\ttotal: 1m 53s\tremaining: 10m 45s\n",
      "15: learn: 0.2201988\ttest: 0.2203552\tbestTest: 0.2203552 (15)\ttotal: 2m 1s\tremaining: 10m 39s\n",
      "16: learn: 0.2200997\ttest: 0.2203249\tbestTest: 0.2203249 (16)\ttotal: 2m 10s\tremaining: 10m 34s\n",
      "17: learn: 0.2199699\ttest: 0.2202642\tbestTest: 0.2202642 (17)\ttotal: 2m 18s\tremaining: 10m 31s\n",
      "18: learn: 0.2197207\ttest: 0.2201828\tbestTest: 0.2201828 (18)\ttotal: 2m 26s\tremaining: 10m 22s\n",
      "19: learn: 0.2196277\ttest: 0.2201563\tbestTest: 0.2201563 (19)\ttotal: 2m 33s\tremaining: 10m 15s\n",
      "20: learn: 0.2194681\ttest: 0.2200754\tbestTest: 0.2200754 (20)\ttotal: 2m 42s\tremaining: 10m 10s\n",
      "21: learn: 0.2193116\ttest: 0.2200245\tbestTest: 0.2200245 (21)\ttotal: 2m 50s\tremaining: 10m 3s\n",
      "22: learn: 0.2191649\ttest: 0.2199158\tbestTest: 0.2199158 (22)\ttotal: 2m 59s\tremaining: 10m\n",
      "23: learn: 0.219064\ttest: 0.219901\tbestTest: 0.219901 (23)\ttotal: 3m 8s\tremaining: 9m 55s\n",
      "24: learn: 0.2189265\ttest: 0.2198589\tbestTest: 0.2198589 (24)\ttotal: 3m 16s\tremaining: 9m 48s\n",
      "25: learn: 0.2188455\ttest: 0.2198262\tbestTest: 0.2198262 (25)\ttotal: 3m 24s\tremaining: 9m 42s\n",
      "26: learn: 0.2187403\ttest: 0.2198011\tbestTest: 0.2198011 (26)\ttotal: 3m 32s\tremaining: 9m 33s\n",
      "27: learn: 0.2186738\ttest: 0.219758\tbestTest: 0.219758 (27)\ttotal: 3m 40s\tremaining: 9m 25s\n",
      "28: learn: 0.2186085\ttest: 0.219721\tbestTest: 0.219721 (28)\ttotal: 3m 48s\tremaining: 9m 18s\n",
      "29: learn: 0.2184973\ttest: 0.2197154\tbestTest: 0.2197154 (29)\ttotal: 3m 55s\tremaining: 9m 9s\n",
      "30: learn: 0.2183244\ttest: 0.2196631\tbestTest: 0.2196631 (30)\ttotal: 4m 3s\tremaining: 9m 1s\n",
      "31: learn: 0.2182056\ttest: 0.2195932\tbestTest: 0.2195932 (31)\ttotal: 4m 11s\tremaining: 8m 54s\n",
      "32: learn: 0.2181491\ttest: 0.2195771\tbestTest: 0.2195771 (32)\ttotal: 4m 20s\tremaining: 8m 49s\n",
      "33: learn: 0.2180737\ttest: 0.2195627\tbestTest: 0.2195627 (33)\ttotal: 4m 28s\tremaining: 8m 41s\n",
      "34: learn: 0.2179912\ttest: 0.2195537\tbestTest: 0.2195537 (34)\ttotal: 4m 36s\tremaining: 8m 34s\n",
      "35: learn: 0.2179039\ttest: 0.2195679\tbestTest: 0.2195537 (34)\ttotal: 4m 45s\tremaining: 8m 26s\n",
      "36: learn: 0.2178556\ttest: 0.2195388\tbestTest: 0.2195388 (36)\ttotal: 4m 53s\tremaining: 8m 19s\n",
      "37: learn: 0.2177845\ttest: 0.2195392\tbestTest: 0.2195388 (36)\ttotal: 5m 1s\tremaining: 8m 12s\n",
      "38: learn: 0.2176957\ttest: 0.2194989\tbestTest: 0.2194989 (38)\ttotal: 5m 9s\tremaining: 8m 4s\n",
      "39: learn: 0.2176089\ttest: 0.2195224\tbestTest: 0.2194989 (38)\ttotal: 5m 17s\tremaining: 7m 55s\n",
      "40: learn: 0.2175642\ttest: 0.2195319\tbestTest: 0.2194989 (38)\ttotal: 5m 25s\tremaining: 7m 48s\n",
      "41: learn: 0.2175026\ttest: 0.2195292\tbestTest: 0.2194989 (38)\ttotal: 5m 33s\tremaining: 7m 40s\n",
      "42: learn: 0.2174445\ttest: 0.2195087\tbestTest: 0.2194989 (38)\ttotal: 5m 41s\tremaining: 7m 32s\n",
      "43: learn: 0.2173966\ttest: 0.2195097\tbestTest: 0.2194989 (38)\ttotal: 5m 50s\tremaining: 7m 26s\n",
      "44: learn: 0.2173373\ttest: 0.2195193\tbestTest: 0.2194989 (38)\ttotal: 5m 58s\tremaining: 7m 18s\n",
      "45: learn: 0.2172648\ttest: 0.2195608\tbestTest: 0.2194989 (38)\ttotal: 6m 6s\tremaining: 7m 10s\n",
      "46: learn: 0.2171482\ttest: 0.2195964\tbestTest: 0.2194989 (38)\ttotal: 6m 15s\tremaining: 7m 3s\n",
      "47: learn: 0.2170561\ttest: 0.2196261\tbestTest: 0.2194989 (38)\ttotal: 6m 23s\tremaining: 6m 55s\n",
      "48: learn: 0.2169403\ttest: 0.2196647\tbestTest: 0.2194989 (38)\ttotal: 6m 31s\tremaining: 6m 46s\n",
      "49: learn: 0.2169008\ttest: 0.219661\tbestTest: 0.2194989 (38)\ttotal: 6m 39s\tremaining: 6m 39s\n",
      "50: learn: 0.2168259\ttest: 0.2196775\tbestTest: 0.2194989 (38)\ttotal: 6m 47s\tremaining: 6m 31s\n",
      "51: learn: 0.2167727\ttest: 0.2196917\tbestTest: 0.2194989 (38)\ttotal: 6m 55s\tremaining: 6m 23s\n",
      "52: learn: 0.2167107\ttest: 0.2197263\tbestTest: 0.2194989 (38)\ttotal: 7m 4s\tremaining: 6m 16s\n",
      "53: learn: 0.2166465\ttest: 0.2197175\tbestTest: 0.2194989 (38)\ttotal: 7m 11s\tremaining: 6m 7s\n",
      "54: learn: 0.2165831\ttest: 0.2197074\tbestTest: 0.2194989 (38)\ttotal: 7m 20s\tremaining: 6m\n",
      "55: learn: 0.2165372\ttest: 0.219718\tbestTest: 0.2194989 (38)\ttotal: 7m 28s\tremaining: 5m 52s\n",
      "56: learn: 0.2164655\ttest: 0.2197267\tbestTest: 0.2194989 (38)\ttotal: 7m 36s\tremaining: 5m 44s\n",
      "57: learn: 0.2163807\ttest: 0.2197522\tbestTest: 0.2194989 (38)\ttotal: 7m 44s\tremaining: 5m 36s\n",
      "58: learn: 0.2163405\ttest: 0.2197632\tbestTest: 0.2194989 (38)\ttotal: 7m 53s\tremaining: 5m 28s\n",
      "59: learn: 0.2163139\ttest: 0.2197709\tbestTest: 0.2194989 (38)\ttotal: 8m 1s\tremaining: 5m 21s\n",
      "60: learn: 0.2162774\ttest: 0.2197686\tbestTest: 0.2194989 (38)\ttotal: 8m 11s\tremaining: 5m 13s\n",
      "61: learn: 0.2162092\ttest: 0.2197782\tbestTest: 0.2194989 (38)\ttotal: 8m 18s\tremaining: 5m 5s\n",
      "62: learn: 0.2161674\ttest: 0.2198015\tbestTest: 0.2194989 (38)\ttotal: 8m 26s\tremaining: 4m 57s\n",
      "63: learn: 0.2160987\ttest: 0.2198214\tbestTest: 0.2194989 (38)\ttotal: 8m 34s\tremaining: 4m 49s\n",
      "64: learn: 0.2160252\ttest: 0.2198156\tbestTest: 0.2194989 (38)\ttotal: 8m 42s\tremaining: 4m 41s\n",
      "65: learn: 0.2159043\ttest: 0.2198673\tbestTest: 0.2194989 (38)\ttotal: 8m 50s\tremaining: 4m 33s\n",
      "66: learn: 0.2158246\ttest: 0.2198722\tbestTest: 0.2194989 (38)\ttotal: 8m 57s\tremaining: 4m 24s\n",
      "67: learn: 0.215793\ttest: 0.2198805\tbestTest: 0.2194989 (38)\ttotal: 9m 6s\tremaining: 4m 17s\n",
      "68: learn: 0.2157914\ttest: 0.219881\tbestTest: 0.2194989 (38)\ttotal: 9m 16s\tremaining: 4m 10s\n",
      "69: learn: 0.2157427\ttest: 0.2198907\tbestTest: 0.2194989 (38)\ttotal: 9m 24s\tremaining: 4m 1s\n",
      "70: learn: 0.2157294\ttest: 0.2198951\tbestTest: 0.2194989 (38)\ttotal: 9m 34s\tremaining: 3m 54s\n",
      "71: learn: 0.2157056\ttest: 0.2198914\tbestTest: 0.2194989 (38)\ttotal: 9m 44s\tremaining: 3m 47s\n",
      "72: learn: 0.2156873\ttest: 0.2199033\tbestTest: 0.2194989 (38)\ttotal: 9m 52s\tremaining: 3m 39s\n",
      "73: learn: 0.2156821\ttest: 0.2199063\tbestTest: 0.2194989 (38)\ttotal: 10m 2s\tremaining: 3m 31s\n",
      "74: learn: 0.2156648\ttest: 0.2199103\tbestTest: 0.2194989 (38)\ttotal: 10m 12s\tremaining: 3m 24s\n",
      "75: learn: 0.2156598\ttest: 0.2199055\tbestTest: 0.2194989 (38)\ttotal: 10m 22s\tremaining: 3m 16s\n",
      "76: learn: 0.2155726\ttest: 0.2199415\tbestTest: 0.2194989 (38)\ttotal: 10m 31s\tremaining: 3m 8s\n",
      "77: learn: 0.2154937\ttest: 0.2199902\tbestTest: 0.2194989 (38)\ttotal: 10m 39s\tremaining: 3m\n",
      "78: learn: 0.2154275\ttest: 0.2200159\tbestTest: 0.2194989 (38)\ttotal: 10m 47s\tremaining: 2m 52s\n",
      "79: learn: 0.2154086\ttest: 0.2200203\tbestTest: 0.2194989 (38)\ttotal: 10m 55s\tremaining: 2m 43s\n",
      "80: learn: 0.2153607\ttest: 0.2200474\tbestTest: 0.2194989 (38)\ttotal: 11m 3s\tremaining: 2m 35s\n",
      "81: learn: 0.2153013\ttest: 0.2200509\tbestTest: 0.2194989 (38)\ttotal: 11m 11s\tremaining: 2m 27s\n",
      "82: learn: 0.215192\ttest: 0.220082\tbestTest: 0.2194989 (38)\ttotal: 11m 19s\tremaining: 2m 19s\n",
      "83: learn: 0.2151477\ttest: 0.2200992\tbestTest: 0.2194989 (38)\ttotal: 11m 27s\tremaining: 2m 10s\n",
      "84: learn: 0.215146\ttest: 0.2201003\tbestTest: 0.2194989 (38)\ttotal: 11m 38s\tremaining: 2m 3s\n",
      "85: learn: 0.2151351\ttest: 0.2201069\tbestTest: 0.2194989 (38)\ttotal: 11m 48s\tremaining: 1m 55s\n",
      "86: learn: 0.2150956\ttest: 0.2201205\tbestTest: 0.2194989 (38)\ttotal: 11m 57s\tremaining: 1m 47s\n",
      "87: learn: 0.2150857\ttest: 0.2201209\tbestTest: 0.2194989 (38)\ttotal: 12m 7s\tremaining: 1m 39s\n",
      "88: learn: 0.215085\ttest: 0.2201206\tbestTest: 0.2194989 (38)\ttotal: 12m 18s\tremaining: 1m 31s\n",
      "89: learn: 0.2150551\ttest: 0.2201177\tbestTest: 0.2194989 (38)\ttotal: 12m 26s\tremaining: 1m 22s\n",
      "90: learn: 0.21503\ttest: 0.2201144\tbestTest: 0.2194989 (38)\ttotal: 12m 35s\tremaining: 1m 14s\n",
      "91: learn: 0.2149639\ttest: 0.2201279\tbestTest: 0.2194989 (38)\ttotal: 12m 43s\tremaining: 1m 6s\n",
      "92: learn: 0.2149481\ttest: 0.2201375\tbestTest: 0.2194989 (38)\ttotal: 12m 52s\tremaining: 58.2s\n",
      "93: learn: 0.2148624\ttest: 0.220171\tbestTest: 0.2194989 (38)\ttotal: 13m\tremaining: 49.8s\n",
      "94: learn: 0.214844\ttest: 0.2201706\tbestTest: 0.2194989 (38)\ttotal: 13m 8s\tremaining: 41.5s\n",
      "95: learn: 0.2148397\ttest: 0.2201704\tbestTest: 0.2194989 (38)\ttotal: 13m 18s\tremaining: 33.3s\n",
      "96: learn: 0.2147879\ttest: 0.2201939\tbestTest: 0.2194989 (38)\ttotal: 13m 26s\tremaining: 24.9s\n",
      "97: learn: 0.2147631\ttest: 0.2201939\tbestTest: 0.2194989 (38)\ttotal: 13m 34s\tremaining: 16.6s\n",
      "98: learn: 0.2147473\ttest: 0.2202022\tbestTest: 0.2194989 (38)\ttotal: 13m 43s\tremaining: 8.32s\n",
      "99: learn: 0.2147043\ttest: 0.2201978\tbestTest: 0.2194989 (38)\ttotal: 13m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2194988819\n",
      "bestIteration = 38\n",
      "\n",
      "Shrink model to first 39 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.75_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 01:36:33.953481\n",
      "train time given below\n",
      "0:17:14.264179\n",
      "2018-03-15 01:36:33.986133\n",
      "2018-03-15 01:36:33.989604\n",
      "GINI ISIT = 0.508282991611\n",
      "2018-03-15 01:38:06.383423\n",
      "GINI OSIT = 0.493476174415\n",
      "2018-03-15 01:38:44.135595\n",
      "GINI OSOT = 0.426477186699\n",
      "2018-03-15 01:38:55.833354\n",
      "2018-03-15 01:38:55.835426\n",
      "loop run time\n",
      "0:19:36.146342\n",
      "learning rate = 1\n",
      "2018-03-15 01:38:55.836999\n",
      "model train start\n",
      "2018-03-15 01:38:55.837252\n",
      "0: learn: 0.2342559\ttest: 0.2333365\tbestTest: 0.2333365 (0)\ttotal: 6.24s\tremaining: 10m 18s\n",
      "1: learn: 0.2287061\ttest: 0.2278982\tbestTest: 0.2278982 (1)\ttotal: 14.3s\tremaining: 11m 40s\n",
      "2: learn: 0.2256142\ttest: 0.2249355\tbestTest: 0.2249355 (2)\ttotal: 22.6s\tremaining: 12m 11s\n",
      "3: learn: 0.2241592\ttest: 0.2236729\tbestTest: 0.2236729 (3)\ttotal: 30.4s\tremaining: 12m 9s\n",
      "4: learn: 0.2232193\ttest: 0.222892\tbestTest: 0.222892 (4)\ttotal: 38.3s\tremaining: 12m 6s\n",
      "5: learn: 0.2227193\ttest: 0.2224513\tbestTest: 0.2224513 (5)\ttotal: 46.2s\tremaining: 12m 3s\n",
      "6: learn: 0.2221568\ttest: 0.2219947\tbestTest: 0.2219947 (6)\ttotal: 54.6s\tremaining: 12m 5s\n",
      "7: learn: 0.2217944\ttest: 0.2217773\tbestTest: 0.2217773 (7)\ttotal: 1m 2s\tremaining: 12m 1s\n",
      "8: learn: 0.2215101\ttest: 0.2215736\tbestTest: 0.2215736 (8)\ttotal: 1m 11s\tremaining: 11m 58s\n",
      "9: learn: 0.2212073\ttest: 0.2213716\tbestTest: 0.2213716 (9)\ttotal: 1m 19s\tremaining: 11m 54s\n",
      "10: learn: 0.2210574\ttest: 0.2212603\tbestTest: 0.2212603 (10)\ttotal: 1m 25s\tremaining: 11m 33s\n",
      "11: learn: 0.2208431\ttest: 0.2210897\tbestTest: 0.2210897 (11)\ttotal: 1m 32s\tremaining: 11m 21s\n",
      "12: learn: 0.2205336\ttest: 0.2209695\tbestTest: 0.2209695 (12)\ttotal: 1m 40s\tremaining: 11m 14s\n",
      "13: learn: 0.2203372\ttest: 0.2207704\tbestTest: 0.2207704 (13)\ttotal: 1m 49s\tremaining: 11m 13s\n",
      "14: learn: 0.2201611\ttest: 0.2207446\tbestTest: 0.2207446 (14)\ttotal: 1m 57s\tremaining: 11m 6s\n",
      "15: learn: 0.2199752\ttest: 0.2206487\tbestTest: 0.2206487 (15)\ttotal: 2m 5s\tremaining: 10m 57s\n",
      "16: learn: 0.219793\ttest: 0.2205923\tbestTest: 0.2205923 (16)\ttotal: 2m 12s\tremaining: 10m 47s\n",
      "17: learn: 0.219623\ttest: 0.2205405\tbestTest: 0.2205405 (17)\ttotal: 2m 20s\tremaining: 10m 40s\n",
      "18: learn: 0.2194117\ttest: 0.2204859\tbestTest: 0.2204859 (18)\ttotal: 2m 28s\tremaining: 10m 31s\n",
      "19: learn: 0.2192843\ttest: 0.2204239\tbestTest: 0.2204239 (19)\ttotal: 2m 35s\tremaining: 10m 22s\n",
      "20: learn: 0.219163\ttest: 0.2203997\tbestTest: 0.2203997 (20)\ttotal: 2m 42s\tremaining: 10m 13s\n",
      "21: learn: 0.2190396\ttest: 0.2203889\tbestTest: 0.2203889 (21)\ttotal: 2m 50s\tremaining: 10m 5s\n",
      "22: learn: 0.2189673\ttest: 0.220385\tbestTest: 0.220385 (22)\ttotal: 2m 59s\tremaining: 10m\n",
      "23: learn: 0.2188112\ttest: 0.2204037\tbestTest: 0.220385 (22)\ttotal: 3m 8s\tremaining: 9m 55s\n",
      "24: learn: 0.2187401\ttest: 0.2204238\tbestTest: 0.220385 (22)\ttotal: 3m 16s\tremaining: 9m 49s\n",
      "25: learn: 0.2185927\ttest: 0.2204625\tbestTest: 0.220385 (22)\ttotal: 3m 24s\tremaining: 9m 42s\n",
      "26: learn: 0.2184873\ttest: 0.2204234\tbestTest: 0.220385 (22)\ttotal: 3m 32s\tremaining: 9m 34s\n",
      "27: learn: 0.2183908\ttest: 0.2204517\tbestTest: 0.220385 (22)\ttotal: 3m 40s\tremaining: 9m 26s\n",
      "28: learn: 0.218312\ttest: 0.220471\tbestTest: 0.220385 (22)\ttotal: 3m 47s\tremaining: 9m 16s\n",
      "29: learn: 0.2182186\ttest: 0.2205\tbestTest: 0.220385 (22)\ttotal: 3m 55s\tremaining: 9m 8s\n",
      "30: learn: 0.2180939\ttest: 0.2205612\tbestTest: 0.220385 (22)\ttotal: 4m 2s\tremaining: 9m\n",
      "31: learn: 0.2180268\ttest: 0.2205544\tbestTest: 0.220385 (22)\ttotal: 4m 10s\tremaining: 8m 52s\n",
      "32: learn: 0.2179089\ttest: 0.2206287\tbestTest: 0.220385 (22)\ttotal: 4m 18s\tremaining: 8m 44s\n",
      "33: learn: 0.2178193\ttest: 0.2206081\tbestTest: 0.220385 (22)\ttotal: 4m 27s\tremaining: 8m 38s\n",
      "34: learn: 0.2177619\ttest: 0.2206335\tbestTest: 0.220385 (22)\ttotal: 4m 35s\tremaining: 8m 31s\n",
      "35: learn: 0.2176487\ttest: 0.2205624\tbestTest: 0.220385 (22)\ttotal: 4m 43s\tremaining: 8m 24s\n",
      "36: learn: 0.2175473\ttest: 0.2205911\tbestTest: 0.220385 (22)\ttotal: 4m 52s\tremaining: 8m 17s\n",
      "37: learn: 0.2174626\ttest: 0.2206449\tbestTest: 0.220385 (22)\ttotal: 4m 59s\tremaining: 8m 9s\n",
      "38: learn: 0.2173664\ttest: 0.2207033\tbestTest: 0.220385 (22)\ttotal: 5m 7s\tremaining: 8m 1s\n",
      "39: learn: 0.217312\ttest: 0.220725\tbestTest: 0.220385 (22)\ttotal: 5m 16s\tremaining: 7m 54s\n",
      "40: learn: 0.2172079\ttest: 0.2208007\tbestTest: 0.220385 (22)\ttotal: 5m 24s\tremaining: 7m 46s\n",
      "41: learn: 0.2171507\ttest: 0.2208264\tbestTest: 0.220385 (22)\ttotal: 5m 31s\tremaining: 7m 38s\n",
      "42: learn: 0.2170733\ttest: 0.2208693\tbestTest: 0.220385 (22)\ttotal: 5m 39s\tremaining: 7m 29s\n",
      "43: learn: 0.2170116\ttest: 0.2208612\tbestTest: 0.220385 (22)\ttotal: 5m 47s\tremaining: 7m 22s\n",
      "44: learn: 0.2169425\ttest: 0.2209046\tbestTest: 0.220385 (22)\ttotal: 5m 55s\tremaining: 7m 14s\n",
      "45: learn: 0.2168987\ttest: 0.2209153\tbestTest: 0.220385 (22)\ttotal: 6m 3s\tremaining: 7m 7s\n",
      "46: learn: 0.2167369\ttest: 0.2210018\tbestTest: 0.220385 (22)\ttotal: 6m 11s\tremaining: 6m 58s\n",
      "47: learn: 0.2166596\ttest: 0.2210202\tbestTest: 0.220385 (22)\ttotal: 6m 19s\tremaining: 6m 51s\n",
      "48: learn: 0.2165891\ttest: 0.2210532\tbestTest: 0.220385 (22)\ttotal: 6m 28s\tremaining: 6m 44s\n",
      "49: learn: 0.2165459\ttest: 0.2210684\tbestTest: 0.220385 (22)\ttotal: 6m 36s\tremaining: 6m 36s\n",
      "50: learn: 0.2165012\ttest: 0.2210881\tbestTest: 0.220385 (22)\ttotal: 6m 43s\tremaining: 6m 28s\n",
      "51: learn: 0.2164018\ttest: 0.221142\tbestTest: 0.220385 (22)\ttotal: 6m 52s\tremaining: 6m 20s\n",
      "52: learn: 0.2163161\ttest: 0.2211897\tbestTest: 0.220385 (22)\ttotal: 6m 59s\tremaining: 6m 12s\n",
      "53: learn: 0.2162574\ttest: 0.2211927\tbestTest: 0.220385 (22)\ttotal: 7m 8s\tremaining: 6m 4s\n",
      "54: learn: 0.2161674\ttest: 0.2212205\tbestTest: 0.220385 (22)\ttotal: 7m 15s\tremaining: 5m 56s\n",
      "55: learn: 0.2160919\ttest: 0.2212354\tbestTest: 0.220385 (22)\ttotal: 7m 24s\tremaining: 5m 48s\n",
      "56: learn: 0.2160285\ttest: 0.2212746\tbestTest: 0.220385 (22)\ttotal: 7m 31s\tremaining: 5m 40s\n",
      "57: learn: 0.2160098\ttest: 0.2213008\tbestTest: 0.220385 (22)\ttotal: 7m 40s\tremaining: 5m 33s\n",
      "58: learn: 0.2160004\ttest: 0.2213085\tbestTest: 0.220385 (22)\ttotal: 7m 49s\tremaining: 5m 26s\n",
      "59: learn: 0.216\ttest: 0.2213095\tbestTest: 0.220385 (22)\ttotal: 7m 58s\tremaining: 5m 19s\n",
      "60: learn: 0.2159139\ttest: 0.2213714\tbestTest: 0.220385 (22)\ttotal: 8m 6s\tremaining: 5m 11s\n",
      "61: learn: 0.2158049\ttest: 0.2214274\tbestTest: 0.220385 (22)\ttotal: 8m 14s\tremaining: 5m 3s\n",
      "62: learn: 0.2157641\ttest: 0.2214442\tbestTest: 0.220385 (22)\ttotal: 8m 22s\tremaining: 4m 55s\n",
      "63: learn: 0.2156931\ttest: 0.2214745\tbestTest: 0.220385 (22)\ttotal: 8m 31s\tremaining: 4m 47s\n",
      "64: learn: 0.215665\ttest: 0.2215048\tbestTest: 0.220385 (22)\ttotal: 8m 39s\tremaining: 4m 39s\n",
      "65: learn: 0.2155881\ttest: 0.2215285\tbestTest: 0.220385 (22)\ttotal: 8m 47s\tremaining: 4m 31s\n",
      "66: learn: 0.2154853\ttest: 0.2216177\tbestTest: 0.220385 (22)\ttotal: 8m 54s\tremaining: 4m 23s\n",
      "67: learn: 0.215402\ttest: 0.2216605\tbestTest: 0.220385 (22)\ttotal: 9m 2s\tremaining: 4m 15s\n",
      "68: learn: 0.2153784\ttest: 0.2216596\tbestTest: 0.220385 (22)\ttotal: 9m 10s\tremaining: 4m 7s\n",
      "69: learn: 0.2152645\ttest: 0.2217473\tbestTest: 0.220385 (22)\ttotal: 9m 18s\tremaining: 3m 59s\n",
      "70: learn: 0.2151957\ttest: 0.2217749\tbestTest: 0.220385 (22)\ttotal: 9m 26s\tremaining: 3m 51s\n",
      "71: learn: 0.215103\ttest: 0.2218173\tbestTest: 0.220385 (22)\ttotal: 9m 33s\tremaining: 3m 43s\n",
      "72: learn: 0.2150496\ttest: 0.2218354\tbestTest: 0.220385 (22)\ttotal: 9m 41s\tremaining: 3m 35s\n",
      "73: learn: 0.2150119\ttest: 0.2218421\tbestTest: 0.220385 (22)\ttotal: 9m 50s\tremaining: 3m 27s\n",
      "74: learn: 0.2149858\ttest: 0.2218432\tbestTest: 0.220385 (22)\ttotal: 9m 57s\tremaining: 3m 19s\n",
      "75: learn: 0.214918\ttest: 0.2218769\tbestTest: 0.220385 (22)\ttotal: 10m 6s\tremaining: 3m 11s\n",
      "76: learn: 0.2148814\ttest: 0.2219012\tbestTest: 0.220385 (22)\ttotal: 10m 14s\tremaining: 3m 3s\n",
      "77: learn: 0.2147539\ttest: 0.2219838\tbestTest: 0.220385 (22)\ttotal: 10m 21s\tremaining: 2m 55s\n",
      "78: learn: 0.2146688\ttest: 0.2220472\tbestTest: 0.220385 (22)\ttotal: 10m 29s\tremaining: 2m 47s\n",
      "79: learn: 0.2146238\ttest: 0.222075\tbestTest: 0.220385 (22)\ttotal: 10m 37s\tremaining: 2m 39s\n",
      "80: learn: 0.2145934\ttest: 0.2220974\tbestTest: 0.220385 (22)\ttotal: 10m 45s\tremaining: 2m 31s\n",
      "81: learn: 0.2145511\ttest: 0.2221415\tbestTest: 0.220385 (22)\ttotal: 10m 54s\tremaining: 2m 23s\n",
      "82: learn: 0.2144828\ttest: 0.222209\tbestTest: 0.220385 (22)\ttotal: 11m 3s\tremaining: 2m 15s\n",
      "83: learn: 0.2144103\ttest: 0.2222599\tbestTest: 0.220385 (22)\ttotal: 11m 11s\tremaining: 2m 7s\n",
      "84: learn: 0.2143249\ttest: 0.2223342\tbestTest: 0.220385 (22)\ttotal: 11m 19s\tremaining: 1m 59s\n",
      "85: learn: 0.2142783\ttest: 0.2223656\tbestTest: 0.220385 (22)\ttotal: 11m 26s\tremaining: 1m 51s\n",
      "86: learn: 0.2142275\ttest: 0.2224033\tbestTest: 0.220385 (22)\ttotal: 11m 34s\tremaining: 1m 43s\n",
      "87: learn: 0.2142255\ttest: 0.2224063\tbestTest: 0.220385 (22)\ttotal: 11m 42s\tremaining: 1m 35s\n",
      "88: learn: 0.2141603\ttest: 0.2224512\tbestTest: 0.220385 (22)\ttotal: 11m 51s\tremaining: 1m 27s\n",
      "89: learn: 0.2140649\ttest: 0.2225322\tbestTest: 0.220385 (22)\ttotal: 11m 59s\tremaining: 1m 19s\n",
      "90: learn: 0.21399\ttest: 0.2225873\tbestTest: 0.220385 (22)\ttotal: 12m 6s\tremaining: 1m 11s\n",
      "91: learn: 0.2139589\ttest: 0.2226108\tbestTest: 0.220385 (22)\ttotal: 12m 15s\tremaining: 1m 3s\n",
      "92: learn: 0.2138837\ttest: 0.2226774\tbestTest: 0.220385 (22)\ttotal: 12m 23s\tremaining: 56s\n",
      "93: learn: 0.2138205\ttest: 0.2227139\tbestTest: 0.220385 (22)\ttotal: 12m 31s\tremaining: 48s\n",
      "94: learn: 0.2137356\ttest: 0.2227793\tbestTest: 0.220385 (22)\ttotal: 12m 39s\tremaining: 40s\n",
      "95: learn: 0.213654\ttest: 0.222831\tbestTest: 0.220385 (22)\ttotal: 12m 46s\tremaining: 31.9s\n",
      "96: learn: 0.2135605\ttest: 0.2229295\tbestTest: 0.220385 (22)\ttotal: 12m 53s\tremaining: 23.9s\n",
      "97: learn: 0.2135588\ttest: 0.2229302\tbestTest: 0.220385 (22)\ttotal: 13m 3s\tremaining: 16s\n",
      "98: learn: 0.2135558\ttest: 0.222932\tbestTest: 0.220385 (22)\ttotal: 13m 12s\tremaining: 8.01s\n",
      "99: learn: 0.2135485\ttest: 0.2229374\tbestTest: 0.220385 (22)\ttotal: 13m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2203850418\n",
      "bestIteration = 22\n",
      "\n",
      "Shrink model to first 23 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_1_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 01:55:28.701107\n",
      "train time given below\n",
      "0:16:32.863855\n",
      "2018-03-15 01:55:28.836879\n",
      "2018-03-15 01:55:28.840544\n",
      "GINI ISIT = 0.499102693283\n",
      "2018-03-15 01:56:56.264904\n",
      "GINI OSIT = 0.485731091952\n",
      "2018-03-15 01:57:32.656528\n",
      "GINI OSOT = 0.414978054546\n",
      "2018-03-15 01:57:44.005835\n",
      "2018-03-15 01:57:44.007858\n",
      "loop run time\n",
      "0:18:48.170857\n",
      "learning rate = 1.5\n",
      "2018-03-15 01:57:44.009515\n",
      "model train start\n",
      "2018-03-15 01:57:44.009737\n",
      "0: learn: 0.2682707\ttest: 0.266829\tbestTest: 0.266829 (0)\ttotal: 6.31s\tremaining: 10m 24s\n",
      "1: learn: nan\ttest: nan\tbestTest: 0.266829 (0)\ttotal: 14.5s\tremaining: 11m 51s\n",
      "Training has stopped (degenerate solution on iteration 1, probably too small l2-regularization, try to increase it)\n",
      "\n",
      "bestTest = 0.266828975\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_1.5_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 02:00:59.576896\n",
      "train time given below\n",
      "0:03:15.567159\n",
      "2018-03-15 02:00:59.596574\n",
      "2018-03-15 02:00:59.600218\n",
      "GINI ISIT = 0.33750530662\n",
      "2018-03-15 02:02:27.706705\n",
      "GINI OSIT = 0.338444437619\n",
      "2018-03-15 02:03:04.634565\n",
      "GINI OSOT = 0.276346106953\n",
      "2018-03-15 02:03:16.016669\n",
      "2018-03-15 02:03:16.018625\n",
      "loop run time\n",
      "0:05:32.009106\n",
      "learning rate = 2\n",
      "2018-03-15 02:03:16.020220\n",
      "model train start\n",
      "2018-03-15 02:03:16.020550\n",
      "0: learn: 0.3345509\ttest: 0.3325882\tbestTest: 0.3325882 (0)\ttotal: 6.37s\tremaining: 10m 30s\n",
      "1: learn: nan\ttest: nan\tbestTest: 0.3325882 (0)\ttotal: 14.7s\tremaining: 12m 2s\n",
      "Training has stopped (degenerate solution on iteration 1, probably too small l2-regularization, try to increase it)\n",
      "\n",
      "bestTest = 0.3325882084\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_2_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 02:06:40.703353\n",
      "train time given below\n",
      "0:03:24.682803\n",
      "2018-03-15 02:06:40.742726\n",
      "2018-03-15 02:06:40.746212\n",
      "GINI ISIT = 0.33750530662\n",
      "2018-03-15 02:08:08.688999\n",
      "GINI OSIT = 0.338444437619\n",
      "2018-03-15 02:08:45.282447\n",
      "GINI OSOT = 0.276346106953\n",
      "2018-03-15 02:08:56.787135\n",
      "2018-03-15 02:08:56.789054\n",
      "loop run time\n",
      "0:05:40.768832\n"
     ]
    }
   ],
   "source": [
    "#optimize learning rate\n",
    "\n",
    "for lrn_rt in lrn_rt_pv2:\n",
    "    \n",
    "    print('learning rate = ' + str(lrn_rt))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_opt,\n",
    "                           lrn_rt = lrn_rt,\n",
    "                           dep = dep_opt,\n",
    "                           l2_reg = l2_reg_opt,\n",
    "                           num_split = num_split_opt,\n",
    "                           cat_split = cat_split_opt,\n",
    "                           bag_temp = bag_temp_def)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_opt\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt\n",
    "    result_df_temp.loc[0,'depth'] = dep_opt\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_opt\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_opt\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_opt\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp_def\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    t2 = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"loop run time\")\n",
    "    print(t2-t1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451849</td>\n",
       "      <td>0.453623</td>\n",
       "      <td>0.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.45484</td>\n",
       "      <td>0.407005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>0.405824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45513</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454684</td>\n",
       "      <td>0.456024</td>\n",
       "      <td>0.408098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455045</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.40867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45336</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.408261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454922</td>\n",
       "      <td>0.456109</td>\n",
       "      <td>0.410751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456208</td>\n",
       "      <td>0.457545</td>\n",
       "      <td>0.41235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454801</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>0.411622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45617</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.411126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.409276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441066</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>0.396312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.450992</td>\n",
       "      <td>0.404413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460658</td>\n",
       "      <td>0.461646</td>\n",
       "      <td>0.416653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>0.465669</td>\n",
       "      <td>0.41762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468306</td>\n",
       "      <td>0.468324</td>\n",
       "      <td>0.417121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.451405</td>\n",
       "      <td>0.400855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46271</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>0.418592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484078</td>\n",
       "      <td>0.481967</td>\n",
       "      <td>0.434897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.075</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493039</td>\n",
       "      <td>0.488949</td>\n",
       "      <td>0.445385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498417</td>\n",
       "      <td>0.492692</td>\n",
       "      <td>0.431242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.125</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503328</td>\n",
       "      <td>0.496473</td>\n",
       "      <td>0.44277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506916</td>\n",
       "      <td>0.497736</td>\n",
       "      <td>0.42221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51677</td>\n",
       "      <td>0.500368</td>\n",
       "      <td>0.429062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515282</td>\n",
       "      <td>0.497004</td>\n",
       "      <td>0.413381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508283</td>\n",
       "      <td>0.493476</td>\n",
       "      <td>0.426477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499103</td>\n",
       "      <td>0.485731</td>\n",
       "      <td>0.414978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337505</td>\n",
       "      <td>0.338444</td>\n",
       "      <td>0.276346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337505</td>\n",
       "      <td>0.338444</td>\n",
       "      <td>0.276346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree   rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100     1          0.03     6                 1             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 5             128   \n",
       "0    100     1          0.03     6                10             128   \n",
       "0    100     1          0.03     6                50             128   \n",
       "0    100     1          0.03     6               100             128   \n",
       "0    100     1          0.03     6                 3               5   \n",
       "0    100     1          0.03     6                 3              10   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              32   \n",
       "0    100     1          0.03     6                 3              64   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             255   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100   0.5          0.03     6                 3              16   \n",
       "0    100   0.6          0.03     6                 3              16   \n",
       "0    100   0.7          0.03     6                 3              16   \n",
       "0    100  0.75          0.03     6                 3              16   \n",
       "0    100   0.8          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100   0.9          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     4                 3              16   \n",
       "0    100  0.85          0.03     5                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     7                 3              16   \n",
       "0    100  0.85          0.03     8                 3              16   \n",
       "0    100  0.85          0.03     9                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "0    100  0.85          0.01    10                 3              16   \n",
       "0    100  0.85          0.02    10                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "0    100  0.85          0.05    10                 3              16   \n",
       "0    100  0.85         0.075    10                 3              16   \n",
       "0    100  0.85           0.1    10                 3              16   \n",
       "0    100  0.85         0.125    10                 3              16   \n",
       "0    100  0.85          0.15    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.5    10                 3              16   \n",
       "0    100  0.85          0.75    10                 3              16   \n",
       "0    100  0.85             1    10                 3              16   \n",
       "0    100  0.85           1.5    10                 3              16   \n",
       "0    100  0.85             2    10                 3              16   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  \n",
       "0                 5                   1  0.451849  0.453623  0.402904  \n",
       "0                10                   1  0.453604   0.45484  0.407005  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                32                   1  0.453115  0.454388  0.405824  \n",
       "0                64                   1   0.45513  0.456311  0.409631  \n",
       "0               128                   1  0.454684  0.456024  0.408098  \n",
       "0               255                   1  0.455045  0.456244   0.40867  \n",
       "0                16                   1   0.45336  0.454692  0.408261  \n",
       "0                16                   1  0.454922  0.456109  0.410751  \n",
       "0                16                   1  0.456208  0.457545   0.41235  \n",
       "0                16                   1  0.454801  0.456263  0.411622  \n",
       "0                16                   1   0.45617  0.457539  0.411126  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.456422  0.457679  0.409276  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.441066  0.442915  0.396312  \n",
       "0                16                   1  0.449438  0.450992  0.404413  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.460658  0.461646  0.416653  \n",
       "0                16                   1  0.465061  0.465669   0.41762  \n",
       "0                16                   1  0.468306  0.468324  0.417121  \n",
       "0                16                   1  0.472581  0.471884  0.421361  \n",
       "0                16                   1  0.451027  0.451405  0.400855  \n",
       "0                16                   1   0.46271  0.462658  0.418592  \n",
       "0                16                   1  0.472581  0.471884  0.421361  \n",
       "0                16                   1  0.484078  0.481967  0.434897  \n",
       "0                16                   1  0.493039  0.488949  0.445385  \n",
       "0                16                   1  0.498417  0.492692  0.431242  \n",
       "0                16                   1  0.503328  0.496473   0.44277  \n",
       "0                16                   1  0.506916  0.497736   0.42221  \n",
       "0                16                   1   0.51677  0.500368  0.429062  \n",
       "0                16                   1  0.515282  0.497004  0.413381  \n",
       "0                16                   1  0.508283  0.493476  0.426477  \n",
       "0                16                   1  0.499103  0.485731  0.414978  \n",
       "0                16                   1  0.337505  0.338444  0.276346  \n",
       "0                16                   1  0.337505  0.338444  0.276346  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_rt_opt = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging temperature = 0\n",
      "2018-03-15 02:15:28.605768\n",
      "model train start\n",
      "2018-03-15 02:15:28.606056\n",
      "0: learn: 0.4126743\ttest: 0.4124469\tbestTest: 0.4124469 (0)\ttotal: 6.55s\tremaining: 10m 48s\n",
      "1: learn: 0.3024897\ttest: 0.3021123\tbestTest: 0.3021123 (1)\ttotal: 14.8s\tremaining: 12m 3s\n",
      "2: learn: 0.2605809\ttest: 0.2600461\tbestTest: 0.2600461 (2)\ttotal: 24s\tremaining: 12m 55s\n",
      "3: learn: 0.2416378\ttest: 0.2410303\tbestTest: 0.2410303 (3)\ttotal: 31.5s\tremaining: 12m 36s\n",
      "4: learn: 0.2336186\ttest: 0.2329648\tbestTest: 0.2329648 (4)\ttotal: 40.8s\tremaining: 12m 55s\n",
      "5: learn: 0.2289503\ttest: 0.2282699\tbestTest: 0.2282699 (5)\ttotal: 49.3s\tremaining: 12m 53s\n",
      "6: learn: 0.226386\ttest: 0.2257378\tbestTest: 0.2257378 (6)\ttotal: 57s\tremaining: 12m 37s\n",
      "7: learn: 0.2248181\ttest: 0.2241906\tbestTest: 0.2241906 (7)\ttotal: 1m 5s\tremaining: 12m 34s\n",
      "8: learn: 0.2240102\ttest: 0.2233974\tbestTest: 0.2233974 (8)\ttotal: 1m 14s\tremaining: 12m 37s\n",
      "9: learn: 0.223473\ttest: 0.2228686\tbestTest: 0.2228686 (9)\ttotal: 1m 23s\tremaining: 12m 31s\n",
      "10: learn: 0.2230238\ttest: 0.2224312\tbestTest: 0.2224312 (10)\ttotal: 1m 32s\tremaining: 12m 24s\n",
      "11: learn: 0.2225298\ttest: 0.2219801\tbestTest: 0.2219801 (11)\ttotal: 1m 40s\tremaining: 12m 16s\n",
      "12: learn: 0.2221626\ttest: 0.2216912\tbestTest: 0.2216912 (12)\ttotal: 1m 48s\tremaining: 12m 7s\n",
      "13: learn: 0.221944\ttest: 0.2214943\tbestTest: 0.2214943 (13)\ttotal: 1m 56s\tremaining: 11m 56s\n",
      "14: learn: 0.2217486\ttest: 0.2213224\tbestTest: 0.2213224 (14)\ttotal: 2m 4s\tremaining: 11m 43s\n",
      "15: learn: 0.2214746\ttest: 0.2211123\tbestTest: 0.2211123 (15)\ttotal: 2m 12s\tremaining: 11m 34s\n",
      "16: learn: 0.2213215\ttest: 0.220977\tbestTest: 0.220977 (16)\ttotal: 2m 20s\tremaining: 11m 27s\n",
      "17: learn: 0.2211049\ttest: 0.2208054\tbestTest: 0.2208054 (17)\ttotal: 2m 28s\tremaining: 11m 16s\n",
      "18: learn: 0.2210367\ttest: 0.2207465\tbestTest: 0.2207465 (18)\ttotal: 2m 37s\tremaining: 11m 11s\n",
      "19: learn: 0.220955\ttest: 0.220674\tbestTest: 0.220674 (19)\ttotal: 2m 43s\tremaining: 10m 53s\n",
      "20: learn: 0.2207937\ttest: 0.220535\tbestTest: 0.220535 (20)\ttotal: 2m 52s\tremaining: 10m 48s\n",
      "21: learn: 0.2207103\ttest: 0.2204659\tbestTest: 0.2204659 (21)\ttotal: 3m 1s\tremaining: 10m 43s\n",
      "22: learn: 0.2205913\ttest: 0.2203664\tbestTest: 0.2203664 (22)\ttotal: 3m 9s\tremaining: 10m 35s\n",
      "23: learn: 0.2205076\ttest: 0.2202988\tbestTest: 0.2202988 (23)\ttotal: 3m 17s\tremaining: 10m 26s\n",
      "24: learn: 0.2204275\ttest: 0.2202389\tbestTest: 0.2202389 (24)\ttotal: 3m 26s\tremaining: 10m 19s\n",
      "25: learn: 0.2203968\ttest: 0.2202108\tbestTest: 0.2202108 (25)\ttotal: 3m 32s\tremaining: 10m 6s\n",
      "26: learn: 0.2202826\ttest: 0.2201192\tbestTest: 0.2201192 (26)\ttotal: 3m 40s\tremaining: 9m 57s\n",
      "27: learn: 0.2201731\ttest: 0.2200383\tbestTest: 0.2200383 (27)\ttotal: 3m 49s\tremaining: 9m 49s\n",
      "28: learn: 0.2200823\ttest: 0.2199741\tbestTest: 0.2199741 (28)\ttotal: 3m 57s\tremaining: 9m 40s\n",
      "29: learn: 0.2200322\ttest: 0.2199318\tbestTest: 0.2199318 (29)\ttotal: 4m 5s\tremaining: 9m 32s\n",
      "30: learn: 0.2199454\ttest: 0.2198551\tbestTest: 0.2198551 (30)\ttotal: 4m 11s\tremaining: 9m 18s\n",
      "31: learn: 0.2198889\ttest: 0.2198139\tbestTest: 0.2198139 (31)\ttotal: 4m 18s\tremaining: 9m 9s\n",
      "32: learn: 0.2197943\ttest: 0.2197482\tbestTest: 0.2197482 (32)\ttotal: 4m 27s\tremaining: 9m 2s\n",
      "33: learn: 0.2196693\ttest: 0.2196849\tbestTest: 0.2196849 (33)\ttotal: 4m 35s\tremaining: 8m 53s\n",
      "34: learn: 0.2196087\ttest: 0.2196503\tbestTest: 0.2196503 (34)\ttotal: 4m 43s\tremaining: 8m 46s\n",
      "35: learn: 0.2195629\ttest: 0.2196102\tbestTest: 0.2196102 (35)\ttotal: 4m 52s\tremaining: 8m 39s\n",
      "36: learn: 0.2194691\ttest: 0.2195567\tbestTest: 0.2195567 (36)\ttotal: 5m\tremaining: 8m 31s\n",
      "37: learn: 0.2193795\ttest: 0.2195068\tbestTest: 0.2195068 (37)\ttotal: 5m 7s\tremaining: 8m 22s\n",
      "38: learn: 0.2193165\ttest: 0.219469\tbestTest: 0.219469 (38)\ttotal: 5m 15s\tremaining: 8m 13s\n",
      "39: learn: 0.2192449\ttest: 0.2194104\tbestTest: 0.2194104 (39)\ttotal: 5m 23s\tremaining: 8m 5s\n",
      "40: learn: 0.2192141\ttest: 0.2193848\tbestTest: 0.2193848 (40)\ttotal: 5m 32s\tremaining: 7m 58s\n",
      "41: learn: 0.2191944\ttest: 0.21937\tbestTest: 0.21937 (41)\ttotal: 5m 41s\tremaining: 7m 51s\n",
      "42: learn: 0.2191647\ttest: 0.2193486\tbestTest: 0.2193486 (42)\ttotal: 5m 48s\tremaining: 7m 42s\n",
      "43: learn: 0.2191314\ttest: 0.2193285\tbestTest: 0.2193285 (43)\ttotal: 5m 56s\tremaining: 7m 34s\n",
      "44: learn: 0.2190516\ttest: 0.2192799\tbestTest: 0.2192799 (44)\ttotal: 6m 4s\tremaining: 7m 25s\n",
      "45: learn: 0.2190042\ttest: 0.219258\tbestTest: 0.219258 (45)\ttotal: 6m 13s\tremaining: 7m 18s\n",
      "46: learn: 0.2189458\ttest: 0.2192285\tbestTest: 0.2192285 (46)\ttotal: 6m 22s\tremaining: 7m 11s\n",
      "47: learn: 0.2189086\ttest: 0.2192028\tbestTest: 0.2192028 (47)\ttotal: 6m 30s\tremaining: 7m 2s\n",
      "48: learn: 0.2188571\ttest: 0.2191638\tbestTest: 0.2191638 (48)\ttotal: 6m 38s\tremaining: 6m 54s\n",
      "49: learn: 0.2187998\ttest: 0.2191221\tbestTest: 0.2191221 (49)\ttotal: 6m 46s\tremaining: 6m 46s\n",
      "50: learn: 0.2187168\ttest: 0.2190672\tbestTest: 0.2190672 (50)\ttotal: 6m 54s\tremaining: 6m 38s\n",
      "51: learn: 0.2186806\ttest: 0.2190425\tbestTest: 0.2190425 (51)\ttotal: 7m 2s\tremaining: 6m 29s\n",
      "52: learn: 0.2186629\ttest: 0.2190319\tbestTest: 0.2190319 (52)\ttotal: 7m 10s\tremaining: 6m 21s\n",
      "53: learn: 0.2186335\ttest: 0.2190104\tbestTest: 0.2190104 (53)\ttotal: 7m 17s\tremaining: 6m 12s\n",
      "54: learn: 0.2186074\ttest: 0.2189932\tbestTest: 0.2189932 (54)\ttotal: 7m 25s\tremaining: 6m 4s\n",
      "55: learn: 0.2185746\ttest: 0.2189715\tbestTest: 0.2189715 (55)\ttotal: 7m 34s\tremaining: 5m 56s\n",
      "56: learn: 0.218536\ttest: 0.2189429\tbestTest: 0.2189429 (56)\ttotal: 7m 40s\tremaining: 5m 47s\n",
      "57: learn: 0.2184672\ttest: 0.2189213\tbestTest: 0.2189213 (57)\ttotal: 7m 48s\tremaining: 5m 39s\n",
      "58: learn: 0.2184208\ttest: 0.2188909\tbestTest: 0.2188909 (58)\ttotal: 7m 57s\tremaining: 5m 31s\n",
      "59: learn: 0.2184001\ttest: 0.2188803\tbestTest: 0.2188803 (59)\ttotal: 8m 6s\tremaining: 5m 24s\n",
      "60: learn: 0.2183427\ttest: 0.2188572\tbestTest: 0.2188572 (60)\ttotal: 8m 15s\tremaining: 5m 16s\n",
      "61: learn: 0.2183107\ttest: 0.2188353\tbestTest: 0.2188353 (61)\ttotal: 8m 23s\tremaining: 5m 8s\n",
      "62: learn: 0.2182878\ttest: 0.2188241\tbestTest: 0.2188241 (62)\ttotal: 8m 33s\tremaining: 5m 1s\n",
      "63: learn: 0.2182434\ttest: 0.2188055\tbestTest: 0.2188055 (63)\ttotal: 8m 41s\tremaining: 4m 53s\n",
      "64: learn: 0.2182033\ttest: 0.2187782\tbestTest: 0.2187782 (64)\ttotal: 8m 50s\tremaining: 4m 45s\n",
      "65: learn: 0.2181624\ttest: 0.2187609\tbestTest: 0.2187609 (65)\ttotal: 8m 58s\tremaining: 4m 37s\n",
      "66: learn: 0.2181406\ttest: 0.218746\tbestTest: 0.218746 (66)\ttotal: 9m 7s\tremaining: 4m 29s\n",
      "67: learn: 0.2180697\ttest: 0.2187159\tbestTest: 0.2187159 (67)\ttotal: 9m 14s\tremaining: 4m 21s\n",
      "68: learn: 0.2179727\ttest: 0.2186647\tbestTest: 0.2186647 (68)\ttotal: 9m 22s\tremaining: 4m 12s\n",
      "69: learn: 0.2179047\ttest: 0.2186474\tbestTest: 0.2186474 (69)\ttotal: 9m 30s\tremaining: 4m 4s\n",
      "70: learn: 0.217827\ttest: 0.2186161\tbestTest: 0.2186161 (70)\ttotal: 9m 38s\tremaining: 3m 56s\n",
      "71: learn: 0.2178013\ttest: 0.2186151\tbestTest: 0.2186151 (71)\ttotal: 9m 46s\tremaining: 3m 48s\n",
      "72: learn: 0.2177358\ttest: 0.2186124\tbestTest: 0.2186124 (72)\ttotal: 9m 54s\tremaining: 3m 39s\n",
      "73: learn: 0.217699\ttest: 0.2186066\tbestTest: 0.2186066 (73)\ttotal: 10m 2s\tremaining: 3m 31s\n",
      "74: learn: 0.2176499\ttest: 0.2185868\tbestTest: 0.2185868 (74)\ttotal: 10m 11s\tremaining: 3m 23s\n",
      "75: learn: 0.2176357\ttest: 0.2185831\tbestTest: 0.2185831 (75)\ttotal: 10m 20s\tremaining: 3m 15s\n",
      "76: learn: 0.2175579\ttest: 0.2185295\tbestTest: 0.2185295 (76)\ttotal: 10m 28s\tremaining: 3m 7s\n",
      "77: learn: 0.2175302\ttest: 0.2185172\tbestTest: 0.2185172 (77)\ttotal: 10m 36s\tremaining: 2m 59s\n",
      "78: learn: 0.217497\ttest: 0.21851\tbestTest: 0.21851 (78)\ttotal: 10m 45s\tremaining: 2m 51s\n",
      "79: learn: 0.2174904\ttest: 0.2185046\tbestTest: 0.2185046 (79)\ttotal: 10m 53s\tremaining: 2m 43s\n",
      "80: learn: 0.217463\ttest: 0.2184973\tbestTest: 0.2184973 (80)\ttotal: 11m 2s\tremaining: 2m 35s\n",
      "81: learn: 0.2174388\ttest: 0.2184916\tbestTest: 0.2184916 (81)\ttotal: 11m 10s\tremaining: 2m 27s\n",
      "82: learn: 0.217419\ttest: 0.2184834\tbestTest: 0.2184834 (82)\ttotal: 11m 19s\tremaining: 2m 19s\n",
      "83: learn: 0.2174183\ttest: 0.2184834\tbestTest: 0.2184834 (82)\ttotal: 11m 28s\tremaining: 2m 11s\n",
      "84: learn: 0.2174033\ttest: 0.2184789\tbestTest: 0.2184789 (84)\ttotal: 11m 37s\tremaining: 2m 3s\n",
      "85: learn: 0.2173732\ttest: 0.218475\tbestTest: 0.218475 (85)\ttotal: 11m 46s\tremaining: 1m 55s\n",
      "86: learn: 0.2173246\ttest: 0.2184647\tbestTest: 0.2184647 (86)\ttotal: 11m 54s\tremaining: 1m 46s\n",
      "87: learn: 0.2172938\ttest: 0.2184553\tbestTest: 0.2184553 (87)\ttotal: 12m 3s\tremaining: 1m 38s\n",
      "88: learn: 0.2172936\ttest: 0.2184553\tbestTest: 0.2184553 (87)\ttotal: 12m 12s\tremaining: 1m 30s\n",
      "89: learn: 0.2172543\ttest: 0.2184405\tbestTest: 0.2184405 (89)\ttotal: 12m 21s\tremaining: 1m 22s\n",
      "90: learn: 0.2172123\ttest: 0.2184237\tbestTest: 0.2184237 (90)\ttotal: 12m 30s\tremaining: 1m 14s\n",
      "91: learn: 0.2172119\ttest: 0.218424\tbestTest: 0.2184237 (90)\ttotal: 12m 39s\tremaining: 1m 6s\n",
      "92: learn: 0.2171861\ttest: 0.2184243\tbestTest: 0.2184237 (90)\ttotal: 12m 49s\tremaining: 57.9s\n",
      "93: learn: 0.2171789\ttest: 0.2184217\tbestTest: 0.2184217 (93)\ttotal: 12m 58s\tremaining: 49.7s\n",
      "94: learn: 0.2171369\ttest: 0.2184255\tbestTest: 0.2184217 (93)\ttotal: 13m 5s\tremaining: 41.4s\n",
      "95: learn: 0.2171336\ttest: 0.218424\tbestTest: 0.2184217 (93)\ttotal: 13m 14s\tremaining: 33.1s\n",
      "96: learn: 0.2170986\ttest: 0.2184211\tbestTest: 0.2184211 (96)\ttotal: 13m 22s\tremaining: 24.8s\n",
      "97: learn: 0.2170674\ttest: 0.2184074\tbestTest: 0.2184074 (97)\ttotal: 13m 32s\tremaining: 16.6s\n",
      "98: learn: 0.2170669\ttest: 0.2184073\tbestTest: 0.2184073 (98)\ttotal: 13m 42s\tremaining: 8.31s\n",
      "99: learn: 0.2170535\ttest: 0.2184054\tbestTest: 0.2184054 (99)\ttotal: 13m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2184053813\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_0\n",
      "2018-03-15 02:33:03.155560\n",
      "train time given below\n",
      "0:17:34.549504\n",
      "2018-03-15 02:33:03.156231\n",
      "2018-03-15 02:33:03.159785\n",
      "GINI ISIT = 0.513645895218\n",
      "2018-03-15 02:34:46.734861\n",
      "GINI OSIT = 0.500912877226\n",
      "2018-03-15 02:35:27.976087\n",
      "GINI OSOT = 0.454185867155\n",
      "2018-03-15 02:35:40.631970\n",
      "2018-03-15 02:35:40.634086\n",
      "loop run time\n",
      "0:20:12.028320\n",
      "bagging temperature = 0.1\n",
      "2018-03-15 02:35:40.635813\n",
      "model train start\n",
      "2018-03-15 02:35:40.636045\n",
      "0: learn: 0.4126743\ttest: 0.4124469\tbestTest: 0.4124469 (0)\ttotal: 6.69s\tremaining: 11m 2s\n",
      "1: learn: 0.3024897\ttest: 0.3021123\tbestTest: 0.3021123 (1)\ttotal: 14.9s\tremaining: 12m 11s\n",
      "2: learn: 0.2605809\ttest: 0.2600461\tbestTest: 0.2600461 (2)\ttotal: 23.7s\tremaining: 12m 47s\n",
      "3: learn: 0.2416378\ttest: 0.2410303\tbestTest: 0.2410303 (3)\ttotal: 31.7s\tremaining: 12m 39s\n",
      "4: learn: 0.2326892\ttest: 0.2320482\tbestTest: 0.2320482 (4)\ttotal: 40.9s\tremaining: 12m 56s\n",
      "5: learn: 0.2284238\ttest: 0.227772\tbestTest: 0.227772 (5)\ttotal: 49.3s\tremaining: 12m 52s\n",
      "6: learn: 0.2262929\ttest: 0.2256428\tbestTest: 0.2256428 (6)\ttotal: 57.8s\tremaining: 12m 48s\n",
      "7: learn: 0.2249328\ttest: 0.22428\tbestTest: 0.22428 (7)\ttotal: 1m 6s\tremaining: 12m 45s\n",
      "8: learn: 0.2238959\ttest: 0.2232859\tbestTest: 0.2232859 (8)\ttotal: 1m 15s\tremaining: 12m 43s\n",
      "9: learn: 0.2233269\ttest: 0.2227118\tbestTest: 0.2227118 (9)\ttotal: 1m 24s\tremaining: 12m 38s\n",
      "10: learn: 0.2228489\ttest: 0.2222364\tbestTest: 0.2222364 (10)\ttotal: 1m 33s\tremaining: 12m 33s\n",
      "11: learn: 0.2224969\ttest: 0.2219077\tbestTest: 0.2219077 (11)\ttotal: 1m 42s\tremaining: 12m 31s\n",
      "12: learn: 0.2221954\ttest: 0.2216585\tbestTest: 0.2216585 (12)\ttotal: 1m 51s\tremaining: 12m 25s\n",
      "13: learn: 0.2220493\ttest: 0.221514\tbestTest: 0.221514 (13)\ttotal: 2m\tremaining: 12m 20s\n",
      "14: learn: 0.2218184\ttest: 0.2213274\tbestTest: 0.2213274 (14)\ttotal: 2m 8s\tremaining: 12m 8s\n",
      "15: learn: 0.2215473\ttest: 0.2210974\tbestTest: 0.2210974 (15)\ttotal: 2m 16s\tremaining: 11m 57s\n",
      "16: learn: 0.2212467\ttest: 0.2208168\tbestTest: 0.2208168 (16)\ttotal: 2m 24s\tremaining: 11m 45s\n",
      "17: learn: 0.2210993\ttest: 0.2206939\tbestTest: 0.2206939 (17)\ttotal: 2m 32s\tremaining: 11m 35s\n",
      "18: learn: 0.2209286\ttest: 0.2205655\tbestTest: 0.2205655 (18)\ttotal: 2m 41s\tremaining: 11m 29s\n",
      "19: learn: 0.2208045\ttest: 0.2204588\tbestTest: 0.2204588 (19)\ttotal: 2m 49s\tremaining: 11m 19s\n",
      "20: learn: 0.2206606\ttest: 0.2203617\tbestTest: 0.2203617 (20)\ttotal: 2m 58s\tremaining: 11m 9s\n",
      "21: learn: 0.2205425\ttest: 0.2202689\tbestTest: 0.2202689 (21)\ttotal: 3m 7s\tremaining: 11m 4s\n",
      "22: learn: 0.2204348\ttest: 0.2201824\tbestTest: 0.2201824 (22)\ttotal: 3m 16s\tremaining: 10m 56s\n",
      "23: learn: 0.2203469\ttest: 0.2201073\tbestTest: 0.2201073 (23)\ttotal: 3m 24s\tremaining: 10m 48s\n",
      "24: learn: 0.2202987\ttest: 0.2200662\tbestTest: 0.2200662 (24)\ttotal: 3m 34s\tremaining: 10m 44s\n",
      "25: learn: 0.2201903\ttest: 0.2199862\tbestTest: 0.2199862 (25)\ttotal: 3m 44s\tremaining: 10m 37s\n",
      "26: learn: 0.2200843\ttest: 0.2199175\tbestTest: 0.2199175 (26)\ttotal: 3m 53s\tremaining: 10m 30s\n",
      "27: learn: 0.2199911\ttest: 0.219862\tbestTest: 0.219862 (27)\ttotal: 4m 1s\tremaining: 10m 22s\n",
      "28: learn: 0.219928\ttest: 0.2198163\tbestTest: 0.2198163 (28)\ttotal: 4m 11s\tremaining: 10m 15s\n",
      "29: learn: 0.2198352\ttest: 0.219766\tbestTest: 0.219766 (29)\ttotal: 4m 19s\tremaining: 10m 5s\n",
      "30: learn: 0.2197002\ttest: 0.2196732\tbestTest: 0.2196732 (30)\ttotal: 4m 28s\tremaining: 9m 56s\n",
      "31: learn: 0.2196306\ttest: 0.2196165\tbestTest: 0.2196165 (31)\ttotal: 4m 37s\tremaining: 9m 48s\n",
      "32: learn: 0.2195639\ttest: 0.2195645\tbestTest: 0.2195645 (32)\ttotal: 4m 45s\tremaining: 9m 39s\n",
      "33: learn: 0.2195275\ttest: 0.2195328\tbestTest: 0.2195328 (33)\ttotal: 4m 50s\tremaining: 9m 24s\n",
      "34: learn: 0.219416\ttest: 0.2194814\tbestTest: 0.2194814 (34)\ttotal: 4m 58s\tremaining: 9m 14s\n",
      "35: learn: 0.2193699\ttest: 0.2194598\tbestTest: 0.2194598 (35)\ttotal: 5m 8s\tremaining: 9m 7s\n",
      "36: learn: 0.2193263\ttest: 0.2194346\tbestTest: 0.2194346 (36)\ttotal: 5m 17s\tremaining: 9m\n",
      "37: learn: 0.2192555\ttest: 0.2193713\tbestTest: 0.2193713 (37)\ttotal: 5m 25s\tremaining: 8m 51s\n",
      "38: learn: 0.2191488\ttest: 0.2193086\tbestTest: 0.2193086 (38)\ttotal: 5m 34s\tremaining: 8m 42s\n",
      "39: learn: 0.2191187\ttest: 0.2192867\tbestTest: 0.2192867 (39)\ttotal: 5m 43s\tremaining: 8m 35s\n",
      "40: learn: 0.2190779\ttest: 0.2192563\tbestTest: 0.2192563 (40)\ttotal: 5m 52s\tremaining: 8m 27s\n",
      "41: learn: 0.2190506\ttest: 0.2192413\tbestTest: 0.2192413 (41)\ttotal: 6m 1s\tremaining: 8m 19s\n",
      "42: learn: 0.2190242\ttest: 0.2192227\tbestTest: 0.2192227 (42)\ttotal: 6m 11s\tremaining: 8m 12s\n",
      "43: learn: 0.2189864\ttest: 0.2192086\tbestTest: 0.2192086 (43)\ttotal: 6m 19s\tremaining: 8m 2s\n",
      "44: learn: 0.218925\ttest: 0.2191671\tbestTest: 0.2191671 (44)\ttotal: 6m 28s\tremaining: 7m 55s\n",
      "45: learn: 0.2188959\ttest: 0.2191426\tbestTest: 0.2191426 (45)\ttotal: 6m 35s\tremaining: 7m 44s\n",
      "46: learn: 0.2188824\ttest: 0.2191357\tbestTest: 0.2191357 (46)\ttotal: 6m 42s\tremaining: 7m 33s\n",
      "47: learn: 0.2187864\ttest: 0.2190928\tbestTest: 0.2190928 (47)\ttotal: 6m 50s\tremaining: 7m 25s\n",
      "48: learn: 0.2187617\ttest: 0.2190713\tbestTest: 0.2190713 (48)\ttotal: 6m 56s\tremaining: 7m 13s\n",
      "49: learn: 0.2186846\ttest: 0.2190091\tbestTest: 0.2190091 (49)\ttotal: 7m 5s\tremaining: 7m 5s\n",
      "50: learn: 0.2186763\ttest: 0.2190034\tbestTest: 0.2190034 (50)\ttotal: 7m 9s\tremaining: 6m 52s\n",
      "51: learn: 0.2186285\ttest: 0.2189735\tbestTest: 0.2189735 (51)\ttotal: 7m 17s\tremaining: 6m 44s\n",
      "52: learn: 0.2185672\ttest: 0.2189333\tbestTest: 0.2189333 (52)\ttotal: 7m 26s\tremaining: 6m 36s\n",
      "53: learn: 0.2185221\ttest: 0.2189167\tbestTest: 0.2189167 (53)\ttotal: 7m 36s\tremaining: 6m 28s\n",
      "54: learn: 0.2184692\ttest: 0.218889\tbestTest: 0.218889 (54)\ttotal: 7m 45s\tremaining: 6m 20s\n",
      "55: learn: 0.2184514\ttest: 0.2188768\tbestTest: 0.2188768 (55)\ttotal: 7m 50s\tremaining: 6m 9s\n",
      "56: learn: 0.2184133\ttest: 0.218867\tbestTest: 0.218867 (56)\ttotal: 7m 58s\tremaining: 6m 1s\n",
      "57: learn: 0.2183766\ttest: 0.2188415\tbestTest: 0.2188415 (57)\ttotal: 8m 7s\tremaining: 5m 53s\n",
      "58: learn: 0.2183424\ttest: 0.2188115\tbestTest: 0.2188115 (58)\ttotal: 8m 16s\tremaining: 5m 45s\n",
      "59: learn: 0.2182821\ttest: 0.2187835\tbestTest: 0.2187835 (59)\ttotal: 8m 25s\tremaining: 5m 37s\n",
      "60: learn: 0.218245\ttest: 0.2187584\tbestTest: 0.2187584 (60)\ttotal: 8m 34s\tremaining: 5m 28s\n",
      "61: learn: 0.2181984\ttest: 0.2187503\tbestTest: 0.2187503 (61)\ttotal: 8m 42s\tremaining: 5m 20s\n",
      "62: learn: 0.218151\ttest: 0.2187404\tbestTest: 0.2187404 (62)\ttotal: 8m 50s\tremaining: 5m 11s\n",
      "63: learn: 0.2181267\ttest: 0.2187302\tbestTest: 0.2187302 (63)\ttotal: 8m 59s\tremaining: 5m 3s\n",
      "64: learn: 0.2181263\ttest: 0.2187302\tbestTest: 0.2187302 (64)\ttotal: 9m 9s\tremaining: 4m 55s\n",
      "65: learn: 0.2181261\ttest: 0.2187302\tbestTest: 0.2187302 (65)\ttotal: 9m 18s\tremaining: 4m 47s\n",
      "66: learn: 0.2181185\ttest: 0.2187248\tbestTest: 0.2187248 (66)\ttotal: 9m 28s\tremaining: 4m 40s\n",
      "67: learn: 0.2180998\ttest: 0.2187119\tbestTest: 0.2187119 (67)\ttotal: 9m 37s\tremaining: 4m 31s\n",
      "68: learn: 0.2180997\ttest: 0.218712\tbestTest: 0.2187119 (67)\ttotal: 9m 47s\tremaining: 4m 23s\n",
      "69: learn: 0.2180995\ttest: 0.218712\tbestTest: 0.2187119 (67)\ttotal: 9m 54s\tremaining: 4m 14s\n",
      "70: learn: 0.218046\ttest: 0.2186889\tbestTest: 0.2186889 (70)\ttotal: 10m 3s\tremaining: 4m 6s\n",
      "71: learn: 0.218046\ttest: 0.2186889\tbestTest: 0.2186889 (70)\ttotal: 10m 13s\tremaining: 3m 58s\n",
      "72: learn: 0.2180439\ttest: 0.2186882\tbestTest: 0.2186882 (72)\ttotal: 10m 22s\tremaining: 3m 50s\n",
      "73: learn: 0.2179875\ttest: 0.2186641\tbestTest: 0.2186641 (73)\ttotal: 10m 31s\tremaining: 3m 41s\n",
      "74: learn: 0.2179875\ttest: 0.218664\tbestTest: 0.218664 (74)\ttotal: 10m 41s\tremaining: 3m 33s\n",
      "75: learn: 0.217946\ttest: 0.2186443\tbestTest: 0.2186443 (75)\ttotal: 10m 49s\tremaining: 3m 25s\n",
      "76: learn: 0.2178941\ttest: 0.2186086\tbestTest: 0.2186086 (76)\ttotal: 10m 59s\tremaining: 3m 16s\n",
      "77: learn: 0.2178803\ttest: 0.218604\tbestTest: 0.218604 (77)\ttotal: 11m 9s\tremaining: 3m 8s\n",
      "78: learn: 0.2178801\ttest: 0.218604\tbestTest: 0.218604 (77)\ttotal: 11m 19s\tremaining: 3m\n",
      "79: learn: 0.2178506\ttest: 0.2185893\tbestTest: 0.2185893 (79)\ttotal: 11m 28s\tremaining: 2m 52s\n",
      "80: learn: 0.2178494\ttest: 0.2185887\tbestTest: 0.2185887 (80)\ttotal: 11m 40s\tremaining: 2m 44s\n",
      "81: learn: 0.2177773\ttest: 0.2185561\tbestTest: 0.2185561 (81)\ttotal: 11m 49s\tremaining: 2m 35s\n",
      "82: learn: 0.2177526\ttest: 0.2185447\tbestTest: 0.2185447 (82)\ttotal: 11m 58s\tremaining: 2m 27s\n",
      "83: learn: 0.2177525\ttest: 0.2185448\tbestTest: 0.2185447 (82)\ttotal: 12m 6s\tremaining: 2m 18s\n",
      "84: learn: 0.217703\ttest: 0.2185161\tbestTest: 0.2185161 (84)\ttotal: 12m 15s\tremaining: 2m 9s\n",
      "85: learn: 0.2176336\ttest: 0.2184644\tbestTest: 0.2184644 (85)\ttotal: 12m 24s\tremaining: 2m 1s\n",
      "86: learn: 0.2176157\ttest: 0.2184656\tbestTest: 0.2184644 (85)\ttotal: 12m 33s\tremaining: 1m 52s\n",
      "87: learn: 0.217595\ttest: 0.2184534\tbestTest: 0.2184534 (87)\ttotal: 12m 41s\tremaining: 1m 43s\n",
      "88: learn: 0.2175943\ttest: 0.2184538\tbestTest: 0.2184534 (87)\ttotal: 12m 50s\tremaining: 1m 35s\n",
      "89: learn: 0.2175941\ttest: 0.2184539\tbestTest: 0.2184534 (87)\ttotal: 13m\tremaining: 1m 26s\n",
      "90: learn: 0.2175941\ttest: 0.2184539\tbestTest: 0.2184534 (87)\ttotal: 13m 8s\tremaining: 1m 18s\n",
      "91: learn: 0.2175685\ttest: 0.218442\tbestTest: 0.218442 (91)\ttotal: 13m 18s\tremaining: 1m 9s\n",
      "92: learn: 0.21755\ttest: 0.2184358\tbestTest: 0.2184358 (92)\ttotal: 13m 26s\tremaining: 1m\n",
      "93: learn: 0.2175125\ttest: 0.2184136\tbestTest: 0.2184136 (93)\ttotal: 13m 36s\tremaining: 52.1s\n",
      "94: learn: 0.2174712\ttest: 0.2184052\tbestTest: 0.2184052 (94)\ttotal: 13m 45s\tremaining: 43.4s\n",
      "95: learn: 0.2173672\ttest: 0.2183805\tbestTest: 0.2183805 (95)\ttotal: 13m 52s\tremaining: 34.7s\n",
      "96: learn: 0.2173159\ttest: 0.2183509\tbestTest: 0.2183509 (96)\ttotal: 14m 2s\tremaining: 26s\n",
      "97: learn: 0.2173001\ttest: 0.2183478\tbestTest: 0.2183478 (97)\ttotal: 14m 12s\tremaining: 17.4s\n",
      "98: learn: 0.2172997\ttest: 0.218348\tbestTest: 0.2183478 (97)\ttotal: 14m 22s\tremaining: 8.71s\n",
      "99: learn: 0.2172421\ttest: 0.2183354\tbestTest: 0.2183354 (99)\ttotal: 14m 31s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2183354228\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_0.1\n",
      "2018-03-15 02:53:54.401121\n",
      "train time given below\n",
      "0:18:13.765076\n",
      "2018-03-15 02:53:54.483465\n",
      "2018-03-15 02:53:54.487205\n",
      "GINI ISIT = 0.512746432913\n",
      "2018-03-15 02:55:34.239657\n",
      "GINI OSIT = 0.501338591545\n",
      "2018-03-15 02:56:17.476512\n",
      "GINI OSOT = 0.430890841979\n",
      "2018-03-15 02:56:30.434719\n",
      "2018-03-15 02:56:30.436730\n",
      "loop run time\n",
      "0:20:49.800914\n",
      "bagging temperature = 0.5\n",
      "2018-03-15 02:56:30.438361\n",
      "model train start\n",
      "2018-03-15 02:56:30.438575\n",
      "0: learn: 0.4126743\ttest: 0.4124469\tbestTest: 0.4124469 (0)\ttotal: 6.27s\tremaining: 10m 20s\n",
      "1: learn: 0.3049293\ttest: 0.3045218\tbestTest: 0.3045218 (1)\ttotal: 14s\tremaining: 11m 24s\n",
      "2: learn: 0.2620721\ttest: 0.2615211\tbestTest: 0.2615211 (2)\ttotal: 22.4s\tremaining: 12m 3s\n",
      "3: learn: 0.2421763\ttest: 0.2415337\tbestTest: 0.2415337 (3)\ttotal: 30.8s\tremaining: 12m 18s\n",
      "4: learn: 0.2332605\ttest: 0.2325628\tbestTest: 0.2325628 (4)\ttotal: 39s\tremaining: 12m 20s\n",
      "5: learn: 0.2287296\ttest: 0.2280449\tbestTest: 0.2280449 (5)\ttotal: 47s\tremaining: 12m 16s\n",
      "6: learn: 0.2262611\ttest: 0.2255999\tbestTest: 0.2255999 (6)\ttotal: 54.8s\tremaining: 12m 7s\n",
      "7: learn: 0.2249838\ttest: 0.2243445\tbestTest: 0.2243445 (7)\ttotal: 1m 2s\tremaining: 11m 54s\n",
      "8: learn: 0.2241148\ttest: 0.2234746\tbestTest: 0.2234746 (8)\ttotal: 1m 10s\tremaining: 11m 51s\n",
      "9: learn: 0.2233775\ttest: 0.2227766\tbestTest: 0.2227766 (9)\ttotal: 1m 18s\tremaining: 11m 48s\n",
      "10: learn: 0.2228802\ttest: 0.2223185\tbestTest: 0.2223185 (10)\ttotal: 1m 26s\tremaining: 11m 38s\n",
      "11: learn: 0.2225224\ttest: 0.2219721\tbestTest: 0.2219721 (11)\ttotal: 1m 34s\tremaining: 11m 33s\n",
      "12: learn: 0.222226\ttest: 0.221717\tbestTest: 0.221717 (12)\ttotal: 1m 41s\tremaining: 11m 22s\n",
      "13: learn: 0.2219069\ttest: 0.2214319\tbestTest: 0.2214319 (13)\ttotal: 1m 50s\tremaining: 11m 16s\n",
      "14: learn: 0.2216494\ttest: 0.2212111\tbestTest: 0.2212111 (14)\ttotal: 1m 57s\tremaining: 11m 8s\n",
      "15: learn: 0.2215249\ttest: 0.221095\tbestTest: 0.221095 (15)\ttotal: 2m 6s\tremaining: 11m 3s\n",
      "16: learn: 0.2214021\ttest: 0.2209835\tbestTest: 0.2209835 (16)\ttotal: 2m 14s\tremaining: 10m 54s\n",
      "17: learn: 0.2210918\ttest: 0.2207004\tbestTest: 0.2207004 (17)\ttotal: 2m 21s\tremaining: 10m 45s\n",
      "18: learn: 0.2209045\ttest: 0.2205625\tbestTest: 0.2205625 (18)\ttotal: 2m 29s\tremaining: 10m 36s\n",
      "19: learn: 0.2207356\ttest: 0.2204409\tbestTest: 0.2204409 (19)\ttotal: 2m 36s\tremaining: 10m 27s\n",
      "20: learn: 0.2205675\ttest: 0.2203085\tbestTest: 0.2203085 (20)\ttotal: 2m 44s\tremaining: 10m 19s\n",
      "21: learn: 0.2204353\ttest: 0.220198\tbestTest: 0.220198 (21)\ttotal: 2m 52s\tremaining: 10m 12s\n",
      "22: learn: 0.2204045\ttest: 0.220168\tbestTest: 0.220168 (22)\ttotal: 2m 57s\tremaining: 9m 53s\n",
      "23: learn: 0.2202732\ttest: 0.2200563\tbestTest: 0.2200563 (23)\ttotal: 3m 6s\tremaining: 9m 50s\n",
      "24: learn: 0.2202173\ttest: 0.2200083\tbestTest: 0.2200083 (24)\ttotal: 3m 13s\tremaining: 9m 40s\n",
      "25: learn: 0.2201673\ttest: 0.2199727\tbestTest: 0.2199727 (25)\ttotal: 3m 22s\tremaining: 9m 35s\n",
      "26: learn: 0.2200896\ttest: 0.2199239\tbestTest: 0.2199239 (26)\ttotal: 3m 30s\tremaining: 9m 30s\n",
      "27: learn: 0.2199491\ttest: 0.2198322\tbestTest: 0.2198322 (27)\ttotal: 3m 39s\tremaining: 9m 23s\n",
      "28: learn: 0.2198501\ttest: 0.2197618\tbestTest: 0.2197618 (28)\ttotal: 3m 47s\tremaining: 9m 16s\n",
      "29: learn: 0.2197665\ttest: 0.2196976\tbestTest: 0.2196976 (29)\ttotal: 3m 56s\tremaining: 9m 11s\n",
      "30: learn: 0.2196978\ttest: 0.2196571\tbestTest: 0.2196571 (30)\ttotal: 4m 5s\tremaining: 9m 5s\n",
      "31: learn: 0.2196196\ttest: 0.2196129\tbestTest: 0.2196129 (31)\ttotal: 4m 13s\tremaining: 8m 58s\n",
      "32: learn: 0.219568\ttest: 0.2195759\tbestTest: 0.2195759 (32)\ttotal: 4m 21s\tremaining: 8m 50s\n",
      "33: learn: 0.2195179\ttest: 0.2195357\tbestTest: 0.2195357 (33)\ttotal: 4m 29s\tremaining: 8m 43s\n",
      "34: learn: 0.2194923\ttest: 0.2195156\tbestTest: 0.2195156 (34)\ttotal: 4m 38s\tremaining: 8m 36s\n",
      "35: learn: 0.2194015\ttest: 0.2194488\tbestTest: 0.2194488 (35)\ttotal: 4m 46s\tremaining: 8m 29s\n",
      "36: learn: 0.2193409\ttest: 0.2194068\tbestTest: 0.2194068 (36)\ttotal: 4m 55s\tremaining: 8m 22s\n",
      "37: learn: 0.2193102\ttest: 0.2193839\tbestTest: 0.2193839 (37)\ttotal: 5m 1s\tremaining: 8m 12s\n",
      "38: learn: 0.2192753\ttest: 0.2193556\tbestTest: 0.2193556 (38)\ttotal: 5m 8s\tremaining: 8m 2s\n",
      "39: learn: 0.2192187\ttest: 0.2193134\tbestTest: 0.2193134 (39)\ttotal: 5m 16s\tremaining: 7m 55s\n",
      "40: learn: 0.2191652\ttest: 0.2192892\tbestTest: 0.2192892 (40)\ttotal: 5m 24s\tremaining: 7m 47s\n",
      "41: learn: 0.219083\ttest: 0.2192441\tbestTest: 0.2192441 (41)\ttotal: 5m 33s\tremaining: 7m 39s\n",
      "42: learn: 0.2190621\ttest: 0.2192274\tbestTest: 0.2192274 (42)\ttotal: 5m 41s\tremaining: 7m 32s\n",
      "43: learn: 0.2190442\ttest: 0.2192153\tbestTest: 0.2192153 (43)\ttotal: 5m 46s\tremaining: 7m 21s\n",
      "44: learn: 0.2190191\ttest: 0.2191965\tbestTest: 0.2191965 (44)\ttotal: 5m 54s\tremaining: 7m 13s\n",
      "45: learn: 0.2189886\ttest: 0.2191801\tbestTest: 0.2191801 (45)\ttotal: 6m 2s\tremaining: 7m 5s\n",
      "46: learn: 0.2189337\ttest: 0.2191631\tbestTest: 0.2191631 (46)\ttotal: 6m 9s\tremaining: 6m 57s\n",
      "47: learn: 0.2188802\ttest: 0.2191221\tbestTest: 0.2191221 (47)\ttotal: 6m 18s\tremaining: 6m 49s\n",
      "48: learn: 0.2188473\ttest: 0.219089\tbestTest: 0.219089 (48)\ttotal: 6m 25s\tremaining: 6m 40s\n",
      "49: learn: 0.2187937\ttest: 0.2190572\tbestTest: 0.2190572 (49)\ttotal: 6m 32s\tremaining: 6m 32s\n",
      "50: learn: 0.2187487\ttest: 0.2190328\tbestTest: 0.2190328 (50)\ttotal: 6m 40s\tremaining: 6m 24s\n",
      "51: learn: 0.2187432\ttest: 0.2190274\tbestTest: 0.2190274 (51)\ttotal: 6m 46s\tremaining: 6m 15s\n",
      "52: learn: 0.2186832\ttest: 0.2189899\tbestTest: 0.2189899 (52)\ttotal: 6m 54s\tremaining: 6m 7s\n",
      "53: learn: 0.2186358\ttest: 0.2189574\tbestTest: 0.2189574 (53)\ttotal: 7m 2s\tremaining: 5m 59s\n",
      "54: learn: 0.2185983\ttest: 0.2189457\tbestTest: 0.2189457 (54)\ttotal: 7m 10s\tremaining: 5m 52s\n",
      "55: learn: 0.2185288\ttest: 0.2189166\tbestTest: 0.2189166 (55)\ttotal: 7m 18s\tremaining: 5m 44s\n",
      "56: learn: 0.2184472\ttest: 0.2188704\tbestTest: 0.2188704 (56)\ttotal: 7m 26s\tremaining: 5m 36s\n",
      "57: learn: 0.2183954\ttest: 0.2188535\tbestTest: 0.2188535 (57)\ttotal: 7m 34s\tremaining: 5m 29s\n",
      "58: learn: 0.2183375\ttest: 0.2188349\tbestTest: 0.2188349 (58)\ttotal: 7m 43s\tremaining: 5m 21s\n",
      "59: learn: 0.2183013\ttest: 0.2188246\tbestTest: 0.2188246 (59)\ttotal: 7m 50s\tremaining: 5m 13s\n",
      "60: learn: 0.2182395\ttest: 0.2188228\tbestTest: 0.2188228 (60)\ttotal: 7m 58s\tremaining: 5m 6s\n",
      "61: learn: 0.2181822\ttest: 0.2188205\tbestTest: 0.2188205 (61)\ttotal: 8m 6s\tremaining: 4m 58s\n",
      "62: learn: 0.2181536\ttest: 0.2188083\tbestTest: 0.2188083 (62)\ttotal: 8m 15s\tremaining: 4m 50s\n",
      "63: learn: 0.218135\ttest: 0.218801\tbestTest: 0.218801 (63)\ttotal: 8m 23s\tremaining: 4m 43s\n",
      "64: learn: 0.2180913\ttest: 0.2187734\tbestTest: 0.2187734 (64)\ttotal: 8m 32s\tremaining: 4m 36s\n",
      "65: learn: 0.2180672\ttest: 0.2187624\tbestTest: 0.2187624 (65)\ttotal: 8m 42s\tremaining: 4m 28s\n",
      "66: learn: 0.2180574\ttest: 0.2187546\tbestTest: 0.2187546 (66)\ttotal: 8m 51s\tremaining: 4m 21s\n",
      "67: learn: 0.2180116\ttest: 0.2187202\tbestTest: 0.2187202 (67)\ttotal: 8m 59s\tremaining: 4m 13s\n",
      "68: learn: 0.2179341\ttest: 0.2186876\tbestTest: 0.2186876 (68)\ttotal: 9m 6s\tremaining: 4m 5s\n",
      "69: learn: 0.2178756\ttest: 0.2186532\tbestTest: 0.2186532 (69)\ttotal: 9m 14s\tremaining: 3m 57s\n",
      "70: learn: 0.217792\ttest: 0.2186477\tbestTest: 0.2186477 (70)\ttotal: 9m 21s\tremaining: 3m 49s\n",
      "71: learn: 0.2177485\ttest: 0.2186302\tbestTest: 0.2186302 (71)\ttotal: 9m 29s\tremaining: 3m 41s\n",
      "72: learn: 0.2177018\ttest: 0.2186132\tbestTest: 0.2186132 (72)\ttotal: 9m 37s\tremaining: 3m 33s\n",
      "73: learn: 0.2176777\ttest: 0.2186043\tbestTest: 0.2186043 (73)\ttotal: 9m 45s\tremaining: 3m 25s\n",
      "74: learn: 0.2176409\ttest: 0.2185977\tbestTest: 0.2185977 (74)\ttotal: 9m 52s\tremaining: 3m 17s\n",
      "75: learn: 0.2175661\ttest: 0.2185477\tbestTest: 0.2185477 (75)\ttotal: 9m 59s\tremaining: 3m 9s\n",
      "76: learn: 0.2175151\ttest: 0.218537\tbestTest: 0.218537 (76)\ttotal: 10m 7s\tremaining: 3m 1s\n",
      "77: learn: 0.2174764\ttest: 0.2185242\tbestTest: 0.2185242 (77)\ttotal: 10m 15s\tremaining: 2m 53s\n",
      "78: learn: 0.2174431\ttest: 0.2185159\tbestTest: 0.2185159 (78)\ttotal: 10m 23s\tremaining: 2m 45s\n",
      "79: learn: 0.2174426\ttest: 0.2185161\tbestTest: 0.2185159 (78)\ttotal: 10m 33s\tremaining: 2m 38s\n",
      "80: learn: 0.2173878\ttest: 0.2184989\tbestTest: 0.2184989 (80)\ttotal: 10m 41s\tremaining: 2m 30s\n",
      "81: learn: 0.2173592\ttest: 0.2184868\tbestTest: 0.2184868 (81)\ttotal: 10m 50s\tremaining: 2m 22s\n",
      "82: learn: 0.2172972\ttest: 0.2184434\tbestTest: 0.2184434 (82)\ttotal: 10m 57s\tremaining: 2m 14s\n",
      "83: learn: 0.2172747\ttest: 0.2184302\tbestTest: 0.2184302 (83)\ttotal: 11m 5s\tremaining: 2m 6s\n",
      "84: learn: 0.2172653\ttest: 0.2184242\tbestTest: 0.2184242 (84)\ttotal: 11m 14s\tremaining: 1m 58s\n",
      "85: learn: 0.217213\ttest: 0.2184216\tbestTest: 0.2184216 (85)\ttotal: 11m 22s\tremaining: 1m 51s\n",
      "86: learn: 0.2171861\ttest: 0.2184142\tbestTest: 0.2184142 (86)\ttotal: 11m 30s\tremaining: 1m 43s\n",
      "87: learn: 0.2171501\ttest: 0.2183991\tbestTest: 0.2183991 (87)\ttotal: 11m 39s\tremaining: 1m 35s\n",
      "88: learn: 0.2171015\ttest: 0.21839\tbestTest: 0.21839 (88)\ttotal: 11m 47s\tremaining: 1m 27s\n",
      "89: learn: 0.2170621\ttest: 0.2183906\tbestTest: 0.21839 (88)\ttotal: 11m 55s\tremaining: 1m 19s\n",
      "90: learn: 0.2170552\ttest: 0.2183857\tbestTest: 0.2183857 (90)\ttotal: 12m 4s\tremaining: 1m 11s\n",
      "91: learn: 0.2170542\ttest: 0.2183856\tbestTest: 0.2183856 (91)\ttotal: 12m 14s\tremaining: 1m 3s\n",
      "92: learn: 0.2170444\ttest: 0.2183815\tbestTest: 0.2183815 (92)\ttotal: 12m 23s\tremaining: 55.9s\n",
      "93: learn: 0.2170191\ttest: 0.2183687\tbestTest: 0.2183687 (93)\ttotal: 12m 31s\tremaining: 48s\n",
      "94: learn: 0.2170188\ttest: 0.2183687\tbestTest: 0.2183687 (94)\ttotal: 12m 41s\tremaining: 40.1s\n",
      "95: learn: 0.2169518\ttest: 0.2183391\tbestTest: 0.2183391 (95)\ttotal: 12m 50s\tremaining: 32.1s\n",
      "96: learn: 0.2169172\ttest: 0.2183282\tbestTest: 0.2183282 (96)\ttotal: 12m 58s\tremaining: 24.1s\n",
      "97: learn: 0.2168789\ttest: 0.2183161\tbestTest: 0.2183161 (97)\ttotal: 13m 7s\tremaining: 16.1s\n",
      "98: learn: 0.2168444\ttest: 0.2183131\tbestTest: 0.2183131 (98)\ttotal: 13m 15s\tremaining: 8.03s\n",
      "99: learn: 0.2168142\ttest: 0.2183126\tbestTest: 0.2183126 (99)\ttotal: 13m 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2183125504\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_0.5\n",
      "2018-03-15 03:13:28.816482\n",
      "train time given below\n",
      "0:16:58.377907\n",
      "2018-03-15 03:13:28.866791\n",
      "2018-03-15 03:13:28.870371\n",
      "GINI ISIT = 0.514458853875\n",
      "2018-03-15 03:15:05.355301\n",
      "GINI OSIT = 0.50147743724\n",
      "2018-03-15 03:15:47.097461\n",
      "GINI OSOT = 0.430488461464\n",
      "2018-03-15 03:15:59.310140\n",
      "2018-03-15 03:15:59.312387\n",
      "loop run time\n",
      "0:19:28.874026\n",
      "bagging temperature = 1\n",
      "2018-03-15 03:15:59.313985\n",
      "model train start\n",
      "2018-03-15 03:15:59.314261\n",
      "0: learn: 0.4126743\ttest: 0.4124469\tbestTest: 0.4124469 (0)\ttotal: 6.06s\tremaining: 9m 59s\n",
      "1: learn: 0.3024897\ttest: 0.3021123\tbestTest: 0.3021123 (1)\ttotal: 13.6s\tremaining: 11m 7s\n",
      "2: learn: 0.2605809\ttest: 0.2600461\tbestTest: 0.2600461 (2)\ttotal: 22s\tremaining: 11m 50s\n",
      "3: learn: 0.241641\ttest: 0.2410223\tbestTest: 0.2410223 (3)\ttotal: 29.4s\tremaining: 11m 44s\n",
      "4: learn: 0.2332284\ttest: 0.2325811\tbestTest: 0.2325811 (4)\ttotal: 38.1s\tremaining: 12m 4s\n",
      "5: learn: 0.2288889\ttest: 0.228194\tbestTest: 0.228194 (5)\ttotal: 47s\tremaining: 12m 17s\n",
      "6: learn: 0.2264316\ttest: 0.2257552\tbestTest: 0.2257552 (6)\ttotal: 55.8s\tremaining: 12m 20s\n",
      "7: learn: 0.2249431\ttest: 0.2242616\tbestTest: 0.2242616 (7)\ttotal: 1m 3s\tremaining: 12m 11s\n",
      "8: learn: 0.2239689\ttest: 0.2233148\tbestTest: 0.2233148 (8)\ttotal: 1m 11s\tremaining: 12m\n",
      "9: learn: 0.2234166\ttest: 0.2227748\tbestTest: 0.2227748 (9)\ttotal: 1m 19s\tremaining: 11m 52s\n",
      "10: learn: 0.2229457\ttest: 0.2223465\tbestTest: 0.2223465 (10)\ttotal: 1m 27s\tremaining: 11m 48s\n",
      "11: learn: 0.2225577\ttest: 0.221989\tbestTest: 0.221989 (11)\ttotal: 1m 35s\tremaining: 11m 42s\n",
      "12: learn: 0.2221995\ttest: 0.2216708\tbestTest: 0.2216708 (12)\ttotal: 1m 43s\tremaining: 11m 32s\n",
      "13: learn: 0.2218089\ttest: 0.2213272\tbestTest: 0.2213272 (13)\ttotal: 1m 51s\tremaining: 11m 23s\n",
      "14: learn: 0.2215306\ttest: 0.2211088\tbestTest: 0.2211088 (14)\ttotal: 1m 59s\tremaining: 11m 16s\n",
      "15: learn: 0.2213527\ttest: 0.2209414\tbestTest: 0.2209414 (15)\ttotal: 2m 7s\tremaining: 11m 7s\n",
      "16: learn: 0.2212163\ttest: 0.2208199\tbestTest: 0.2208199 (16)\ttotal: 2m 15s\tremaining: 11m\n",
      "17: learn: 0.2210791\ttest: 0.2207036\tbestTest: 0.2207036 (17)\ttotal: 2m 23s\tremaining: 10m 55s\n",
      "18: learn: 0.2208972\ttest: 0.2205724\tbestTest: 0.2205724 (18)\ttotal: 2m 32s\tremaining: 10m 48s\n",
      "19: learn: 0.220764\ttest: 0.2204771\tbestTest: 0.2204771 (19)\ttotal: 2m 39s\tremaining: 10m 39s\n",
      "20: learn: 0.2206623\ttest: 0.2204004\tbestTest: 0.2204004 (20)\ttotal: 2m 48s\tremaining: 10m 32s\n",
      "21: learn: 0.2205627\ttest: 0.2203258\tbestTest: 0.2203258 (21)\ttotal: 2m 56s\tremaining: 10m 24s\n",
      "22: learn: 0.2204942\ttest: 0.2202713\tbestTest: 0.2202713 (22)\ttotal: 3m 2s\tremaining: 10m 11s\n",
      "23: learn: 0.2203778\ttest: 0.2201893\tbestTest: 0.2201893 (23)\ttotal: 3m 11s\tremaining: 10m 4s\n",
      "24: learn: 0.2202029\ttest: 0.2200488\tbestTest: 0.2200488 (24)\ttotal: 3m 18s\tremaining: 9m 55s\n",
      "25: learn: 0.2201203\ttest: 0.2199869\tbestTest: 0.2199869 (25)\ttotal: 3m 26s\tremaining: 9m 46s\n",
      "26: learn: 0.2200525\ttest: 0.2199308\tbestTest: 0.2199308 (26)\ttotal: 3m 34s\tremaining: 9m 39s\n",
      "27: learn: 0.2200153\ttest: 0.2198986\tbestTest: 0.2198986 (27)\ttotal: 3m 39s\tremaining: 9m 25s\n",
      "28: learn: 0.219879\ttest: 0.2197956\tbestTest: 0.2197956 (28)\ttotal: 3m 47s\tremaining: 9m 17s\n",
      "29: learn: 0.2197394\ttest: 0.2197129\tbestTest: 0.2197129 (29)\ttotal: 3m 55s\tremaining: 9m 8s\n",
      "30: learn: 0.2196849\ttest: 0.219676\tbestTest: 0.219676 (30)\ttotal: 4m 3s\tremaining: 9m 1s\n",
      "31: learn: 0.2195991\ttest: 0.2196128\tbestTest: 0.2196128 (31)\ttotal: 4m 11s\tremaining: 8m 55s\n",
      "32: learn: 0.2195439\ttest: 0.2195765\tbestTest: 0.2195765 (32)\ttotal: 4m 19s\tremaining: 8m 46s\n",
      "33: learn: 0.2194865\ttest: 0.2195509\tbestTest: 0.2195509 (33)\ttotal: 4m 27s\tremaining: 8m 39s\n",
      "34: learn: 0.2194101\ttest: 0.2194912\tbestTest: 0.2194912 (34)\ttotal: 4m 35s\tremaining: 8m 31s\n",
      "35: learn: 0.2193451\ttest: 0.2194609\tbestTest: 0.2194609 (35)\ttotal: 4m 43s\tremaining: 8m 23s\n",
      "36: learn: 0.219284\ttest: 0.2194381\tbestTest: 0.2194381 (36)\ttotal: 4m 51s\tremaining: 8m 16s\n",
      "37: learn: 0.2192154\ttest: 0.2193811\tbestTest: 0.2193811 (37)\ttotal: 4m 59s\tremaining: 8m 8s\n",
      "38: learn: 0.2191824\ttest: 0.2193636\tbestTest: 0.2193636 (38)\ttotal: 5m 7s\tremaining: 8m\n",
      "39: learn: 0.2191301\ttest: 0.2193297\tbestTest: 0.2193297 (39)\ttotal: 5m 14s\tremaining: 7m 52s\n",
      "40: learn: 0.219083\ttest: 0.2193104\tbestTest: 0.2193104 (40)\ttotal: 5m 23s\tremaining: 7m 45s\n",
      "41: learn: 0.2190201\ttest: 0.2192594\tbestTest: 0.2192594 (41)\ttotal: 5m 32s\tremaining: 7m 38s\n",
      "42: learn: 0.2189492\ttest: 0.2192169\tbestTest: 0.2192169 (42)\ttotal: 5m 39s\tremaining: 7m 30s\n",
      "43: learn: 0.218929\ttest: 0.2192011\tbestTest: 0.2192011 (43)\ttotal: 5m 45s\tremaining: 7m 19s\n",
      "44: learn: 0.2188718\ttest: 0.2191701\tbestTest: 0.2191701 (44)\ttotal: 5m 54s\tremaining: 7m 13s\n",
      "45: learn: 0.2187982\ttest: 0.2191119\tbestTest: 0.2191119 (45)\ttotal: 6m 1s\tremaining: 7m 4s\n",
      "46: learn: 0.2187179\ttest: 0.2190687\tbestTest: 0.2190687 (46)\ttotal: 6m 9s\tremaining: 6m 56s\n",
      "47: learn: 0.218651\ttest: 0.2190484\tbestTest: 0.2190484 (47)\ttotal: 6m 17s\tremaining: 6m 49s\n",
      "48: learn: 0.218592\ttest: 0.2190183\tbestTest: 0.2190183 (48)\ttotal: 6m 26s\tremaining: 6m 42s\n",
      "49: learn: 0.2185039\ttest: 0.2189979\tbestTest: 0.2189979 (49)\ttotal: 6m 34s\tremaining: 6m 34s\n",
      "50: learn: 0.2184629\ttest: 0.2189772\tbestTest: 0.2189772 (50)\ttotal: 6m 42s\tremaining: 6m 26s\n",
      "51: learn: 0.2184074\ttest: 0.2189594\tbestTest: 0.2189594 (51)\ttotal: 6m 50s\tremaining: 6m 18s\n",
      "52: learn: 0.2183818\ttest: 0.2189498\tbestTest: 0.2189498 (52)\ttotal: 6m 58s\tremaining: 6m 11s\n",
      "53: learn: 0.2182989\ttest: 0.2188998\tbestTest: 0.2188998 (53)\ttotal: 7m 6s\tremaining: 6m 3s\n",
      "54: learn: 0.2182207\ttest: 0.2188578\tbestTest: 0.2188578 (54)\ttotal: 7m 14s\tremaining: 5m 55s\n",
      "55: learn: 0.2181698\ttest: 0.2188431\tbestTest: 0.2188431 (55)\ttotal: 7m 22s\tremaining: 5m 47s\n",
      "56: learn: 0.2181172\ttest: 0.2188219\tbestTest: 0.2188219 (56)\ttotal: 7m 30s\tremaining: 5m 39s\n",
      "57: learn: 0.2180862\ttest: 0.2188105\tbestTest: 0.2188105 (57)\ttotal: 7m 39s\tremaining: 5m 32s\n",
      "58: learn: 0.2180416\ttest: 0.2187801\tbestTest: 0.2187801 (58)\ttotal: 7m 47s\tremaining: 5m 24s\n",
      "59: learn: 0.2179786\ttest: 0.2187409\tbestTest: 0.2187409 (59)\ttotal: 7m 55s\tremaining: 5m 17s\n",
      "60: learn: 0.2179017\ttest: 0.2187241\tbestTest: 0.2187241 (60)\ttotal: 8m 2s\tremaining: 5m 8s\n",
      "61: learn: 0.2178468\ttest: 0.218699\tbestTest: 0.218699 (61)\ttotal: 8m 10s\tremaining: 5m\n",
      "62: learn: 0.2178155\ttest: 0.2186784\tbestTest: 0.2186784 (62)\ttotal: 8m 18s\tremaining: 4m 52s\n",
      "63: learn: 0.2177778\ttest: 0.2186624\tbestTest: 0.2186624 (63)\ttotal: 8m 26s\tremaining: 4m 44s\n",
      "64: learn: 0.2177191\ttest: 0.2186467\tbestTest: 0.2186467 (64)\ttotal: 8m 33s\tremaining: 4m 36s\n",
      "65: learn: 0.2177035\ttest: 0.2186434\tbestTest: 0.2186434 (65)\ttotal: 8m 41s\tremaining: 4m 28s\n",
      "66: learn: 0.2176875\ttest: 0.2186374\tbestTest: 0.2186374 (66)\ttotal: 8m 50s\tremaining: 4m 21s\n",
      "67: learn: 0.2176352\ttest: 0.2186265\tbestTest: 0.2186265 (67)\ttotal: 8m 58s\tremaining: 4m 13s\n",
      "68: learn: 0.2176049\ttest: 0.2186229\tbestTest: 0.2186229 (68)\ttotal: 9m 6s\tremaining: 4m 5s\n",
      "69: learn: 0.2175645\ttest: 0.218607\tbestTest: 0.218607 (69)\ttotal: 9m 14s\tremaining: 3m 57s\n",
      "70: learn: 0.2175325\ttest: 0.2185974\tbestTest: 0.2185974 (70)\ttotal: 9m 22s\tremaining: 3m 49s\n",
      "71: learn: 0.2174949\ttest: 0.2185888\tbestTest: 0.2185888 (71)\ttotal: 9m 30s\tremaining: 3m 41s\n",
      "72: learn: 0.2174494\ttest: 0.2185585\tbestTest: 0.2185585 (72)\ttotal: 9m 38s\tremaining: 3m 34s\n",
      "73: learn: 0.2174286\ttest: 0.2185479\tbestTest: 0.2185479 (73)\ttotal: 9m 48s\tremaining: 3m 26s\n",
      "74: learn: 0.2173795\ttest: 0.2185444\tbestTest: 0.2185444 (74)\ttotal: 9m 56s\tremaining: 3m 18s\n",
      "75: learn: 0.2173229\ttest: 0.2185457\tbestTest: 0.2185444 (74)\ttotal: 10m 4s\tremaining: 3m 10s\n",
      "76: learn: 0.2172999\ttest: 0.2185372\tbestTest: 0.2185372 (76)\ttotal: 10m 12s\tremaining: 3m 3s\n",
      "77: learn: 0.2172829\ttest: 0.218533\tbestTest: 0.218533 (77)\ttotal: 10m 20s\tremaining: 2m 55s\n",
      "78: learn: 0.2172243\ttest: 0.2185343\tbestTest: 0.218533 (77)\ttotal: 10m 29s\tremaining: 2m 47s\n",
      "79: learn: 0.2171841\ttest: 0.2185261\tbestTest: 0.2185261 (79)\ttotal: 10m 37s\tremaining: 2m 39s\n",
      "80: learn: 0.2171737\ttest: 0.2185234\tbestTest: 0.2185234 (80)\ttotal: 10m 47s\tremaining: 2m 31s\n",
      "81: learn: 0.2171403\ttest: 0.218525\tbestTest: 0.2185234 (80)\ttotal: 10m 55s\tremaining: 2m 23s\n",
      "82: learn: 0.2171394\ttest: 0.2185248\tbestTest: 0.2185234 (80)\ttotal: 11m 5s\tremaining: 2m 16s\n",
      "83: learn: 0.2170922\ttest: 0.218524\tbestTest: 0.2185234 (80)\ttotal: 11m 14s\tremaining: 2m 8s\n",
      "84: learn: 0.2170648\ttest: 0.2185123\tbestTest: 0.2185123 (84)\ttotal: 11m 23s\tremaining: 2m\n",
      "85: learn: 0.2170347\ttest: 0.2185088\tbestTest: 0.2185088 (85)\ttotal: 11m 31s\tremaining: 1m 52s\n",
      "86: learn: 0.2170079\ttest: 0.2185083\tbestTest: 0.2185083 (86)\ttotal: 11m 39s\tremaining: 1m 44s\n",
      "87: learn: 0.2169467\ttest: 0.2185076\tbestTest: 0.2185076 (87)\ttotal: 11m 46s\tremaining: 1m 36s\n",
      "88: learn: 0.216918\ttest: 0.218509\tbestTest: 0.2185076 (87)\ttotal: 11m 54s\tremaining: 1m 28s\n",
      "89: learn: 0.2168329\ttest: 0.2185045\tbestTest: 0.2185045 (89)\ttotal: 12m 1s\tremaining: 1m 20s\n",
      "90: learn: 0.2167967\ttest: 0.2185031\tbestTest: 0.2185031 (90)\ttotal: 12m 9s\tremaining: 1m 12s\n",
      "91: learn: 0.2167427\ttest: 0.21849\tbestTest: 0.21849 (91)\ttotal: 12m 17s\tremaining: 1m 4s\n",
      "92: learn: 0.2166951\ttest: 0.2184872\tbestTest: 0.2184872 (92)\ttotal: 12m 25s\tremaining: 56.1s\n",
      "93: learn: 0.216652\ttest: 0.2184915\tbestTest: 0.2184872 (92)\ttotal: 12m 33s\tremaining: 48.1s\n",
      "94: learn: 0.2166129\ttest: 0.218481\tbestTest: 0.218481 (94)\ttotal: 12m 41s\tremaining: 40.1s\n",
      "95: learn: 0.2165625\ttest: 0.2184758\tbestTest: 0.2184758 (95)\ttotal: 12m 49s\tremaining: 32.1s\n",
      "96: learn: 0.2165178\ttest: 0.2184682\tbestTest: 0.2184682 (96)\ttotal: 12m 57s\tremaining: 24.1s\n",
      "97: learn: 0.2164721\ttest: 0.2184599\tbestTest: 0.2184599 (97)\ttotal: 13m 5s\tremaining: 16s\n",
      "98: learn: 0.2164438\ttest: 0.2184499\tbestTest: 0.2184499 (98)\ttotal: 13m 13s\tremaining: 8.01s\n",
      "99: learn: 0.2163877\ttest: 0.2184478\tbestTest: 0.2184478 (99)\ttotal: 13m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2184477764\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_1\n",
      "2018-03-15 03:32:50.640026\n",
      "train time given below\n",
      "0:16:51.325765\n",
      "2018-03-15 03:32:50.801936\n",
      "2018-03-15 03:32:50.805853\n",
      "GINI ISIT = 0.516769885861\n",
      "2018-03-15 03:34:27.784395\n",
      "GINI OSIT = 0.500367852\n",
      "2018-03-15 03:35:08.456143\n",
      "GINI OSOT = 0.429061950528\n",
      "2018-03-15 03:35:20.955404\n",
      "2018-03-15 03:35:20.957436\n",
      "loop run time\n",
      "0:19:21.643448\n",
      "bagging temperature = 2\n",
      "2018-03-15 03:35:20.959026\n",
      "model train start\n",
      "2018-03-15 03:35:20.959288\n",
      "0: learn: 0.4118032\ttest: 0.4116412\tbestTest: 0.4116412 (0)\ttotal: 8.88s\tremaining: 14m 38s\n",
      "1: learn: 0.3017421\ttest: 0.3013805\tbestTest: 0.3013805 (1)\ttotal: 17.2s\tremaining: 14m 2s\n",
      "2: learn: 0.2590787\ttest: 0.2585773\tbestTest: 0.2585773 (2)\ttotal: 26.3s\tremaining: 14m 9s\n",
      "3: learn: 0.2412294\ttest: 0.2406821\tbestTest: 0.2406821 (3)\ttotal: 34.9s\tremaining: 13m 56s\n",
      "4: learn: 0.2328082\ttest: 0.2322464\tbestTest: 0.2322464 (4)\ttotal: 43s\tremaining: 13m 36s\n",
      "5: learn: 0.2284855\ttest: 0.2279113\tbestTest: 0.2279113 (5)\ttotal: 51.1s\tremaining: 13m 19s\n",
      "6: learn: 0.2262516\ttest: 0.2256642\tbestTest: 0.2256642 (6)\ttotal: 59.3s\tremaining: 13m 8s\n",
      "7: learn: 0.2249018\ttest: 0.2243298\tbestTest: 0.2243298 (7)\ttotal: 1m 7s\tremaining: 12m 56s\n",
      "8: learn: 0.224017\ttest: 0.2234625\tbestTest: 0.2234625 (8)\ttotal: 1m 15s\tremaining: 12m 48s\n",
      "9: learn: 0.2233503\ttest: 0.2228271\tbestTest: 0.2228271 (9)\ttotal: 1m 23s\tremaining: 12m 31s\n",
      "10: learn: 0.2227952\ttest: 0.2223078\tbestTest: 0.2223078 (10)\ttotal: 1m 31s\tremaining: 12m 21s\n",
      "11: learn: 0.2224164\ttest: 0.2219398\tbestTest: 0.2219398 (11)\ttotal: 1m 39s\tremaining: 12m 6s\n",
      "12: learn: 0.2220724\ttest: 0.2216623\tbestTest: 0.2216623 (12)\ttotal: 1m 47s\tremaining: 11m 57s\n",
      "13: learn: 0.2218723\ttest: 0.2214986\tbestTest: 0.2214986 (13)\ttotal: 1m 55s\tremaining: 11m 50s\n",
      "14: learn: 0.2216693\ttest: 0.2213174\tbestTest: 0.2213174 (14)\ttotal: 2m 4s\tremaining: 11m 43s\n",
      "15: learn: 0.2214513\ttest: 0.2211398\tbestTest: 0.2211398 (15)\ttotal: 2m 12s\tremaining: 11m 37s\n",
      "16: learn: 0.221212\ttest: 0.2209194\tbestTest: 0.2209194 (16)\ttotal: 2m 20s\tremaining: 11m 27s\n",
      "17: learn: 0.2210806\ttest: 0.2208251\tbestTest: 0.2208251 (17)\ttotal: 2m 28s\tremaining: 11m 14s\n",
      "18: learn: 0.2209293\ttest: 0.2207187\tbestTest: 0.2207187 (18)\ttotal: 2m 36s\tremaining: 11m 5s\n",
      "19: learn: 0.2207455\ttest: 0.2205883\tbestTest: 0.2205883 (19)\ttotal: 2m 44s\tremaining: 10m 58s\n",
      "20: learn: 0.2205819\ttest: 0.2204549\tbestTest: 0.2204549 (20)\ttotal: 2m 52s\tremaining: 10m 50s\n",
      "21: learn: 0.2204874\ttest: 0.2203984\tbestTest: 0.2203984 (21)\ttotal: 3m\tremaining: 10m 38s\n",
      "22: learn: 0.2203204\ttest: 0.2202743\tbestTest: 0.2202743 (22)\ttotal: 3m 8s\tremaining: 10m 32s\n",
      "23: learn: 0.2201541\ttest: 0.2201536\tbestTest: 0.2201536 (23)\ttotal: 3m 17s\tremaining: 10m 26s\n",
      "24: learn: 0.220088\ttest: 0.2201202\tbestTest: 0.2201202 (24)\ttotal: 3m 26s\tremaining: 10m 18s\n",
      "25: learn: 0.219986\ttest: 0.2200437\tbestTest: 0.2200437 (25)\ttotal: 3m 35s\tremaining: 10m 12s\n",
      "26: learn: 0.2198839\ttest: 0.2199943\tbestTest: 0.2199943 (26)\ttotal: 3m 43s\tremaining: 10m 4s\n",
      "27: learn: 0.2197745\ttest: 0.2199506\tbestTest: 0.2199506 (27)\ttotal: 3m 52s\tremaining: 9m 57s\n",
      "28: learn: 0.2196784\ttest: 0.2198893\tbestTest: 0.2198893 (28)\ttotal: 4m\tremaining: 9m 47s\n",
      "29: learn: 0.2195996\ttest: 0.2198502\tbestTest: 0.2198502 (29)\ttotal: 4m 9s\tremaining: 9m 41s\n",
      "30: learn: 0.2194938\ttest: 0.2197667\tbestTest: 0.2197667 (30)\ttotal: 4m 17s\tremaining: 9m 34s\n",
      "31: learn: 0.2193733\ttest: 0.2197251\tbestTest: 0.2197251 (31)\ttotal: 4m 25s\tremaining: 9m 23s\n",
      "32: learn: 0.2192832\ttest: 0.2196795\tbestTest: 0.2196795 (32)\ttotal: 4m 32s\tremaining: 9m 13s\n",
      "33: learn: 0.2192371\ttest: 0.2196539\tbestTest: 0.2196539 (33)\ttotal: 4m 40s\tremaining: 9m 4s\n",
      "34: learn: 0.2191687\ttest: 0.2196393\tbestTest: 0.2196393 (34)\ttotal: 4m 48s\tremaining: 8m 56s\n",
      "35: learn: 0.2190897\ttest: 0.219604\tbestTest: 0.219604 (35)\ttotal: 4m 56s\tremaining: 8m 47s\n",
      "36: learn: 0.2190565\ttest: 0.2195846\tbestTest: 0.2195846 (36)\ttotal: 5m 4s\tremaining: 8m 39s\n",
      "37: learn: 0.2189891\ttest: 0.2195706\tbestTest: 0.2195706 (37)\ttotal: 5m 12s\tremaining: 8m 30s\n",
      "38: learn: 0.218926\ttest: 0.219547\tbestTest: 0.219547 (38)\ttotal: 5m 21s\tremaining: 8m 22s\n",
      "39: learn: 0.2188107\ttest: 0.2194623\tbestTest: 0.2194623 (39)\ttotal: 5m 29s\tremaining: 8m 13s\n",
      "40: learn: 0.2187674\ttest: 0.2194463\tbestTest: 0.2194463 (40)\ttotal: 5m 37s\tremaining: 8m 5s\n",
      "41: learn: 0.2187094\ttest: 0.21943\tbestTest: 0.21943 (41)\ttotal: 5m 45s\tremaining: 7m 56s\n",
      "42: learn: 0.2186711\ttest: 0.2194096\tbestTest: 0.2194096 (42)\ttotal: 5m 53s\tremaining: 7m 48s\n",
      "43: learn: 0.2185961\ttest: 0.2193859\tbestTest: 0.2193859 (43)\ttotal: 6m 1s\tremaining: 7m 40s\n",
      "44: learn: 0.2185474\ttest: 0.2193727\tbestTest: 0.2193727 (44)\ttotal: 6m 9s\tremaining: 7m 31s\n",
      "45: learn: 0.2185082\ttest: 0.2193591\tbestTest: 0.2193591 (45)\ttotal: 6m 17s\tremaining: 7m 23s\n",
      "46: learn: 0.2184203\ttest: 0.2193225\tbestTest: 0.2193225 (46)\ttotal: 6m 25s\tremaining: 7m 15s\n",
      "47: learn: 0.2183414\ttest: 0.2192813\tbestTest: 0.2192813 (47)\ttotal: 6m 33s\tremaining: 7m 6s\n",
      "48: learn: 0.2182631\ttest: 0.219247\tbestTest: 0.219247 (48)\ttotal: 6m 41s\tremaining: 6m 57s\n",
      "49: learn: 0.2182024\ttest: 0.2192376\tbestTest: 0.2192376 (49)\ttotal: 6m 48s\tremaining: 6m 48s\n",
      "50: learn: 0.2181363\ttest: 0.219214\tbestTest: 0.219214 (50)\ttotal: 6m 57s\tremaining: 6m 41s\n",
      "51: learn: 0.2180802\ttest: 0.2191991\tbestTest: 0.2191991 (51)\ttotal: 7m 5s\tremaining: 6m 32s\n",
      "52: learn: 0.2180094\ttest: 0.2191851\tbestTest: 0.2191851 (52)\ttotal: 7m 13s\tremaining: 6m 24s\n",
      "53: learn: 0.2179452\ttest: 0.2191539\tbestTest: 0.2191539 (53)\ttotal: 7m 21s\tremaining: 6m 16s\n",
      "54: learn: 0.217892\ttest: 0.2191441\tbestTest: 0.2191441 (54)\ttotal: 7m 29s\tremaining: 6m 7s\n",
      "55: learn: 0.2178626\ttest: 0.2191402\tbestTest: 0.2191402 (55)\ttotal: 7m 37s\tremaining: 5m 59s\n",
      "56: learn: 0.217817\ttest: 0.2191341\tbestTest: 0.2191341 (56)\ttotal: 7m 45s\tremaining: 5m 51s\n",
      "57: learn: 0.2177871\ttest: 0.2191325\tbestTest: 0.2191325 (57)\ttotal: 7m 53s\tremaining: 5m 42s\n",
      "58: learn: 0.2177568\ttest: 0.2191252\tbestTest: 0.2191252 (58)\ttotal: 8m 2s\tremaining: 5m 35s\n",
      "59: learn: 0.21772\ttest: 0.2191265\tbestTest: 0.2191252 (58)\ttotal: 8m 10s\tremaining: 5m 27s\n",
      "60: learn: 0.2176405\ttest: 0.2191141\tbestTest: 0.2191141 (60)\ttotal: 8m 18s\tremaining: 5m 18s\n",
      "61: learn: 0.2176047\ttest: 0.219085\tbestTest: 0.219085 (61)\ttotal: 8m 27s\tremaining: 5m 11s\n",
      "62: learn: 0.2175571\ttest: 0.2190833\tbestTest: 0.2190833 (62)\ttotal: 8m 35s\tremaining: 5m 2s\n",
      "63: learn: 0.217508\ttest: 0.2190786\tbestTest: 0.2190786 (63)\ttotal: 8m 44s\tremaining: 4m 54s\n",
      "64: learn: 0.2174376\ttest: 0.2190407\tbestTest: 0.2190407 (64)\ttotal: 8m 51s\tremaining: 4m 46s\n",
      "65: learn: 0.2173801\ttest: 0.2190271\tbestTest: 0.2190271 (65)\ttotal: 8m 59s\tremaining: 4m 38s\n",
      "66: learn: 0.2173471\ttest: 0.2190151\tbestTest: 0.2190151 (66)\ttotal: 9m 7s\tremaining: 4m 29s\n",
      "67: learn: 0.2173095\ttest: 0.219017\tbestTest: 0.2190151 (66)\ttotal: 9m 16s\tremaining: 4m 21s\n",
      "68: learn: 0.2172733\ttest: 0.2190121\tbestTest: 0.2190121 (68)\ttotal: 9m 25s\tremaining: 4m 14s\n",
      "69: learn: 0.2172441\ttest: 0.2190026\tbestTest: 0.2190026 (69)\ttotal: 9m 35s\tremaining: 4m 6s\n",
      "70: learn: 0.2171864\ttest: 0.2189904\tbestTest: 0.2189904 (70)\ttotal: 9m 43s\tremaining: 3m 58s\n",
      "71: learn: 0.2171231\ttest: 0.2189609\tbestTest: 0.2189609 (71)\ttotal: 9m 51s\tremaining: 3m 49s\n",
      "72: learn: 0.2170884\ttest: 0.2189474\tbestTest: 0.2189474 (72)\ttotal: 9m 58s\tremaining: 3m 41s\n",
      "73: learn: 0.2170471\ttest: 0.2189425\tbestTest: 0.2189425 (73)\ttotal: 10m 6s\tremaining: 3m 33s\n",
      "74: learn: 0.2170204\ttest: 0.2189301\tbestTest: 0.2189301 (74)\ttotal: 10m 14s\tremaining: 3m 24s\n",
      "75: learn: 0.2169793\ttest: 0.2189295\tbestTest: 0.2189295 (75)\ttotal: 10m 22s\tremaining: 3m 16s\n",
      "76: learn: 0.2169457\ttest: 0.2189215\tbestTest: 0.2189215 (76)\ttotal: 10m 30s\tremaining: 3m 8s\n",
      "77: learn: 0.2169199\ttest: 0.2189129\tbestTest: 0.2189129 (77)\ttotal: 10m 39s\tremaining: 3m\n",
      "78: learn: 0.2168623\ttest: 0.2189096\tbestTest: 0.2189096 (78)\ttotal: 10m 47s\tremaining: 2m 52s\n",
      "79: learn: 0.2167971\ttest: 0.2188825\tbestTest: 0.2188825 (79)\ttotal: 10m 55s\tremaining: 2m 43s\n",
      "80: learn: 0.216779\ttest: 0.2188778\tbestTest: 0.2188778 (80)\ttotal: 11m 4s\tremaining: 2m 35s\n",
      "81: learn: 0.2167457\ttest: 0.2188593\tbestTest: 0.2188593 (81)\ttotal: 11m 12s\tremaining: 2m 27s\n",
      "82: learn: 0.2166948\ttest: 0.218851\tbestTest: 0.218851 (82)\ttotal: 11m 20s\tremaining: 2m 19s\n",
      "83: learn: 0.2166405\ttest: 0.2188465\tbestTest: 0.2188465 (83)\ttotal: 11m 28s\tremaining: 2m 11s\n",
      "84: learn: 0.2165944\ttest: 0.218844\tbestTest: 0.218844 (84)\ttotal: 11m 36s\tremaining: 2m 2s\n",
      "85: learn: 0.2165471\ttest: 0.2188361\tbestTest: 0.2188361 (85)\ttotal: 11m 45s\tremaining: 1m 54s\n",
      "86: learn: 0.2164923\ttest: 0.218825\tbestTest: 0.218825 (86)\ttotal: 11m 53s\tremaining: 1m 46s\n",
      "87: learn: 0.2164501\ttest: 0.2188191\tbestTest: 0.2188191 (87)\ttotal: 12m 2s\tremaining: 1m 38s\n",
      "88: learn: 0.2164185\ttest: 0.2188189\tbestTest: 0.2188189 (88)\ttotal: 12m 10s\tremaining: 1m 30s\n",
      "89: learn: 0.2163553\ttest: 0.218807\tbestTest: 0.218807 (89)\ttotal: 12m 17s\tremaining: 1m 21s\n",
      "90: learn: 0.2163339\ttest: 0.2188073\tbestTest: 0.218807 (89)\ttotal: 12m 26s\tremaining: 1m 13s\n",
      "91: learn: 0.2163169\ttest: 0.2188052\tbestTest: 0.2188052 (91)\ttotal: 12m 34s\tremaining: 1m 5s\n",
      "92: learn: 0.2162908\ttest: 0.2188022\tbestTest: 0.2188022 (92)\ttotal: 12m 43s\tremaining: 57.5s\n",
      "93: learn: 0.2162378\ttest: 0.2188058\tbestTest: 0.2188022 (92)\ttotal: 12m 51s\tremaining: 49.2s\n",
      "94: learn: 0.2161907\ttest: 0.2188105\tbestTest: 0.2188022 (92)\ttotal: 12m 59s\tremaining: 41s\n",
      "95: learn: 0.2161716\ttest: 0.2188043\tbestTest: 0.2188022 (92)\ttotal: 13m 7s\tremaining: 32.8s\n",
      "96: learn: 0.2161363\ttest: 0.2188011\tbestTest: 0.2188011 (96)\ttotal: 13m 15s\tremaining: 24.6s\n",
      "97: learn: 0.2161065\ttest: 0.2187911\tbestTest: 0.2187911 (97)\ttotal: 13m 22s\tremaining: 16.4s\n",
      "98: learn: 0.2160741\ttest: 0.2187874\tbestTest: 0.2187874 (98)\ttotal: 13m 30s\tremaining: 8.19s\n",
      "99: learn: 0.2160359\ttest: 0.2187879\tbestTest: 0.2187874 (98)\ttotal: 13m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.218787402\n",
      "bestIteration = 98\n",
      "\n",
      "Shrink model to first 99 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_2\n",
      "2018-03-15 03:52:26.768902\n",
      "train time given below\n",
      "0:17:05.809614\n",
      "2018-03-15 03:52:26.809827\n",
      "2018-03-15 03:52:26.813591\n",
      "GINI ISIT = 0.517779659176\n",
      "2018-03-15 03:54:04.020346\n",
      "GINI OSIT = 0.497869421183\n",
      "2018-03-15 03:54:45.260970\n",
      "GINI OSOT = 0.451159151452\n",
      "2018-03-15 03:54:57.930659\n",
      "2018-03-15 03:54:57.932910\n",
      "loop run time\n",
      "0:19:36.973881\n",
      "bagging temperature = 5\n",
      "2018-03-15 03:54:57.934615\n",
      "model train start\n",
      "2018-03-15 03:54:57.934840\n",
      "0: learn: 0.4067814\ttest: 0.4065584\tbestTest: 0.4065584 (0)\ttotal: 8.37s\tremaining: 13m 48s\n",
      "1: learn: 0.3013854\ttest: 0.3010199\tbestTest: 0.3010199 (1)\ttotal: 17.7s\tremaining: 14m 25s\n",
      "2: learn: 0.2600438\ttest: 0.2595214\tbestTest: 0.2595214 (2)\ttotal: 26.3s\tremaining: 14m 10s\n",
      "3: learn: 0.2414876\ttest: 0.2408788\tbestTest: 0.2408788 (3)\ttotal: 35.1s\tremaining: 14m 3s\n",
      "4: learn: 0.233265\ttest: 0.2326376\tbestTest: 0.2326376 (4)\ttotal: 43.7s\tremaining: 13m 51s\n",
      "5: learn: 0.2292425\ttest: 0.2285919\tbestTest: 0.2285919 (5)\ttotal: 52.8s\tremaining: 13m 46s\n",
      "6: learn: 0.226708\ttest: 0.226041\tbestTest: 0.226041 (6)\ttotal: 1m 1s\tremaining: 13m 32s\n",
      "7: learn: 0.2256344\ttest: 0.2249598\tbestTest: 0.2249598 (7)\ttotal: 1m 10s\tremaining: 13m 32s\n",
      "8: learn: 0.2248279\ttest: 0.224177\tbestTest: 0.224177 (8)\ttotal: 1m 19s\tremaining: 13m 23s\n",
      "9: learn: 0.2241016\ttest: 0.2234832\tbestTest: 0.2234832 (9)\ttotal: 1m 28s\tremaining: 13m 15s\n",
      "10: learn: 0.2235364\ttest: 0.2229255\tbestTest: 0.2229255 (10)\ttotal: 1m 37s\tremaining: 13m 11s\n",
      "11: learn: 0.2232561\ttest: 0.2226826\tbestTest: 0.2226826 (11)\ttotal: 1m 47s\tremaining: 13m 4s\n",
      "12: learn: 0.2230067\ttest: 0.2224885\tbestTest: 0.2224885 (12)\ttotal: 1m 55s\tremaining: 12m 52s\n",
      "13: learn: 0.2226956\ttest: 0.2222367\tbestTest: 0.2222367 (13)\ttotal: 2m 3s\tremaining: 12m 39s\n",
      "14: learn: 0.2224582\ttest: 0.2220337\tbestTest: 0.2220337 (14)\ttotal: 2m 11s\tremaining: 12m 26s\n",
      "15: learn: 0.2222989\ttest: 0.2219204\tbestTest: 0.2219204 (15)\ttotal: 2m 21s\tremaining: 12m 22s\n",
      "16: learn: 0.2221506\ttest: 0.2218013\tbestTest: 0.2218013 (16)\ttotal: 2m 30s\tremaining: 12m 14s\n",
      "17: learn: 0.2220277\ttest: 0.2217381\tbestTest: 0.2217381 (17)\ttotal: 2m 38s\tremaining: 12m 3s\n",
      "18: learn: 0.221882\ttest: 0.2216221\tbestTest: 0.2216221 (18)\ttotal: 2m 49s\tremaining: 12m\n",
      "19: learn: 0.2217846\ttest: 0.2215504\tbestTest: 0.2215504 (19)\ttotal: 2m 57s\tremaining: 11m 49s\n",
      "20: learn: 0.2216043\ttest: 0.2214454\tbestTest: 0.2214454 (20)\ttotal: 3m 5s\tremaining: 11m 36s\n",
      "21: learn: 0.2215332\ttest: 0.2213916\tbestTest: 0.2213916 (21)\ttotal: 3m 14s\tremaining: 11m 28s\n",
      "22: learn: 0.2214257\ttest: 0.2213166\tbestTest: 0.2213166 (22)\ttotal: 3m 23s\tremaining: 11m 20s\n",
      "23: learn: 0.2213137\ttest: 0.2212487\tbestTest: 0.2212487 (23)\ttotal: 3m 32s\tremaining: 11m 13s\n",
      "24: learn: 0.2212315\ttest: 0.2212036\tbestTest: 0.2212036 (24)\ttotal: 3m 40s\tremaining: 11m 1s\n",
      "25: learn: 0.2210235\ttest: 0.221048\tbestTest: 0.221048 (25)\ttotal: 3m 48s\tremaining: 10m 50s\n",
      "26: learn: 0.2209338\ttest: 0.2210166\tbestTest: 0.2210166 (26)\ttotal: 3m 57s\tremaining: 10m 42s\n",
      "27: learn: 0.2208546\ttest: 0.220964\tbestTest: 0.220964 (27)\ttotal: 4m 7s\tremaining: 10m 35s\n",
      "28: learn: 0.2208144\ttest: 0.2209437\tbestTest: 0.2209437 (28)\ttotal: 4m 16s\tremaining: 10m 26s\n",
      "29: learn: 0.2207434\ttest: 0.2209056\tbestTest: 0.2209056 (29)\ttotal: 4m 24s\tremaining: 10m 18s\n",
      "30: learn: 0.2206591\ttest: 0.2208669\tbestTest: 0.2208669 (30)\ttotal: 4m 34s\tremaining: 10m 10s\n",
      "31: learn: 0.2205843\ttest: 0.2208319\tbestTest: 0.2208319 (31)\ttotal: 4m 42s\tremaining: 10m 1s\n",
      "32: learn: 0.2205071\ttest: 0.2207888\tbestTest: 0.2207888 (32)\ttotal: 4m 51s\tremaining: 9m 51s\n",
      "33: learn: 0.2204724\ttest: 0.2207746\tbestTest: 0.2207746 (33)\ttotal: 4m 59s\tremaining: 9m 42s\n",
      "34: learn: 0.2203997\ttest: 0.2207226\tbestTest: 0.2207226 (34)\ttotal: 5m 8s\tremaining: 9m 32s\n",
      "35: learn: 0.2203736\ttest: 0.2207058\tbestTest: 0.2207058 (35)\ttotal: 5m 17s\tremaining: 9m 23s\n",
      "36: learn: 0.2203045\ttest: 0.2206762\tbestTest: 0.2206762 (36)\ttotal: 5m 25s\tremaining: 9m 14s\n",
      "37: learn: 0.2202526\ttest: 0.220665\tbestTest: 0.220665 (37)\ttotal: 5m 35s\tremaining: 9m 7s\n",
      "38: learn: 0.2201994\ttest: 0.2206501\tbestTest: 0.2206501 (38)\ttotal: 5m 43s\tremaining: 8m 57s\n",
      "39: learn: 0.2200475\ttest: 0.2205441\tbestTest: 0.2205441 (39)\ttotal: 5m 52s\tremaining: 8m 49s\n",
      "40: learn: 0.2200241\ttest: 0.2205425\tbestTest: 0.2205425 (40)\ttotal: 6m 1s\tremaining: 8m 40s\n",
      "41: learn: 0.2199497\ttest: 0.220503\tbestTest: 0.220503 (41)\ttotal: 6m 10s\tremaining: 8m 31s\n",
      "42: learn: 0.2199152\ttest: 0.2204917\tbestTest: 0.2204917 (42)\ttotal: 6m 19s\tremaining: 8m 22s\n",
      "43: learn: 0.2198511\ttest: 0.2204669\tbestTest: 0.2204669 (43)\ttotal: 6m 27s\tremaining: 8m 13s\n",
      "44: learn: 0.2198068\ttest: 0.2204506\tbestTest: 0.2204506 (44)\ttotal: 6m 35s\tremaining: 8m 3s\n",
      "45: learn: 0.2197863\ttest: 0.2204501\tbestTest: 0.2204501 (45)\ttotal: 6m 44s\tremaining: 7m 55s\n",
      "46: learn: 0.2197544\ttest: 0.22044\tbestTest: 0.22044 (46)\ttotal: 6m 54s\tremaining: 7m 47s\n",
      "47: learn: 0.2197084\ttest: 0.2204142\tbestTest: 0.2204142 (47)\ttotal: 7m 3s\tremaining: 7m 38s\n",
      "48: learn: 0.2196794\ttest: 0.2203934\tbestTest: 0.2203934 (48)\ttotal: 7m 11s\tremaining: 7m 29s\n",
      "49: learn: 0.2196234\ttest: 0.2203848\tbestTest: 0.2203848 (49)\ttotal: 7m 20s\tremaining: 7m 20s\n",
      "50: learn: 0.2195898\ttest: 0.2203741\tbestTest: 0.2203741 (50)\ttotal: 7m 29s\tremaining: 7m 11s\n",
      "51: learn: 0.2195092\ttest: 0.220348\tbestTest: 0.220348 (51)\ttotal: 7m 38s\tremaining: 7m 3s\n",
      "52: learn: 0.2194433\ttest: 0.220327\tbestTest: 0.220327 (52)\ttotal: 7m 46s\tremaining: 6m 53s\n",
      "53: learn: 0.2193951\ttest: 0.2203063\tbestTest: 0.2203063 (53)\ttotal: 7m 55s\tremaining: 6m 44s\n",
      "54: learn: 0.2193512\ttest: 0.220298\tbestTest: 0.220298 (54)\ttotal: 8m 3s\tremaining: 6m 35s\n",
      "55: learn: 0.2193183\ttest: 0.220289\tbestTest: 0.220289 (55)\ttotal: 8m 11s\tremaining: 6m 26s\n",
      "56: learn: 0.2192614\ttest: 0.2202688\tbestTest: 0.2202688 (56)\ttotal: 8m 20s\tremaining: 6m 17s\n",
      "57: learn: 0.2192267\ttest: 0.2202575\tbestTest: 0.2202575 (57)\ttotal: 8m 29s\tremaining: 6m 9s\n",
      "58: learn: 0.2191164\ttest: 0.2201867\tbestTest: 0.2201867 (58)\ttotal: 8m 38s\tremaining: 6m\n",
      "59: learn: 0.2190949\ttest: 0.2201833\tbestTest: 0.2201833 (59)\ttotal: 8m 47s\tremaining: 5m 51s\n",
      "60: learn: 0.2190143\ttest: 0.2201385\tbestTest: 0.2201385 (60)\ttotal: 8m 56s\tremaining: 5m 42s\n",
      "61: learn: 0.218977\ttest: 0.2201353\tbestTest: 0.2201353 (61)\ttotal: 9m 4s\tremaining: 5m 33s\n",
      "62: learn: 0.2189296\ttest: 0.2201137\tbestTest: 0.2201137 (62)\ttotal: 9m 14s\tremaining: 5m 25s\n",
      "63: learn: 0.2188877\ttest: 0.2201013\tbestTest: 0.2201013 (63)\ttotal: 9m 22s\tremaining: 5m 16s\n",
      "64: learn: 0.2188541\ttest: 0.2200915\tbestTest: 0.2200915 (64)\ttotal: 9m 32s\tremaining: 5m 8s\n",
      "65: learn: 0.2188042\ttest: 0.220079\tbestTest: 0.220079 (65)\ttotal: 9m 41s\tremaining: 4m 59s\n",
      "66: learn: 0.2187766\ttest: 0.2200756\tbestTest: 0.2200756 (66)\ttotal: 9m 50s\tremaining: 4m 50s\n",
      "67: learn: 0.2187514\ttest: 0.2200711\tbestTest: 0.2200711 (67)\ttotal: 9m 59s\tremaining: 4m 42s\n",
      "68: learn: 0.2187229\ttest: 0.2200662\tbestTest: 0.2200662 (68)\ttotal: 10m 7s\tremaining: 4m 33s\n",
      "69: learn: 0.2186437\ttest: 0.2200203\tbestTest: 0.2200203 (69)\ttotal: 10m 16s\tremaining: 4m 24s\n",
      "70: learn: 0.218611\ttest: 0.2200145\tbestTest: 0.2200145 (70)\ttotal: 10m 24s\tremaining: 4m 15s\n",
      "71: learn: 0.2185698\ttest: 0.2200075\tbestTest: 0.2200075 (71)\ttotal: 10m 32s\tremaining: 4m 6s\n",
      "72: learn: 0.218543\ttest: 0.2199991\tbestTest: 0.2199991 (72)\ttotal: 10m 41s\tremaining: 3m 57s\n",
      "73: learn: 0.2185231\ttest: 0.2199953\tbestTest: 0.2199953 (73)\ttotal: 10m 50s\tremaining: 3m 48s\n",
      "74: learn: 0.2184936\ttest: 0.2199832\tbestTest: 0.2199832 (74)\ttotal: 11m\tremaining: 3m 40s\n",
      "75: learn: 0.2184593\ttest: 0.2199778\tbestTest: 0.2199778 (75)\ttotal: 11m 8s\tremaining: 3m 31s\n",
      "76: learn: 0.2184425\ttest: 0.2199768\tbestTest: 0.2199768 (76)\ttotal: 11m 17s\tremaining: 3m 22s\n",
      "77: learn: 0.2184222\ttest: 0.2199687\tbestTest: 0.2199687 (77)\ttotal: 11m 26s\tremaining: 3m 13s\n",
      "78: learn: 0.2183916\ttest: 0.2199656\tbestTest: 0.2199656 (78)\ttotal: 11m 35s\tremaining: 3m 4s\n",
      "79: learn: 0.2183579\ttest: 0.2199685\tbestTest: 0.2199656 (78)\ttotal: 11m 43s\tremaining: 2m 55s\n",
      "80: learn: 0.2183219\ttest: 0.2199628\tbestTest: 0.2199628 (80)\ttotal: 11m 52s\tremaining: 2m 47s\n",
      "81: learn: 0.2182819\ttest: 0.2199544\tbestTest: 0.2199544 (81)\ttotal: 12m\tremaining: 2m 38s\n",
      "82: learn: 0.2182271\ttest: 0.2199376\tbestTest: 0.2199376 (82)\ttotal: 12m 9s\tremaining: 2m 29s\n",
      "83: learn: 0.218189\ttest: 0.2199328\tbestTest: 0.2199328 (83)\ttotal: 12m 18s\tremaining: 2m 20s\n",
      "84: learn: 0.2181726\ttest: 0.2199317\tbestTest: 0.2199317 (84)\ttotal: 12m 28s\tremaining: 2m 12s\n",
      "85: learn: 0.218134\ttest: 0.2199206\tbestTest: 0.2199206 (85)\ttotal: 12m 36s\tremaining: 2m 3s\n",
      "86: learn: 0.2181101\ttest: 0.2199091\tbestTest: 0.2199091 (86)\ttotal: 12m 46s\tremaining: 1m 54s\n",
      "87: learn: 0.2180911\ttest: 0.2199077\tbestTest: 0.2199077 (87)\ttotal: 12m 56s\tremaining: 1m 45s\n",
      "88: learn: 0.2180362\ttest: 0.2199112\tbestTest: 0.2199077 (87)\ttotal: 13m 4s\tremaining: 1m 37s\n",
      "89: learn: 0.2180104\ttest: 0.2199117\tbestTest: 0.2199077 (87)\ttotal: 13m 13s\tremaining: 1m 28s\n",
      "90: learn: 0.217966\ttest: 0.219895\tbestTest: 0.219895 (90)\ttotal: 13m 23s\tremaining: 1m 19s\n",
      "91: learn: 0.2179322\ttest: 0.2198935\tbestTest: 0.2198935 (91)\ttotal: 13m 32s\tremaining: 1m 10s\n",
      "92: learn: 0.2178981\ttest: 0.2198823\tbestTest: 0.2198823 (92)\ttotal: 13m 41s\tremaining: 1m 1s\n",
      "93: learn: 0.2178709\ttest: 0.219877\tbestTest: 0.219877 (93)\ttotal: 13m 51s\tremaining: 53s\n",
      "94: learn: 0.2178421\ttest: 0.2198778\tbestTest: 0.219877 (93)\ttotal: 13m 59s\tremaining: 44.2s\n",
      "95: learn: 0.2178091\ttest: 0.2198767\tbestTest: 0.2198767 (95)\ttotal: 14m 9s\tremaining: 35.4s\n",
      "96: learn: 0.217769\ttest: 0.2198565\tbestTest: 0.2198565 (96)\ttotal: 14m 18s\tremaining: 26.6s\n",
      "97: learn: 0.2177489\ttest: 0.2198539\tbestTest: 0.2198539 (97)\ttotal: 14m 28s\tremaining: 17.7s\n",
      "98: learn: 0.2177284\ttest: 0.2198506\tbestTest: 0.2198506 (98)\ttotal: 14m 38s\tremaining: 8.87s\n",
      "99: learn: 0.2177042\ttest: 0.2198518\tbestTest: 0.2198506 (98)\ttotal: 14m 47s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2198505981\n",
      "bestIteration = 98\n",
      "\n",
      "Shrink model to first 99 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_5\n",
      "2018-03-15 04:13:18.341627\n",
      "train time given below\n",
      "0:18:20.406787\n",
      "2018-03-15 04:13:18.350254\n",
      "2018-03-15 04:13:18.353658\n",
      "GINI ISIT = 0.503686737982\n",
      "2018-03-15 04:14:57.860564\n",
      "GINI OSIT = 0.488422270408\n",
      "2018-03-15 04:15:39.178347\n",
      "GINI OSOT = 0.438761270073\n",
      "2018-03-15 04:15:51.770958\n",
      "2018-03-15 04:15:51.773118\n",
      "loop run time\n",
      "0:20:53.838501\n",
      "bagging temperature = 10\n",
      "2018-03-15 04:15:51.774785\n",
      "model train start\n",
      "2018-03-15 04:15:51.775014\n",
      "0: learn: 0.4098035\ttest: 0.409624\tbestTest: 0.409624 (0)\ttotal: 9.39s\tremaining: 15m 29s\n",
      "1: learn: 0.3077264\ttest: 0.3073292\tbestTest: 0.3073292 (1)\ttotal: 18s\tremaining: 14m 42s\n",
      "2: learn: 0.2636419\ttest: 0.2631147\tbestTest: 0.2631147 (2)\ttotal: 27s\tremaining: 14m 32s\n",
      "3: learn: 0.2443961\ttest: 0.243836\tbestTest: 0.243836 (3)\ttotal: 35.6s\tremaining: 14m 14s\n",
      "4: learn: 0.2346358\ttest: 0.2340528\tbestTest: 0.2340528 (4)\ttotal: 43.8s\tremaining: 13m 52s\n",
      "5: learn: 0.23067\ttest: 0.2300669\tbestTest: 0.2300669 (5)\ttotal: 53.6s\tremaining: 14m\n",
      "6: learn: 0.2286115\ttest: 0.2279857\tbestTest: 0.2279857 (6)\ttotal: 1m 1s\tremaining: 13m 39s\n",
      "7: learn: 0.2271076\ttest: 0.2265074\tbestTest: 0.2265074 (7)\ttotal: 1m 11s\tremaining: 13m 38s\n",
      "8: learn: 0.2263187\ttest: 0.2257742\tbestTest: 0.2257742 (8)\ttotal: 1m 19s\tremaining: 13m 24s\n",
      "9: learn: 0.2255087\ttest: 0.2249762\tbestTest: 0.2249762 (9)\ttotal: 1m 28s\tremaining: 13m 16s\n",
      "10: learn: 0.2250845\ttest: 0.2245615\tbestTest: 0.2245615 (10)\ttotal: 1m 36s\tremaining: 13m 1s\n",
      "11: learn: 0.2248344\ttest: 0.2243435\tbestTest: 0.2243435 (11)\ttotal: 1m 45s\tremaining: 12m 51s\n",
      "12: learn: 0.2244769\ttest: 0.2240315\tbestTest: 0.2240315 (12)\ttotal: 1m 53s\tremaining: 12m 39s\n",
      "13: learn: 0.224271\ttest: 0.2238493\tbestTest: 0.2238493 (13)\ttotal: 2m 1s\tremaining: 12m 27s\n",
      "14: learn: 0.2240943\ttest: 0.2237097\tbestTest: 0.2237097 (14)\ttotal: 2m 10s\tremaining: 12m 19s\n",
      "15: learn: 0.2239188\ttest: 0.2235733\tbestTest: 0.2235733 (15)\ttotal: 2m 18s\tremaining: 12m 7s\n",
      "16: learn: 0.2236335\ttest: 0.2233277\tbestTest: 0.2233277 (16)\ttotal: 2m 27s\tremaining: 12m 1s\n",
      "17: learn: 0.2235297\ttest: 0.2232537\tbestTest: 0.2232537 (17)\ttotal: 2m 36s\tremaining: 11m 51s\n",
      "18: learn: 0.2232065\ttest: 0.2229671\tbestTest: 0.2229671 (18)\ttotal: 2m 44s\tremaining: 11m 39s\n",
      "19: learn: 0.2230513\ttest: 0.2228482\tbestTest: 0.2228482 (19)\ttotal: 2m 53s\tremaining: 11m 32s\n",
      "20: learn: 0.2228927\ttest: 0.2227218\tbestTest: 0.2227218 (20)\ttotal: 3m 1s\tremaining: 11m 24s\n",
      "21: learn: 0.2228189\ttest: 0.2226652\tbestTest: 0.2226652 (21)\ttotal: 3m 11s\tremaining: 11m 19s\n",
      "22: learn: 0.2226898\ttest: 0.2225843\tbestTest: 0.2225843 (22)\ttotal: 3m 19s\tremaining: 11m 9s\n",
      "23: learn: 0.2225533\ttest: 0.2224947\tbestTest: 0.2224947 (23)\ttotal: 3m 28s\tremaining: 11m\n",
      "24: learn: 0.2224666\ttest: 0.2224269\tbestTest: 0.2224269 (24)\ttotal: 3m 37s\tremaining: 10m 53s\n",
      "25: learn: 0.2223597\ttest: 0.2223454\tbestTest: 0.2223454 (25)\ttotal: 3m 46s\tremaining: 10m 43s\n",
      "26: learn: 0.222214\ttest: 0.2222084\tbestTest: 0.2222084 (26)\ttotal: 3m 55s\tremaining: 10m 36s\n",
      "27: learn: 0.222169\ttest: 0.222184\tbestTest: 0.222184 (27)\ttotal: 4m 4s\tremaining: 10m 29s\n",
      "28: learn: 0.2220084\ttest: 0.2220409\tbestTest: 0.2220409 (28)\ttotal: 4m 13s\tremaining: 10m 21s\n",
      "29: learn: 0.2218945\ttest: 0.2219622\tbestTest: 0.2219622 (29)\ttotal: 4m 22s\tremaining: 10m 12s\n",
      "30: learn: 0.2217559\ttest: 0.2218768\tbestTest: 0.2218768 (30)\ttotal: 4m 30s\tremaining: 10m 2s\n",
      "31: learn: 0.2216551\ttest: 0.2218311\tbestTest: 0.2218311 (31)\ttotal: 4m 39s\tremaining: 9m 53s\n",
      "32: learn: 0.2215866\ttest: 0.2217801\tbestTest: 0.2217801 (32)\ttotal: 4m 48s\tremaining: 9m 46s\n",
      "33: learn: 0.2214858\ttest: 0.2217097\tbestTest: 0.2217097 (33)\ttotal: 4m 57s\tremaining: 9m 38s\n",
      "34: learn: 0.2214317\ttest: 0.2216761\tbestTest: 0.2216761 (34)\ttotal: 5m 7s\tremaining: 9m 30s\n",
      "35: learn: 0.2213124\ttest: 0.2216105\tbestTest: 0.2216105 (35)\ttotal: 5m 16s\tremaining: 9m 22s\n",
      "36: learn: 0.221221\ttest: 0.2215463\tbestTest: 0.2215463 (36)\ttotal: 5m 25s\tremaining: 9m 14s\n",
      "37: learn: 0.2211732\ttest: 0.2215171\tbestTest: 0.2215171 (37)\ttotal: 5m 34s\tremaining: 9m 6s\n",
      "38: learn: 0.2211026\ttest: 0.2214888\tbestTest: 0.2214888 (38)\ttotal: 5m 43s\tremaining: 8m 57s\n",
      "39: learn: 0.2209303\ttest: 0.2213533\tbestTest: 0.2213533 (39)\ttotal: 5m 53s\tremaining: 8m 49s\n",
      "40: learn: 0.2208958\ttest: 0.2213416\tbestTest: 0.2213416 (40)\ttotal: 6m 1s\tremaining: 8m 40s\n",
      "41: learn: 0.220811\ttest: 0.2213179\tbestTest: 0.2213179 (41)\ttotal: 6m 11s\tremaining: 8m 32s\n",
      "42: learn: 0.2207563\ttest: 0.2212975\tbestTest: 0.2212975 (42)\ttotal: 6m 19s\tremaining: 8m 23s\n",
      "43: learn: 0.2207013\ttest: 0.2212666\tbestTest: 0.2212666 (43)\ttotal: 6m 27s\tremaining: 8m 13s\n",
      "44: learn: 0.220615\ttest: 0.2212165\tbestTest: 0.2212165 (44)\ttotal: 6m 35s\tremaining: 8m 3s\n",
      "45: learn: 0.2205445\ttest: 0.221188\tbestTest: 0.221188 (45)\ttotal: 6m 44s\tremaining: 7m 54s\n",
      "46: learn: 0.2205041\ttest: 0.2211735\tbestTest: 0.2211735 (46)\ttotal: 6m 53s\tremaining: 7m 46s\n",
      "47: learn: 0.2204477\ttest: 0.2211457\tbestTest: 0.2211457 (47)\ttotal: 7m 2s\tremaining: 7m 38s\n",
      "48: learn: 0.2203969\ttest: 0.2211261\tbestTest: 0.2211261 (48)\ttotal: 7m 11s\tremaining: 7m 28s\n",
      "49: learn: 0.220341\ttest: 0.2210966\tbestTest: 0.2210966 (49)\ttotal: 7m 20s\tremaining: 7m 20s\n",
      "50: learn: 0.2202996\ttest: 0.2210744\tbestTest: 0.2210744 (50)\ttotal: 7m 28s\tremaining: 7m 10s\n",
      "51: learn: 0.2202724\ttest: 0.2210639\tbestTest: 0.2210639 (51)\ttotal: 7m 38s\tremaining: 7m 3s\n",
      "52: learn: 0.2202438\ttest: 0.2210618\tbestTest: 0.2210618 (52)\ttotal: 7m 48s\tremaining: 6m 55s\n",
      "53: learn: 0.2201453\ttest: 0.2210235\tbestTest: 0.2210235 (53)\ttotal: 7m 57s\tremaining: 6m 46s\n",
      "54: learn: 0.2200353\ttest: 0.2209483\tbestTest: 0.2209483 (54)\ttotal: 8m 6s\tremaining: 6m 37s\n",
      "55: learn: 0.2199689\ttest: 0.2209009\tbestTest: 0.2209009 (55)\ttotal: 8m 14s\tremaining: 6m 28s\n",
      "56: learn: 0.2199195\ttest: 0.2208876\tbestTest: 0.2208876 (56)\ttotal: 8m 23s\tremaining: 6m 19s\n",
      "57: learn: 0.2198557\ttest: 0.2208794\tbestTest: 0.2208794 (57)\ttotal: 8m 32s\tremaining: 6m 10s\n",
      "58: learn: 0.2198304\ttest: 0.2208716\tbestTest: 0.2208716 (58)\ttotal: 8m 40s\tremaining: 6m 1s\n",
      "59: learn: 0.2197263\ttest: 0.2207963\tbestTest: 0.2207963 (59)\ttotal: 8m 49s\tremaining: 5m 52s\n",
      "60: learn: 0.219676\ttest: 0.2207714\tbestTest: 0.2207714 (60)\ttotal: 8m 58s\tremaining: 5m 44s\n",
      "61: learn: 0.2196494\ttest: 0.2207584\tbestTest: 0.2207584 (61)\ttotal: 9m 7s\tremaining: 5m 35s\n",
      "62: learn: 0.2196039\ttest: 0.2207428\tbestTest: 0.2207428 (62)\ttotal: 9m 15s\tremaining: 5m 26s\n",
      "63: learn: 0.2195705\ttest: 0.2207303\tbestTest: 0.2207303 (63)\ttotal: 9m 25s\tremaining: 5m 17s\n",
      "64: learn: 0.219542\ttest: 0.2207218\tbestTest: 0.2207218 (64)\ttotal: 9m 33s\tremaining: 5m 8s\n",
      "65: learn: 0.2194918\ttest: 0.220711\tbestTest: 0.220711 (65)\ttotal: 9m 42s\tremaining: 5m\n",
      "66: learn: 0.2194241\ttest: 0.2206764\tbestTest: 0.2206764 (66)\ttotal: 9m 50s\tremaining: 4m 50s\n",
      "67: learn: 0.2193953\ttest: 0.2206724\tbestTest: 0.2206724 (67)\ttotal: 9m 59s\tremaining: 4m 42s\n",
      "68: learn: 0.2193449\ttest: 0.2206681\tbestTest: 0.2206681 (68)\ttotal: 10m 7s\tremaining: 4m 32s\n",
      "69: learn: 0.2193064\ttest: 0.2206529\tbestTest: 0.2206529 (69)\ttotal: 10m 16s\tremaining: 4m 24s\n",
      "70: learn: 0.2192718\ttest: 0.2206439\tbestTest: 0.2206439 (70)\ttotal: 10m 25s\tremaining: 4m 15s\n",
      "71: learn: 0.2192063\ttest: 0.2206293\tbestTest: 0.2206293 (71)\ttotal: 10m 34s\tremaining: 4m 6s\n",
      "72: learn: 0.219155\ttest: 0.220623\tbestTest: 0.220623 (72)\ttotal: 10m 43s\tremaining: 3m 57s\n",
      "73: learn: 0.2191161\ttest: 0.2206183\tbestTest: 0.2206183 (73)\ttotal: 10m 51s\tremaining: 3m 48s\n",
      "74: learn: 0.2190915\ttest: 0.2206157\tbestTest: 0.2206157 (74)\ttotal: 11m\tremaining: 3m 40s\n",
      "75: learn: 0.2190116\ttest: 0.2205706\tbestTest: 0.2205706 (75)\ttotal: 11m 9s\tremaining: 3m 31s\n",
      "76: learn: 0.2189567\ttest: 0.2205665\tbestTest: 0.2205665 (76)\ttotal: 11m 19s\tremaining: 3m 22s\n",
      "77: learn: 0.2189164\ttest: 0.2205576\tbestTest: 0.2205576 (77)\ttotal: 11m 28s\tremaining: 3m 14s\n",
      "78: learn: 0.2188786\ttest: 0.2205465\tbestTest: 0.2205465 (78)\ttotal: 11m 37s\tremaining: 3m 5s\n",
      "79: learn: 0.2188344\ttest: 0.2205246\tbestTest: 0.2205246 (79)\ttotal: 11m 45s\tremaining: 2m 56s\n",
      "80: learn: 0.2187942\ttest: 0.2205065\tbestTest: 0.2205065 (80)\ttotal: 11m 54s\tremaining: 2m 47s\n",
      "81: learn: 0.2187125\ttest: 0.2204697\tbestTest: 0.2204697 (81)\ttotal: 12m 2s\tremaining: 2m 38s\n",
      "82: learn: 0.2186702\ttest: 0.2204637\tbestTest: 0.2204637 (82)\ttotal: 12m 11s\tremaining: 2m 29s\n",
      "83: learn: 0.2186377\ttest: 0.2204582\tbestTest: 0.2204582 (83)\ttotal: 12m 20s\tremaining: 2m 20s\n",
      "84: learn: 0.2186054\ttest: 0.2204443\tbestTest: 0.2204443 (84)\ttotal: 12m 29s\tremaining: 2m 12s\n",
      "85: learn: 0.2185906\ttest: 0.2204421\tbestTest: 0.2204421 (85)\ttotal: 12m 39s\tremaining: 2m 3s\n",
      "86: learn: 0.2185514\ttest: 0.2204293\tbestTest: 0.2204293 (86)\ttotal: 12m 47s\tremaining: 1m 54s\n",
      "87: learn: 0.2185262\ttest: 0.2204295\tbestTest: 0.2204293 (86)\ttotal: 12m 56s\tremaining: 1m 45s\n",
      "88: learn: 0.2184864\ttest: 0.2204208\tbestTest: 0.2204208 (88)\ttotal: 13m 4s\tremaining: 1m 36s\n",
      "89: learn: 0.2184468\ttest: 0.2204171\tbestTest: 0.2204171 (89)\ttotal: 13m 12s\tremaining: 1m 28s\n",
      "90: learn: 0.2183929\ttest: 0.2203989\tbestTest: 0.2203989 (90)\ttotal: 13m 22s\tremaining: 1m 19s\n",
      "91: learn: 0.218372\ttest: 0.2203982\tbestTest: 0.2203982 (91)\ttotal: 13m 30s\tremaining: 1m 10s\n",
      "92: learn: 0.2183598\ttest: 0.2204001\tbestTest: 0.2203982 (91)\ttotal: 13m 39s\tremaining: 1m 1s\n",
      "93: learn: 0.2183163\ttest: 0.2203968\tbestTest: 0.2203968 (93)\ttotal: 13m 48s\tremaining: 52.9s\n",
      "94: learn: 0.2182949\ttest: 0.2203927\tbestTest: 0.2203927 (94)\ttotal: 13m 57s\tremaining: 44.1s\n",
      "95: learn: 0.2182458\ttest: 0.2203853\tbestTest: 0.2203853 (95)\ttotal: 14m 6s\tremaining: 35.3s\n",
      "96: learn: 0.2182078\ttest: 0.2203813\tbestTest: 0.2203813 (96)\ttotal: 14m 15s\tremaining: 26.4s\n",
      "97: learn: 0.2181522\ttest: 0.220368\tbestTest: 0.220368 (97)\ttotal: 14m 23s\tremaining: 17.6s\n",
      "98: learn: 0.2181166\ttest: 0.2203672\tbestTest: 0.2203672 (98)\ttotal: 14m 32s\tremaining: 8.81s\n",
      "99: learn: 0.218077\ttest: 0.2203631\tbestTest: 0.2203631 (99)\ttotal: 14m 41s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2203631011\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "read5\n",
      "model_w3_100T_rsm_0.85_learn_rate_0.3_depth_10_l2_reg_3_num_split_16_cat_split_16_bag_temp_10\n",
      "2018-03-15 04:34:00.841006\n",
      "train time given below\n",
      "0:18:09.065992\n",
      "2018-03-15 04:34:00.887709\n",
      "2018-03-15 04:34:00.891292\n",
      "GINI ISIT = 0.500941613264\n",
      "2018-03-15 04:35:42.689962\n",
      "GINI OSIT = 0.483913277253\n",
      "2018-03-15 04:36:25.906293\n",
      "GINI OSOT = 0.428592813213\n",
      "2018-03-15 04:36:38.134278\n",
      "2018-03-15 04:36:38.136336\n",
      "loop run time\n",
      "0:20:46.361550\n",
      "bagging temperature = 100\n",
      "2018-03-15 04:36:38.137937\n",
      "model train start\n",
      "2018-03-15 04:36:38.138197\n",
      "0: learn: 0.4290819\ttest: 0.4288239\tbestTest: 0.4288239 (0)\ttotal: 1.68s\tremaining: 2m 46s\n",
      "1: learn: 0.3243974\ttest: 0.3239588\tbestTest: 0.3239588 (1)\ttotal: 3.37s\tremaining: 2m 44s\n",
      "2: learn: 0.2817061\ttest: 0.281141\tbestTest: 0.281141 (2)\ttotal: 4.85s\tremaining: 2m 36s\n",
      "3: learn: 0.2634987\ttest: 0.2628452\tbestTest: 0.2628452 (3)\ttotal: 6.3s\tremaining: 2m 31s\n",
      "4: learn: 0.2554249\ttest: 0.2547095\tbestTest: 0.2547095 (4)\ttotal: 7.77s\tremaining: 2m 27s\n",
      "5: learn: 0.251738\ttest: 0.2509792\tbestTest: 0.2509792 (5)\ttotal: 9.16s\tremaining: 2m 23s\n",
      "6: learn: 0.2500185\ttest: 0.2492293\tbestTest: 0.2492293 (6)\ttotal: 10.6s\tremaining: 2m 20s\n",
      "7: learn: 0.2492045\ttest: 0.2483941\tbestTest: 0.2483941 (7)\ttotal: 12.1s\tremaining: 2m 19s\n",
      "8: learn: 0.2488152\ttest: 0.2479899\tbestTest: 0.2479899 (8)\ttotal: 13.6s\tremaining: 2m 17s\n",
      "9: learn: 0.2486276\ttest: 0.247792\tbestTest: 0.247792 (9)\ttotal: 15s\tremaining: 2m 15s\n",
      "10: learn: 0.2485368\ttest: 0.2476938\tbestTest: 0.2476938 (10)\ttotal: 16.5s\tremaining: 2m 13s\n",
      "11: learn: 0.2484927\ttest: 0.2476446\tbestTest: 0.2476446 (11)\ttotal: 18.2s\tremaining: 2m 13s\n",
      "12: learn: 0.2484712\ttest: 0.2476195\tbestTest: 0.2476195 (12)\ttotal: 19.6s\tremaining: 2m 11s\n",
      "13: learn: 0.2484607\ttest: 0.2476065\tbestTest: 0.2476065 (13)\ttotal: 21.1s\tremaining: 2m 9s\n",
      "14: learn: 0.2484555\ttest: 0.2475996\tbestTest: 0.2475996 (14)\ttotal: 22.5s\tremaining: 2m 7s\n",
      "15: learn: 0.248453\ttest: 0.2475959\tbestTest: 0.2475959 (15)\ttotal: 23.9s\tremaining: 2m 5s\n",
      "16: learn: 0.2484518\ttest: 0.2475938\tbestTest: 0.2475938 (16)\ttotal: 25.3s\tremaining: 2m 3s\n",
      "17: learn: 0.2484512\ttest: 0.2475926\tbestTest: 0.2475926 (17)\ttotal: 26.8s\tremaining: 2m 1s\n",
      "18: learn: 0.2484509\ttest: 0.2475919\tbestTest: 0.2475919 (18)\ttotal: 28.2s\tremaining: 2m\n",
      "19: learn: 0.2484508\ttest: 0.2475915\tbestTest: 0.2475915 (19)\ttotal: 29.7s\tremaining: 1m 58s\n",
      "20: learn: 0.2484507\ttest: 0.2475912\tbestTest: 0.2475912 (20)\ttotal: 31.2s\tremaining: 1m 57s\n",
      "21: learn: 0.2484507\ttest: 0.247591\tbestTest: 0.247591 (21)\ttotal: 32.6s\tremaining: 1m 55s\n",
      "22: learn: 0.2484506\ttest: 0.2475909\tbestTest: 0.2475909 (22)\ttotal: 34.1s\tremaining: 1m 54s\n",
      "23: learn: 0.2484506\ttest: 0.2475908\tbestTest: 0.2475908 (23)\ttotal: 35.6s\tremaining: 1m 52s\n",
      "24: learn: 0.2484506\ttest: 0.2475908\tbestTest: 0.2475908 (24)\ttotal: 37.1s\tremaining: 1m 51s\n",
      "25: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (25)\ttotal: 38.6s\tremaining: 1m 49s\n",
      "26: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (26)\ttotal: 40s\tremaining: 1m 48s\n",
      "27: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (27)\ttotal: 41.5s\tremaining: 1m 46s\n",
      "28: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (28)\ttotal: 43s\tremaining: 1m 45s\n",
      "29: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (29)\ttotal: 44.4s\tremaining: 1m 43s\n",
      "30: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (30)\ttotal: 45.8s\tremaining: 1m 42s\n",
      "31: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (31)\ttotal: 47.2s\tremaining: 1m 40s\n",
      "32: learn: 0.2484506\ttest: 0.2475907\tbestTest: 0.2475907 (32)\ttotal: 48.7s\tremaining: 1m 38s\n",
      "33: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (33)\ttotal: 50.1s\tremaining: 1m 37s\n",
      "34: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (34)\ttotal: 51.6s\tremaining: 1m 35s\n",
      "35: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (35)\ttotal: 53s\tremaining: 1m 34s\n",
      "36: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (36)\ttotal: 54.4s\tremaining: 1m 32s\n",
      "37: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (37)\ttotal: 55.8s\tremaining: 1m 31s\n",
      "38: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (38)\ttotal: 57.3s\tremaining: 1m 29s\n",
      "39: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (39)\ttotal: 58.7s\tremaining: 1m 28s\n",
      "40: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (40)\ttotal: 1m\tremaining: 1m 26s\n",
      "41: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (41)\ttotal: 1m 1s\tremaining: 1m 24s\n",
      "42: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (42)\ttotal: 1m 3s\tremaining: 1m 23s\n",
      "43: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (43)\ttotal: 1m 4s\tremaining: 1m 21s\n",
      "44: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (44)\ttotal: 1m 5s\tremaining: 1m 20s\n",
      "45: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (45)\ttotal: 1m 7s\tremaining: 1m 18s\n",
      "46: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (46)\ttotal: 1m 8s\tremaining: 1m 17s\n",
      "47: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (47)\ttotal: 1m 10s\tremaining: 1m 16s\n",
      "48: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (48)\ttotal: 1m 11s\tremaining: 1m 14s\n",
      "49: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (49)\ttotal: 1m 13s\tremaining: 1m 13s\n",
      "50: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (50)\ttotal: 1m 14s\tremaining: 1m 11s\n",
      "51: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (51)\ttotal: 1m 15s\tremaining: 1m 10s\n",
      "52: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (52)\ttotal: 1m 17s\tremaining: 1m 8s\n",
      "53: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (53)\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "54: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (54)\ttotal: 1m 20s\tremaining: 1m 5s\n",
      "55: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (55)\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "56: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (55)\ttotal: 1m 23s\tremaining: 1m 2s\n",
      "57: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (57)\ttotal: 1m 24s\tremaining: 1m 1s\n",
      "58: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (58)\ttotal: 1m 26s\tremaining: 59.8s\n",
      "59: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (58)\ttotal: 1m 27s\tremaining: 58.4s\n",
      "60: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (60)\ttotal: 1m 28s\tremaining: 56.9s\n",
      "61: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (61)\ttotal: 1m 30s\tremaining: 55.4s\n",
      "62: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (61)\ttotal: 1m 31s\tremaining: 54s\n",
      "63: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (61)\ttotal: 1m 33s\tremaining: 52.5s\n",
      "64: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 34s\tremaining: 51s\n",
      "65: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 36s\tremaining: 49.6s\n",
      "66: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 37s\tremaining: 48.1s\n",
      "67: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 39s\tremaining: 46.7s\n",
      "68: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 40s\tremaining: 45.2s\n",
      "69: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 41s\tremaining: 43.7s\n",
      "70: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 43s\tremaining: 42.2s\n",
      "71: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (64)\ttotal: 1m 44s\tremaining: 40.8s\n",
      "72: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 46s\tremaining: 39.3s\n",
      "73: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 47s\tremaining: 37.8s\n",
      "74: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 49s\tremaining: 36.4s\n",
      "75: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 50s\tremaining: 34.9s\n",
      "76: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 52s\tremaining: 33.5s\n",
      "77: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 53s\tremaining: 32s\n",
      "78: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 54s\tremaining: 30.6s\n",
      "79: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 56s\tremaining: 29.1s\n",
      "80: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 57s\tremaining: 27.7s\n",
      "81: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 1m 59s\tremaining: 26.2s\n",
      "82: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 2m\tremaining: 24.7s\n",
      "83: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 2m 2s\tremaining: 23.3s\n",
      "84: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 2m 3s\tremaining: 21.8s\n",
      "85: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 2m 5s\tremaining: 20.4s\n",
      "86: learn: 0.2484506\ttest: 0.2475906\tbestTest: 0.2475906 (72)\ttotal: 2m 6s\tremaining: 18.9s\n",
      "87: "
     ]
    }
   ],
   "source": [
    "#optimize bagging temperature\n",
    "\n",
    "for bag_temp in bag_temp_pv:\n",
    "    \n",
    "    print('bagging temperature = ' + str(bag_temp))\n",
    "    \n",
    "    result_df_temp = pd.DataFrame(data=None,columns=result_col_list)\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    model_t = catboost_run(X_train = X_train100,\n",
    "                           y_train = y_train,\n",
    "                           X_val = X_val100,\n",
    "                           y_val = y_val,\n",
    "                           X_test = X_test100,\n",
    "                           y_test = y_test,\n",
    "                           cat_indices = cat_indices100,\n",
    "                           n_tr = n_tree,\n",
    "                           rsm = rsm_opt,\n",
    "                           lrn_rt = lrn_rt_opt,\n",
    "                           dep = dep_opt,\n",
    "                           l2_reg = l2_reg_opt,\n",
    "                           num_split = num_split_opt,\n",
    "                           cat_split = cat_split_opt,\n",
    "                           bag_temp = bag_temp)\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'n_tree'] = n_tree\n",
    "    result_df_temp.loc[0,'rsm'] = rsm_opt\n",
    "    result_df_temp.loc[0,'learning_rate'] = lrn_rt_opt\n",
    "    result_df_temp.loc[0,'depth'] = dep_opt\n",
    "    result_df_temp.loc[0,'l2_regularization'] = l2_reg_opt\n",
    "    result_df_temp.loc[0,'numerical_split'] = num_split_opt\n",
    "    result_df_temp.loc[0,'categorical_split'] = cat_split_opt\n",
    "    result_df_temp.loc[0,'bagging_temperature'] = bag_temp\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_train100)[:,1]\n",
    "    gini_isit = gini_catboost(predict_prob, y_train)\n",
    "    print(\"GINI ISIT = \" + str(gini_isit))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_val100)[:,1]\n",
    "    gini_osit = gini_catboost(predict_prob, y_val)\n",
    "    print(\"GINI OSIT = \" + str(gini_osit))\n",
    "\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    predict_prob = model_t.predict_proba(X_test100)[:,1]\n",
    "    gini_osot = gini_catboost(predict_prob, y_test)\n",
    "    print(\"GINI OSOT = \" + str(gini_osot))\n",
    "    \n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    result_df_temp.loc[0,'ISIT_GINI'] = gini_isit\n",
    "    result_df_temp.loc[0,'OSIT_GINI'] = gini_osit\n",
    "    result_df_temp.loc[0,'OSOT_GINI'] = gini_osot\n",
    "    \n",
    "    results_df = results_df.append(result_df_temp)\n",
    "    \n",
    "    t2 = datetime.datetime.now()\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"loop run time\")\n",
    "    print(t2-t1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>rsm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>depth</th>\n",
       "      <th>l2_regularization</th>\n",
       "      <th>numerical_split</th>\n",
       "      <th>categorical_split</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>ISIT_GINI</th>\n",
       "      <th>OSIT_GINI</th>\n",
       "      <th>OSOT_GINI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455218</td>\n",
       "      <td>0.456686</td>\n",
       "      <td>0.4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455099</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.41027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455106</td>\n",
       "      <td>0.456588</td>\n",
       "      <td>0.410701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454778</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.411099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454004</td>\n",
       "      <td>0.455345</td>\n",
       "      <td>0.407067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455664</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>0.410218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455663</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.411056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455678</td>\n",
       "      <td>0.456834</td>\n",
       "      <td>0.41085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.45837</td>\n",
       "      <td>0.413166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455057</td>\n",
       "      <td>0.456448</td>\n",
       "      <td>0.41194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451849</td>\n",
       "      <td>0.453623</td>\n",
       "      <td>0.402904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>0.45484</td>\n",
       "      <td>0.407005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455322</td>\n",
       "      <td>0.456847</td>\n",
       "      <td>0.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.454388</td>\n",
       "      <td>0.405824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45513</td>\n",
       "      <td>0.456311</td>\n",
       "      <td>0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454684</td>\n",
       "      <td>0.456024</td>\n",
       "      <td>0.408098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455045</td>\n",
       "      <td>0.456244</td>\n",
       "      <td>0.40867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45336</td>\n",
       "      <td>0.454692</td>\n",
       "      <td>0.408261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454922</td>\n",
       "      <td>0.456109</td>\n",
       "      <td>0.410751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456208</td>\n",
       "      <td>0.457545</td>\n",
       "      <td>0.41235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454801</td>\n",
       "      <td>0.456263</td>\n",
       "      <td>0.411622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45617</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.411126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.457679</td>\n",
       "      <td>0.409276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.457325</td>\n",
       "      <td>0.411554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441066</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>0.396312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.450992</td>\n",
       "      <td>0.404413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45655</td>\n",
       "      <td>0.457718</td>\n",
       "      <td>0.408875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460658</td>\n",
       "      <td>0.461646</td>\n",
       "      <td>0.416653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>0.465669</td>\n",
       "      <td>0.41762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468306</td>\n",
       "      <td>0.468324</td>\n",
       "      <td>0.417121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451027</td>\n",
       "      <td>0.451405</td>\n",
       "      <td>0.400855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46271</td>\n",
       "      <td>0.462658</td>\n",
       "      <td>0.418592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472581</td>\n",
       "      <td>0.471884</td>\n",
       "      <td>0.421361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484078</td>\n",
       "      <td>0.481967</td>\n",
       "      <td>0.434897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.075</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493039</td>\n",
       "      <td>0.488949</td>\n",
       "      <td>0.445385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.498417</td>\n",
       "      <td>0.492692</td>\n",
       "      <td>0.431242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.125</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503328</td>\n",
       "      <td>0.496473</td>\n",
       "      <td>0.44277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506916</td>\n",
       "      <td>0.497736</td>\n",
       "      <td>0.42221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51677</td>\n",
       "      <td>0.500368</td>\n",
       "      <td>0.429062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515282</td>\n",
       "      <td>0.497004</td>\n",
       "      <td>0.413381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508283</td>\n",
       "      <td>0.493476</td>\n",
       "      <td>0.426477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499103</td>\n",
       "      <td>0.485731</td>\n",
       "      <td>0.414978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337505</td>\n",
       "      <td>0.338444</td>\n",
       "      <td>0.276346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337505</td>\n",
       "      <td>0.338444</td>\n",
       "      <td>0.276346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513646</td>\n",
       "      <td>0.500913</td>\n",
       "      <td>0.454186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.512746</td>\n",
       "      <td>0.501339</td>\n",
       "      <td>0.430891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.514459</td>\n",
       "      <td>0.501477</td>\n",
       "      <td>0.430488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51677</td>\n",
       "      <td>0.500368</td>\n",
       "      <td>0.429062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.51778</td>\n",
       "      <td>0.497869</td>\n",
       "      <td>0.451159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.503687</td>\n",
       "      <td>0.488422</td>\n",
       "      <td>0.438761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500942</td>\n",
       "      <td>0.483913</td>\n",
       "      <td>0.428593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  n_tree   rsm learning_rate depth l2_regularization numerical_split  \\\n",
       "0    100     1          0.03     6                 1             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 5             128   \n",
       "0    100     1          0.03     6                10             128   \n",
       "0    100     1          0.03     6                50             128   \n",
       "0    100     1          0.03     6               100             128   \n",
       "0    100     1          0.03     6                 3               5   \n",
       "0    100     1          0.03     6                 3              10   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              32   \n",
       "0    100     1          0.03     6                 3              64   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             255   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100     1          0.03     6                 3             128   \n",
       "0    100   0.5          0.03     6                 3              16   \n",
       "0    100   0.6          0.03     6                 3              16   \n",
       "0    100   0.7          0.03     6                 3              16   \n",
       "0    100  0.75          0.03     6                 3              16   \n",
       "0    100   0.8          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100   0.9          0.03     6                 3              16   \n",
       "0    100     1          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     4                 3              16   \n",
       "0    100  0.85          0.03     5                 3              16   \n",
       "0    100  0.85          0.03     6                 3              16   \n",
       "0    100  0.85          0.03     7                 3              16   \n",
       "0    100  0.85          0.03     8                 3              16   \n",
       "0    100  0.85          0.03     9                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "0    100  0.85          0.01    10                 3              16   \n",
       "0    100  0.85          0.02    10                 3              16   \n",
       "0    100  0.85          0.03    10                 3              16   \n",
       "0    100  0.85          0.05    10                 3              16   \n",
       "0    100  0.85         0.075    10                 3              16   \n",
       "0    100  0.85           0.1    10                 3              16   \n",
       "0    100  0.85         0.125    10                 3              16   \n",
       "0    100  0.85          0.15    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.5    10                 3              16   \n",
       "0    100  0.85          0.75    10                 3              16   \n",
       "0    100  0.85             1    10                 3              16   \n",
       "0    100  0.85           1.5    10                 3              16   \n",
       "0    100  0.85             2    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "0    100  0.85           0.3    10                 3              16   \n",
       "\n",
       "  categorical_split bagging_temperature ISIT_GINI OSIT_GINI OSOT_GINI  \n",
       "0                16                   1  0.455218  0.456686    0.4102  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455099  0.456474   0.41027  \n",
       "0                16                   1  0.455106  0.456588  0.410701  \n",
       "0                16                   1  0.454778    0.4563  0.411099  \n",
       "0                16                   1  0.454004  0.455345  0.407067  \n",
       "0                16                   1  0.455664  0.456603  0.410218  \n",
       "0                16                   1  0.455663  0.456817  0.411056  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.455678  0.456834   0.41085  \n",
       "0                16                   1  0.456934   0.45837  0.413166  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                16                   1  0.455057  0.456448   0.41194  \n",
       "0                 5                   1  0.451849  0.453623  0.402904  \n",
       "0                10                   1  0.453604   0.45484  0.407005  \n",
       "0                16                   1  0.455322  0.456847  0.411086  \n",
       "0                32                   1  0.453115  0.454388  0.405824  \n",
       "0                64                   1   0.45513  0.456311  0.409631  \n",
       "0               128                   1  0.454684  0.456024  0.408098  \n",
       "0               255                   1  0.455045  0.456244   0.40867  \n",
       "0                16                   1   0.45336  0.454692  0.408261  \n",
       "0                16                   1  0.454922  0.456109  0.410751  \n",
       "0                16                   1  0.456208  0.457545   0.41235  \n",
       "0                16                   1  0.454801  0.456263  0.411622  \n",
       "0                16                   1   0.45617  0.457539  0.411126  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.456422  0.457679  0.409276  \n",
       "0                16                   1  0.456057  0.457325  0.411554  \n",
       "0                16                   1  0.441066  0.442915  0.396312  \n",
       "0                16                   1  0.449438  0.450992  0.404413  \n",
       "0                16                   1   0.45655  0.457718  0.408875  \n",
       "0                16                   1  0.460658  0.461646  0.416653  \n",
       "0                16                   1  0.465061  0.465669   0.41762  \n",
       "0                16                   1  0.468306  0.468324  0.417121  \n",
       "0                16                   1  0.472581  0.471884  0.421361  \n",
       "0                16                   1  0.451027  0.451405  0.400855  \n",
       "0                16                   1   0.46271  0.462658  0.418592  \n",
       "0                16                   1  0.472581  0.471884  0.421361  \n",
       "0                16                   1  0.484078  0.481967  0.434897  \n",
       "0                16                   1  0.493039  0.488949  0.445385  \n",
       "0                16                   1  0.498417  0.492692  0.431242  \n",
       "0                16                   1  0.503328  0.496473   0.44277  \n",
       "0                16                   1  0.506916  0.497736   0.42221  \n",
       "0                16                   1   0.51677  0.500368  0.429062  \n",
       "0                16                   1  0.515282  0.497004  0.413381  \n",
       "0                16                   1  0.508283  0.493476  0.426477  \n",
       "0                16                   1  0.499103  0.485731  0.414978  \n",
       "0                16                   1  0.337505  0.338444  0.276346  \n",
       "0                16                   1  0.337505  0.338444  0.276346  \n",
       "0                16                   0  0.513646  0.500913  0.454186  \n",
       "0                16                 0.1  0.512746  0.501339  0.430891  \n",
       "0                16                 0.5  0.514459  0.501477  0.430488  \n",
       "0                16                   1   0.51677  0.500368  0.429062  \n",
       "0                16                   2   0.51778  0.497869  0.451159  \n",
       "0                16                   5  0.503687  0.488422  0.438761  \n",
       "0                16                  10  0.500942  0.483913  0.428593  \n",
       "0                16                 100         0         0         0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv('catboost_parameter_tuning_results.csv',index=False,header=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bag_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6e03fb607c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbag_temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bag_temp' is not defined"
     ]
    }
   ],
   "source": [
    "bag_temp_opt = 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "projectdetails": {
   "creator_id": "agupt489",
   "notebook_id": "c6a0db2a-bee3-403f-936a-b829e006c25d",
   "notebook_name": "catboost_example_grid_Search.ipynb",
   "prod_sys": "",
   "project_desc": "",
   "project_id": "713ddc7d-9570-44cb-86a9-0e3b3751ac70",
   "project_name": "catboost_test_run",
   "project_status": null,
   "status": "new"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
